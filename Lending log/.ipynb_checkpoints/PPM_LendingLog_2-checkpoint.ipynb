{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10f68cb7",
   "metadata": {},
   "source": [
    "## Lending Event Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115026d",
   "metadata": {},
   "source": [
    "- <b>Processo</b>: Esses dados ilustram as etapas de um processo de solicitação de empréstimo. A partir de uma solicitação inicial de consulta, o processo passa por várias etapas, incluindo verificação de informações e subscrição, culminando na aprovação ou negação do empréstimo. Podem ser necessárias etapas adicionais, como alistamento de co-signatários ou avaliação de garantias. Alguns casos registam uma recusa total de nomeação, indicando a variabilidade do processo, refletindo as diferentes situações de crédito dos requerentes.\n",
    "\n",
    "- <b> Atributos</b>: Os atributos dos registos podem ajudar a identificar influências nos resultados e a detectar discriminação. As características pessoais ('idade', 'cidadão', 'língua alemã' e 'género') e indicadores socioeconómicos ('Anos de Educação' e 'Pontuação de Crédito') podem impactar o processo. Embora 'Anos de Educação' e 'Pontuação de Crédito' possam informar validamente a solvabilidade, 'idade', 'cidadão', 'habilidade linguística' e 'género' não devem influenciar as decisões de empréstimo, garantir que estes atributos são utilizados de forma responsável promove processos de empréstimo equitativos.\n",
    "\n",
    "- <b>Três registros de eventos</b>: os três registos de eventos representam vários graus de discriminação, oferecendo aos investigadores uma oportunidade de explorar as nuances e complexidades que surgem em diversos cenários do mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a592d",
   "metadata": {},
   "source": [
    "| Base | Eventos | Cases | Variantes | Atividades |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| lending_log_high | 58822 | 10000 | 41 | 12 |\n",
    "| lending_log_low | 60746 | 10000 | 31 | 12 |\n",
    "| lending_log_medim | 58668 | 10000 | 33 | 12 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32debc2",
   "metadata": {},
   "source": [
    "- <b>Atributos sensíveis</b>:\n",
    "    - Age\n",
    "    - Citizenship\n",
    "    - German Proficiency\n",
    "    - Gender\n",
    "    - Years of Education\n",
    "    - Score de crédito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75569df8",
   "metadata": {},
   "source": [
    "### Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811138aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\anaconda3\\Lib\\site-packages\\torch\\_functorch\\deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\AIF360.py:339: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\micka\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From C:\\Users\\micka\\AppData\\Local\\Temp\\ipykernel_8960\\618957644.py:24: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pm4py\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "#Biblioteca implementada com funções customizadas\n",
    "# Adicionar o caminho da pasta onde está a biblioteca ao sys.path\n",
    "sys.path.append(os.path.abspath('C:\\\\Users\\\\micka\\\\OneDrive\\\\Documentos\\\\[EACH USP] Doutorado\\\\2. Pesquisa\\\\6. Experimento\\\\3. Predictive Process Monitoring'))\n",
    "from _PythonProcessMining import TraceEncoding\n",
    "from _PythonProcessMining import ResourceEncoding\n",
    "from _PythonProcessMining import DataPrep\n",
    "from _PythonProcessMining import TrainTestSplit\n",
    "from _PythonProcessMining import MachineLearning\n",
    "from _PythonProcessMining import Metrics\n",
    "from _PythonProcessMining import MachineLearninExplanation\n",
    "from _PythonProcessMining import AIF360\n",
    "\n",
    "# Definir seeds para reprodutibilidade\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e4953",
   "metadata": {},
   "source": [
    "### Importar a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3053c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio_log = \"C:\\\\Users\\\\micka\\\\OneDrive\\\\Documentos\\\\[EACH USP] Doutorado\\\\2. Pesquisa\\\\6. Experimento\\\\0. Logs\\\\Lending log\\\\\"\n",
    "diretorio = \".\\\\Lending log\\\\\"\n",
    "name_prefix = 'lending_log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b930eb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254e92722d054424ba00965a69b2a4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10cdecc2f5b84f7ebbee2a7c344ab54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4117f5d4d665403db322a465ba0b9319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da base de dados - High: (58822, 16)\n",
      "Tamanho da base de dados - Medium: (58668, 16)\n",
      "Tamanho da base de dados - Low: (60746, 16)\n"
     ]
    }
   ],
   "source": [
    "log_high = pm4py.read_xes(os.path.join(diretorio_log, f'{name_prefix}_high-xes.gz'))\n",
    "log_medium = pm4py.read_xes(os.path.join(diretorio_log, f'{name_prefix}_medium-xes.gz'))\n",
    "log_low = pm4py.read_xes(os.path.join(diretorio_log, f'{name_prefix}_low-xes.gz'))\n",
    "\n",
    "print(\"Tamanho da base de dados - High:\", log_high.shape)\n",
    "print(\"Tamanho da base de dados - Medium:\", log_medium.shape)\n",
    "print(\"Tamanho da base de dados - Low:\", log_low.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ba666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_high.to_csv(f'{name_prefix}_high-csv.csv')\n",
    "log_medium.to_csv(f'{name_prefix}_medium-csv.csv')\n",
    "log_low.to_csv(f'{name_prefix}_low-csv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e495b9",
   "metadata": {},
   "source": [
    "### Preparação da base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c381ce01",
   "metadata": {},
   "source": [
    "<b>Resultado do case</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32e2cc",
   "metadata": {},
   "source": [
    "Adicionamos uma coluna de \"Resultado\" à base de dados:\n",
    "- Última atividade realizada no case;\n",
    "- Definir se o resultado é positivo ou negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f8c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_determine_result(df):\n",
    "    # Ordena o DataFrame por ID do caso e timestamp para garantir a ordem dos eventos\n",
    "    df = df.sort_values(by=['case:concept:name', 'time:timestamp'])\n",
    "\n",
    "    # Identifica o último evento de cada caso\n",
    "    last_events = df.groupby('case:concept:name').last().reset_index()\n",
    "\n",
    "    # Função interna para determinar o resultado baseado no último evento\n",
    "    def df_aux_determine_result(event):\n",
    "        if event == 'Sign Loan Agreement':\n",
    "            return 'Positive'\n",
    "        elif event == 'Application Rejected':\n",
    "            return 'Negative'\n",
    "        elif event == 'Loan Denied':\n",
    "            return 'Negative'\n",
    "        elif event == 'Appointment Denied':\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Undefined'  # para casos que não terminam com um desses eventos\n",
    "\n",
    "    # Aplica a função para determinar o resultado de cada caso\n",
    "    last_events['Resultado'] = last_events['concept:name'].apply(df_aux_determine_result)\n",
    "\n",
    "    # Merge o resultado de volta ao DataFrame original\n",
    "    df = df.merge(last_events[['case:concept:name', 'Resultado']], on='case:concept:name', how='left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746d727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_high = def_determine_result(log_high)\n",
    "df_log_medium = def_determine_result(log_medium)\n",
    "df_log_low = def_determine_result(log_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5cfda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_descriptive_results(df):\n",
    "    # Parte 1: Eliminar duplicidade de caso\n",
    "    df_unico = df.drop_duplicates(subset='case:concept:name', keep='first')\n",
    "    \n",
    "    # Parte 2: Calcular o % de registros com 'Resultado' igual a 1\n",
    "    total_registros = len(df_unico)  # Total de registros após eliminar duplicidades\n",
    "    registros_resultado = len(df_unico[df_unico['Resultado'] == 'Positive'])  # Registros com Resultado == 1\n",
    "    percentual_resultado = (registros_resultado / total_registros) * 100  # Cálculo do percentual\n",
    "    \n",
    "    return percentual_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20dafa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentual de registros com 'Resultado' positivo - High: 26.27%\n",
      "Percentual de registros com 'Resultado' positivo - Medium: 29.85%\n",
      "Percentual de registros com 'Resultado' positivo - Low: 32.72%\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentual de registros com 'Resultado' positivo - High: {:.2f}%\".format(def_descriptive_results(df_log_high)))\n",
    "print(\"Percentual de registros com 'Resultado' positivo - Medium: {:.2f}%\".format(def_descriptive_results(df_log_medium)))\n",
    "print(\"Percentual de registros com 'Resultado' positivo - Low: {:.2f}%\".format(def_descriptive_results(df_log_low)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e0d904",
   "metadata": {},
   "source": [
    "<b> Variável Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "350b5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a nova coluna 'Target' mapeando 'Negativo' para 0 e 'Positivo' para 1\n",
    "df_log_high['Target'] = df_log_high['Resultado'].replace({'Negative': 0, 'Positive': 1})\n",
    "df_log_medium['Target'] = df_log_medium['Resultado'].replace({'Negative': 0, 'Positive': 1})\n",
    "df_log_low['Target'] = df_log_low['Resultado'].replace({'Negative': 0, 'Positive': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e27a760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da base de dados - High: (58822, 18)\n",
      "Tamanho da base de dados - Medium: (58668, 18)\n",
      "Tamanho da base de dados - Low: (60746, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho da base de dados - High:\", df_log_high.shape)\n",
    "print(\"Tamanho da base de dados - Medium:\", df_log_medium.shape)\n",
    "print(\"Tamanho da base de dados - Low:\", df_log_low.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd414bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>% Protected = 1</th>\n",
       "      <td>30.01%</td>\n",
       "      <td>20.12%</td>\n",
       "      <td>9.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% Protected = 1 &amp; Target = 1</th>\n",
       "      <td>1.66%</td>\n",
       "      <td>2.42%</td>\n",
       "      <td>2.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic Parity</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Target = 0</th>\n",
       "      <td>7373</td>\n",
       "      <td>7015</td>\n",
       "      <td>6728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Target = 1</th>\n",
       "      <td>2627</td>\n",
       "      <td>2985</td>\n",
       "      <td>3272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                High  Medium    Low\n",
       "% Protected = 1               30.01%  20.12%  9.74%\n",
       "% Protected = 1 & Target = 1   1.66%   2.42%  2.03%\n",
       "Demographic Parity              0.30    0.22   0.13\n",
       "Disparate Impact                0.16    0.35   0.61\n",
       "Total                          10000   10000  10000\n",
       "Total Target = 0                7373    7015   6728\n",
       "Total Target = 1                2627    2985   3272"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protected_attribute = 'case:protected'\n",
    "outcome_attribute = 'Target'\n",
    "privileged_group = 0\n",
    "unprivileged_group = 1\n",
    "\n",
    "\n",
    "# Aplicar a função de resumo para cada base\n",
    "summary_high = TrainTestSplit.Descriptive(df_log_high, \"High\", outcome_attribute, protected_attribute, privileged_group, unprivileged_group)\n",
    "summary_medium = TrainTestSplit.Descriptive(df_log_medium, \"Medium\", outcome_attribute, protected_attribute, privileged_group, unprivileged_group)\n",
    "summary_low = TrainTestSplit.Descriptive(df_log_low, \"Low\", outcome_attribute, protected_attribute, privileged_group, unprivileged_group)\n",
    "\n",
    "# Combinar todas as tabelas de resumo em uma única tabela\n",
    "df_summary_table = pd.concat([summary_high, summary_medium, summary_low], axis=1)\n",
    "df_summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10bbb36",
   "metadata": {},
   "source": [
    "<b> Data de início e data de fim do case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582fe03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_TimestampStartEnd(df):\n",
    "    # Converter 'time:timestamp' para datetime\n",
    "    df['time:timestamp'] = pd.to_datetime(df['time:timestamp'])\n",
    "\n",
    "    # Calcular a data de início do case\n",
    "    df['case_start_date'] = df.groupby('case:concept:name')['time:timestamp'].transform('min')\n",
    "\n",
    "    # Calcular a data de fim do case\n",
    "    df['case_end_date'] = df.groupby('case:concept:name')['time:timestamp'].transform('max')\n",
    "\n",
    "    # Calcular o lead time em dias\n",
    "    df['lead_time_days'] = (df['case_end_date'] - df['case_start_date']).dt.days\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "756a8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar datas de início e fim do case\n",
    "df_log_high = def_TimestampStartEnd(df_log_high)\n",
    "df_log_medium = def_TimestampStartEnd(df_log_medium)\n",
    "df_log_low = def_TimestampStartEnd(df_log_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8152b2ac",
   "metadata": {},
   "source": [
    "<b>Atributos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a90b24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idade\n",
    "    #Infância (0-12 anos)\n",
    "    #Adolescência (13-17 anos)\n",
    "    #Juventude (18-24 anos)\n",
    "    #Adulto jovem (25-34 anos)\n",
    "    #Adulto de meia-idade (35-49 anos)\n",
    "    #Pré-aposentadoria (50-64 anos)\n",
    "    #Aposentado (65 anos ou mais)\n",
    "    \n",
    "# Categorizar idade\n",
    "bins = [0, 12, 17, 24, 34, 49, 64, float('inf')]\n",
    "labels = ['Childhood', 'Adolescence', 'Youth', 'Young Adult', 'Middle-Aged Adult', 'Pre-Retirement', 'Retired']\n",
    "\n",
    "#Aplicar as bases de dados\n",
    "df_log_high['age'] = pd.cut(df_log_high['case:age'], bins=bins, labels=labels, right=False)\n",
    "df_log_medium['age'] = pd.cut(df_log_medium['case:age'], bins=bins, labels=labels, right=False)\n",
    "df_log_low['age'] = pd.cut(df_log_low['case:age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6efa8bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anos de educação\n",
    "    #Sem educação formal (0 anos)\n",
    "    #Educação fundamental (1-8 anos)\n",
    "    #Educação média (9-12 anos)\n",
    "    #Educação superior (13 - 16 anos)\n",
    "    #Pós-graduação (+17 anos)\n",
    "\n",
    "bins = [-1, 0, 8, 12, 16, float('inf')]\n",
    "labels = ['No Formal Education', 'Elementary Education', 'Secondary Education', 'Higher Education', 'Postgraduate Education']\n",
    "\n",
    "#Aplicar as bases de dados\n",
    "df_log_high['yearsOfEducation'] = pd.cut(df_log_high['case:yearsOfEducation'], bins=bins, labels=labels, right=False)\n",
    "df_log_medium['yearsOfEducation'] = pd.cut(df_log_medium['case:yearsOfEducation'], bins=bins, labels=labels, right=False)\n",
    "df_log_low['yearsOfEducation'] = pd.cut(df_log_low['case:yearsOfEducation'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b179a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit score\n",
    "    #Low (0-20)\n",
    "    #Moderate (21-40)\n",
    "    #Medium (41-60)\n",
    "    #High (61-80)\n",
    "    #Excellent (81-100)\n",
    "\n",
    "bins = [0, 20, 40, 60, 80, 100]\n",
    "labels = ['Low', 'Moderate', 'Medium', 'High', 'Excellent']\n",
    "\n",
    "#Aplicar as bases de dados\n",
    "df_log_high['CreditScore'] = pd.cut(df_log_high['case:CreditScore'], bins=bins, labels=labels, right=False)\n",
    "df_log_medium['CreditScore'] = pd.cut(df_log_medium['case:CreditScore'], bins=bins, labels=labels, right=False)\n",
    "df_log_low['CreditScore'] = pd.cut(df_log_low['case:CreditScore'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4378af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerar dummies das categorizações\n",
    "df_log_high = pd.get_dummies(df_log_high, columns=['age', 'yearsOfEducation', 'CreditScore'])\n",
    "df_log_medium = pd.get_dummies(df_log_medium, columns=['age', 'yearsOfEducation', 'CreditScore'])\n",
    "df_log_low = pd.get_dummies(df_log_low, columns=['age', 'yearsOfEducation', 'CreditScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ab3da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo valores booleanos true/false para 1/0\n",
    "bool_columns = ['age_Childhood', 'age_Adolescence', 'age_Youth', 'age_Young Adult', 'age_Middle-Aged Adult', 'age_Pre-Retirement', 'age_Retired',\n",
    "                'yearsOfEducation_No Formal Education', 'yearsOfEducation_Elementary Education', 'yearsOfEducation_Secondary Education', 'yearsOfEducation_Higher Education', 'yearsOfEducation_Postgraduate Education',\n",
    "                'CreditScore_Low', 'CreditScore_Moderate', 'CreditScore_Medium', 'CreditScore_High', 'CreditScore_Excellent'\n",
    "               ]\n",
    "\n",
    "df_log_high[bool_columns] = df_log_high[bool_columns].astype(int)\n",
    "df_log_medium[bool_columns] = df_log_medium[bool_columns].astype(int)\n",
    "df_log_low[bool_columns] = df_log_low[bool_columns].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71acffe8",
   "metadata": {},
   "source": [
    "<b>Atributos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fd5d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo valores booleanos true/false para 1/0\n",
    "atributos_categoricos = ['case:german speaking', 'case:gender', 'case:citizen', 'case:protected']\n",
    "\n",
    "df_log_high[atributos_categoricos] = df_log_high[atributos_categoricos].astype(int)\n",
    "df_log_medium[atributos_categoricos] = df_log_medium[atributos_categoricos].astype(int)\n",
    "df_log_low[atributos_categoricos] = df_log_low[atributos_categoricos].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15021a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrair base tratada\n",
    "df_log_high.to_csv(f'{name_prefix}_high-prep.csv')\n",
    "df_log_medium.to_csv(f'{name_prefix}_medium-prep.csv')\n",
    "df_log_low.to_csv(f'{name_prefix}_low-prep.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e77ac",
   "metadata": {},
   "source": [
    "<b> Trace encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed267c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_high_transitions, log_high_all_transitions = TraceEncoding.ActivityTransitionsOneHotEncoding(df_log_high, var_id = 'case:case', var_activity = 'activity', var_timestamp = 'time:timestamp')\n",
    "log_medium_transitions, log_medium_all_transitions = TraceEncoding.ActivityTransitionsOneHotEncoding(df_log_medium, var_id = 'case:case', var_activity = 'activity', var_timestamp = 'time:timestamp')\n",
    "log_low_transitions, log_low_all_transitions = TraceEncoding.ActivityTransitionsOneHotEncoding(df_log_low, var_id = 'case:case', var_activity = 'activity', var_timestamp = 'time:timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b29ca51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trazer o encoding das transições para o dataframe\n",
    "df_log_high = df_log_high.merge(log_high_transitions, on = 'case:case')\n",
    "df_log_medium = df_log_medium.merge(log_medium_transitions, on = 'case:case')\n",
    "df_log_low = df_log_low.merge(log_low_transitions, on = 'case:case')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fec2ba",
   "metadata": {},
   "source": [
    "<b> Resource encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "204a1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_high_resources, log_high_all_resources = ResourceEncoding.ResourceTransitionsOneHotEncoding(df_log_high, var_id = 'case:case', var_resource = 'resource', var_timestamp = 'time:timestamp')\n",
    "log_medium_resources, log_medium_all_resources = ResourceEncoding.ResourceTransitionsOneHotEncoding(df_log_medium, var_id = 'case:case', var_resource = 'resource', var_timestamp = 'time:timestamp')\n",
    "log_low_resources, log_low_all_resources = ResourceEncoding.ResourceTransitionsOneHotEncoding(df_log_low, var_id = 'case:case', var_resource = 'resource', var_timestamp = 'time:timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1d7a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trazer o encoding das transições para o dataframe\n",
    "df_log_high = df_log_high.merge(log_high_resources, on = 'case:case')\n",
    "df_log_medium = df_log_medium.merge(log_medium_resources, on = 'case:case')\n",
    "df_log_low = df_log_low.merge(log_low_resources, on = 'case:case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "497aa3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mater apenas um registro por case\n",
    "df_log_high = df_log_high.drop_duplicates(subset=['case:case']).drop(columns=['activity', 'resource', 'time', 'concept:name', 'time:timestamp', '@@index', 'case:concept:name', 'case:@@case_index'])\n",
    "df_log_medium = df_log_medium.drop_duplicates(subset=['case:case']).drop(columns=['activity', 'resource', 'time', 'concept:name', 'time:timestamp', '@@index', 'case:concept:name', 'case:@@case_index'])\n",
    "df_log_low = df_log_low.drop_duplicates(subset=['case:case']).drop(columns=['activity', 'resource', 'time', 'concept:name', 'time:timestamp', '@@index', 'case:concept:name', 'case:@@case_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b9183c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrair base tratada\n",
    "log_high.to_csv(f'{name_prefix}_high-tratada.csv')\n",
    "log_medium.to_csv(f'{name_prefix}_medium-tratada.csv')\n",
    "log_low.to_csv(f'{name_prefix}_low-tratada.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d940c8c",
   "metadata": {},
   "source": [
    "<b>Eliminar Duplicidades/conflitos de casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c246ee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Loan Officer 3 -> Loan Officer 4', 'Make Visit to Assess Colatteral -> Request Co-Signer On Loan', 'Resource 1 -> Hotline', 'Resource 1 -> Online System', 'Resource 5 -> Hotline', 'yearsOfEducation_Secondary Education', 'Resource 2 -> Resource 2', 'case:citizen', 'Loan Officer 5 -> Loan Officer 3', 'CreditScore_Medio', 'Loan Officer 4 -> Loan Officer 5', 'Resource 3 -> Resource 1', 'Loan Officer 5 -> Loan Officer 2', 'Online System -> Loan Officer 4', 'Make Visit to Assess Colatteral -> Make Visit to Assess Colatteral', 'Loan Officer 2 -> Loan Officer 2', 'Loan Officer 1 -> Loan Officer 5', 'Loan Officer 4 -> Loan Officer 2', 'Loan Officer 4 -> Loan Officer 4', 'age_Retired', 'Loan Officer 1 -> Loan Officer 2', 'Request Co-Signer On Loan -> Submit File to Underwriter', 'Hotline -> Resource 3', 'Hotline -> Resource 4', 'age_Young Adult', 'Resource 4 -> Resource 3', 'Resource 1 -> Resource 3', 'Loan Officer 3 -> Loan Officer 1', 'Loan Officer 1 -> Loan Officer 1', 'Loan Officer 4 -> Loan Officer 1', 'Online System -> Loan Officer 5', 'yearsOfEducation_Higher Education', 'Resource 4 -> Resource 5', 'Resource 3 -> Resource 3', 'Resource 5 -> Resource 5', 'Resource 4 -> Resource 2', 'Resource 3 -> Hotline', 'Resource 3 -> Online System', 'Loan Officer 1 -> Loan Officer 4', 'Online System -> Loan Officer 3', 'yearsOfEducation_Elementary Education', 'Loan Officer 5 -> Loan Officer 5', 'Resource 1 -> Resource 5', 'case:gender', 'Resource 3 -> Resource 4', 'Loan Officer 3 -> Loan Officer 2', 'Resource 2 -> Resource 5', 'Resource 5 -> Resource 2', 'Hand In Credit Appliaction -> Verify Borrowers Information', 'Resource 2 -> Resource 4', 'age_Middle-Aged Adult', 'Loan Officer 2 -> Loan Officer 5', 'Resource 1 -> Resource 4', 'Loan Officer 5 -> Loan Officer 4', 'Online System -> Loan Officer 2', 'Loan Officer 4 -> Loan Officer 3', 'Resource 1 -> Resource 1', 'Request Co-Signer On Loan -> Make Visit to Assess Colatteral', 'Resource 2 -> Resource 1', 'Hotline -> Resource 5', 'case:protected', 'CreditScore_Moderado', 'Resource 5 -> Online System', 'Resource 3 -> Resource 2', 'Resource 5 -> Resource 1', 'CreditScore_Excelente', 'Resource 4 -> Online System', 'Verify Borrowers Information -> Make Visit to Assess Colatteral', 'Verify Borrowers Information -> skipped_examination', 'Hotline -> Online System', 'Hotline -> Resource 1', 'Loan Officer 3 -> Loan Officer 5', 'Resource 2 -> Online System', 'Loan Officer 5 -> Loan Officer 1', 'Hotline -> Resource 2', 'Set Appointment -> Hand In Credit Appliaction', 'CreditScore_Alto', 'Resource 5 -> Resource 3', 'Loan Officer 2 -> Loan Officer 1', 'Online System -> Loan Officer 1', 'yearsOfEducation_Postgraduate Education', 'Loan Officer 1 -> Loan Officer 3', 'Resource 4 -> Hotline', 'Target', 'case:german speaking', 'Request Appointment -> Set Appointment', 'Make Visit to Assess Colatteral -> Submit File to Underwriter', 'Resource 5 -> Resource 4', 'age_Pre-Retirement', 'Verify Borrowers Information -> Request Co-Signer On Loan', 'Loan Officer 2 -> Loan Officer 3', 'Hotline -> Hotline', 'Verify Borrowers Information -> Submit File to Underwriter', 'Loan Officer 2 -> Loan Officer 4', 'Resource 2 -> Resource 3', 'Resource 4 -> Resource 1', 'Resource 1 -> Resource 2', 'Resource 4 -> Resource 4', 'Resource 2 -> Hotline', 'Loan Officer 3 -> Loan Officer 3', 'Resource 3 -> Resource 5']\n"
     ]
    }
   ],
   "source": [
    "#Lista de variáveis que NÃO serão consideradas no modelo\n",
    "exclude_variavel = [\n",
    "             'case:case', \n",
    "             'case_start_date', \n",
    "             'case_end_date', \n",
    "             'lead_time_days', \n",
    "             'Resultado',\n",
    "             #'Target', \n",
    "             #'case:protected',\n",
    "             #'case:german speaking', \n",
    "             #'case:gender', \n",
    "             #'case:citizen',\n",
    "             'case:age', \n",
    "             'age_Childhood',\n",
    "             'age_Adolescence', \n",
    "             'age_Youth', \n",
    "             #'age_Young Adult',\n",
    "             #'age_Middle-Aged Adult', \n",
    "             #'age_Pre-Retirement', \n",
    "             #'age_Retired',\n",
    "             'case:yearsOfEducation',\n",
    "             'yearsOfEducation_No Formal Education',\n",
    "             #'yearsOfEducation_Elementary Education',\n",
    "             #'yearsOfEducation_Secondary Education',\n",
    "             #'yearsOfEducation_Higher Education',\n",
    "             #'yearsOfEducation_Postgraduate Education',\n",
    "             'case:CreditScore', \n",
    "             'CreditScore_Baixo',\n",
    "             #'CreditScore_Moderado', \n",
    "             #'CreditScore_Medio', \n",
    "             #'CreditScore_Alto',\n",
    "             #'CreditScore_Excelente'\n",
    "]\n",
    "\n",
    "#Criar a lista 'variaveis', excluindo as atividades que contenha o resultado do case\n",
    "todas_variaveis = set(df_log_high.columns) | set(df_log_medium.columns) | set(df_log_low.columns)\n",
    "variaveis = [\n",
    "    col for col in todas_variaveis  \n",
    "    if col not in exclude_variavel\n",
    "]\n",
    "\n",
    "print(variaveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5a4797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copia da base para resolver problemas de fragmentação da base\n",
    "df_log_high = df_log_high.copy()\n",
    "df_log_medium = df_log_medium.copy()\n",
    "df_log_low = df_log_low.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffbfcb",
   "metadata": {},
   "source": [
    "Identificar e eliminar registros conflitantes na base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d6e8d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped = df.groupby(variaveis_sem_target)[var_target].nunique().reset_index().copy()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped = df.groupby(variaveis_sem_target)[var_target].nunique().reset_index().copy()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped = df.groupby(variaveis_sem_target)[var_target].nunique().reset_index().copy()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\DataPrep.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_first_records = conflicting_cases.sort_values(var_date).groupby(variaveis_sem_target, as_index=False).first()\n"
     ]
    }
   ],
   "source": [
    "conflicting_groups_high, conflicting_cases_high, df_log_high_cleaned = DataPrep.KeepFirstConflictingCases(df_log_high, variaveis, var_timestamp = 'time:timestamp', var_target = 'Target', var_id = 'case:case', var_date = 'case_start_date')\n",
    "conflicting_groups_medium, conflicting_cases_medium, df_log_medium_cleaned = DataPrep.KeepFirstConflictingCases(df_log_medium, variaveis, var_timestamp = 'time:timestamp', var_target = 'Target', var_id = 'case:case', var_date = 'case_start_date')\n",
    "conflicting_groups_low, conflicting_cases_low, df_log_low_cleaned = DataPrep.KeepFirstConflictingCases(df_log_low, variaveis, var_timestamp = 'time:timestamp', var_target = 'Target', var_id = 'case:case', var_date = 'case_start_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84833549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_high = df_log_high_cleaned.copy()\n",
    "df_log_medium = df_log_medium_cleaned.copy()\n",
    "df_log_low = df_log_low_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58e42af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da base de dados - High: (8953, 114)\n",
      "Tamanho da base de dados - Medium: (9201, 114)\n",
      "Tamanho da base de dados - Low: (9389, 114)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho da base de dados - High:\", df_log_high.shape)\n",
    "print(\"Tamanho da base de dados - Medium:\", df_log_medium.shape)\n",
    "print(\"Tamanho da base de dados - Low:\", df_log_low.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1913963b",
   "metadata": {},
   "source": [
    "Identificar e eliminar duplicidades de registros na base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80544e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar casos duplicados\n",
    "df_log_high_duplicates, df_log_high_merged, df_log_high_cleaned = DataPrep.KeepFirstDuplicateCases(df_log_high, variaveis, var_timestamp = 'time:timestamp', var_target = 'Target', var_id = 'case:case', var_date = 'case_start_date')\n",
    "df_log_medium_duplicates, df_log_medium_merged, df_log_medium_cleaned = DataPrep.KeepFirstDuplicateCases(df_log_medium, variaveis, var_timestamp = 'time:timestamp', var_target = 'Target', var_id = 'case:case', var_date = 'case_start_date')\n",
    "df_log_low_duplicates, df_log_low_merged, df_log_low_cleaned = DataPrep.KeepFirstDuplicateCases(df_log_low, variaveis, var_timestamp = 'time:timestamp', var_target = 'Target', var_id = 'case:case', var_date = 'case_start_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "066aaf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_high = df_log_high_cleaned.copy()\n",
    "df_log_medium = df_log_medium_cleaned.copy()\n",
    "df_log_low = df_log_low_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d83d8415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da base de dados - High: (8802, 114)\n",
      "Tamanho da base de dados - Medium: (9073, 114)\n",
      "Tamanho da base de dados - Low: (9294, 114)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho da base de dados - High:\", df_log_high.shape)\n",
    "print(\"Tamanho da base de dados - Medium:\", df_log_medium.shape)\n",
    "print(\"Tamanho da base de dados - Low:\", df_log_low.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "054b9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrair base tratada\n",
    "df_log_high.to_csv(f'{name_prefix}_high-tratada-semdpl.csv')\n",
    "df_log_medium.to_csv(f'{name_prefix}_medium-tratada-semdpl.csv')\n",
    "df_log_low.to_csv(f'{name_prefix}_low-tratada-semdpl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3686265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>% Protected = 1</th>\n",
       "      <td>26.72%</td>\n",
       "      <td>18.76%</td>\n",
       "      <td>9.37%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% Protected = 1 &amp; Target = 1</th>\n",
       "      <td>1.89%</td>\n",
       "      <td>2.67%</td>\n",
       "      <td>2.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>8802</td>\n",
       "      <td>9073</td>\n",
       "      <td>9294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Target = 0</th>\n",
       "      <td>6240</td>\n",
       "      <td>6156</td>\n",
       "      <td>6070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Target = 1</th>\n",
       "      <td>2562</td>\n",
       "      <td>2917</td>\n",
       "      <td>3224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                High  Medium    Low\n",
       "% Protected = 1               26.72%  18.76%  9.37%\n",
       "% Protected = 1 & Target = 1   1.89%   2.67%  2.17%\n",
       "Disparate Impact                0.19    0.39   0.65\n",
       "Total                           8802    9073   9294\n",
       "Total Target = 0                6240    6156   6070\n",
       "Total Target = 1                2562    2917   3224"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protected_attribute = 'case:protected'\n",
    "outcome_attribute = 'Target'\n",
    "privileged_group = 0\n",
    "unprivileged_group = 1\n",
    "\n",
    "\n",
    "# Aplicar a função de resumo para cada base\n",
    "summary_high = TrainTestSplit.Descriptive(df_log_high, \"High\", outcome_attribute, protected_attribute, privileged_group, unprivileged_group)\n",
    "summary_medium = TrainTestSplit.Descriptive(df_log_medium, \"Medium\", outcome_attribute, protected_attribute, privileged_group, unprivileged_group)\n",
    "summary_low = TrainTestSplit.Descriptive(df_log_low, \"Low\", outcome_attribute, protected_attribute, privileged_group, unprivileged_group)\n",
    "\n",
    "# Combinar todas as tabelas de resumo em uma única tabela\n",
    "df_summary_table = pd.concat([summary_high, summary_medium, summary_low], axis=1)\n",
    "df_summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d00be",
   "metadata": {},
   "source": [
    "<b> Divisão da base em treino/teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de6720d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a divisão entre treino e teste\n",
    "  #Pela data de início do case\n",
    "df_train_high, df_test_high = TrainTestSplit.SplitDataTemporal(df_log_high, test_size=0.3, var_date = 'case_start_date')\n",
    "df_train_medium, df_test_medium = TrainTestSplit.SplitDataTemporal(df_log_medium, test_size=0.3, var_date = 'case_start_date')\n",
    "df_train_low, df_test_low = TrainTestSplit.SplitDataTemporal(df_log_low, test_size=0.3, var_date = 'case_start_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a24d61de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copia dos dataframe para resolver problema de fragmentação\n",
    "df_train_high = df_train_high.copy()\n",
    "df_test_high = df_test_high.copy()\n",
    "df_train_medium = df_train_medium.copy()\n",
    "df_test_medium = df_test_medium.copy()\n",
    "df_train_low = df_train_low.copy()\n",
    "df_test_low = df_test_low.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09368f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High - Train</th>\n",
       "      <th>High - Test</th>\n",
       "      <th>Medium - Train</th>\n",
       "      <th>Medium - Test</th>\n",
       "      <th>Low - Train</th>\n",
       "      <th>Low - Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>6161</td>\n",
       "      <td>2641</td>\n",
       "      <td>6351</td>\n",
       "      <td>2722</td>\n",
       "      <td>6505</td>\n",
       "      <td>2789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% Target = 0</th>\n",
       "      <td>70.56%</td>\n",
       "      <td>71.68%</td>\n",
       "      <td>67.64%</td>\n",
       "      <td>68.33%</td>\n",
       "      <td>64.92%</td>\n",
       "      <td>66.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% Target = 1</th>\n",
       "      <td>29.44%</td>\n",
       "      <td>28.32%</td>\n",
       "      <td>32.36%</td>\n",
       "      <td>31.67%</td>\n",
       "      <td>35.08%</td>\n",
       "      <td>33.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% Protected = 1</th>\n",
       "      <td>26.39%</td>\n",
       "      <td>27.49%</td>\n",
       "      <td>18.53%</td>\n",
       "      <td>19.29%</td>\n",
       "      <td>9.35%</td>\n",
       "      <td>9.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% Protected = 1 &amp; Target = 1</th>\n",
       "      <td>1.92%</td>\n",
       "      <td>1.82%</td>\n",
       "      <td>2.74%</td>\n",
       "      <td>2.50%</td>\n",
       "      <td>2.20%</td>\n",
       "      <td>2.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             High - Train High - Test Medium - Train  \\\n",
       "Total                                6161        2641           6351   \n",
       "% Target = 0                       70.56%      71.68%         67.64%   \n",
       "% Target = 1                       29.44%      28.32%         32.36%   \n",
       "% Protected = 1                    26.39%      27.49%         18.53%   \n",
       "% Protected = 1 & Target = 1        1.92%       1.82%          2.74%   \n",
       "Disparate Impact                     0.19        0.18           0.41   \n",
       "\n",
       "                             Medium - Test Low - Train Low - Test  \n",
       "Total                                 2722        6505       2789  \n",
       "% Target = 0                        68.33%      64.92%     66.22%  \n",
       "% Target = 1                        31.67%      35.08%     33.78%  \n",
       "% Protected = 1                     19.29%       9.35%      9.43%  \n",
       "% Protected = 1 & Target = 1         2.50%       2.20%      2.12%  \n",
       "Disparate Impact                      0.36        0.65       0.64  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protected_attribute = 'case:protected'\n",
    "outcome_attribute = 'Target'\n",
    "privileged_group = 0\n",
    "unprivileged_group = 1\n",
    "\n",
    "\n",
    "# Aplicar a função de resumo para cada base\n",
    "summary_high = TrainTestSplit.DescriptiveTrainTest(df_train_high, df_test_high, \"High\", outcome_attribute, protected_attribute, privileged_group, unprivileged_group)\n",
    "summary_medium = TrainTestSplit.DescriptiveTrainTest(df_train_medium, df_test_medium, \"Medium\", outcome_attribute, protected_attribute, privileged_group, unprivileged_group)\n",
    "summary_low = TrainTestSplit.DescriptiveTrainTest(df_train_low, df_test_low, \"Low\", outcome_attribute, protected_attribute, privileged_group, unprivileged_group)\n",
    "\n",
    "# Combinar todas as tabelas de resumo em uma única tabela\n",
    "df_summary_table = pd.concat([summary_high, summary_medium, summary_low], axis=1)\n",
    "df_summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77016bf2",
   "metadata": {},
   "source": [
    "<b> Definição das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fd89752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover 'Target' da lista de variáveis, caso esteja presente\n",
    "variaveis = [var for var in variaveis if var != 'Target']\n",
    "\n",
    "# Selecionando características e o alvo\n",
    "variaveis_high = [var for var in variaveis if var in df_log_high.columns]\n",
    "X_train_high, y_train_high = df_train_high[variaveis_high], df_train_high['Target']\n",
    "X_test_high, y_test_high = df_test_high[variaveis_high], df_test_high['Target']\n",
    "\n",
    "variaveis_medium = [var for var in variaveis if var in df_log_medium.columns]\n",
    "X_train_medium, y_train_medium = df_train_medium[variaveis_medium], df_train_medium['Target']\n",
    "X_test_medium, y_test_medium = df_test_medium[variaveis_medium], df_test_medium['Target']\n",
    "\n",
    "variaveis_low = [var for var in variaveis if var in df_log_low.columns]\n",
    "X_train_low, y_train_low = df_train_low[variaveis_low], df_train_low['Target']\n",
    "X_test_low, y_test_low = df_test_low[variaveis_low], df_test_low['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cad2b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High: Index([], dtype='object')\n",
      "Medium: Index([], dtype='object')\n",
      "Low: Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Verificar a existência de colunas que NÃO estão no formato numérico\n",
    "print(\"High:\", X_train_high.select_dtypes(exclude=['number']).columns)\n",
    "print(\"Medium:\", X_train_medium.select_dtypes(exclude=['number']).columns)\n",
    "print(\"Low:\", X_train_low.select_dtypes(exclude=['number']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "199c75ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionalidade - High: (6161, 100)\n",
      "Dimensionalidad - Medium: (6351, 100)\n",
      "Dimensionalidad - Low: (6505, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensionalidade - High:\", X_train_high.shape)\n",
    "print(\"Dimensionalidad - Medium:\", X_train_medium.shape)\n",
    "print(\"Dimensionalidad - Low:\", X_train_low.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0c73b4",
   "metadata": {},
   "source": [
    "## Predictive Process Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ec974",
   "metadata": {},
   "source": [
    "### 1. Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bd5bda",
   "metadata": {},
   "source": [
    "<b> Random Florest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2936f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso da função:\n",
    "df_final_high, best_model_high, best_params_high, best_score_high, explanations_high = MachineLearning.RandomFlorestOptuna(X_train_high, y_train_high, X_test_high, y_test_high, df_train_high, df_test_high, num_trials=50)\n",
    "df_final_medium, best_model_medium, best_params_medium, best_score_medium, explanations_medium = MachineLearning.RandomFlorestOptuna(X_train_medium, y_train_medium, X_test_medium, y_test_medium, df_train_medium, df_test_medium, num_trials=50)\n",
    "df_final_low, best_model_low, best_params_low, best_score_low, explanations_low = MachineLearning.RandomFlorestOptuna(X_train_low, y_train_low, X_test_low, y_test_low, df_train_low, df_test_low, num_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "391acd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High - Parâmetros: {'n_estimators': 120, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.8127806499748195}\n",
      "Medium - Parâmetros: {'n_estimators': 51, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6039604456428882}\n",
      "Low - Parâmetros: {'n_estimators': 137, 'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.951424944155355}\n"
     ]
    }
   ],
   "source": [
    "print('High - Parâmetros:', best_params_high)\n",
    "print('Medium - Parâmetros:', best_params_medium)\n",
    "print('Low - Parâmetros:', best_params_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92402b91",
   "metadata": {},
   "source": [
    "Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d99045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas do modelo\n",
    "df_metrics_high = Metrics.ModelMetrics(df_final_high, 'case:protected', 'High', 'Baseline', privileged_group, unprivileged_group)\n",
    "df_metrics_medium = Metrics.ModelMetrics(df_final_medium, 'case:protected', 'Medium', 'Baseline', privileged_group, unprivileged_group)\n",
    "df_metrics_low = Metrics.ModelMetrics(df_final_low, 'case:protected', 'Low', 'Baseline', privileged_group, unprivileged_group)\n",
    "\n",
    "df_metrics = pd.concat([df_metrics_high, df_metrics_medium, df_metrics_low], ignore_index=True)\n",
    "df_metrics.to_excel(f'{name_prefix}_metrics.xlsx', index = False)\n",
    "#df_metrics[df_metrics['Metric'].isin(['Accuracy', 'F1-Score', 'Disparate Impact'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57c3491",
   "metadata": {},
   "source": [
    "Explicação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0e6d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(explanations, feature_names):\n",
    "    \"\"\"\n",
    "    Calcula a importância média das variáveis a partir das explicações LIME.\n",
    "    \"\"\"\n",
    "    feature_importances = np.zeros(len(feature_names))\n",
    "    for explanation in explanations:\n",
    "        for feature, importance in explanation.local_exp[1]:  # 1 é a classe alvo\n",
    "            feature_importances[feature] += importance\n",
    "    feature_importances /= len(explanations)\n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92b731e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance_High</th>\n",
       "      <th>Importance_Medium</th>\n",
       "      <th>Importance_Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; skipped_examination</th>\n",
       "      <td>-0.368307</td>\n",
       "      <td>-0.339685</td>\n",
       "      <td>-0.245108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; Submit File to Underwriter</th>\n",
       "      <td>0.063008</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.026971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case:protected</th>\n",
       "      <td>0.048906</td>\n",
       "      <td>0.156780</td>\n",
       "      <td>0.045870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 4 -&gt; Loan Officer 4</th>\n",
       "      <td>-0.045812</td>\n",
       "      <td>-0.019334</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 3 -&gt; Loan Officer 4</th>\n",
       "      <td>-0.038682</td>\n",
       "      <td>-0.008599</td>\n",
       "      <td>-0.041522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_Retired</th>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>0.011065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource 1 -&gt; Resource 3</th>\n",
       "      <td>-0.000080</td>\n",
       "      <td>0.019335</td>\n",
       "      <td>-0.026734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hand In Credit Appliaction -&gt; Verify Borrowers Information</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Request Appointment -&gt; Set Appointment</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set Appointment -&gt; Hand In Credit Appliaction</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Importance_High  \\\n",
       "Feature                                                               \n",
       "Verify Borrowers Information -> skipped_examina...        -0.368307   \n",
       "Verify Borrowers Information -> Submit File to ...         0.063008   \n",
       "case:protected                                             0.048906   \n",
       "Loan Officer 4 -> Loan Officer 4                          -0.045812   \n",
       "Loan Officer 3 -> Loan Officer 4                          -0.038682   \n",
       "...                                                             ...   \n",
       "age_Retired                                               -0.000208   \n",
       "Resource 1 -> Resource 3                                  -0.000080   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...         0.000000   \n",
       "Request Appointment -> Set Appointment                     0.000000   \n",
       "Set Appointment -> Hand In Credit Appliaction              0.000000   \n",
       "\n",
       "                                                    Importance_Medium  \\\n",
       "Feature                                                                 \n",
       "Verify Borrowers Information -> skipped_examina...          -0.339685   \n",
       "Verify Borrowers Information -> Submit File to ...          -0.000478   \n",
       "case:protected                                               0.156780   \n",
       "Loan Officer 4 -> Loan Officer 4                            -0.019334   \n",
       "Loan Officer 3 -> Loan Officer 4                            -0.008599   \n",
       "...                                                               ...   \n",
       "age_Retired                                                  0.005966   \n",
       "Resource 1 -> Resource 3                                     0.019335   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...           0.000000   \n",
       "Request Appointment -> Set Appointment                       0.000000   \n",
       "Set Appointment -> Hand In Credit Appliaction                0.000000   \n",
       "\n",
       "                                                    Importance_Low  \n",
       "Feature                                                             \n",
       "Verify Borrowers Information -> skipped_examina...       -0.245108  \n",
       "Verify Borrowers Information -> Submit File to ...        0.026971  \n",
       "case:protected                                            0.045870  \n",
       "Loan Officer 4 -> Loan Officer 4                          0.000584  \n",
       "Loan Officer 3 -> Loan Officer 4                         -0.041522  \n",
       "...                                                            ...  \n",
       "age_Retired                                               0.011065  \n",
       "Resource 1 -> Resource 3                                 -0.026734  \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...        0.000000  \n",
       "Request Appointment -> Set Appointment                    0.000000  \n",
       "Set Appointment -> Hand In Credit Appliaction             0.000000  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerar tabelas de importância das variáveis\n",
    "importance_high = get_feature_importance(explanations_high, X_train_high.columns)\n",
    "importance_medium = get_feature_importance(explanations_medium, X_train_medium.columns)\n",
    "importance_low = get_feature_importance(explanations_low, X_train_low.columns)\n",
    "\n",
    "# Criar DataFrames com a importância das variáveis\n",
    "importance_high_df = pd.DataFrame({'Feature': X_train_high.columns, 'Importance_High': importance_high})\n",
    "importance_medium_df = pd.DataFrame({'Feature': X_train_medium.columns, 'Importance_Medium': importance_medium})\n",
    "importance_low_df = pd.DataFrame({'Feature': X_train_low.columns, 'Importance_Low': importance_low})\n",
    "\n",
    "# Realizar o merge dos DataFrames utilizando 'Feature' como chave e preenchendo valores faltantes com NaN\n",
    "importance_df = importance_high_df.merge(importance_medium_df, on='Feature', how='outer').merge(importance_low_df, on='Feature', how='outer')\n",
    "\n",
    "# Ordenar o DataFrame com base no módulo dos valores da coluna 'Importance_High'\n",
    "importance_df['Importance_High_Abs'] = importance_df['Importance_High'].abs()\n",
    "importance_df = importance_df.sort_values(by='Importance_High_Abs', ascending=False)\n",
    "importance_df.drop(columns=['Importance_High_Abs'], inplace=True)\n",
    "\n",
    "# Definir o índice como a coluna 'Feature'\n",
    "importance_df.set_index('Feature', inplace=True)\n",
    "\n",
    "# Salvar o DataFrame como CSV\n",
    "importance_df.to_csv(f'{name_prefix}_baseline_model_lime.csv')\n",
    "\n",
    "# Exibir o DataFrame\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f8d73",
   "metadata": {},
   "source": [
    "### 2. Estratégia para Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee91b60d",
   "metadata": {},
   "source": [
    "<b> 2.1 Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "710da85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso da função:\n",
    "df_final_high, best_model_high, best_params_high, best_score_high, explanations_high = AIF360.PreReweighingRandomFlorestOptuna(X_train_high, y_train_high, X_test_high, y_test_high, df_train_high, df_test_high, protected_attribute, alpha = 0.1, num_trials=50)\n",
    "df_final_medium, best_model_medium, best_params_medium, best_score_medium, explanations_medium = AIF360.PreReweighingRandomFlorestOptuna(X_train_medium, y_train_medium, X_test_medium, y_test_medium, df_train_medium, df_test_medium, protected_attribute, alpha = 0.1, num_trials=50)\n",
    "df_final_low, best_model_low, best_params_low, best_score_low, explanations_low = AIF360.PreReweighingRandomFlorestOptuna(X_train_low, y_train_low, X_test_low, y_test_low, df_train_low, df_test_low, protected_attribute, alpha = 0.1, num_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e784f3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High - Parâmetros: {'n_estimators': 142, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.9635402925192512}\n",
      "Medium - Parâmetros: {'n_estimators': 150, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.8752952047026342}\n",
      "Low - Parâmetros: {'n_estimators': 90, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.9353036739438481}\n"
     ]
    }
   ],
   "source": [
    "print('High - Parâmetros:', best_params_high)\n",
    "print('Medium - Parâmetros:', best_params_medium)\n",
    "print('Low - Parâmetros:', best_params_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf85e79",
   "metadata": {},
   "source": [
    "Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9797d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas do modelo\n",
    "df_metrics_high = Metrics.ModelMetrics(df_final_high, 'case:protected', 'High', 'Preprocessing: Reweighing', privileged_group, unprivileged_group)\n",
    "df_metrics_medium = Metrics.ModelMetrics(df_final_medium, 'case:protected', 'Medium', 'Preprocessing: Reweighing', privileged_group, unprivileged_group)\n",
    "df_metrics_low = Metrics.ModelMetrics(df_final_low, 'case:protected', 'Low', 'Preprocessing: Reweighing', privileged_group, unprivileged_group)\n",
    "\n",
    "df_metrics_Rew = pd.concat([df_metrics_high, df_metrics_medium, df_metrics_low], ignore_index=True)\n",
    "df_metrics = pd.concat([df_metrics, df_metrics_Rew], ignore_index=True)\n",
    "df_metrics.to_excel(f'{name_prefix}_metrics.xlsx', index = False)\n",
    "#df_metrics[df_metrics['Metric'].isin(['Accuracy', 'F1-Score', 'Disparate Impact'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccc4fdf",
   "metadata": {},
   "source": [
    "Explicação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c1bdcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance_High</th>\n",
       "      <th>Importance_Medium</th>\n",
       "      <th>Importance_Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; skipped_examination</th>\n",
       "      <td>-0.257071</td>\n",
       "      <td>-0.309098</td>\n",
       "      <td>-0.205603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 3 -&gt; Loan Officer 4</th>\n",
       "      <td>-0.036114</td>\n",
       "      <td>-0.012571</td>\n",
       "      <td>-0.038151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Make Visit to Assess Colatteral -&gt; Submit File to Underwriter</th>\n",
       "      <td>-0.033984</td>\n",
       "      <td>-0.009857</td>\n",
       "      <td>-0.033239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 4 -&gt; Loan Officer 4</th>\n",
       "      <td>-0.031125</td>\n",
       "      <td>-0.028905</td>\n",
       "      <td>-0.002578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; Make Visit to Assess Colatteral</th>\n",
       "      <td>-0.025164</td>\n",
       "      <td>-0.010037</td>\n",
       "      <td>-0.013649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource 2 -&gt; Resource 3</th>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.001642</td>\n",
       "      <td>0.009262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_Middle-Aged Adult</th>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set Appointment -&gt; Hand In Credit Appliaction</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Request Appointment -&gt; Set Appointment</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hand In Credit Appliaction -&gt; Verify Borrowers Information</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Importance_High  \\\n",
       "Feature                                                               \n",
       "Verify Borrowers Information -> skipped_examina...        -0.257071   \n",
       "Loan Officer 3 -> Loan Officer 4                          -0.036114   \n",
       "Make Visit to Assess Colatteral -> Submit File ...        -0.033984   \n",
       "Loan Officer 4 -> Loan Officer 4                          -0.031125   \n",
       "Verify Borrowers Information -> Make Visit to A...        -0.025164   \n",
       "...                                                             ...   \n",
       "Resource 2 -> Resource 3                                  -0.000028   \n",
       "age_Middle-Aged Adult                                     -0.000010   \n",
       "Set Appointment -> Hand In Credit Appliaction              0.000000   \n",
       "Request Appointment -> Set Appointment                     0.000000   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...         0.000000   \n",
       "\n",
       "                                                    Importance_Medium  \\\n",
       "Feature                                                                 \n",
       "Verify Borrowers Information -> skipped_examina...          -0.309098   \n",
       "Loan Officer 3 -> Loan Officer 4                            -0.012571   \n",
       "Make Visit to Assess Colatteral -> Submit File ...          -0.009857   \n",
       "Loan Officer 4 -> Loan Officer 4                            -0.028905   \n",
       "Verify Borrowers Information -> Make Visit to A...          -0.010037   \n",
       "...                                                               ...   \n",
       "Resource 2 -> Resource 3                                    -0.001642   \n",
       "age_Middle-Aged Adult                                        0.000163   \n",
       "Set Appointment -> Hand In Credit Appliaction                0.000000   \n",
       "Request Appointment -> Set Appointment                       0.000000   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...           0.000000   \n",
       "\n",
       "                                                    Importance_Low  \n",
       "Feature                                                             \n",
       "Verify Borrowers Information -> skipped_examina...       -0.205603  \n",
       "Loan Officer 3 -> Loan Officer 4                         -0.038151  \n",
       "Make Visit to Assess Colatteral -> Submit File ...       -0.033239  \n",
       "Loan Officer 4 -> Loan Officer 4                         -0.002578  \n",
       "Verify Borrowers Information -> Make Visit to A...       -0.013649  \n",
       "...                                                            ...  \n",
       "Resource 2 -> Resource 3                                  0.009262  \n",
       "age_Middle-Aged Adult                                     0.000596  \n",
       "Set Appointment -> Hand In Credit Appliaction             0.000000  \n",
       "Request Appointment -> Set Appointment                    0.000000  \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...        0.000000  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerar tabelas de importância das variáveis\n",
    "importance_high = get_feature_importance(explanations_high, X_train_high.columns)\n",
    "importance_medium = get_feature_importance(explanations_medium, X_train_medium.columns)\n",
    "importance_low = get_feature_importance(explanations_low, X_train_low.columns)\n",
    "\n",
    "# Criar DataFrames com a importância das variáveis\n",
    "importance_high_df = pd.DataFrame({'Feature': X_train_high.columns, 'Importance_High': importance_high})\n",
    "importance_medium_df = pd.DataFrame({'Feature': X_train_medium.columns, 'Importance_Medium': importance_medium})\n",
    "importance_low_df = pd.DataFrame({'Feature': X_train_low.columns, 'Importance_Low': importance_low})\n",
    "\n",
    "# Realizar o merge dos DataFrames utilizando 'Feature' como chave e preenchendo valores faltantes com NaN\n",
    "importance_df = importance_high_df.merge(importance_medium_df, on='Feature', how='outer').merge(importance_low_df, on='Feature', how='outer')\n",
    "\n",
    "# Ordenar o DataFrame com base no módulo dos valores da coluna 'Importance_High'\n",
    "importance_df['Importance_High_Abs'] = importance_df['Importance_High'].abs()\n",
    "importance_df = importance_df.sort_values(by='Importance_High_Abs', ascending=False)\n",
    "importance_df.drop(columns=['Importance_High_Abs'], inplace=True)\n",
    "\n",
    "# Definir o índice como a coluna 'Feature'\n",
    "importance_df.set_index('Feature', inplace=True)\n",
    "\n",
    "# Salvar o DataFrame como CSV\n",
    "importance_df.to_csv(f'{name_prefix}_pre_rew_model_lime.csv')\n",
    "\n",
    "# Exibir o DataFrame\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82ca0d",
   "metadata": {},
   "source": [
    "<b> 2.2 Disparate Impact Remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26a08dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso da função:\n",
    "df_final_high, best_model_high, best_params_high, best_score_high, explanations_high = AIF360.PreDisparateImpactRemoverRandomFlorestOptuna(X_train_high, y_train_high, X_test_high, y_test_high, df_train_high, df_test_high, protected_attribute, alpha = 0.1, num_trials=50)\n",
    "df_final_medium, best_model_medium, best_params_medium, best_score_medium, explanations_medium = AIF360.PreDisparateImpactRemoverRandomFlorestOptuna(X_train_medium, y_train_medium, X_test_medium, y_test_medium, df_train_medium, df_test_medium, protected_attribute, alpha = 0.1, num_trials=50)\n",
    "df_final_low, best_model_low, best_params_low, best_score_low, explanations_low = AIF360.PreDisparateImpactRemoverRandomFlorestOptuna(X_train_low, y_train_low, X_test_low, y_test_low, df_train_low, df_test_low, protected_attribute, alpha = 0.1, num_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "706eb938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High - Parâmetros: {'n_estimators': 53, 'max_depth': 17, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.602087923377874}\n",
      "Medium - Parâmetros: {'n_estimators': 192, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.9237283486106316}\n",
      "Low - Parâmetros: {'n_estimators': 84, 'max_depth': 20, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.8445932431146854}\n"
     ]
    }
   ],
   "source": [
    "print('High - Parâmetros:', best_params_high)\n",
    "print('Medium - Parâmetros:', best_params_medium)\n",
    "print('Low - Parâmetros:', best_params_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da54e5",
   "metadata": {},
   "source": [
    "Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9192ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas do modelo\n",
    "df_metrics_high = Metrics.ModelMetrics(df_final_high, 'case:protected', 'High', 'Preprocessing: Disparate Impact Remover', privileged_group, unprivileged_group)\n",
    "df_metrics_medium = Metrics.ModelMetrics(df_final_medium, 'case:protected', 'Medium', 'Preprocessing: Disparate Impact Remover', privileged_group, unprivileged_group)\n",
    "df_metrics_low = Metrics.ModelMetrics(df_final_low, 'case:protected', 'Low', 'Preprocessing: Disparate Impact Remover', privileged_group, unprivileged_group)\n",
    "\n",
    "df_metrics_Dir = pd.concat([df_metrics_high, df_metrics_medium, df_metrics_low], ignore_index=True)\n",
    "df_metrics = pd.concat([df_metrics, df_metrics_Dir], ignore_index=True)\n",
    "df_metrics.to_excel(f'{name_prefix}_metrics.xlsx', index = False)\n",
    "#df_metrics[df_metrics['Metric'].isin(['Accuracy', 'F1-Score', 'Disparate Impact'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e30f8",
   "metadata": {},
   "source": [
    "Explicação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a65161d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance_High</th>\n",
       "      <th>Importance_Medium</th>\n",
       "      <th>Importance_Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>case:protected</th>\n",
       "      <td>0.041679</td>\n",
       "      <td>0.198763</td>\n",
       "      <td>0.068514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 2 -&gt; Loan Officer 2</th>\n",
       "      <td>-0.029952</td>\n",
       "      <td>-0.012601</td>\n",
       "      <td>0.011771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 4 -&gt; Loan Officer 4</th>\n",
       "      <td>-0.028542</td>\n",
       "      <td>-0.019446</td>\n",
       "      <td>-0.005721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Make Visit to Assess Colatteral -&gt; Make Visit to Assess Colatteral</th>\n",
       "      <td>0.028193</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>0.028822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 4 -&gt; Loan Officer 1</th>\n",
       "      <td>-0.027826</td>\n",
       "      <td>-0.020016</td>\n",
       "      <td>-0.015991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; skipped_examination</th>\n",
       "      <td>0.000119</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource 5 -&gt; Resource 5</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>-0.005830</td>\n",
       "      <td>-0.003670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Request Appointment -&gt; Set Appointment</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hand In Credit Appliaction -&gt; Verify Borrowers Information</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set Appointment -&gt; Hand In Credit Appliaction</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Importance_High  \\\n",
       "Feature                                                               \n",
       "case:protected                                             0.041679   \n",
       "Loan Officer 2 -> Loan Officer 2                          -0.029952   \n",
       "Loan Officer 4 -> Loan Officer 4                          -0.028542   \n",
       "Make Visit to Assess Colatteral -> Make Visit t...         0.028193   \n",
       "Loan Officer 4 -> Loan Officer 1                          -0.027826   \n",
       "...                                                             ...   \n",
       "Verify Borrowers Information -> skipped_examina...         0.000119   \n",
       "Resource 5 -> Resource 5                                   0.000057   \n",
       "Request Appointment -> Set Appointment                     0.000000   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...         0.000000   \n",
       "Set Appointment -> Hand In Credit Appliaction              0.000000   \n",
       "\n",
       "                                                    Importance_Medium  \\\n",
       "Feature                                                                 \n",
       "case:protected                                               0.198763   \n",
       "Loan Officer 2 -> Loan Officer 2                            -0.012601   \n",
       "Loan Officer 4 -> Loan Officer 4                            -0.019446   \n",
       "Make Visit to Assess Colatteral -> Make Visit t...           0.009028   \n",
       "Loan Officer 4 -> Loan Officer 1                            -0.020016   \n",
       "...                                                               ...   \n",
       "Verify Borrowers Information -> skipped_examina...          -0.000029   \n",
       "Resource 5 -> Resource 5                                    -0.005830   \n",
       "Request Appointment -> Set Appointment                       0.000000   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...           0.000000   \n",
       "Set Appointment -> Hand In Credit Appliaction                0.000000   \n",
       "\n",
       "                                                    Importance_Low  \n",
       "Feature                                                             \n",
       "case:protected                                            0.068514  \n",
       "Loan Officer 2 -> Loan Officer 2                          0.011771  \n",
       "Loan Officer 4 -> Loan Officer 4                         -0.005721  \n",
       "Make Visit to Assess Colatteral -> Make Visit t...        0.028822  \n",
       "Loan Officer 4 -> Loan Officer 1                         -0.015991  \n",
       "...                                                            ...  \n",
       "Verify Borrowers Information -> skipped_examina...        0.000301  \n",
       "Resource 5 -> Resource 5                                 -0.003670  \n",
       "Request Appointment -> Set Appointment                    0.000000  \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...        0.000000  \n",
       "Set Appointment -> Hand In Credit Appliaction             0.000000  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerar tabelas de importância das variáveis\n",
    "importance_high = get_feature_importance(explanations_high, X_train_high.columns)\n",
    "importance_medium = get_feature_importance(explanations_medium, X_train_medium.columns)\n",
    "importance_low = get_feature_importance(explanations_low, X_train_low.columns)\n",
    "\n",
    "# Criar DataFrames com a importância das variáveis\n",
    "importance_high_df = pd.DataFrame({'Feature': X_train_high.columns, 'Importance_High': importance_high})\n",
    "importance_medium_df = pd.DataFrame({'Feature': X_train_medium.columns, 'Importance_Medium': importance_medium})\n",
    "importance_low_df = pd.DataFrame({'Feature': X_train_low.columns, 'Importance_Low': importance_low})\n",
    "\n",
    "# Realizar o merge dos DataFrames utilizando 'Feature' como chave e preenchendo valores faltantes com NaN\n",
    "importance_df = importance_high_df.merge(importance_medium_df, on='Feature', how='outer').merge(importance_low_df, on='Feature', how='outer')\n",
    "\n",
    "# Ordenar o DataFrame com base no módulo dos valores da coluna 'Importance_High'\n",
    "importance_df['Importance_High_Abs'] = importance_df['Importance_High'].abs()\n",
    "importance_df = importance_df.sort_values(by='Importance_High_Abs', ascending=False)\n",
    "importance_df.drop(columns=['Importance_High_Abs'], inplace=True)\n",
    "\n",
    "# Definir o índice como a coluna 'Feature'\n",
    "importance_df.set_index('Feature', inplace=True)\n",
    "\n",
    "# Salvar o DataFrame como CSV\n",
    "importance_df.to_csv(f'{name_prefix}_pre_dir_model_lime.csv')\n",
    "\n",
    "# Exibir o DataFrame\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d78aa8",
   "metadata": {},
   "source": [
    "<b> 2.3 Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5fa6179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\micka\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\micka\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:164: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709988; batch adversarial loss: 0.791750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.683922; batch adversarial loss: 0.869057\n",
      "epoch 2; iter: 0; batch classifier loss: 0.644313; batch adversarial loss: 0.778428\n",
      "epoch 3; iter: 0; batch classifier loss: 0.468588; batch adversarial loss: 0.739706\n",
      "epoch 4; iter: 0; batch classifier loss: 0.460634; batch adversarial loss: 0.722741\n",
      "epoch 5; iter: 0; batch classifier loss: 0.481754; batch adversarial loss: 0.657214\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563847; batch adversarial loss: 0.678683\n",
      "epoch 7; iter: 0; batch classifier loss: 0.489799; batch adversarial loss: 0.660316\n",
      "epoch 8; iter: 0; batch classifier loss: 0.475246; batch adversarial loss: 0.637353\n",
      "epoch 9; iter: 0; batch classifier loss: 0.478186; batch adversarial loss: 0.653710\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462703; batch adversarial loss: 0.658661\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573395; batch adversarial loss: 0.613464\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545748; batch adversarial loss: 0.622812\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511235; batch adversarial loss: 0.629914\n",
      "epoch 14; iter: 0; batch classifier loss: 0.485367; batch adversarial loss: 0.611834\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502456; batch adversarial loss: 0.591600\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480652; batch adversarial loss: 0.563958\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497998; batch adversarial loss: 0.594102\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484573; batch adversarial loss: 0.528787\n",
      "epoch 19; iter: 0; batch classifier loss: 0.415776; batch adversarial loss: 0.567384\n",
      "epoch 20; iter: 0; batch classifier loss: 0.421479; batch adversarial loss: 0.604829\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480251; batch adversarial loss: 0.571722\n",
      "epoch 22; iter: 0; batch classifier loss: 0.414256; batch adversarial loss: 0.536211\n",
      "epoch 23; iter: 0; batch classifier loss: 0.455348; batch adversarial loss: 0.514867\n",
      "epoch 24; iter: 0; batch classifier loss: 0.406227; batch adversarial loss: 0.507277\n",
      "epoch 25; iter: 0; batch classifier loss: 0.413369; batch adversarial loss: 0.513556\n",
      "epoch 26; iter: 0; batch classifier loss: 0.372928; batch adversarial loss: 0.580049\n",
      "epoch 27; iter: 0; batch classifier loss: 0.408126; batch adversarial loss: 0.608346\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472371; batch adversarial loss: 0.574835\n",
      "epoch 29; iter: 0; batch classifier loss: 0.424133; batch adversarial loss: 0.564714\n",
      "epoch 30; iter: 0; batch classifier loss: 0.424576; batch adversarial loss: 0.583836\n",
      "epoch 31; iter: 0; batch classifier loss: 0.472159; batch adversarial loss: 0.583672\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506351; batch adversarial loss: 0.580779\n",
      "epoch 33; iter: 0; batch classifier loss: 0.473968; batch adversarial loss: 0.601654\n",
      "epoch 34; iter: 0; batch classifier loss: 0.449806; batch adversarial loss: 0.663802\n",
      "epoch 35; iter: 0; batch classifier loss: 0.450126; batch adversarial loss: 0.622346\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492562; batch adversarial loss: 0.626170\n",
      "epoch 37; iter: 0; batch classifier loss: 0.704834; batch adversarial loss: 0.729156\n",
      "epoch 38; iter: 0; batch classifier loss: 0.765359; batch adversarial loss: 0.602618\n",
      "epoch 39; iter: 0; batch classifier loss: 0.732995; batch adversarial loss: 0.707537\n",
      "epoch 40; iter: 0; batch classifier loss: 0.753352; batch adversarial loss: 0.673975\n",
      "epoch 41; iter: 0; batch classifier loss: 0.566607; batch adversarial loss: 0.548211\n",
      "epoch 42; iter: 0; batch classifier loss: 0.664765; batch adversarial loss: 0.606870\n",
      "epoch 43; iter: 0; batch classifier loss: 0.704926; batch adversarial loss: 0.566931\n",
      "epoch 44; iter: 0; batch classifier loss: 0.535612; batch adversarial loss: 0.687565\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412536; batch adversarial loss: 0.583218\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370842; batch adversarial loss: 0.563282\n",
      "epoch 47; iter: 0; batch classifier loss: 0.299836; batch adversarial loss: 0.584207\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370029; batch adversarial loss: 0.555458\n",
      "epoch 49; iter: 0; batch classifier loss: 0.333799; batch adversarial loss: 0.548817\n",
      "epoch 50; iter: 0; batch classifier loss: 0.342028; batch adversarial loss: 0.512619\n",
      "epoch 51; iter: 0; batch classifier loss: 0.362645; batch adversarial loss: 0.596520\n",
      "epoch 52; iter: 0; batch classifier loss: 0.395616; batch adversarial loss: 0.525875\n",
      "epoch 53; iter: 0; batch classifier loss: 0.335653; batch adversarial loss: 0.585245\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394329; batch adversarial loss: 0.624990\n",
      "epoch 55; iter: 0; batch classifier loss: 0.432467; batch adversarial loss: 0.529655\n",
      "epoch 56; iter: 0; batch classifier loss: 0.293323; batch adversarial loss: 0.525780\n",
      "epoch 57; iter: 0; batch classifier loss: 0.372668; batch adversarial loss: 0.578442\n",
      "epoch 58; iter: 0; batch classifier loss: 0.316555; batch adversarial loss: 0.547188\n",
      "epoch 59; iter: 0; batch classifier loss: 0.368692; batch adversarial loss: 0.563690\n",
      "epoch 60; iter: 0; batch classifier loss: 0.251553; batch adversarial loss: 0.614274\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389617; batch adversarial loss: 0.612450\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445073; batch adversarial loss: 0.620907\n",
      "epoch 63; iter: 0; batch classifier loss: 0.356625; batch adversarial loss: 0.637287\n",
      "epoch 64; iter: 0; batch classifier loss: 0.465105; batch adversarial loss: 0.584171\n",
      "epoch 65; iter: 0; batch classifier loss: 0.378405; batch adversarial loss: 0.619044\n",
      "epoch 66; iter: 0; batch classifier loss: 0.460706; batch adversarial loss: 0.603867\n",
      "epoch 67; iter: 0; batch classifier loss: 0.287638; batch adversarial loss: 0.538334\n",
      "epoch 68; iter: 0; batch classifier loss: 0.494451; batch adversarial loss: 0.497567\n",
      "epoch 69; iter: 0; batch classifier loss: 0.359452; batch adversarial loss: 0.587716\n",
      "epoch 70; iter: 0; batch classifier loss: 0.407821; batch adversarial loss: 0.625476\n",
      "epoch 71; iter: 0; batch classifier loss: 0.422323; batch adversarial loss: 0.530821\n",
      "epoch 72; iter: 0; batch classifier loss: 0.390578; batch adversarial loss: 0.561190\n",
      "epoch 73; iter: 0; batch classifier loss: 0.289204; batch adversarial loss: 0.570916\n",
      "epoch 74; iter: 0; batch classifier loss: 0.444090; batch adversarial loss: 0.591652\n",
      "epoch 75; iter: 0; batch classifier loss: 0.319055; batch adversarial loss: 0.544208\n",
      "epoch 76; iter: 0; batch classifier loss: 0.468847; batch adversarial loss: 0.572514\n",
      "epoch 77; iter: 0; batch classifier loss: 0.375136; batch adversarial loss: 0.483399\n",
      "epoch 78; iter: 0; batch classifier loss: 0.431288; batch adversarial loss: 0.549332\n",
      "epoch 79; iter: 0; batch classifier loss: 0.416161; batch adversarial loss: 0.610372\n",
      "epoch 80; iter: 0; batch classifier loss: 0.369825; batch adversarial loss: 0.611117\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422113; batch adversarial loss: 0.596968\n",
      "epoch 82; iter: 0; batch classifier loss: 0.421743; batch adversarial loss: 0.531597\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412996; batch adversarial loss: 0.624301\n",
      "epoch 84; iter: 0; batch classifier loss: 0.438722; batch adversarial loss: 0.609286\n",
      "epoch 85; iter: 0; batch classifier loss: 0.351649; batch adversarial loss: 0.610767\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427091; batch adversarial loss: 0.627440\n",
      "epoch 87; iter: 0; batch classifier loss: 0.393492; batch adversarial loss: 0.601957\n",
      "epoch 88; iter: 0; batch classifier loss: 0.510752; batch adversarial loss: 0.499204\n",
      "epoch 89; iter: 0; batch classifier loss: 0.366565; batch adversarial loss: 0.548032\n",
      "epoch 90; iter: 0; batch classifier loss: 0.427885; batch adversarial loss: 0.547063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91; iter: 0; batch classifier loss: 0.423818; batch adversarial loss: 0.617496\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389027; batch adversarial loss: 0.632358\n",
      "epoch 93; iter: 0; batch classifier loss: 0.590343; batch adversarial loss: 0.560840\n",
      "epoch 94; iter: 0; batch classifier loss: 0.475775; batch adversarial loss: 0.507727\n",
      "epoch 95; iter: 0; batch classifier loss: 0.466886; batch adversarial loss: 0.582987\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429576; batch adversarial loss: 0.575518\n",
      "epoch 97; iter: 0; batch classifier loss: 0.477226; batch adversarial loss: 0.645976\n",
      "epoch 98; iter: 0; batch classifier loss: 0.457760; batch adversarial loss: 0.522293\n",
      "epoch 99; iter: 0; batch classifier loss: 0.448786; batch adversarial loss: 0.553426\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.907378; batch adversarial loss: 0.909998\n",
      "epoch 2; iter: 0; batch classifier loss: 0.909708; batch adversarial loss: 0.810178\n",
      "epoch 3; iter: 0; batch classifier loss: 0.753008; batch adversarial loss: 0.777754\n",
      "epoch 4; iter: 0; batch classifier loss: 0.644858; batch adversarial loss: 0.773094\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567359; batch adversarial loss: 0.669557\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569738; batch adversarial loss: 0.681886\n",
      "epoch 7; iter: 0; batch classifier loss: 0.478258; batch adversarial loss: 0.663753\n",
      "epoch 8; iter: 0; batch classifier loss: 0.465644; batch adversarial loss: 0.639038\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434888; batch adversarial loss: 0.662587\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445003; batch adversarial loss: 0.660649\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546146; batch adversarial loss: 0.617569\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527722; batch adversarial loss: 0.625086\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518080; batch adversarial loss: 0.627799\n",
      "epoch 14; iter: 0; batch classifier loss: 0.488634; batch adversarial loss: 0.606066\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489928; batch adversarial loss: 0.593619\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481448; batch adversarial loss: 0.568398\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515601; batch adversarial loss: 0.610133\n",
      "epoch 18; iter: 0; batch classifier loss: 0.469779; batch adversarial loss: 0.558341\n",
      "epoch 19; iter: 0; batch classifier loss: 0.436970; batch adversarial loss: 0.585998\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474177; batch adversarial loss: 0.622782\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487886; batch adversarial loss: 0.594731\n",
      "epoch 22; iter: 0; batch classifier loss: 0.494521; batch adversarial loss: 0.592701\n",
      "epoch 23; iter: 0; batch classifier loss: 0.592749; batch adversarial loss: 0.575490\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458224; batch adversarial loss: 0.568056\n",
      "epoch 25; iter: 0; batch classifier loss: 0.533825; batch adversarial loss: 0.586318\n",
      "epoch 26; iter: 0; batch classifier loss: 0.776974; batch adversarial loss: 0.723673\n",
      "epoch 27; iter: 0; batch classifier loss: 0.892226; batch adversarial loss: 0.711094\n",
      "epoch 28; iter: 0; batch classifier loss: 0.929121; batch adversarial loss: 0.654097\n",
      "epoch 29; iter: 0; batch classifier loss: 0.803841; batch adversarial loss: 0.627071\n",
      "epoch 30; iter: 0; batch classifier loss: 0.659651; batch adversarial loss: 0.597637\n",
      "epoch 31; iter: 0; batch classifier loss: 0.567327; batch adversarial loss: 0.566195\n",
      "epoch 32; iter: 0; batch classifier loss: 0.587501; batch adversarial loss: 0.571859\n",
      "epoch 33; iter: 0; batch classifier loss: 0.509537; batch adversarial loss: 0.580114\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451099; batch adversarial loss: 0.620555\n",
      "epoch 35; iter: 0; batch classifier loss: 0.391923; batch adversarial loss: 0.576315\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442965; batch adversarial loss: 0.572320\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450000; batch adversarial loss: 0.620848\n",
      "epoch 38; iter: 0; batch classifier loss: 0.494514; batch adversarial loss: 0.529128\n",
      "epoch 39; iter: 0; batch classifier loss: 0.397785; batch adversarial loss: 0.633727\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430077; batch adversarial loss: 0.619945\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462217; batch adversarial loss: 0.518549\n",
      "epoch 42; iter: 0; batch classifier loss: 0.487342; batch adversarial loss: 0.598255\n",
      "epoch 43; iter: 0; batch classifier loss: 0.633709; batch adversarial loss: 0.573629\n",
      "epoch 44; iter: 0; batch classifier loss: 0.747028; batch adversarial loss: 0.729778\n",
      "epoch 45; iter: 0; batch classifier loss: 0.779390; batch adversarial loss: 0.600684\n",
      "epoch 46; iter: 0; batch classifier loss: 0.731370; batch adversarial loss: 0.567074\n",
      "epoch 47; iter: 0; batch classifier loss: 0.384492; batch adversarial loss: 0.588287\n",
      "epoch 48; iter: 0; batch classifier loss: 0.438880; batch adversarial loss: 0.554297\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420336; batch adversarial loss: 0.552023\n",
      "epoch 50; iter: 0; batch classifier loss: 0.451224; batch adversarial loss: 0.515059\n",
      "epoch 51; iter: 0; batch classifier loss: 0.437215; batch adversarial loss: 0.600671\n",
      "epoch 52; iter: 0; batch classifier loss: 0.439528; batch adversarial loss: 0.525610\n",
      "epoch 53; iter: 0; batch classifier loss: 0.423867; batch adversarial loss: 0.581726\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447208; batch adversarial loss: 0.623838\n",
      "epoch 55; iter: 0; batch classifier loss: 0.506486; batch adversarial loss: 0.528304\n",
      "epoch 56; iter: 0; batch classifier loss: 0.362072; batch adversarial loss: 0.529162\n",
      "epoch 57; iter: 0; batch classifier loss: 0.426234; batch adversarial loss: 0.579003\n",
      "epoch 58; iter: 0; batch classifier loss: 0.409130; batch adversarial loss: 0.546098\n",
      "epoch 59; iter: 0; batch classifier loss: 0.440946; batch adversarial loss: 0.563684\n",
      "epoch 60; iter: 0; batch classifier loss: 0.378818; batch adversarial loss: 0.616866\n",
      "epoch 61; iter: 0; batch classifier loss: 0.437870; batch adversarial loss: 0.613725\n",
      "epoch 62; iter: 0; batch classifier loss: 0.499838; batch adversarial loss: 0.620124\n",
      "epoch 63; iter: 0; batch classifier loss: 0.428931; batch adversarial loss: 0.637025\n",
      "epoch 64; iter: 0; batch classifier loss: 0.494782; batch adversarial loss: 0.586321\n",
      "epoch 65; iter: 0; batch classifier loss: 0.469848; batch adversarial loss: 0.623566\n",
      "epoch 66; iter: 0; batch classifier loss: 0.440001; batch adversarial loss: 0.600860\n",
      "epoch 67; iter: 0; batch classifier loss: 0.371462; batch adversarial loss: 0.541079\n",
      "epoch 68; iter: 0; batch classifier loss: 0.526055; batch adversarial loss: 0.495316\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440341; batch adversarial loss: 0.591280\n",
      "epoch 70; iter: 0; batch classifier loss: 0.411697; batch adversarial loss: 0.622059\n",
      "epoch 71; iter: 0; batch classifier loss: 0.476309; batch adversarial loss: 0.532021\n",
      "epoch 72; iter: 0; batch classifier loss: 0.448495; batch adversarial loss: 0.563013\n",
      "epoch 73; iter: 0; batch classifier loss: 0.340263; batch adversarial loss: 0.570350\n",
      "epoch 74; iter: 0; batch classifier loss: 0.545232; batch adversarial loss: 0.587101\n",
      "epoch 75; iter: 0; batch classifier loss: 0.357946; batch adversarial loss: 0.543209\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461774; batch adversarial loss: 0.570409\n",
      "epoch 77; iter: 0; batch classifier loss: 0.427296; batch adversarial loss: 0.482535\n",
      "epoch 78; iter: 0; batch classifier loss: 0.510884; batch adversarial loss: 0.549099\n",
      "epoch 79; iter: 0; batch classifier loss: 0.449749; batch adversarial loss: 0.607466\n",
      "epoch 80; iter: 0; batch classifier loss: 0.357633; batch adversarial loss: 0.610355\n",
      "epoch 81; iter: 0; batch classifier loss: 0.463875; batch adversarial loss: 0.600442\n",
      "epoch 82; iter: 0; batch classifier loss: 0.444000; batch adversarial loss: 0.529384\n",
      "epoch 83; iter: 0; batch classifier loss: 0.461971; batch adversarial loss: 0.622385\n",
      "epoch 84; iter: 0; batch classifier loss: 0.432786; batch adversarial loss: 0.605606\n",
      "epoch 85; iter: 0; batch classifier loss: 0.353256; batch adversarial loss: 0.609155\n",
      "epoch 86; iter: 0; batch classifier loss: 0.457461; batch adversarial loss: 0.624501\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423054; batch adversarial loss: 0.598396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.535065; batch adversarial loss: 0.495644\n",
      "epoch 89; iter: 0; batch classifier loss: 0.426362; batch adversarial loss: 0.547492\n",
      "epoch 90; iter: 0; batch classifier loss: 0.438536; batch adversarial loss: 0.544967\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413592; batch adversarial loss: 0.611220\n",
      "epoch 92; iter: 0; batch classifier loss: 0.467056; batch adversarial loss: 0.630949\n",
      "epoch 93; iter: 0; batch classifier loss: 0.583016; batch adversarial loss: 0.556624\n",
      "epoch 94; iter: 0; batch classifier loss: 0.473549; batch adversarial loss: 0.505682\n",
      "epoch 95; iter: 0; batch classifier loss: 0.512172; batch adversarial loss: 0.584887\n",
      "epoch 96; iter: 0; batch classifier loss: 0.435374; batch adversarial loss: 0.575093\n",
      "epoch 97; iter: 0; batch classifier loss: 0.524626; batch adversarial loss: 0.644164\n",
      "epoch 98; iter: 0; batch classifier loss: 0.445800; batch adversarial loss: 0.518084\n",
      "epoch 99; iter: 0; batch classifier loss: 0.468311; batch adversarial loss: 0.549462\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709988; batch adversarial loss: 0.791750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.814816; batch adversarial loss: 0.908949\n",
      "epoch 2; iter: 0; batch classifier loss: 0.828760; batch adversarial loss: 0.810932\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612968; batch adversarial loss: 0.777082\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557077; batch adversarial loss: 0.770697\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524091; batch adversarial loss: 0.669917\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537904; batch adversarial loss: 0.689079\n",
      "epoch 7; iter: 0; batch classifier loss: 0.470278; batch adversarial loss: 0.666606\n",
      "epoch 8; iter: 0; batch classifier loss: 0.458301; batch adversarial loss: 0.641591\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434259; batch adversarial loss: 0.664096\n",
      "epoch 10; iter: 0; batch classifier loss: 0.435293; batch adversarial loss: 0.664125\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538954; batch adversarial loss: 0.619971\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511034; batch adversarial loss: 0.626929\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488108; batch adversarial loss: 0.630263\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473895; batch adversarial loss: 0.608551\n",
      "epoch 15; iter: 0; batch classifier loss: 0.454235; batch adversarial loss: 0.595263\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454182; batch adversarial loss: 0.567936\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481580; batch adversarial loss: 0.606462\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454438; batch adversarial loss: 0.553867\n",
      "epoch 19; iter: 0; batch classifier loss: 0.397791; batch adversarial loss: 0.591013\n",
      "epoch 20; iter: 0; batch classifier loss: 0.435993; batch adversarial loss: 0.625673\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482477; batch adversarial loss: 0.594951\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472864; batch adversarial loss: 0.589060\n",
      "epoch 23; iter: 0; batch classifier loss: 0.610758; batch adversarial loss: 0.586250\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478871; batch adversarial loss: 0.579703\n",
      "epoch 25; iter: 0; batch classifier loss: 0.634938; batch adversarial loss: 0.620564\n",
      "epoch 26; iter: 0; batch classifier loss: 0.811001; batch adversarial loss: 0.718064\n",
      "epoch 27; iter: 0; batch classifier loss: 0.871128; batch adversarial loss: 0.697532\n",
      "epoch 28; iter: 0; batch classifier loss: 0.772291; batch adversarial loss: 0.637975\n",
      "epoch 29; iter: 0; batch classifier loss: 0.691172; batch adversarial loss: 0.618997\n",
      "epoch 30; iter: 0; batch classifier loss: 0.529339; batch adversarial loss: 0.589720\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459297; batch adversarial loss: 0.557697\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477634; batch adversarial loss: 0.561767\n",
      "epoch 33; iter: 0; batch classifier loss: 0.406261; batch adversarial loss: 0.567861\n",
      "epoch 34; iter: 0; batch classifier loss: 0.398382; batch adversarial loss: 0.608698\n",
      "epoch 35; iter: 0; batch classifier loss: 0.342106; batch adversarial loss: 0.567959\n",
      "epoch 36; iter: 0; batch classifier loss: 0.385219; batch adversarial loss: 0.568315\n",
      "epoch 37; iter: 0; batch classifier loss: 0.405121; batch adversarial loss: 0.627392\n",
      "epoch 38; iter: 0; batch classifier loss: 0.492186; batch adversarial loss: 0.535567\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490443; batch adversarial loss: 0.659072\n",
      "epoch 40; iter: 0; batch classifier loss: 0.723055; batch adversarial loss: 0.664146\n",
      "epoch 41; iter: 0; batch classifier loss: 0.646841; batch adversarial loss: 0.541138\n",
      "epoch 42; iter: 0; batch classifier loss: 0.761136; batch adversarial loss: 0.604819\n",
      "epoch 43; iter: 0; batch classifier loss: 0.801825; batch adversarial loss: 0.561382\n",
      "epoch 44; iter: 0; batch classifier loss: 0.450857; batch adversarial loss: 0.690851\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434011; batch adversarial loss: 0.583279\n",
      "epoch 46; iter: 0; batch classifier loss: 0.394139; batch adversarial loss: 0.561892\n",
      "epoch 47; iter: 0; batch classifier loss: 0.328475; batch adversarial loss: 0.586968\n",
      "epoch 48; iter: 0; batch classifier loss: 0.398567; batch adversarial loss: 0.554805\n",
      "epoch 49; iter: 0; batch classifier loss: 0.363390; batch adversarial loss: 0.550312\n",
      "epoch 50; iter: 0; batch classifier loss: 0.366069; batch adversarial loss: 0.512966\n",
      "epoch 51; iter: 0; batch classifier loss: 0.372959; batch adversarial loss: 0.600116\n",
      "epoch 52; iter: 0; batch classifier loss: 0.391542; batch adversarial loss: 0.525987\n",
      "epoch 53; iter: 0; batch classifier loss: 0.357558; batch adversarial loss: 0.584847\n",
      "epoch 54; iter: 0; batch classifier loss: 0.418234; batch adversarial loss: 0.627493\n",
      "epoch 55; iter: 0; batch classifier loss: 0.463779; batch adversarial loss: 0.529500\n",
      "epoch 56; iter: 0; batch classifier loss: 0.363713; batch adversarial loss: 0.531811\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401114; batch adversarial loss: 0.579905\n",
      "epoch 58; iter: 0; batch classifier loss: 0.362556; batch adversarial loss: 0.547300\n",
      "epoch 59; iter: 0; batch classifier loss: 0.391436; batch adversarial loss: 0.565822\n",
      "epoch 60; iter: 0; batch classifier loss: 0.283170; batch adversarial loss: 0.615997\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439400; batch adversarial loss: 0.617134\n",
      "epoch 62; iter: 0; batch classifier loss: 0.484546; batch adversarial loss: 0.625624\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374808; batch adversarial loss: 0.638293\n",
      "epoch 64; iter: 0; batch classifier loss: 0.483456; batch adversarial loss: 0.588596\n",
      "epoch 65; iter: 0; batch classifier loss: 0.445327; batch adversarial loss: 0.624777\n",
      "epoch 66; iter: 0; batch classifier loss: 0.459909; batch adversarial loss: 0.605099\n",
      "epoch 67; iter: 0; batch classifier loss: 0.325358; batch adversarial loss: 0.541777\n",
      "epoch 68; iter: 0; batch classifier loss: 0.539298; batch adversarial loss: 0.500445\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411657; batch adversarial loss: 0.593683\n",
      "epoch 70; iter: 0; batch classifier loss: 0.451440; batch adversarial loss: 0.628402\n",
      "epoch 71; iter: 0; batch classifier loss: 0.482495; batch adversarial loss: 0.536051\n",
      "epoch 72; iter: 0; batch classifier loss: 0.431361; batch adversarial loss: 0.567005\n",
      "epoch 73; iter: 0; batch classifier loss: 0.347046; batch adversarial loss: 0.573671\n",
      "epoch 74; iter: 0; batch classifier loss: 0.542921; batch adversarial loss: 0.595670\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352313; batch adversarial loss: 0.547878\n",
      "epoch 76; iter: 0; batch classifier loss: 0.506435; batch adversarial loss: 0.575184\n",
      "epoch 77; iter: 0; batch classifier loss: 0.442373; batch adversarial loss: 0.487154\n",
      "epoch 78; iter: 0; batch classifier loss: 0.503801; batch adversarial loss: 0.553371\n",
      "epoch 79; iter: 0; batch classifier loss: 0.464352; batch adversarial loss: 0.611684\n",
      "epoch 80; iter: 0; batch classifier loss: 0.392859; batch adversarial loss: 0.615817\n",
      "epoch 81; iter: 0; batch classifier loss: 0.457132; batch adversarial loss: 0.602012\n",
      "epoch 82; iter: 0; batch classifier loss: 0.479919; batch adversarial loss: 0.533497\n",
      "epoch 83; iter: 0; batch classifier loss: 0.451809; batch adversarial loss: 0.628095\n",
      "epoch 84; iter: 0; batch classifier loss: 0.508901; batch adversarial loss: 0.612006\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390425; batch adversarial loss: 0.614169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.488219; batch adversarial loss: 0.626982\n",
      "epoch 87; iter: 0; batch classifier loss: 0.472130; batch adversarial loss: 0.606843\n",
      "epoch 88; iter: 0; batch classifier loss: 0.570047; batch adversarial loss: 0.502346\n",
      "epoch 89; iter: 0; batch classifier loss: 0.433722; batch adversarial loss: 0.552068\n",
      "epoch 90; iter: 0; batch classifier loss: 0.499350; batch adversarial loss: 0.551221\n",
      "epoch 91; iter: 0; batch classifier loss: 0.449939; batch adversarial loss: 0.617579\n",
      "epoch 92; iter: 0; batch classifier loss: 0.466946; batch adversarial loss: 0.633453\n",
      "epoch 93; iter: 0; batch classifier loss: 0.612742; batch adversarial loss: 0.562643\n",
      "epoch 94; iter: 0; batch classifier loss: 0.524561; batch adversarial loss: 0.510711\n",
      "epoch 95; iter: 0; batch classifier loss: 0.551520; batch adversarial loss: 0.592143\n",
      "epoch 96; iter: 0; batch classifier loss: 0.445932; batch adversarial loss: 0.573415\n",
      "epoch 97; iter: 0; batch classifier loss: 0.540464; batch adversarial loss: 0.644839\n",
      "epoch 98; iter: 0; batch classifier loss: 0.483324; batch adversarial loss: 0.523042\n",
      "epoch 99; iter: 0; batch classifier loss: 0.489776; batch adversarial loss: 0.552248\n",
      "epoch 100; iter: 0; batch classifier loss: 0.571707; batch adversarial loss: 0.587907\n",
      "epoch 101; iter: 0; batch classifier loss: 0.500574; batch adversarial loss: 0.629431\n",
      "epoch 102; iter: 0; batch classifier loss: 0.686737; batch adversarial loss: 0.548577\n",
      "epoch 103; iter: 0; batch classifier loss: 0.597310; batch adversarial loss: 0.572223\n",
      "epoch 104; iter: 0; batch classifier loss: 0.508032; batch adversarial loss: 0.543236\n",
      "epoch 105; iter: 0; batch classifier loss: 0.506117; batch adversarial loss: 0.654195\n",
      "epoch 106; iter: 0; batch classifier loss: 0.503359; batch adversarial loss: 0.643656\n",
      "epoch 107; iter: 0; batch classifier loss: 0.577704; batch adversarial loss: 0.571273\n",
      "epoch 108; iter: 0; batch classifier loss: 0.507215; batch adversarial loss: 0.583810\n",
      "epoch 109; iter: 0; batch classifier loss: 0.606884; batch adversarial loss: 0.503835\n",
      "epoch 110; iter: 0; batch classifier loss: 0.646832; batch adversarial loss: 0.532723\n",
      "epoch 111; iter: 0; batch classifier loss: 0.436344; batch adversarial loss: 0.590148\n",
      "epoch 112; iter: 0; batch classifier loss: 0.575157; batch adversarial loss: 0.563848\n",
      "epoch 113; iter: 0; batch classifier loss: 0.578240; batch adversarial loss: 0.558173\n",
      "epoch 114; iter: 0; batch classifier loss: 0.520021; batch adversarial loss: 0.589145\n",
      "epoch 115; iter: 0; batch classifier loss: 0.542340; batch adversarial loss: 0.515831\n",
      "epoch 116; iter: 0; batch classifier loss: 0.467372; batch adversarial loss: 0.558057\n",
      "epoch 117; iter: 0; batch classifier loss: 0.449581; batch adversarial loss: 0.602118\n",
      "epoch 118; iter: 0; batch classifier loss: 0.579742; batch adversarial loss: 0.593199\n",
      "epoch 119; iter: 0; batch classifier loss: 0.460494; batch adversarial loss: 0.613011\n",
      "epoch 120; iter: 0; batch classifier loss: 0.529770; batch adversarial loss: 0.600599\n",
      "epoch 121; iter: 0; batch classifier loss: 0.678271; batch adversarial loss: 0.642646\n",
      "epoch 122; iter: 0; batch classifier loss: 0.650017; batch adversarial loss: 0.575168\n",
      "epoch 123; iter: 0; batch classifier loss: 0.652145; batch adversarial loss: 0.608408\n",
      "epoch 124; iter: 0; batch classifier loss: 0.630131; batch adversarial loss: 0.558182\n",
      "epoch 125; iter: 0; batch classifier loss: 0.554459; batch adversarial loss: 0.616791\n",
      "epoch 126; iter: 0; batch classifier loss: 0.660274; batch adversarial loss: 0.577026\n",
      "epoch 127; iter: 0; batch classifier loss: 0.580876; batch adversarial loss: 0.523831\n",
      "epoch 128; iter: 0; batch classifier loss: 0.519295; batch adversarial loss: 0.583714\n",
      "epoch 129; iter: 0; batch classifier loss: 0.492171; batch adversarial loss: 0.635784\n",
      "epoch 130; iter: 0; batch classifier loss: 0.526941; batch adversarial loss: 0.562589\n",
      "epoch 131; iter: 0; batch classifier loss: 0.450053; batch adversarial loss: 0.607368\n",
      "epoch 132; iter: 0; batch classifier loss: 0.626168; batch adversarial loss: 0.541384\n",
      "epoch 133; iter: 0; batch classifier loss: 0.577673; batch adversarial loss: 0.627575\n",
      "epoch 134; iter: 0; batch classifier loss: 0.560500; batch adversarial loss: 0.569870\n",
      "epoch 135; iter: 0; batch classifier loss: 0.684686; batch adversarial loss: 0.629536\n",
      "epoch 136; iter: 0; batch classifier loss: 0.567647; batch adversarial loss: 0.575715\n",
      "epoch 137; iter: 0; batch classifier loss: 0.523651; batch adversarial loss: 0.650842\n",
      "epoch 138; iter: 0; batch classifier loss: 0.491222; batch adversarial loss: 0.555217\n",
      "epoch 139; iter: 0; batch classifier loss: 0.528806; batch adversarial loss: 0.553436\n",
      "epoch 140; iter: 0; batch classifier loss: 0.493571; batch adversarial loss: 0.605461\n",
      "epoch 141; iter: 0; batch classifier loss: 0.538637; batch adversarial loss: 0.504261\n",
      "epoch 142; iter: 0; batch classifier loss: 0.700568; batch adversarial loss: 0.578855\n",
      "epoch 143; iter: 0; batch classifier loss: 0.580743; batch adversarial loss: 0.504410\n",
      "epoch 144; iter: 0; batch classifier loss: 0.389767; batch adversarial loss: 0.617112\n",
      "epoch 145; iter: 0; batch classifier loss: 0.546644; batch adversarial loss: 0.522345\n",
      "epoch 146; iter: 0; batch classifier loss: 0.691358; batch adversarial loss: 0.570595\n",
      "epoch 147; iter: 0; batch classifier loss: 0.582151; batch adversarial loss: 0.508940\n",
      "epoch 148; iter: 0; batch classifier loss: 0.620926; batch adversarial loss: 0.575934\n",
      "epoch 149; iter: 0; batch classifier loss: 0.558023; batch adversarial loss: 0.547945\n",
      "epoch 150; iter: 0; batch classifier loss: 0.559428; batch adversarial loss: 0.569271\n",
      "epoch 151; iter: 0; batch classifier loss: 0.486512; batch adversarial loss: 0.544373\n",
      "epoch 152; iter: 0; batch classifier loss: 0.509782; batch adversarial loss: 0.595896\n",
      "epoch 153; iter: 0; batch classifier loss: 0.695421; batch adversarial loss: 0.553438\n",
      "epoch 154; iter: 0; batch classifier loss: 0.493365; batch adversarial loss: 0.599112\n",
      "epoch 155; iter: 0; batch classifier loss: 0.515550; batch adversarial loss: 0.609632\n",
      "epoch 156; iter: 0; batch classifier loss: 0.366117; batch adversarial loss: 0.605909\n",
      "epoch 157; iter: 0; batch classifier loss: 0.442440; batch adversarial loss: 0.514202\n",
      "epoch 158; iter: 0; batch classifier loss: 0.555697; batch adversarial loss: 0.620352\n",
      "epoch 159; iter: 0; batch classifier loss: 0.495392; batch adversarial loss: 0.586725\n",
      "epoch 160; iter: 0; batch classifier loss: 0.585395; batch adversarial loss: 0.579236\n",
      "epoch 161; iter: 0; batch classifier loss: 0.550851; batch adversarial loss: 0.561279\n",
      "epoch 162; iter: 0; batch classifier loss: 0.452041; batch adversarial loss: 0.571282\n",
      "epoch 163; iter: 0; batch classifier loss: 0.601497; batch adversarial loss: 0.545622\n",
      "epoch 164; iter: 0; batch classifier loss: 0.371690; batch adversarial loss: 0.560466\n",
      "epoch 165; iter: 0; batch classifier loss: 0.478167; batch adversarial loss: 0.561932\n",
      "epoch 166; iter: 0; batch classifier loss: 0.534489; batch adversarial loss: 0.593448\n",
      "epoch 167; iter: 0; batch classifier loss: 0.407576; batch adversarial loss: 0.570154\n",
      "epoch 168; iter: 0; batch classifier loss: 0.536551; batch adversarial loss: 0.608688\n",
      "epoch 169; iter: 0; batch classifier loss: 0.599252; batch adversarial loss: 0.594241\n",
      "epoch 170; iter: 0; batch classifier loss: 0.519384; batch adversarial loss: 0.547121\n",
      "epoch 171; iter: 0; batch classifier loss: 0.428019; batch adversarial loss: 0.516195\n",
      "epoch 172; iter: 0; batch classifier loss: 0.480514; batch adversarial loss: 0.579833\n",
      "epoch 173; iter: 0; batch classifier loss: 0.631849; batch adversarial loss: 0.546904\n",
      "epoch 174; iter: 0; batch classifier loss: 0.578153; batch adversarial loss: 0.553620\n",
      "epoch 175; iter: 0; batch classifier loss: 0.521659; batch adversarial loss: 0.548400\n",
      "epoch 176; iter: 0; batch classifier loss: 0.610855; batch adversarial loss: 0.522693\n",
      "epoch 177; iter: 0; batch classifier loss: 0.535838; batch adversarial loss: 0.602957\n",
      "epoch 178; iter: 0; batch classifier loss: 0.391999; batch adversarial loss: 0.541679\n",
      "epoch 179; iter: 0; batch classifier loss: 0.516982; batch adversarial loss: 0.609902\n",
      "epoch 180; iter: 0; batch classifier loss: 0.505119; batch adversarial loss: 0.538159\n",
      "epoch 181; iter: 0; batch classifier loss: 0.682974; batch adversarial loss: 0.641448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.558282; batch adversarial loss: 0.595235\n",
      "epoch 183; iter: 0; batch classifier loss: 0.611902; batch adversarial loss: 0.642729\n",
      "epoch 184; iter: 0; batch classifier loss: 0.472366; batch adversarial loss: 0.529874\n",
      "epoch 185; iter: 0; batch classifier loss: 0.616275; batch adversarial loss: 0.626303\n",
      "epoch 186; iter: 0; batch classifier loss: 0.439977; batch adversarial loss: 0.530654\n",
      "epoch 187; iter: 0; batch classifier loss: 0.476736; batch adversarial loss: 0.548970\n",
      "epoch 188; iter: 0; batch classifier loss: 0.396663; batch adversarial loss: 0.562434\n",
      "epoch 189; iter: 0; batch classifier loss: 0.540833; batch adversarial loss: 0.563191\n",
      "epoch 190; iter: 0; batch classifier loss: 0.600132; batch adversarial loss: 0.536790\n",
      "epoch 191; iter: 0; batch classifier loss: 0.354294; batch adversarial loss: 0.594157\n",
      "epoch 192; iter: 0; batch classifier loss: 0.460275; batch adversarial loss: 0.569619\n",
      "epoch 193; iter: 0; batch classifier loss: 0.568934; batch adversarial loss: 0.506101\n",
      "epoch 194; iter: 0; batch classifier loss: 0.454226; batch adversarial loss: 0.595062\n",
      "epoch 195; iter: 0; batch classifier loss: 0.596231; batch adversarial loss: 0.529243\n",
      "epoch 196; iter: 0; batch classifier loss: 0.586121; batch adversarial loss: 0.602428\n",
      "epoch 197; iter: 0; batch classifier loss: 0.421752; batch adversarial loss: 0.605893\n",
      "epoch 198; iter: 0; batch classifier loss: 0.497038; batch adversarial loss: 0.608600\n",
      "epoch 199; iter: 0; batch classifier loss: 0.333239; batch adversarial loss: 0.652774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.709988; batch adversarial loss: 0.791750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.807506; batch adversarial loss: 0.907628\n",
      "epoch 2; iter: 0; batch classifier loss: 0.815220; batch adversarial loss: 0.809717\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598077; batch adversarial loss: 0.775393\n",
      "epoch 4; iter: 0; batch classifier loss: 0.547524; batch adversarial loss: 0.769091\n",
      "epoch 5; iter: 0; batch classifier loss: 0.514920; batch adversarial loss: 0.669441\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538735; batch adversarial loss: 0.688380\n",
      "epoch 7; iter: 0; batch classifier loss: 0.469846; batch adversarial loss: 0.666457\n",
      "epoch 8; iter: 0; batch classifier loss: 0.457672; batch adversarial loss: 0.641890\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434429; batch adversarial loss: 0.664328\n",
      "epoch 10; iter: 0; batch classifier loss: 0.435318; batch adversarial loss: 0.664446\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538252; batch adversarial loss: 0.620513\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511253; batch adversarial loss: 0.627129\n",
      "epoch 13; iter: 0; batch classifier loss: 0.487791; batch adversarial loss: 0.630544\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477451; batch adversarial loss: 0.608335\n",
      "epoch 15; iter: 0; batch classifier loss: 0.456269; batch adversarial loss: 0.594713\n",
      "epoch 16; iter: 0; batch classifier loss: 0.453949; batch adversarial loss: 0.567023\n",
      "epoch 17; iter: 0; batch classifier loss: 0.478629; batch adversarial loss: 0.605729\n",
      "epoch 18; iter: 0; batch classifier loss: 0.451894; batch adversarial loss: 0.553410\n",
      "epoch 19; iter: 0; batch classifier loss: 0.397079; batch adversarial loss: 0.589817\n",
      "epoch 20; iter: 0; batch classifier loss: 0.433234; batch adversarial loss: 0.624104\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484176; batch adversarial loss: 0.592563\n",
      "epoch 22; iter: 0; batch classifier loss: 0.440705; batch adversarial loss: 0.571059\n",
      "epoch 23; iter: 0; batch classifier loss: 0.571985; batch adversarial loss: 0.572360\n",
      "epoch 24; iter: 0; batch classifier loss: 0.463140; batch adversarial loss: 0.573131\n",
      "epoch 25; iter: 0; batch classifier loss: 0.523981; batch adversarial loss: 0.587417\n",
      "epoch 26; iter: 0; batch classifier loss: 0.767097; batch adversarial loss: 0.731929\n",
      "epoch 27; iter: 0; batch classifier loss: 0.891984; batch adversarial loss: 0.717360\n",
      "epoch 28; iter: 0; batch classifier loss: 0.832990; batch adversarial loss: 0.650789\n",
      "epoch 29; iter: 0; batch classifier loss: 0.759864; batch adversarial loss: 0.630506\n",
      "epoch 30; iter: 0; batch classifier loss: 0.572230; batch adversarial loss: 0.596546\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515766; batch adversarial loss: 0.566210\n",
      "epoch 32; iter: 0; batch classifier loss: 0.528670; batch adversarial loss: 0.570504\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437119; batch adversarial loss: 0.575373\n",
      "epoch 34; iter: 0; batch classifier loss: 0.401059; batch adversarial loss: 0.613626\n",
      "epoch 35; iter: 0; batch classifier loss: 0.349676; batch adversarial loss: 0.569861\n",
      "epoch 36; iter: 0; batch classifier loss: 0.387535; batch adversarial loss: 0.567592\n",
      "epoch 37; iter: 0; batch classifier loss: 0.388314; batch adversarial loss: 0.620827\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459678; batch adversarial loss: 0.529386\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419733; batch adversarial loss: 0.646243\n",
      "epoch 40; iter: 0; batch classifier loss: 0.520283; batch adversarial loss: 0.642933\n",
      "epoch 41; iter: 0; batch classifier loss: 0.564654; batch adversarial loss: 0.541043\n",
      "epoch 42; iter: 0; batch classifier loss: 0.717430; batch adversarial loss: 0.613838\n",
      "epoch 43; iter: 0; batch classifier loss: 0.776804; batch adversarial loss: 0.569175\n",
      "epoch 44; iter: 0; batch classifier loss: 0.704707; batch adversarial loss: 0.696246\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433704; batch adversarial loss: 0.583043\n",
      "epoch 46; iter: 0; batch classifier loss: 0.392117; batch adversarial loss: 0.562059\n",
      "epoch 47; iter: 0; batch classifier loss: 0.320204; batch adversarial loss: 0.586311\n",
      "epoch 48; iter: 0; batch classifier loss: 0.388544; batch adversarial loss: 0.554694\n",
      "epoch 49; iter: 0; batch classifier loss: 0.366014; batch adversarial loss: 0.550285\n",
      "epoch 50; iter: 0; batch classifier loss: 0.354382; batch adversarial loss: 0.512512\n",
      "epoch 51; iter: 0; batch classifier loss: 0.368399; batch adversarial loss: 0.599532\n",
      "epoch 52; iter: 0; batch classifier loss: 0.390260; batch adversarial loss: 0.525542\n",
      "epoch 53; iter: 0; batch classifier loss: 0.355597; batch adversarial loss: 0.584447\n",
      "epoch 54; iter: 0; batch classifier loss: 0.404100; batch adversarial loss: 0.626454\n",
      "epoch 55; iter: 0; batch classifier loss: 0.448681; batch adversarial loss: 0.528842\n",
      "epoch 56; iter: 0; batch classifier loss: 0.356012; batch adversarial loss: 0.531027\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398483; batch adversarial loss: 0.579306\n",
      "epoch 58; iter: 0; batch classifier loss: 0.367483; batch adversarial loss: 0.547412\n",
      "epoch 59; iter: 0; batch classifier loss: 0.383815; batch adversarial loss: 0.565643\n",
      "epoch 60; iter: 0; batch classifier loss: 0.273845; batch adversarial loss: 0.615907\n",
      "epoch 61; iter: 0; batch classifier loss: 0.434820; batch adversarial loss: 0.616561\n",
      "epoch 62; iter: 0; batch classifier loss: 0.475717; batch adversarial loss: 0.624779\n",
      "epoch 63; iter: 0; batch classifier loss: 0.372793; batch adversarial loss: 0.638348\n",
      "epoch 64; iter: 0; batch classifier loss: 0.474103; batch adversarial loss: 0.587587\n",
      "epoch 65; iter: 0; batch classifier loss: 0.425234; batch adversarial loss: 0.623051\n",
      "epoch 66; iter: 0; batch classifier loss: 0.455807; batch adversarial loss: 0.604480\n",
      "epoch 67; iter: 0; batch classifier loss: 0.314105; batch adversarial loss: 0.540566\n",
      "epoch 68; iter: 0; batch classifier loss: 0.547519; batch adversarial loss: 0.500582\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397541; batch adversarial loss: 0.592649\n",
      "epoch 70; iter: 0; batch classifier loss: 0.440500; batch adversarial loss: 0.627674\n",
      "epoch 71; iter: 0; batch classifier loss: 0.463806; batch adversarial loss: 0.534642\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412467; batch adversarial loss: 0.565484\n",
      "epoch 73; iter: 0; batch classifier loss: 0.336356; batch adversarial loss: 0.573198\n",
      "epoch 74; iter: 0; batch classifier loss: 0.540458; batch adversarial loss: 0.595447\n",
      "epoch 75; iter: 0; batch classifier loss: 0.353344; batch adversarial loss: 0.547489\n",
      "epoch 76; iter: 0; batch classifier loss: 0.516053; batch adversarial loss: 0.575666\n",
      "epoch 77; iter: 0; batch classifier loss: 0.426822; batch adversarial loss: 0.486440\n",
      "epoch 78; iter: 0; batch classifier loss: 0.509529; batch adversarial loss: 0.553470\n",
      "epoch 79; iter: 0; batch classifier loss: 0.457604; batch adversarial loss: 0.611659\n",
      "epoch 80; iter: 0; batch classifier loss: 0.394209; batch adversarial loss: 0.615618\n",
      "epoch 81; iter: 0; batch classifier loss: 0.474851; batch adversarial loss: 0.601976\n",
      "epoch 82; iter: 0; batch classifier loss: 0.484205; batch adversarial loss: 0.534041\n",
      "epoch 83; iter: 0; batch classifier loss: 0.460398; batch adversarial loss: 0.628151\n",
      "epoch 84; iter: 0; batch classifier loss: 0.506288; batch adversarial loss: 0.612042\n",
      "epoch 85; iter: 0; batch classifier loss: 0.388820; batch adversarial loss: 0.613402\n",
      "epoch 86; iter: 0; batch classifier loss: 0.485582; batch adversarial loss: 0.626795\n",
      "epoch 87; iter: 0; batch classifier loss: 0.457244; batch adversarial loss: 0.605878\n",
      "epoch 88; iter: 0; batch classifier loss: 0.562009; batch adversarial loss: 0.502021\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436512; batch adversarial loss: 0.552547\n",
      "epoch 90; iter: 0; batch classifier loss: 0.504462; batch adversarial loss: 0.551512\n",
      "epoch 91; iter: 0; batch classifier loss: 0.437460; batch adversarial loss: 0.617973\n",
      "epoch 92; iter: 0; batch classifier loss: 0.471852; batch adversarial loss: 0.633532\n",
      "epoch 93; iter: 0; batch classifier loss: 0.605147; batch adversarial loss: 0.561910\n",
      "epoch 94; iter: 0; batch classifier loss: 0.525996; batch adversarial loss: 0.510752\n",
      "epoch 95; iter: 0; batch classifier loss: 0.556165; batch adversarial loss: 0.592322\n",
      "epoch 96; iter: 0; batch classifier loss: 0.464473; batch adversarial loss: 0.574515\n",
      "epoch 97; iter: 0; batch classifier loss: 0.542420; batch adversarial loss: 0.645286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.487116; batch adversarial loss: 0.522943\n",
      "epoch 99; iter: 0; batch classifier loss: 0.487941; batch adversarial loss: 0.552641\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.827101; batch adversarial loss: 0.895960\n",
      "epoch 2; iter: 0; batch classifier loss: 0.818421; batch adversarial loss: 0.799626\n",
      "epoch 3; iter: 0; batch classifier loss: 0.637454; batch adversarial loss: 0.762452\n",
      "epoch 4; iter: 0; batch classifier loss: 0.535263; batch adversarial loss: 0.755459\n",
      "epoch 5; iter: 0; batch classifier loss: 0.508265; batch adversarial loss: 0.662815\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585217; batch adversarial loss: 0.675070\n",
      "epoch 7; iter: 0; batch classifier loss: 0.479173; batch adversarial loss: 0.663117\n",
      "epoch 8; iter: 0; batch classifier loss: 0.471604; batch adversarial loss: 0.638659\n",
      "epoch 9; iter: 0; batch classifier loss: 0.443722; batch adversarial loss: 0.660957\n",
      "epoch 10; iter: 0; batch classifier loss: 0.451349; batch adversarial loss: 0.659291\n",
      "epoch 11; iter: 0; batch classifier loss: 0.558498; batch adversarial loss: 0.615699\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539143; batch adversarial loss: 0.624111\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535005; batch adversarial loss: 0.625591\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498831; batch adversarial loss: 0.605611\n",
      "epoch 15; iter: 0; batch classifier loss: 0.520582; batch adversarial loss: 0.587535\n",
      "epoch 16; iter: 0; batch classifier loss: 0.486802; batch adversarial loss: 0.562603\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508648; batch adversarial loss: 0.602025\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466959; batch adversarial loss: 0.550972\n",
      "epoch 19; iter: 0; batch classifier loss: 0.433631; batch adversarial loss: 0.579766\n",
      "epoch 20; iter: 0; batch classifier loss: 0.467036; batch adversarial loss: 0.614230\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494943; batch adversarial loss: 0.586361\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433831; batch adversarial loss: 0.558489\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487531; batch adversarial loss: 0.531638\n",
      "epoch 24; iter: 0; batch classifier loss: 0.401926; batch adversarial loss: 0.525596\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439892; batch adversarial loss: 0.530303\n",
      "epoch 26; iter: 0; batch classifier loss: 0.439070; batch adversarial loss: 0.619706\n",
      "epoch 27; iter: 0; batch classifier loss: 0.588529; batch adversarial loss: 0.684480\n",
      "epoch 28; iter: 0; batch classifier loss: 0.639000; batch adversarial loss: 0.628912\n",
      "epoch 29; iter: 0; batch classifier loss: 0.640121; batch adversarial loss: 0.637432\n",
      "epoch 30; iter: 0; batch classifier loss: 0.748001; batch adversarial loss: 0.651860\n",
      "epoch 31; iter: 0; batch classifier loss: 0.779104; batch adversarial loss: 0.624835\n",
      "epoch 32; iter: 0; batch classifier loss: 0.853289; batch adversarial loss: 0.624085\n",
      "epoch 33; iter: 0; batch classifier loss: 0.781192; batch adversarial loss: 0.623093\n",
      "epoch 34; iter: 0; batch classifier loss: 0.681121; batch adversarial loss: 0.663224\n",
      "epoch 35; iter: 0; batch classifier loss: 0.599706; batch adversarial loss: 0.610442\n",
      "epoch 36; iter: 0; batch classifier loss: 0.569056; batch adversarial loss: 0.598964\n",
      "epoch 37; iter: 0; batch classifier loss: 0.574960; batch adversarial loss: 0.640174\n",
      "epoch 38; iter: 0; batch classifier loss: 0.564527; batch adversarial loss: 0.545576\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438507; batch adversarial loss: 0.637865\n",
      "epoch 40; iter: 0; batch classifier loss: 0.432681; batch adversarial loss: 0.616942\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416977; batch adversarial loss: 0.516956\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424374; batch adversarial loss: 0.587014\n",
      "epoch 43; iter: 0; batch classifier loss: 0.547469; batch adversarial loss: 0.558864\n",
      "epoch 44; iter: 0; batch classifier loss: 0.546970; batch adversarial loss: 0.700474\n",
      "epoch 45; iter: 0; batch classifier loss: 0.583992; batch adversarial loss: 0.587318\n",
      "epoch 46; iter: 0; batch classifier loss: 0.476234; batch adversarial loss: 0.563235\n",
      "epoch 47; iter: 0; batch classifier loss: 0.354022; batch adversarial loss: 0.587435\n",
      "epoch 48; iter: 0; batch classifier loss: 0.425353; batch adversarial loss: 0.553847\n",
      "epoch 49; iter: 0; batch classifier loss: 0.397952; batch adversarial loss: 0.550721\n",
      "epoch 50; iter: 0; batch classifier loss: 0.443280; batch adversarial loss: 0.513864\n",
      "epoch 51; iter: 0; batch classifier loss: 0.418928; batch adversarial loss: 0.599886\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421713; batch adversarial loss: 0.524090\n",
      "epoch 53; iter: 0; batch classifier loss: 0.409274; batch adversarial loss: 0.581852\n",
      "epoch 54; iter: 0; batch classifier loss: 0.421185; batch adversarial loss: 0.623307\n",
      "epoch 55; iter: 0; batch classifier loss: 0.485876; batch adversarial loss: 0.527571\n",
      "epoch 56; iter: 0; batch classifier loss: 0.343713; batch adversarial loss: 0.527024\n",
      "epoch 57; iter: 0; batch classifier loss: 0.412889; batch adversarial loss: 0.578768\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402358; batch adversarial loss: 0.545621\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425609; batch adversarial loss: 0.563153\n",
      "epoch 60; iter: 0; batch classifier loss: 0.381146; batch adversarial loss: 0.617741\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403657; batch adversarial loss: 0.611016\n",
      "epoch 62; iter: 0; batch classifier loss: 0.463238; batch adversarial loss: 0.616250\n",
      "epoch 63; iter: 0; batch classifier loss: 0.384297; batch adversarial loss: 0.634221\n",
      "epoch 64; iter: 0; batch classifier loss: 0.465277; batch adversarial loss: 0.582062\n",
      "epoch 65; iter: 0; batch classifier loss: 0.435572; batch adversarial loss: 0.620218\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415663; batch adversarial loss: 0.597483\n",
      "epoch 67; iter: 0; batch classifier loss: 0.352786; batch adversarial loss: 0.538456\n",
      "epoch 68; iter: 0; batch classifier loss: 0.491534; batch adversarial loss: 0.491572\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418462; batch adversarial loss: 0.587263\n",
      "epoch 70; iter: 0; batch classifier loss: 0.362585; batch adversarial loss: 0.617166\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437239; batch adversarial loss: 0.527901\n",
      "epoch 72; iter: 0; batch classifier loss: 0.376427; batch adversarial loss: 0.555947\n",
      "epoch 73; iter: 0; batch classifier loss: 0.300727; batch adversarial loss: 0.567610\n",
      "epoch 74; iter: 0; batch classifier loss: 0.507381; batch adversarial loss: 0.584123\n",
      "epoch 75; iter: 0; batch classifier loss: 0.327962; batch adversarial loss: 0.539016\n",
      "epoch 76; iter: 0; batch classifier loss: 0.393394; batch adversarial loss: 0.563537\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398536; batch adversarial loss: 0.479364\n",
      "epoch 78; iter: 0; batch classifier loss: 0.471745; batch adversarial loss: 0.546558\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386870; batch adversarial loss: 0.601359\n",
      "epoch 80; iter: 0; batch classifier loss: 0.312613; batch adversarial loss: 0.604097\n",
      "epoch 81; iter: 0; batch classifier loss: 0.442267; batch adversarial loss: 0.597590\n",
      "epoch 82; iter: 0; batch classifier loss: 0.416963; batch adversarial loss: 0.528420\n",
      "epoch 83; iter: 0; batch classifier loss: 0.423448; batch adversarial loss: 0.617199\n",
      "epoch 84; iter: 0; batch classifier loss: 0.418932; batch adversarial loss: 0.602942\n",
      "epoch 85; iter: 0; batch classifier loss: 0.310131; batch adversarial loss: 0.604260\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407342; batch adversarial loss: 0.620231\n",
      "epoch 87; iter: 0; batch classifier loss: 0.404838; batch adversarial loss: 0.595637\n",
      "epoch 88; iter: 0; batch classifier loss: 0.504715; batch adversarial loss: 0.492895\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386958; batch adversarial loss: 0.542717\n",
      "epoch 90; iter: 0; batch classifier loss: 0.412243; batch adversarial loss: 0.542055\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388490; batch adversarial loss: 0.607723\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418826; batch adversarial loss: 0.628375\n",
      "epoch 93; iter: 0; batch classifier loss: 0.538478; batch adversarial loss: 0.551356\n",
      "epoch 94; iter: 0; batch classifier loss: 0.424088; batch adversarial loss: 0.501076\n",
      "epoch 95; iter: 0; batch classifier loss: 0.493388; batch adversarial loss: 0.579175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.406244; batch adversarial loss: 0.575453\n",
      "epoch 97; iter: 0; batch classifier loss: 0.473700; batch adversarial loss: 0.643431\n",
      "epoch 98; iter: 0; batch classifier loss: 0.407598; batch adversarial loss: 0.514020\n",
      "epoch 99; iter: 0; batch classifier loss: 0.439820; batch adversarial loss: 0.548077\n",
      "epoch 100; iter: 0; batch classifier loss: 0.509118; batch adversarial loss: 0.576705\n",
      "epoch 101; iter: 0; batch classifier loss: 0.413585; batch adversarial loss: 0.623969\n",
      "epoch 102; iter: 0; batch classifier loss: 0.610931; batch adversarial loss: 0.537586\n",
      "epoch 103; iter: 0; batch classifier loss: 0.552769; batch adversarial loss: 0.561793\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399614; batch adversarial loss: 0.536668\n",
      "epoch 105; iter: 0; batch classifier loss: 0.444848; batch adversarial loss: 0.642892\n",
      "epoch 106; iter: 0; batch classifier loss: 0.420641; batch adversarial loss: 0.639488\n",
      "epoch 107; iter: 0; batch classifier loss: 0.519889; batch adversarial loss: 0.563943\n",
      "epoch 108; iter: 0; batch classifier loss: 0.419345; batch adversarial loss: 0.579293\n",
      "epoch 109; iter: 0; batch classifier loss: 0.583213; batch adversarial loss: 0.496034\n",
      "epoch 110; iter: 0; batch classifier loss: 0.541577; batch adversarial loss: 0.521681\n",
      "epoch 111; iter: 0; batch classifier loss: 0.423851; batch adversarial loss: 0.590087\n",
      "epoch 112; iter: 0; batch classifier loss: 0.513882; batch adversarial loss: 0.551315\n",
      "epoch 113; iter: 0; batch classifier loss: 0.513853; batch adversarial loss: 0.555814\n",
      "epoch 114; iter: 0; batch classifier loss: 0.491831; batch adversarial loss: 0.586304\n",
      "epoch 115; iter: 0; batch classifier loss: 0.418690; batch adversarial loss: 0.511397\n",
      "epoch 116; iter: 0; batch classifier loss: 0.476673; batch adversarial loss: 0.551940\n",
      "epoch 117; iter: 0; batch classifier loss: 0.435752; batch adversarial loss: 0.599698\n",
      "epoch 118; iter: 0; batch classifier loss: 0.453655; batch adversarial loss: 0.579184\n",
      "epoch 119; iter: 0; batch classifier loss: 0.423565; batch adversarial loss: 0.601098\n",
      "epoch 120; iter: 0; batch classifier loss: 0.406096; batch adversarial loss: 0.584324\n",
      "epoch 121; iter: 0; batch classifier loss: 0.569019; batch adversarial loss: 0.629845\n",
      "epoch 122; iter: 0; batch classifier loss: 0.636264; batch adversarial loss: 0.567930\n",
      "epoch 123; iter: 0; batch classifier loss: 0.601967; batch adversarial loss: 0.599928\n",
      "epoch 124; iter: 0; batch classifier loss: 0.492113; batch adversarial loss: 0.551275\n",
      "epoch 125; iter: 0; batch classifier loss: 0.507883; batch adversarial loss: 0.609218\n",
      "epoch 126; iter: 0; batch classifier loss: 0.564837; batch adversarial loss: 0.567244\n",
      "epoch 127; iter: 0; batch classifier loss: 0.491737; batch adversarial loss: 0.517819\n",
      "epoch 128; iter: 0; batch classifier loss: 0.415356; batch adversarial loss: 0.599388\n",
      "epoch 129; iter: 0; batch classifier loss: 0.453177; batch adversarial loss: 0.633390\n",
      "epoch 130; iter: 0; batch classifier loss: 0.512203; batch adversarial loss: 0.559254\n",
      "epoch 131; iter: 0; batch classifier loss: 0.436755; batch adversarial loss: 0.596361\n",
      "epoch 132; iter: 0; batch classifier loss: 0.553177; batch adversarial loss: 0.544260\n",
      "epoch 133; iter: 0; batch classifier loss: 0.470280; batch adversarial loss: 0.620535\n",
      "epoch 134; iter: 0; batch classifier loss: 0.441486; batch adversarial loss: 0.557697\n",
      "epoch 135; iter: 0; batch classifier loss: 0.578363; batch adversarial loss: 0.631572\n",
      "epoch 136; iter: 0; batch classifier loss: 0.510234; batch adversarial loss: 0.562986\n",
      "epoch 137; iter: 0; batch classifier loss: 0.396076; batch adversarial loss: 0.643467\n",
      "epoch 138; iter: 0; batch classifier loss: 0.482785; batch adversarial loss: 0.554841\n",
      "epoch 139; iter: 0; batch classifier loss: 0.474273; batch adversarial loss: 0.544058\n",
      "epoch 140; iter: 0; batch classifier loss: 0.524943; batch adversarial loss: 0.615412\n",
      "epoch 141; iter: 0; batch classifier loss: 0.521442; batch adversarial loss: 0.494692\n",
      "epoch 142; iter: 0; batch classifier loss: 0.600409; batch adversarial loss: 0.574511\n",
      "epoch 143; iter: 0; batch classifier loss: 0.534154; batch adversarial loss: 0.493177\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408164; batch adversarial loss: 0.608958\n",
      "epoch 145; iter: 0; batch classifier loss: 0.460894; batch adversarial loss: 0.514863\n",
      "epoch 146; iter: 0; batch classifier loss: 0.608488; batch adversarial loss: 0.560608\n",
      "epoch 147; iter: 0; batch classifier loss: 0.518328; batch adversarial loss: 0.514848\n",
      "epoch 148; iter: 0; batch classifier loss: 0.624909; batch adversarial loss: 0.565107\n",
      "epoch 149; iter: 0; batch classifier loss: 0.505138; batch adversarial loss: 0.550416\n",
      "epoch 150; iter: 0; batch classifier loss: 0.511735; batch adversarial loss: 0.559373\n",
      "epoch 151; iter: 0; batch classifier loss: 0.545080; batch adversarial loss: 0.533629\n",
      "epoch 152; iter: 0; batch classifier loss: 0.491600; batch adversarial loss: 0.596414\n",
      "epoch 153; iter: 0; batch classifier loss: 0.631654; batch adversarial loss: 0.541961\n",
      "epoch 154; iter: 0; batch classifier loss: 0.465897; batch adversarial loss: 0.621083\n",
      "epoch 155; iter: 0; batch classifier loss: 0.495576; batch adversarial loss: 0.601626\n",
      "epoch 156; iter: 0; batch classifier loss: 0.311040; batch adversarial loss: 0.619890\n",
      "epoch 157; iter: 0; batch classifier loss: 0.484425; batch adversarial loss: 0.513078\n",
      "epoch 158; iter: 0; batch classifier loss: 0.609037; batch adversarial loss: 0.630692\n",
      "epoch 159; iter: 0; batch classifier loss: 0.469025; batch adversarial loss: 0.584378\n",
      "epoch 160; iter: 0; batch classifier loss: 0.534394; batch adversarial loss: 0.579426\n",
      "epoch 161; iter: 0; batch classifier loss: 0.602409; batch adversarial loss: 0.552086\n",
      "epoch 162; iter: 0; batch classifier loss: 0.467095; batch adversarial loss: 0.575372\n",
      "epoch 163; iter: 0; batch classifier loss: 0.573042; batch adversarial loss: 0.535785\n",
      "epoch 164; iter: 0; batch classifier loss: 0.442057; batch adversarial loss: 0.549155\n",
      "epoch 165; iter: 0; batch classifier loss: 0.562775; batch adversarial loss: 0.561678\n",
      "epoch 166; iter: 0; batch classifier loss: 0.521739; batch adversarial loss: 0.585852\n",
      "epoch 167; iter: 0; batch classifier loss: 0.471981; batch adversarial loss: 0.570354\n",
      "epoch 168; iter: 0; batch classifier loss: 0.573861; batch adversarial loss: 0.599847\n",
      "epoch 169; iter: 0; batch classifier loss: 0.524355; batch adversarial loss: 0.587372\n",
      "epoch 170; iter: 0; batch classifier loss: 0.606854; batch adversarial loss: 0.552705\n",
      "epoch 171; iter: 0; batch classifier loss: 0.454433; batch adversarial loss: 0.521888\n",
      "epoch 172; iter: 0; batch classifier loss: 0.489271; batch adversarial loss: 0.581929\n",
      "epoch 173; iter: 0; batch classifier loss: 0.536116; batch adversarial loss: 0.542454\n",
      "epoch 174; iter: 0; batch classifier loss: 0.559715; batch adversarial loss: 0.546214\n",
      "epoch 175; iter: 0; batch classifier loss: 0.488661; batch adversarial loss: 0.553513\n",
      "epoch 176; iter: 0; batch classifier loss: 0.628576; batch adversarial loss: 0.521582\n",
      "epoch 177; iter: 0; batch classifier loss: 0.571827; batch adversarial loss: 0.604246\n",
      "epoch 178; iter: 0; batch classifier loss: 0.359855; batch adversarial loss: 0.552654\n",
      "epoch 179; iter: 0; batch classifier loss: 0.488513; batch adversarial loss: 0.603379\n",
      "epoch 180; iter: 0; batch classifier loss: 0.472652; batch adversarial loss: 0.533696\n",
      "epoch 181; iter: 0; batch classifier loss: 0.626068; batch adversarial loss: 0.631924\n",
      "epoch 182; iter: 0; batch classifier loss: 0.525463; batch adversarial loss: 0.595273\n",
      "epoch 183; iter: 0; batch classifier loss: 0.654864; batch adversarial loss: 0.643193\n",
      "epoch 184; iter: 0; batch classifier loss: 0.482734; batch adversarial loss: 0.525264\n",
      "epoch 185; iter: 0; batch classifier loss: 0.582057; batch adversarial loss: 0.618371\n",
      "epoch 186; iter: 0; batch classifier loss: 0.425288; batch adversarial loss: 0.528490\n",
      "epoch 187; iter: 0; batch classifier loss: 0.473636; batch adversarial loss: 0.557245\n",
      "epoch 188; iter: 0; batch classifier loss: 0.432592; batch adversarial loss: 0.561433\n",
      "epoch 189; iter: 0; batch classifier loss: 0.576010; batch adversarial loss: 0.566301\n",
      "epoch 190; iter: 0; batch classifier loss: 0.516132; batch adversarial loss: 0.525112\n",
      "epoch 191; iter: 0; batch classifier loss: 0.383875; batch adversarial loss: 0.595576\n",
      "epoch 192; iter: 0; batch classifier loss: 0.454518; batch adversarial loss: 0.565624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 193; iter: 0; batch classifier loss: 0.534291; batch adversarial loss: 0.502113\n",
      "epoch 194; iter: 0; batch classifier loss: 0.449310; batch adversarial loss: 0.593936\n",
      "epoch 195; iter: 0; batch classifier loss: 0.641599; batch adversarial loss: 0.526505\n",
      "epoch 196; iter: 0; batch classifier loss: 0.538123; batch adversarial loss: 0.598084\n",
      "epoch 197; iter: 0; batch classifier loss: 0.398524; batch adversarial loss: 0.612518\n",
      "epoch 198; iter: 0; batch classifier loss: 0.563690; batch adversarial loss: 0.603115\n",
      "epoch 199; iter: 0; batch classifier loss: 0.327213; batch adversarial loss: 0.656943\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.970441; batch adversarial loss: 0.917116\n",
      "epoch 2; iter: 0; batch classifier loss: 0.980249; batch adversarial loss: 0.815629\n",
      "epoch 3; iter: 0; batch classifier loss: 0.861581; batch adversarial loss: 0.788022\n",
      "epoch 4; iter: 0; batch classifier loss: 0.826976; batch adversarial loss: 0.792350\n",
      "epoch 5; iter: 0; batch classifier loss: 0.877856; batch adversarial loss: 0.690827\n",
      "epoch 6; iter: 0; batch classifier loss: 0.756070; batch adversarial loss: 0.733023\n",
      "epoch 7; iter: 0; batch classifier loss: 0.727784; batch adversarial loss: 0.710003\n",
      "epoch 8; iter: 0; batch classifier loss: 0.672345; batch adversarial loss: 0.667600\n",
      "epoch 9; iter: 0; batch classifier loss: 0.685560; batch adversarial loss: 0.715370\n",
      "epoch 10; iter: 0; batch classifier loss: 0.684649; batch adversarial loss: 0.714914\n",
      "epoch 11; iter: 0; batch classifier loss: 0.691359; batch adversarial loss: 0.651897\n",
      "epoch 12; iter: 0; batch classifier loss: 0.709378; batch adversarial loss: 0.667951\n",
      "epoch 13; iter: 0; batch classifier loss: 0.678434; batch adversarial loss: 0.680900\n",
      "epoch 14; iter: 0; batch classifier loss: 0.684662; batch adversarial loss: 0.649543\n",
      "epoch 15; iter: 0; batch classifier loss: 0.617975; batch adversarial loss: 0.634672\n",
      "epoch 16; iter: 0; batch classifier loss: 0.658236; batch adversarial loss: 0.609845\n",
      "epoch 17; iter: 0; batch classifier loss: 0.622561; batch adversarial loss: 0.653230\n",
      "epoch 18; iter: 0; batch classifier loss: 0.613213; batch adversarial loss: 0.586898\n",
      "epoch 19; iter: 0; batch classifier loss: 0.636423; batch adversarial loss: 0.620925\n",
      "epoch 20; iter: 0; batch classifier loss: 0.673770; batch adversarial loss: 0.652513\n",
      "epoch 21; iter: 0; batch classifier loss: 0.627144; batch adversarial loss: 0.613200\n",
      "epoch 22; iter: 0; batch classifier loss: 0.578068; batch adversarial loss: 0.588522\n",
      "epoch 23; iter: 0; batch classifier loss: 0.579643; batch adversarial loss: 0.547121\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485034; batch adversarial loss: 0.546305\n",
      "epoch 25; iter: 0; batch classifier loss: 0.526438; batch adversarial loss: 0.545518\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478877; batch adversarial loss: 0.609034\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439136; batch adversarial loss: 0.600554\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538733; batch adversarial loss: 0.578562\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485785; batch adversarial loss: 0.562134\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486543; batch adversarial loss: 0.556009\n",
      "epoch 31; iter: 0; batch classifier loss: 0.497710; batch adversarial loss: 0.547683\n",
      "epoch 32; iter: 0; batch classifier loss: 0.616287; batch adversarial loss: 0.567035\n",
      "epoch 33; iter: 0; batch classifier loss: 0.696492; batch adversarial loss: 0.601407\n",
      "epoch 34; iter: 0; batch classifier loss: 0.764234; batch adversarial loss: 0.662325\n",
      "epoch 35; iter: 0; batch classifier loss: 0.752374; batch adversarial loss: 0.600060\n",
      "epoch 36; iter: 0; batch classifier loss: 0.766551; batch adversarial loss: 0.583153\n",
      "epoch 37; iter: 0; batch classifier loss: 0.662459; batch adversarial loss: 0.623480\n",
      "epoch 38; iter: 0; batch classifier loss: 0.575616; batch adversarial loss: 0.536682\n",
      "epoch 39; iter: 0; batch classifier loss: 0.489897; batch adversarial loss: 0.634302\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477206; batch adversarial loss: 0.615449\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465995; batch adversarial loss: 0.512016\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452386; batch adversarial loss: 0.583071\n",
      "epoch 43; iter: 0; batch classifier loss: 0.606601; batch adversarial loss: 0.553031\n",
      "epoch 44; iter: 0; batch classifier loss: 0.516879; batch adversarial loss: 0.695715\n",
      "epoch 45; iter: 0; batch classifier loss: 0.545901; batch adversarial loss: 0.582061\n",
      "epoch 46; iter: 0; batch classifier loss: 0.510701; batch adversarial loss: 0.561258\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440677; batch adversarial loss: 0.587675\n",
      "epoch 48; iter: 0; batch classifier loss: 0.486999; batch adversarial loss: 0.553209\n",
      "epoch 49; iter: 0; batch classifier loss: 0.470820; batch adversarial loss: 0.550504\n",
      "epoch 50; iter: 0; batch classifier loss: 0.489321; batch adversarial loss: 0.512197\n",
      "epoch 51; iter: 0; batch classifier loss: 0.479811; batch adversarial loss: 0.600308\n",
      "epoch 52; iter: 0; batch classifier loss: 0.512926; batch adversarial loss: 0.524307\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465077; batch adversarial loss: 0.581652\n",
      "epoch 54; iter: 0; batch classifier loss: 0.499889; batch adversarial loss: 0.624056\n",
      "epoch 55; iter: 0; batch classifier loss: 0.547053; batch adversarial loss: 0.527800\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423665; batch adversarial loss: 0.529697\n",
      "epoch 57; iter: 0; batch classifier loss: 0.485447; batch adversarial loss: 0.579826\n",
      "epoch 58; iter: 0; batch classifier loss: 0.465126; batch adversarial loss: 0.546320\n",
      "epoch 59; iter: 0; batch classifier loss: 0.505928; batch adversarial loss: 0.565643\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394514; batch adversarial loss: 0.617245\n",
      "epoch 61; iter: 0; batch classifier loss: 0.473547; batch adversarial loss: 0.615142\n",
      "epoch 62; iter: 0; batch classifier loss: 0.572903; batch adversarial loss: 0.619802\n",
      "epoch 63; iter: 0; batch classifier loss: 0.479876; batch adversarial loss: 0.636181\n",
      "epoch 64; iter: 0; batch classifier loss: 0.527095; batch adversarial loss: 0.587296\n",
      "epoch 65; iter: 0; batch classifier loss: 0.477408; batch adversarial loss: 0.621977\n",
      "epoch 66; iter: 0; batch classifier loss: 0.482843; batch adversarial loss: 0.601685\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406924; batch adversarial loss: 0.540760\n",
      "epoch 68; iter: 0; batch classifier loss: 0.568441; batch adversarial loss: 0.493552\n",
      "epoch 69; iter: 0; batch classifier loss: 0.480464; batch adversarial loss: 0.591765\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418636; batch adversarial loss: 0.619401\n",
      "epoch 71; iter: 0; batch classifier loss: 0.511739; batch adversarial loss: 0.531178\n",
      "epoch 72; iter: 0; batch classifier loss: 0.495783; batch adversarial loss: 0.558896\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393321; batch adversarial loss: 0.569854\n",
      "epoch 74; iter: 0; batch classifier loss: 0.595805; batch adversarial loss: 0.586094\n",
      "epoch 75; iter: 0; batch classifier loss: 0.379941; batch adversarial loss: 0.543659\n",
      "epoch 76; iter: 0; batch classifier loss: 0.500844; batch adversarial loss: 0.570308\n",
      "epoch 77; iter: 0; batch classifier loss: 0.480852; batch adversarial loss: 0.482717\n",
      "epoch 78; iter: 0; batch classifier loss: 0.501473; batch adversarial loss: 0.547864\n",
      "epoch 79; iter: 0; batch classifier loss: 0.430830; batch adversarial loss: 0.603182\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365928; batch adversarial loss: 0.609191\n",
      "epoch 81; iter: 0; batch classifier loss: 0.483483; batch adversarial loss: 0.597302\n",
      "epoch 82; iter: 0; batch classifier loss: 0.495178; batch adversarial loss: 0.529112\n",
      "epoch 83; iter: 0; batch classifier loss: 0.466610; batch adversarial loss: 0.619931\n",
      "epoch 84; iter: 0; batch classifier loss: 0.452783; batch adversarial loss: 0.602325\n",
      "epoch 85; iter: 0; batch classifier loss: 0.386652; batch adversarial loss: 0.608570\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420444; batch adversarial loss: 0.618801\n",
      "epoch 87; iter: 0; batch classifier loss: 0.441340; batch adversarial loss: 0.595318\n",
      "epoch 88; iter: 0; batch classifier loss: 0.579314; batch adversarial loss: 0.495492\n",
      "epoch 89; iter: 0; batch classifier loss: 0.449086; batch adversarial loss: 0.546922\n",
      "epoch 90; iter: 0; batch classifier loss: 0.457446; batch adversarial loss: 0.543700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91; iter: 0; batch classifier loss: 0.467135; batch adversarial loss: 0.608576\n",
      "epoch 92; iter: 0; batch classifier loss: 0.436035; batch adversarial loss: 0.630257\n",
      "epoch 93; iter: 0; batch classifier loss: 0.589820; batch adversarial loss: 0.556732\n",
      "epoch 94; iter: 0; batch classifier loss: 0.508319; batch adversarial loss: 0.506355\n",
      "epoch 95; iter: 0; batch classifier loss: 0.521758; batch adversarial loss: 0.582259\n",
      "epoch 96; iter: 0; batch classifier loss: 0.441302; batch adversarial loss: 0.572543\n",
      "epoch 97; iter: 0; batch classifier loss: 0.535793; batch adversarial loss: 0.635664\n",
      "epoch 98; iter: 0; batch classifier loss: 0.467300; batch adversarial loss: 0.518668\n",
      "epoch 99; iter: 0; batch classifier loss: 0.441827; batch adversarial loss: 0.549228\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.934149; batch adversarial loss: 0.913231\n",
      "epoch 2; iter: 0; batch classifier loss: 0.939975; batch adversarial loss: 0.812699\n",
      "epoch 3; iter: 0; batch classifier loss: 0.798664; batch adversarial loss: 0.782486\n",
      "epoch 4; iter: 0; batch classifier loss: 0.711364; batch adversarial loss: 0.780693\n",
      "epoch 5; iter: 0; batch classifier loss: 0.663804; batch adversarial loss: 0.677394\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599495; batch adversarial loss: 0.699500\n",
      "epoch 7; iter: 0; batch classifier loss: 0.502616; batch adversarial loss: 0.668352\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466255; batch adversarial loss: 0.639601\n",
      "epoch 9; iter: 0; batch classifier loss: 0.435872; batch adversarial loss: 0.663280\n",
      "epoch 10; iter: 0; batch classifier loss: 0.446630; batch adversarial loss: 0.660997\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543844; batch adversarial loss: 0.617729\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529649; batch adversarial loss: 0.624284\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510407; batch adversarial loss: 0.629046\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487060; batch adversarial loss: 0.607046\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481446; batch adversarial loss: 0.596598\n",
      "epoch 16; iter: 0; batch classifier loss: 0.486924; batch adversarial loss: 0.570743\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518256; batch adversarial loss: 0.612953\n",
      "epoch 18; iter: 0; batch classifier loss: 0.469486; batch adversarial loss: 0.560305\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444605; batch adversarial loss: 0.588923\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477719; batch adversarial loss: 0.628874\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498590; batch adversarial loss: 0.601542\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526284; batch adversarial loss: 0.603706\n",
      "epoch 23; iter: 0; batch classifier loss: 0.621664; batch adversarial loss: 0.581766\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484163; batch adversarial loss: 0.575815\n",
      "epoch 25; iter: 0; batch classifier loss: 0.615361; batch adversarial loss: 0.608988\n",
      "epoch 26; iter: 0; batch classifier loss: 0.868588; batch adversarial loss: 0.717355\n",
      "epoch 27; iter: 0; batch classifier loss: 0.875578; batch adversarial loss: 0.691774\n",
      "epoch 28; iter: 0; batch classifier loss: 0.867810; batch adversarial loss: 0.639018\n",
      "epoch 29; iter: 0; batch classifier loss: 0.750128; batch adversarial loss: 0.614740\n",
      "epoch 30; iter: 0; batch classifier loss: 0.605034; batch adversarial loss: 0.589680\n",
      "epoch 31; iter: 0; batch classifier loss: 0.517469; batch adversarial loss: 0.559354\n",
      "epoch 32; iter: 0; batch classifier loss: 0.554371; batch adversarial loss: 0.566483\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477909; batch adversarial loss: 0.574646\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474088; batch adversarial loss: 0.615281\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390755; batch adversarial loss: 0.573000\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438016; batch adversarial loss: 0.570938\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460059; batch adversarial loss: 0.622596\n",
      "epoch 38; iter: 0; batch classifier loss: 0.510636; batch adversarial loss: 0.531083\n",
      "epoch 39; iter: 0; batch classifier loss: 0.428207; batch adversarial loss: 0.641597\n",
      "epoch 40; iter: 0; batch classifier loss: 0.486701; batch adversarial loss: 0.629433\n",
      "epoch 41; iter: 0; batch classifier loss: 0.507735; batch adversarial loss: 0.525005\n",
      "epoch 42; iter: 0; batch classifier loss: 0.565746; batch adversarial loss: 0.605833\n",
      "epoch 43; iter: 0; batch classifier loss: 0.748713; batch adversarial loss: 0.577227\n",
      "epoch 44; iter: 0; batch classifier loss: 0.875283; batch adversarial loss: 0.717003\n",
      "epoch 45; iter: 0; batch classifier loss: 0.766726; batch adversarial loss: 0.588112\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454909; batch adversarial loss: 0.562839\n",
      "epoch 47; iter: 0; batch classifier loss: 0.392077; batch adversarial loss: 0.588693\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443021; batch adversarial loss: 0.554191\n",
      "epoch 49; iter: 0; batch classifier loss: 0.431013; batch adversarial loss: 0.552235\n",
      "epoch 50; iter: 0; batch classifier loss: 0.466389; batch adversarial loss: 0.514866\n",
      "epoch 51; iter: 0; batch classifier loss: 0.465908; batch adversarial loss: 0.601753\n",
      "epoch 52; iter: 0; batch classifier loss: 0.457373; batch adversarial loss: 0.526437\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445644; batch adversarial loss: 0.582759\n",
      "epoch 54; iter: 0; batch classifier loss: 0.459450; batch adversarial loss: 0.625422\n",
      "epoch 55; iter: 0; batch classifier loss: 0.526875; batch adversarial loss: 0.528869\n",
      "epoch 56; iter: 0; batch classifier loss: 0.378626; batch adversarial loss: 0.531266\n",
      "epoch 57; iter: 0; batch classifier loss: 0.439443; batch adversarial loss: 0.580207\n",
      "epoch 58; iter: 0; batch classifier loss: 0.420765; batch adversarial loss: 0.546966\n",
      "epoch 59; iter: 0; batch classifier loss: 0.468801; batch adversarial loss: 0.565028\n",
      "epoch 60; iter: 0; batch classifier loss: 0.387851; batch adversarial loss: 0.617197\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446873; batch adversarial loss: 0.614909\n",
      "epoch 62; iter: 0; batch classifier loss: 0.514142; batch adversarial loss: 0.621861\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432392; batch adversarial loss: 0.637615\n",
      "epoch 64; iter: 0; batch classifier loss: 0.506021; batch adversarial loss: 0.588093\n",
      "epoch 65; iter: 0; batch classifier loss: 0.475090; batch adversarial loss: 0.624229\n",
      "epoch 66; iter: 0; batch classifier loss: 0.441449; batch adversarial loss: 0.601765\n",
      "epoch 67; iter: 0; batch classifier loss: 0.376902; batch adversarial loss: 0.541653\n",
      "epoch 68; iter: 0; batch classifier loss: 0.541101; batch adversarial loss: 0.496554\n",
      "epoch 69; iter: 0; batch classifier loss: 0.448590; batch adversarial loss: 0.592782\n",
      "epoch 70; iter: 0; batch classifier loss: 0.425305; batch adversarial loss: 0.622877\n",
      "epoch 71; iter: 0; batch classifier loss: 0.479647; batch adversarial loss: 0.532601\n",
      "epoch 72; iter: 0; batch classifier loss: 0.464705; batch adversarial loss: 0.563888\n",
      "epoch 73; iter: 0; batch classifier loss: 0.348154; batch adversarial loss: 0.571164\n",
      "epoch 74; iter: 0; batch classifier loss: 0.568501; batch adversarial loss: 0.588381\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362396; batch adversarial loss: 0.544429\n",
      "epoch 76; iter: 0; batch classifier loss: 0.481506; batch adversarial loss: 0.571928\n",
      "epoch 77; iter: 0; batch classifier loss: 0.454454; batch adversarial loss: 0.484077\n",
      "epoch 78; iter: 0; batch classifier loss: 0.515388; batch adversarial loss: 0.550603\n",
      "epoch 79; iter: 0; batch classifier loss: 0.463134; batch adversarial loss: 0.608749\n",
      "epoch 80; iter: 0; batch classifier loss: 0.364840; batch adversarial loss: 0.611734\n",
      "epoch 81; iter: 0; batch classifier loss: 0.481454; batch adversarial loss: 0.601233\n",
      "epoch 82; iter: 0; batch classifier loss: 0.441969; batch adversarial loss: 0.528971\n",
      "epoch 83; iter: 0; batch classifier loss: 0.479913; batch adversarial loss: 0.624383\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446342; batch adversarial loss: 0.606315\n",
      "epoch 85; iter: 0; batch classifier loss: 0.368918; batch adversarial loss: 0.610350\n",
      "epoch 86; iter: 0; batch classifier loss: 0.459572; batch adversarial loss: 0.624028\n",
      "epoch 87; iter: 0; batch classifier loss: 0.448103; batch adversarial loss: 0.599387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.546433; batch adversarial loss: 0.496093\n",
      "epoch 89; iter: 0; batch classifier loss: 0.428845; batch adversarial loss: 0.547773\n",
      "epoch 90; iter: 0; batch classifier loss: 0.446218; batch adversarial loss: 0.545759\n",
      "epoch 91; iter: 0; batch classifier loss: 0.435201; batch adversarial loss: 0.612444\n",
      "epoch 92; iter: 0; batch classifier loss: 0.476045; batch adversarial loss: 0.630696\n",
      "epoch 93; iter: 0; batch classifier loss: 0.602315; batch adversarial loss: 0.559590\n",
      "epoch 94; iter: 0; batch classifier loss: 0.481810; batch adversarial loss: 0.506852\n",
      "epoch 95; iter: 0; batch classifier loss: 0.528361; batch adversarial loss: 0.587188\n",
      "epoch 96; iter: 0; batch classifier loss: 0.441655; batch adversarial loss: 0.575184\n",
      "epoch 97; iter: 0; batch classifier loss: 0.551246; batch adversarial loss: 0.642231\n",
      "epoch 98; iter: 0; batch classifier loss: 0.463192; batch adversarial loss: 0.519577\n",
      "epoch 99; iter: 0; batch classifier loss: 0.454525; batch adversarial loss: 0.549749\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.910483; batch adversarial loss: 0.910364\n",
      "epoch 2; iter: 0; batch classifier loss: 0.913173; batch adversarial loss: 0.810465\n",
      "epoch 3; iter: 0; batch classifier loss: 0.757938; batch adversarial loss: 0.778285\n",
      "epoch 4; iter: 0; batch classifier loss: 0.649489; batch adversarial loss: 0.773741\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572397; batch adversarial loss: 0.669970\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569426; batch adversarial loss: 0.682508\n",
      "epoch 7; iter: 0; batch classifier loss: 0.478402; batch adversarial loss: 0.663807\n",
      "epoch 8; iter: 0; batch classifier loss: 0.464576; batch adversarial loss: 0.639194\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434345; batch adversarial loss: 0.662636\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445106; batch adversarial loss: 0.660647\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546380; batch adversarial loss: 0.617422\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526896; batch adversarial loss: 0.625190\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516521; batch adversarial loss: 0.627922\n",
      "epoch 14; iter: 0; batch classifier loss: 0.488163; batch adversarial loss: 0.606129\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488809; batch adversarial loss: 0.593915\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481649; batch adversarial loss: 0.568605\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515721; batch adversarial loss: 0.610303\n",
      "epoch 18; iter: 0; batch classifier loss: 0.469876; batch adversarial loss: 0.558476\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437640; batch adversarial loss: 0.586447\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474164; batch adversarial loss: 0.623473\n",
      "epoch 21; iter: 0; batch classifier loss: 0.489047; batch adversarial loss: 0.595363\n",
      "epoch 22; iter: 0; batch classifier loss: 0.498410; batch adversarial loss: 0.594317\n",
      "epoch 23; iter: 0; batch classifier loss: 0.597078; batch adversarial loss: 0.576482\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460339; batch adversarial loss: 0.568537\n",
      "epoch 25; iter: 0; batch classifier loss: 0.539330; batch adversarial loss: 0.587965\n",
      "epoch 26; iter: 0; batch classifier loss: 0.791802; batch adversarial loss: 0.724243\n",
      "epoch 27; iter: 0; batch classifier loss: 0.893094; batch adversarial loss: 0.709524\n",
      "epoch 28; iter: 0; batch classifier loss: 0.926940; batch adversarial loss: 0.652593\n",
      "epoch 29; iter: 0; batch classifier loss: 0.794210; batch adversarial loss: 0.625630\n",
      "epoch 30; iter: 0; batch classifier loss: 0.650106; batch adversarial loss: 0.596669\n",
      "epoch 31; iter: 0; batch classifier loss: 0.565669; batch adversarial loss: 0.565628\n",
      "epoch 32; iter: 0; batch classifier loss: 0.586606; batch adversarial loss: 0.571396\n",
      "epoch 33; iter: 0; batch classifier loss: 0.504821; batch adversarial loss: 0.579588\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453962; batch adversarial loss: 0.619943\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390667; batch adversarial loss: 0.575894\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443439; batch adversarial loss: 0.572127\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450439; batch adversarial loss: 0.620951\n",
      "epoch 38; iter: 0; batch classifier loss: 0.496307; batch adversarial loss: 0.529287\n",
      "epoch 39; iter: 0; batch classifier loss: 0.399515; batch adversarial loss: 0.634394\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434559; batch adversarial loss: 0.620858\n",
      "epoch 41; iter: 0; batch classifier loss: 0.462662; batch adversarial loss: 0.519406\n",
      "epoch 42; iter: 0; batch classifier loss: 0.493797; batch adversarial loss: 0.599623\n",
      "epoch 43; iter: 0; batch classifier loss: 0.664019; batch adversarial loss: 0.575797\n",
      "epoch 44; iter: 0; batch classifier loss: 0.788158; batch adversarial loss: 0.728797\n",
      "epoch 45; iter: 0; batch classifier loss: 0.791265; batch adversarial loss: 0.598036\n",
      "epoch 46; iter: 0; batch classifier loss: 0.665878; batch adversarial loss: 0.565116\n",
      "epoch 47; iter: 0; batch classifier loss: 0.375198; batch adversarial loss: 0.588223\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440037; batch adversarial loss: 0.554155\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417025; batch adversarial loss: 0.551892\n",
      "epoch 50; iter: 0; batch classifier loss: 0.451555; batch adversarial loss: 0.514828\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438062; batch adversarial loss: 0.600819\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442034; batch adversarial loss: 0.525802\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421358; batch adversarial loss: 0.581715\n",
      "epoch 54; iter: 0; batch classifier loss: 0.447422; batch adversarial loss: 0.624205\n",
      "epoch 55; iter: 0; batch classifier loss: 0.510117; batch adversarial loss: 0.528299\n",
      "epoch 56; iter: 0; batch classifier loss: 0.361378; batch adversarial loss: 0.529144\n",
      "epoch 57; iter: 0; batch classifier loss: 0.428514; batch adversarial loss: 0.579050\n",
      "epoch 58; iter: 0; batch classifier loss: 0.408806; batch adversarial loss: 0.545904\n",
      "epoch 59; iter: 0; batch classifier loss: 0.445240; batch adversarial loss: 0.563681\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385609; batch adversarial loss: 0.616877\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439703; batch adversarial loss: 0.613832\n",
      "epoch 62; iter: 0; batch classifier loss: 0.501703; batch adversarial loss: 0.620217\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423853; batch adversarial loss: 0.636952\n",
      "epoch 64; iter: 0; batch classifier loss: 0.503677; batch adversarial loss: 0.586624\n",
      "epoch 65; iter: 0; batch classifier loss: 0.468730; batch adversarial loss: 0.623606\n",
      "epoch 66; iter: 0; batch classifier loss: 0.438901; batch adversarial loss: 0.601012\n",
      "epoch 67; iter: 0; batch classifier loss: 0.371485; batch adversarial loss: 0.541211\n",
      "epoch 68; iter: 0; batch classifier loss: 0.526699; batch adversarial loss: 0.495529\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442984; batch adversarial loss: 0.591496\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418275; batch adversarial loss: 0.622000\n",
      "epoch 71; iter: 0; batch classifier loss: 0.477307; batch adversarial loss: 0.531856\n",
      "epoch 72; iter: 0; batch classifier loss: 0.442062; batch adversarial loss: 0.562473\n",
      "epoch 73; iter: 0; batch classifier loss: 0.341867; batch adversarial loss: 0.570373\n",
      "epoch 74; iter: 0; batch classifier loss: 0.538408; batch adversarial loss: 0.587460\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354205; batch adversarial loss: 0.543053\n",
      "epoch 76; iter: 0; batch classifier loss: 0.465943; batch adversarial loss: 0.570303\n",
      "epoch 77; iter: 0; batch classifier loss: 0.435511; batch adversarial loss: 0.483435\n",
      "epoch 78; iter: 0; batch classifier loss: 0.514192; batch adversarial loss: 0.549435\n",
      "epoch 79; iter: 0; batch classifier loss: 0.450908; batch adversarial loss: 0.607587\n",
      "epoch 80; iter: 0; batch classifier loss: 0.346739; batch adversarial loss: 0.609910\n",
      "epoch 81; iter: 0; batch classifier loss: 0.469714; batch adversarial loss: 0.600424\n",
      "epoch 82; iter: 0; batch classifier loss: 0.448173; batch adversarial loss: 0.529409\n",
      "epoch 83; iter: 0; batch classifier loss: 0.461544; batch adversarial loss: 0.622624\n",
      "epoch 84; iter: 0; batch classifier loss: 0.441216; batch adversarial loss: 0.605969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85; iter: 0; batch classifier loss: 0.342454; batch adversarial loss: 0.608640\n",
      "epoch 86; iter: 0; batch classifier loss: 0.455972; batch adversarial loss: 0.624040\n",
      "epoch 87; iter: 0; batch classifier loss: 0.439530; batch adversarial loss: 0.599047\n",
      "epoch 88; iter: 0; batch classifier loss: 0.530677; batch adversarial loss: 0.496607\n",
      "epoch 89; iter: 0; batch classifier loss: 0.429495; batch adversarial loss: 0.547256\n",
      "epoch 90; iter: 0; batch classifier loss: 0.427623; batch adversarial loss: 0.544645\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399657; batch adversarial loss: 0.610532\n",
      "epoch 92; iter: 0; batch classifier loss: 0.473666; batch adversarial loss: 0.631088\n",
      "epoch 93; iter: 0; batch classifier loss: 0.584066; batch adversarial loss: 0.557385\n",
      "epoch 94; iter: 0; batch classifier loss: 0.471681; batch adversarial loss: 0.505903\n",
      "epoch 95; iter: 0; batch classifier loss: 0.516549; batch adversarial loss: 0.585278\n",
      "epoch 96; iter: 0; batch classifier loss: 0.432355; batch adversarial loss: 0.575505\n",
      "epoch 97; iter: 0; batch classifier loss: 0.512975; batch adversarial loss: 0.643927\n",
      "epoch 98; iter: 0; batch classifier loss: 0.446548; batch adversarial loss: 0.518633\n",
      "epoch 99; iter: 0; batch classifier loss: 0.474219; batch adversarial loss: 0.550906\n",
      "epoch 100; iter: 0; batch classifier loss: 0.565995; batch adversarial loss: 0.583259\n",
      "epoch 101; iter: 0; batch classifier loss: 0.434100; batch adversarial loss: 0.626127\n",
      "epoch 102; iter: 0; batch classifier loss: 0.653624; batch adversarial loss: 0.542463\n",
      "epoch 103; iter: 0; batch classifier loss: 0.589633; batch adversarial loss: 0.567312\n",
      "epoch 104; iter: 0; batch classifier loss: 0.437598; batch adversarial loss: 0.539548\n",
      "epoch 105; iter: 0; batch classifier loss: 0.494070; batch adversarial loss: 0.647659\n",
      "epoch 106; iter: 0; batch classifier loss: 0.447640; batch adversarial loss: 0.642907\n",
      "epoch 107; iter: 0; batch classifier loss: 0.576618; batch adversarial loss: 0.567734\n",
      "epoch 108; iter: 0; batch classifier loss: 0.457387; batch adversarial loss: 0.580855\n",
      "epoch 109; iter: 0; batch classifier loss: 0.645474; batch adversarial loss: 0.501315\n",
      "epoch 110; iter: 0; batch classifier loss: 0.604022; batch adversarial loss: 0.527996\n",
      "epoch 111; iter: 0; batch classifier loss: 0.466736; batch adversarial loss: 0.592136\n",
      "epoch 112; iter: 0; batch classifier loss: 0.587623; batch adversarial loss: 0.558868\n",
      "epoch 113; iter: 0; batch classifier loss: 0.588093; batch adversarial loss: 0.560414\n",
      "epoch 114; iter: 0; batch classifier loss: 0.511029; batch adversarial loss: 0.589068\n",
      "epoch 115; iter: 0; batch classifier loss: 0.480193; batch adversarial loss: 0.514913\n",
      "epoch 116; iter: 0; batch classifier loss: 0.504189; batch adversarial loss: 0.555166\n",
      "epoch 117; iter: 0; batch classifier loss: 0.468509; batch adversarial loss: 0.602012\n",
      "epoch 118; iter: 0; batch classifier loss: 0.494723; batch adversarial loss: 0.585521\n",
      "epoch 119; iter: 0; batch classifier loss: 0.471387; batch adversarial loss: 0.608449\n",
      "epoch 120; iter: 0; batch classifier loss: 0.437953; batch adversarial loss: 0.590854\n",
      "epoch 121; iter: 0; batch classifier loss: 0.602880; batch adversarial loss: 0.635226\n",
      "epoch 122; iter: 0; batch classifier loss: 0.651855; batch adversarial loss: 0.571117\n",
      "epoch 123; iter: 0; batch classifier loss: 0.630440; batch adversarial loss: 0.604290\n",
      "epoch 124; iter: 0; batch classifier loss: 0.565372; batch adversarial loss: 0.555291\n",
      "epoch 125; iter: 0; batch classifier loss: 0.553908; batch adversarial loss: 0.614368\n",
      "epoch 126; iter: 0; batch classifier loss: 0.615191; batch adversarial loss: 0.572549\n",
      "epoch 127; iter: 0; batch classifier loss: 0.534132; batch adversarial loss: 0.521602\n",
      "epoch 128; iter: 0; batch classifier loss: 0.460465; batch adversarial loss: 0.594781\n",
      "epoch 129; iter: 0; batch classifier loss: 0.503320; batch adversarial loss: 0.634404\n",
      "epoch 130; iter: 0; batch classifier loss: 0.544752; batch adversarial loss: 0.562131\n",
      "epoch 131; iter: 0; batch classifier loss: 0.483579; batch adversarial loss: 0.602719\n",
      "epoch 132; iter: 0; batch classifier loss: 0.565476; batch adversarial loss: 0.542833\n",
      "epoch 133; iter: 0; batch classifier loss: 0.545089; batch adversarial loss: 0.626260\n",
      "epoch 134; iter: 0; batch classifier loss: 0.497036; batch adversarial loss: 0.564112\n",
      "epoch 135; iter: 0; batch classifier loss: 0.583816; batch adversarial loss: 0.630980\n",
      "epoch 136; iter: 0; batch classifier loss: 0.556459; batch adversarial loss: 0.569216\n",
      "epoch 137; iter: 0; batch classifier loss: 0.457539; batch adversarial loss: 0.648121\n",
      "epoch 138; iter: 0; batch classifier loss: 0.511780; batch adversarial loss: 0.555909\n",
      "epoch 139; iter: 0; batch classifier loss: 0.510293; batch adversarial loss: 0.548737\n",
      "epoch 140; iter: 0; batch classifier loss: 0.525178; batch adversarial loss: 0.611553\n",
      "epoch 141; iter: 0; batch classifier loss: 0.581818; batch adversarial loss: 0.500490\n",
      "epoch 142; iter: 0; batch classifier loss: 0.664028; batch adversarial loss: 0.578118\n",
      "epoch 143; iter: 0; batch classifier loss: 0.553619; batch adversarial loss: 0.497412\n",
      "epoch 144; iter: 0; batch classifier loss: 0.432653; batch adversarial loss: 0.611818\n",
      "epoch 145; iter: 0; batch classifier loss: 0.513110; batch adversarial loss: 0.519243\n",
      "epoch 146; iter: 0; batch classifier loss: 0.651045; batch adversarial loss: 0.565237\n",
      "epoch 147; iter: 0; batch classifier loss: 0.559986; batch adversarial loss: 0.513480\n",
      "epoch 148; iter: 0; batch classifier loss: 0.680827; batch adversarial loss: 0.570581\n",
      "epoch 149; iter: 0; batch classifier loss: 0.528158; batch adversarial loss: 0.549880\n",
      "epoch 150; iter: 0; batch classifier loss: 0.559718; batch adversarial loss: 0.564806\n",
      "epoch 151; iter: 0; batch classifier loss: 0.563419; batch adversarial loss: 0.538641\n",
      "epoch 152; iter: 0; batch classifier loss: 0.511832; batch adversarial loss: 0.596663\n",
      "epoch 153; iter: 0; batch classifier loss: 0.695024; batch adversarial loss: 0.548867\n",
      "epoch 154; iter: 0; batch classifier loss: 0.493036; batch adversarial loss: 0.612217\n",
      "epoch 155; iter: 0; batch classifier loss: 0.512875; batch adversarial loss: 0.605528\n",
      "epoch 156; iter: 0; batch classifier loss: 0.328828; batch adversarial loss: 0.614116\n",
      "epoch 157; iter: 0; batch classifier loss: 0.490804; batch adversarial loss: 0.513424\n",
      "epoch 158; iter: 0; batch classifier loss: 0.624665; batch adversarial loss: 0.626403\n",
      "epoch 159; iter: 0; batch classifier loss: 0.495752; batch adversarial loss: 0.585594\n",
      "epoch 160; iter: 0; batch classifier loss: 0.577677; batch adversarial loss: 0.580280\n",
      "epoch 161; iter: 0; batch classifier loss: 0.591417; batch adversarial loss: 0.556305\n",
      "epoch 162; iter: 0; batch classifier loss: 0.522243; batch adversarial loss: 0.575366\n",
      "epoch 163; iter: 0; batch classifier loss: 0.637321; batch adversarial loss: 0.541810\n",
      "epoch 164; iter: 0; batch classifier loss: 0.460186; batch adversarial loss: 0.554704\n",
      "epoch 165; iter: 0; batch classifier loss: 0.597821; batch adversarial loss: 0.563006\n",
      "epoch 166; iter: 0; batch classifier loss: 0.542345; batch adversarial loss: 0.590017\n",
      "epoch 167; iter: 0; batch classifier loss: 0.495654; batch adversarial loss: 0.571134\n",
      "epoch 168; iter: 0; batch classifier loss: 0.620429; batch adversarial loss: 0.606195\n",
      "epoch 169; iter: 0; batch classifier loss: 0.557951; batch adversarial loss: 0.591270\n",
      "epoch 170; iter: 0; batch classifier loss: 0.627866; batch adversarial loss: 0.550585\n",
      "epoch 171; iter: 0; batch classifier loss: 0.485816; batch adversarial loss: 0.519485\n",
      "epoch 172; iter: 0; batch classifier loss: 0.516291; batch adversarial loss: 0.581437\n",
      "epoch 173; iter: 0; batch classifier loss: 0.566357; batch adversarial loss: 0.544988\n",
      "epoch 174; iter: 0; batch classifier loss: 0.581677; batch adversarial loss: 0.551046\n",
      "epoch 175; iter: 0; batch classifier loss: 0.509234; batch adversarial loss: 0.550474\n",
      "epoch 176; iter: 0; batch classifier loss: 0.646943; batch adversarial loss: 0.522390\n",
      "epoch 177; iter: 0; batch classifier loss: 0.585786; batch adversarial loss: 0.603960\n",
      "epoch 178; iter: 0; batch classifier loss: 0.402968; batch adversarial loss: 0.547067\n",
      "epoch 179; iter: 0; batch classifier loss: 0.544610; batch adversarial loss: 0.607710\n",
      "epoch 180; iter: 0; batch classifier loss: 0.513365; batch adversarial loss: 0.536664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 181; iter: 0; batch classifier loss: 0.703602; batch adversarial loss: 0.638155\n",
      "epoch 182; iter: 0; batch classifier loss: 0.523197; batch adversarial loss: 0.594817\n",
      "epoch 183; iter: 0; batch classifier loss: 0.637288; batch adversarial loss: 0.642667\n",
      "epoch 184; iter: 0; batch classifier loss: 0.497824; batch adversarial loss: 0.527586\n",
      "epoch 185; iter: 0; batch classifier loss: 0.636162; batch adversarial loss: 0.624207\n",
      "epoch 186; iter: 0; batch classifier loss: 0.495429; batch adversarial loss: 0.530912\n",
      "epoch 187; iter: 0; batch classifier loss: 0.499666; batch adversarial loss: 0.552786\n",
      "epoch 188; iter: 0; batch classifier loss: 0.474417; batch adversarial loss: 0.562927\n",
      "epoch 189; iter: 0; batch classifier loss: 0.565754; batch adversarial loss: 0.563411\n",
      "epoch 190; iter: 0; batch classifier loss: 0.550706; batch adversarial loss: 0.532119\n",
      "epoch 191; iter: 0; batch classifier loss: 0.423106; batch adversarial loss: 0.595646\n",
      "epoch 192; iter: 0; batch classifier loss: 0.504829; batch adversarial loss: 0.568959\n",
      "epoch 193; iter: 0; batch classifier loss: 0.530005; batch adversarial loss: 0.504350\n",
      "epoch 194; iter: 0; batch classifier loss: 0.495725; batch adversarial loss: 0.595370\n",
      "epoch 195; iter: 0; batch classifier loss: 0.663648; batch adversarial loss: 0.528896\n",
      "epoch 196; iter: 0; batch classifier loss: 0.615066; batch adversarial loss: 0.601406\n",
      "epoch 197; iter: 0; batch classifier loss: 0.444984; batch adversarial loss: 0.608201\n",
      "epoch 198; iter: 0; batch classifier loss: 0.574713; batch adversarial loss: 0.605325\n",
      "epoch 199; iter: 0; batch classifier loss: 0.348439; batch adversarial loss: 0.653690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.709988; batch adversarial loss: 0.791750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.859359; batch adversarial loss: 0.915447\n",
      "epoch 2; iter: 0; batch classifier loss: 0.913747; batch adversarial loss: 0.817913\n",
      "epoch 3; iter: 0; batch classifier loss: 0.722599; batch adversarial loss: 0.786484\n",
      "epoch 4; iter: 0; batch classifier loss: 0.640128; batch adversarial loss: 0.780033\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613501; batch adversarial loss: 0.676182\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535712; batch adversarial loss: 0.698373\n",
      "epoch 7; iter: 0; batch classifier loss: 0.478717; batch adversarial loss: 0.666135\n",
      "epoch 8; iter: 0; batch classifier loss: 0.452990; batch adversarial loss: 0.641389\n",
      "epoch 9; iter: 0; batch classifier loss: 0.430407; batch adversarial loss: 0.663897\n",
      "epoch 10; iter: 0; batch classifier loss: 0.441151; batch adversarial loss: 0.661897\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539085; batch adversarial loss: 0.617785\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507962; batch adversarial loss: 0.626026\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484423; batch adversarial loss: 0.629860\n",
      "epoch 14; iter: 0; batch classifier loss: 0.472011; batch adversarial loss: 0.609420\n",
      "epoch 15; iter: 0; batch classifier loss: 0.449989; batch adversarial loss: 0.599210\n",
      "epoch 16; iter: 0; batch classifier loss: 0.465943; batch adversarial loss: 0.571670\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486963; batch adversarial loss: 0.612577\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458243; batch adversarial loss: 0.559550\n",
      "epoch 19; iter: 0; batch classifier loss: 0.436258; batch adversarial loss: 0.612316\n",
      "epoch 20; iter: 0; batch classifier loss: 0.663144; batch adversarial loss: 0.702837\n",
      "epoch 21; iter: 0; batch classifier loss: 0.745087; batch adversarial loss: 0.689107\n",
      "epoch 22; iter: 0; batch classifier loss: 0.813270; batch adversarial loss: 0.675659\n",
      "epoch 23; iter: 0; batch classifier loss: 0.834285; batch adversarial loss: 0.606307\n",
      "epoch 24; iter: 0; batch classifier loss: 0.633585; batch adversarial loss: 0.594822\n",
      "epoch 25; iter: 0; batch classifier loss: 0.665396; batch adversarial loss: 0.593607\n",
      "epoch 26; iter: 0; batch classifier loss: 0.665763; batch adversarial loss: 0.654237\n",
      "epoch 27; iter: 0; batch classifier loss: 0.644088; batch adversarial loss: 0.640379\n",
      "epoch 28; iter: 0; batch classifier loss: 0.556516; batch adversarial loss: 0.606174\n",
      "epoch 29; iter: 0; batch classifier loss: 0.431613; batch adversarial loss: 0.586162\n",
      "epoch 30; iter: 0; batch classifier loss: 0.425416; batch adversarial loss: 0.568424\n",
      "epoch 31; iter: 0; batch classifier loss: 0.413328; batch adversarial loss: 0.536347\n",
      "epoch 32; iter: 0; batch classifier loss: 0.492854; batch adversarial loss: 0.546697\n",
      "epoch 33; iter: 0; batch classifier loss: 0.401609; batch adversarial loss: 0.560974\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363041; batch adversarial loss: 0.613982\n",
      "epoch 35; iter: 0; batch classifier loss: 0.362365; batch adversarial loss: 0.576153\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456410; batch adversarial loss: 0.592247\n",
      "epoch 37; iter: 0; batch classifier loss: 0.791003; batch adversarial loss: 0.684307\n",
      "epoch 38; iter: 0; batch classifier loss: 0.962596; batch adversarial loss: 0.569391\n",
      "epoch 39; iter: 0; batch classifier loss: 0.896760; batch adversarial loss: 0.662129\n",
      "epoch 40; iter: 0; batch classifier loss: 0.833903; batch adversarial loss: 0.623126\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403705; batch adversarial loss: 0.516166\n",
      "epoch 42; iter: 0; batch classifier loss: 0.387155; batch adversarial loss: 0.585165\n",
      "epoch 43; iter: 0; batch classifier loss: 0.461971; batch adversarial loss: 0.554575\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437257; batch adversarial loss: 0.695011\n",
      "epoch 45; iter: 0; batch classifier loss: 0.453462; batch adversarial loss: 0.584235\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432616; batch adversarial loss: 0.562831\n",
      "epoch 47; iter: 0; batch classifier loss: 0.352530; batch adversarial loss: 0.588537\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424829; batch adversarial loss: 0.555364\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391539; batch adversarial loss: 0.551909\n",
      "epoch 50; iter: 0; batch classifier loss: 0.388322; batch adversarial loss: 0.513265\n",
      "epoch 51; iter: 0; batch classifier loss: 0.405854; batch adversarial loss: 0.603074\n",
      "epoch 52; iter: 0; batch classifier loss: 0.457753; batch adversarial loss: 0.528819\n",
      "epoch 53; iter: 0; batch classifier loss: 0.400333; batch adversarial loss: 0.585954\n",
      "epoch 54; iter: 0; batch classifier loss: 0.476675; batch adversarial loss: 0.629569\n",
      "epoch 55; iter: 0; batch classifier loss: 0.467607; batch adversarial loss: 0.528508\n",
      "epoch 56; iter: 0; batch classifier loss: 0.370697; batch adversarial loss: 0.532825\n",
      "epoch 57; iter: 0; batch classifier loss: 0.436122; batch adversarial loss: 0.581063\n",
      "epoch 58; iter: 0; batch classifier loss: 0.373487; batch adversarial loss: 0.547732\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420441; batch adversarial loss: 0.567553\n",
      "epoch 60; iter: 0; batch classifier loss: 0.313002; batch adversarial loss: 0.617004\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454895; batch adversarial loss: 0.619222\n",
      "epoch 62; iter: 0; batch classifier loss: 0.508746; batch adversarial loss: 0.627194\n",
      "epoch 63; iter: 0; batch classifier loss: 0.387110; batch adversarial loss: 0.639179\n",
      "epoch 64; iter: 0; batch classifier loss: 0.520433; batch adversarial loss: 0.591843\n",
      "epoch 65; iter: 0; batch classifier loss: 0.464292; batch adversarial loss: 0.627046\n",
      "epoch 66; iter: 0; batch classifier loss: 0.473573; batch adversarial loss: 0.605845\n",
      "epoch 67; iter: 0; batch classifier loss: 0.348398; batch adversarial loss: 0.542917\n",
      "epoch 68; iter: 0; batch classifier loss: 0.568471; batch adversarial loss: 0.501943\n",
      "epoch 69; iter: 0; batch classifier loss: 0.443644; batch adversarial loss: 0.596461\n",
      "epoch 70; iter: 0; batch classifier loss: 0.476796; batch adversarial loss: 0.630343\n",
      "epoch 71; iter: 0; batch classifier loss: 0.492580; batch adversarial loss: 0.537403\n",
      "epoch 72; iter: 0; batch classifier loss: 0.454183; batch adversarial loss: 0.569326\n",
      "epoch 73; iter: 0; batch classifier loss: 0.356750; batch adversarial loss: 0.573022\n",
      "epoch 74; iter: 0; batch classifier loss: 0.551425; batch adversarial loss: 0.594440\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367855; batch adversarial loss: 0.549162\n",
      "epoch 76; iter: 0; batch classifier loss: 0.548424; batch adversarial loss: 0.576844\n",
      "epoch 77; iter: 0; batch classifier loss: 0.477635; batch adversarial loss: 0.488346\n",
      "epoch 78; iter: 0; batch classifier loss: 0.535797; batch adversarial loss: 0.553991\n",
      "epoch 79; iter: 0; batch classifier loss: 0.481720; batch adversarial loss: 0.613368\n",
      "epoch 80; iter: 0; batch classifier loss: 0.406130; batch adversarial loss: 0.618013\n",
      "epoch 81; iter: 0; batch classifier loss: 0.510869; batch adversarial loss: 0.605238\n",
      "epoch 82; iter: 0; batch classifier loss: 0.511575; batch adversarial loss: 0.534241\n",
      "epoch 83; iter: 0; batch classifier loss: 0.491487; batch adversarial loss: 0.630494\n",
      "epoch 84; iter: 0; batch classifier loss: 0.521213; batch adversarial loss: 0.612392\n",
      "epoch 85; iter: 0; batch classifier loss: 0.400287; batch adversarial loss: 0.615123\n",
      "epoch 86; iter: 0; batch classifier loss: 0.521522; batch adversarial loss: 0.626804\n",
      "epoch 87; iter: 0; batch classifier loss: 0.515345; batch adversarial loss: 0.608939\n",
      "epoch 88; iter: 0; batch classifier loss: 0.602699; batch adversarial loss: 0.503553\n",
      "epoch 89; iter: 0; batch classifier loss: 0.460048; batch adversarial loss: 0.553278\n",
      "epoch 90; iter: 0; batch classifier loss: 0.505105; batch adversarial loss: 0.551734\n",
      "epoch 91; iter: 0; batch classifier loss: 0.449538; batch adversarial loss: 0.618689\n",
      "epoch 92; iter: 0; batch classifier loss: 0.491012; batch adversarial loss: 0.632562\n",
      "epoch 93; iter: 0; batch classifier loss: 0.621869; batch adversarial loss: 0.562997\n",
      "epoch 94; iter: 0; batch classifier loss: 0.538609; batch adversarial loss: 0.512098\n",
      "epoch 95; iter: 0; batch classifier loss: 0.582896; batch adversarial loss: 0.595375\n",
      "epoch 96; iter: 0; batch classifier loss: 0.474682; batch adversarial loss: 0.572092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.558655; batch adversarial loss: 0.643785\n",
      "epoch 98; iter: 0; batch classifier loss: 0.500511; batch adversarial loss: 0.522957\n",
      "epoch 99; iter: 0; batch classifier loss: 0.507822; batch adversarial loss: 0.551695\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709988; batch adversarial loss: 0.791750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.793024; batch adversarial loss: 0.905437\n",
      "epoch 2; iter: 0; batch classifier loss: 0.791209; batch adversarial loss: 0.807048\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576412; batch adversarial loss: 0.771970\n",
      "epoch 4; iter: 0; batch classifier loss: 0.529834; batch adversarial loss: 0.765623\n",
      "epoch 5; iter: 0; batch classifier loss: 0.502650; batch adversarial loss: 0.667914\n",
      "epoch 6; iter: 0; batch classifier loss: 0.540799; batch adversarial loss: 0.687101\n",
      "epoch 7; iter: 0; batch classifier loss: 0.469573; batch adversarial loss: 0.666384\n",
      "epoch 8; iter: 0; batch classifier loss: 0.458805; batch adversarial loss: 0.642038\n",
      "epoch 9; iter: 0; batch classifier loss: 0.436690; batch adversarial loss: 0.664256\n",
      "epoch 10; iter: 0; batch classifier loss: 0.436133; batch adversarial loss: 0.664788\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538639; batch adversarial loss: 0.621035\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514606; batch adversarial loss: 0.627139\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489246; batch adversarial loss: 0.630860\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478222; batch adversarial loss: 0.608766\n",
      "epoch 15; iter: 0; batch classifier loss: 0.461140; batch adversarial loss: 0.593724\n",
      "epoch 16; iter: 0; batch classifier loss: 0.453061; batch adversarial loss: 0.566273\n",
      "epoch 17; iter: 0; batch classifier loss: 0.478702; batch adversarial loss: 0.604348\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452912; batch adversarial loss: 0.551455\n",
      "epoch 19; iter: 0; batch classifier loss: 0.395447; batch adversarial loss: 0.587893\n",
      "epoch 20; iter: 0; batch classifier loss: 0.431840; batch adversarial loss: 0.621260\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478381; batch adversarial loss: 0.589473\n",
      "epoch 22; iter: 0; batch classifier loss: 0.417208; batch adversarial loss: 0.556194\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477801; batch adversarial loss: 0.536637\n",
      "epoch 24; iter: 0; batch classifier loss: 0.405857; batch adversarial loss: 0.530806\n",
      "epoch 25; iter: 0; batch classifier loss: 0.454591; batch adversarial loss: 0.556471\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467907; batch adversarial loss: 0.651741\n",
      "epoch 27; iter: 0; batch classifier loss: 0.669776; batch adversarial loss: 0.706028\n",
      "epoch 28; iter: 0; batch classifier loss: 0.714101; batch adversarial loss: 0.665104\n",
      "epoch 29; iter: 0; batch classifier loss: 0.897942; batch adversarial loss: 0.681086\n",
      "epoch 30; iter: 0; batch classifier loss: 0.713569; batch adversarial loss: 0.629774\n",
      "epoch 31; iter: 0; batch classifier loss: 0.695968; batch adversarial loss: 0.598374\n",
      "epoch 32; iter: 0; batch classifier loss: 0.690915; batch adversarial loss: 0.594564\n",
      "epoch 33; iter: 0; batch classifier loss: 0.584553; batch adversarial loss: 0.596289\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481194; batch adversarial loss: 0.636785\n",
      "epoch 35; iter: 0; batch classifier loss: 0.385350; batch adversarial loss: 0.586761\n",
      "epoch 36; iter: 0; batch classifier loss: 0.398804; batch adversarial loss: 0.578446\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394017; batch adversarial loss: 0.623825\n",
      "epoch 38; iter: 0; batch classifier loss: 0.427520; batch adversarial loss: 0.530573\n",
      "epoch 39; iter: 0; batch classifier loss: 0.352485; batch adversarial loss: 0.628775\n",
      "epoch 40; iter: 0; batch classifier loss: 0.368922; batch adversarial loss: 0.617428\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389430; batch adversarial loss: 0.521741\n",
      "epoch 42; iter: 0; batch classifier loss: 0.456875; batch adversarial loss: 0.599535\n",
      "epoch 43; iter: 0; batch classifier loss: 0.582458; batch adversarial loss: 0.572576\n",
      "epoch 44; iter: 0; batch classifier loss: 0.712879; batch adversarial loss: 0.719933\n",
      "epoch 45; iter: 0; batch classifier loss: 0.754758; batch adversarial loss: 0.593138\n",
      "epoch 46; iter: 0; batch classifier loss: 0.412870; batch adversarial loss: 0.562397\n",
      "epoch 47; iter: 0; batch classifier loss: 0.325974; batch adversarial loss: 0.586053\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387553; batch adversarial loss: 0.554275\n",
      "epoch 49; iter: 0; batch classifier loss: 0.346245; batch adversarial loss: 0.549700\n",
      "epoch 50; iter: 0; batch classifier loss: 0.344625; batch adversarial loss: 0.512210\n",
      "epoch 51; iter: 0; batch classifier loss: 0.363315; batch adversarial loss: 0.598955\n",
      "epoch 52; iter: 0; batch classifier loss: 0.383240; batch adversarial loss: 0.525080\n",
      "epoch 53; iter: 0; batch classifier loss: 0.342666; batch adversarial loss: 0.583893\n",
      "epoch 54; iter: 0; batch classifier loss: 0.392266; batch adversarial loss: 0.625497\n",
      "epoch 55; iter: 0; batch classifier loss: 0.425086; batch adversarial loss: 0.527940\n",
      "epoch 56; iter: 0; batch classifier loss: 0.308976; batch adversarial loss: 0.527684\n",
      "epoch 57; iter: 0; batch classifier loss: 0.365912; batch adversarial loss: 0.576557\n",
      "epoch 58; iter: 0; batch classifier loss: 0.333178; batch adversarial loss: 0.544664\n",
      "epoch 59; iter: 0; batch classifier loss: 0.372951; batch adversarial loss: 0.563990\n",
      "epoch 60; iter: 0; batch classifier loss: 0.263303; batch adversarial loss: 0.614879\n",
      "epoch 61; iter: 0; batch classifier loss: 0.419009; batch adversarial loss: 0.614366\n",
      "epoch 62; iter: 0; batch classifier loss: 0.448692; batch adversarial loss: 0.622135\n",
      "epoch 63; iter: 0; batch classifier loss: 0.370977; batch adversarial loss: 0.637897\n",
      "epoch 64; iter: 0; batch classifier loss: 0.482947; batch adversarial loss: 0.586847\n",
      "epoch 65; iter: 0; batch classifier loss: 0.414513; batch adversarial loss: 0.621545\n",
      "epoch 66; iter: 0; batch classifier loss: 0.454706; batch adversarial loss: 0.604407\n",
      "epoch 67; iter: 0; batch classifier loss: 0.303498; batch adversarial loss: 0.539600\n",
      "epoch 68; iter: 0; batch classifier loss: 0.532036; batch adversarial loss: 0.499508\n",
      "epoch 69; iter: 0; batch classifier loss: 0.388543; batch adversarial loss: 0.591299\n",
      "epoch 70; iter: 0; batch classifier loss: 0.435792; batch adversarial loss: 0.626627\n",
      "epoch 71; iter: 0; batch classifier loss: 0.435380; batch adversarial loss: 0.532340\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411534; batch adversarial loss: 0.564464\n",
      "epoch 73; iter: 0; batch classifier loss: 0.332656; batch adversarial loss: 0.573806\n",
      "epoch 74; iter: 0; batch classifier loss: 0.503573; batch adversarial loss: 0.593549\n",
      "epoch 75; iter: 0; batch classifier loss: 0.343074; batch adversarial loss: 0.546652\n",
      "epoch 76; iter: 0; batch classifier loss: 0.504907; batch adversarial loss: 0.574732\n",
      "epoch 77; iter: 0; batch classifier loss: 0.384787; batch adversarial loss: 0.483934\n",
      "epoch 78; iter: 0; batch classifier loss: 0.487196; batch adversarial loss: 0.552238\n",
      "epoch 79; iter: 0; batch classifier loss: 0.444564; batch adversarial loss: 0.610330\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395619; batch adversarial loss: 0.614472\n",
      "epoch 81; iter: 0; batch classifier loss: 0.443810; batch adversarial loss: 0.599678\n",
      "epoch 82; iter: 0; batch classifier loss: 0.487293; batch adversarial loss: 0.534558\n",
      "epoch 83; iter: 0; batch classifier loss: 0.443135; batch adversarial loss: 0.626889\n",
      "epoch 84; iter: 0; batch classifier loss: 0.487336; batch adversarial loss: 0.611304\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376416; batch adversarial loss: 0.612955\n",
      "epoch 86; iter: 0; batch classifier loss: 0.478751; batch adversarial loss: 0.627171\n",
      "epoch 87; iter: 0; batch classifier loss: 0.458309; batch adversarial loss: 0.605636\n",
      "epoch 88; iter: 0; batch classifier loss: 0.546911; batch adversarial loss: 0.501359\n",
      "epoch 89; iter: 0; batch classifier loss: 0.414743; batch adversarial loss: 0.551004\n",
      "epoch 90; iter: 0; batch classifier loss: 0.453704; batch adversarial loss: 0.548599\n",
      "epoch 91; iter: 0; batch classifier loss: 0.429750; batch adversarial loss: 0.618508\n",
      "epoch 92; iter: 0; batch classifier loss: 0.465284; batch adversarial loss: 0.634517\n",
      "epoch 93; iter: 0; batch classifier loss: 0.578686; batch adversarial loss: 0.560680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.521726; batch adversarial loss: 0.510122\n",
      "epoch 95; iter: 0; batch classifier loss: 0.529135; batch adversarial loss: 0.589395\n",
      "epoch 96; iter: 0; batch classifier loss: 0.433131; batch adversarial loss: 0.573652\n",
      "epoch 97; iter: 0; batch classifier loss: 0.529714; batch adversarial loss: 0.646034\n",
      "epoch 98; iter: 0; batch classifier loss: 0.486356; batch adversarial loss: 0.523074\n",
      "epoch 99; iter: 0; batch classifier loss: 0.477150; batch adversarial loss: 0.552414\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.989443; batch adversarial loss: 0.918890\n",
      "epoch 2; iter: 0; batch classifier loss: 0.999420; batch adversarial loss: 0.816868\n",
      "epoch 3; iter: 0; batch classifier loss: 0.892650; batch adversarial loss: 0.790442\n",
      "epoch 4; iter: 0; batch classifier loss: 0.887273; batch adversarial loss: 0.797863\n",
      "epoch 5; iter: 0; batch classifier loss: 0.952508; batch adversarial loss: 0.693697\n",
      "epoch 6; iter: 0; batch classifier loss: 0.792919; batch adversarial loss: 0.738083\n",
      "epoch 7; iter: 0; batch classifier loss: 0.763733; batch adversarial loss: 0.714831\n",
      "epoch 8; iter: 0; batch classifier loss: 0.703005; batch adversarial loss: 0.670389\n",
      "epoch 9; iter: 0; batch classifier loss: 0.704616; batch adversarial loss: 0.716795\n",
      "epoch 10; iter: 0; batch classifier loss: 0.704960; batch adversarial loss: 0.716237\n",
      "epoch 11; iter: 0; batch classifier loss: 0.696741; batch adversarial loss: 0.653333\n",
      "epoch 12; iter: 0; batch classifier loss: 0.717380; batch adversarial loss: 0.668261\n",
      "epoch 13; iter: 0; batch classifier loss: 0.685185; batch adversarial loss: 0.680736\n",
      "epoch 14; iter: 0; batch classifier loss: 0.692727; batch adversarial loss: 0.649947\n",
      "epoch 15; iter: 0; batch classifier loss: 0.616314; batch adversarial loss: 0.635083\n",
      "epoch 16; iter: 0; batch classifier loss: 0.667174; batch adversarial loss: 0.610847\n",
      "epoch 17; iter: 0; batch classifier loss: 0.628528; batch adversarial loss: 0.653325\n",
      "epoch 18; iter: 0; batch classifier loss: 0.621299; batch adversarial loss: 0.587420\n",
      "epoch 19; iter: 0; batch classifier loss: 0.652490; batch adversarial loss: 0.621612\n",
      "epoch 20; iter: 0; batch classifier loss: 0.696476; batch adversarial loss: 0.653469\n",
      "epoch 21; iter: 0; batch classifier loss: 0.635087; batch adversarial loss: 0.613566\n",
      "epoch 22; iter: 0; batch classifier loss: 0.590605; batch adversarial loss: 0.589245\n",
      "epoch 23; iter: 0; batch classifier loss: 0.591869; batch adversarial loss: 0.547971\n",
      "epoch 24; iter: 0; batch classifier loss: 0.492276; batch adversarial loss: 0.548135\n",
      "epoch 25; iter: 0; batch classifier loss: 0.529946; batch adversarial loss: 0.548138\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482813; batch adversarial loss: 0.609932\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437156; batch adversarial loss: 0.601233\n",
      "epoch 28; iter: 0; batch classifier loss: 0.540424; batch adversarial loss: 0.578818\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479710; batch adversarial loss: 0.562482\n",
      "epoch 30; iter: 0; batch classifier loss: 0.487397; batch adversarial loss: 0.555610\n",
      "epoch 31; iter: 0; batch classifier loss: 0.493905; batch adversarial loss: 0.544756\n",
      "epoch 32; iter: 0; batch classifier loss: 0.613550; batch adversarial loss: 0.564020\n",
      "epoch 33; iter: 0; batch classifier loss: 0.656071; batch adversarial loss: 0.592215\n",
      "epoch 34; iter: 0; batch classifier loss: 0.738108; batch adversarial loss: 0.660331\n",
      "epoch 35; iter: 0; batch classifier loss: 0.755490; batch adversarial loss: 0.600097\n",
      "epoch 36; iter: 0; batch classifier loss: 0.768068; batch adversarial loss: 0.582825\n",
      "epoch 37; iter: 0; batch classifier loss: 0.590208; batch adversarial loss: 0.626177\n",
      "epoch 38; iter: 0; batch classifier loss: 0.544760; batch adversarial loss: 0.536818\n",
      "epoch 39; iter: 0; batch classifier loss: 0.491548; batch adversarial loss: 0.634141\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466170; batch adversarial loss: 0.613118\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470406; batch adversarial loss: 0.511578\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449781; batch adversarial loss: 0.582675\n",
      "epoch 43; iter: 0; batch classifier loss: 0.590316; batch adversarial loss: 0.553379\n",
      "epoch 44; iter: 0; batch classifier loss: 0.511356; batch adversarial loss: 0.696363\n",
      "epoch 45; iter: 0; batch classifier loss: 0.543799; batch adversarial loss: 0.582604\n",
      "epoch 46; iter: 0; batch classifier loss: 0.513365; batch adversarial loss: 0.561538\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430350; batch adversarial loss: 0.587266\n",
      "epoch 48; iter: 0; batch classifier loss: 0.481861; batch adversarial loss: 0.553031\n",
      "epoch 49; iter: 0; batch classifier loss: 0.471919; batch adversarial loss: 0.550405\n",
      "epoch 50; iter: 0; batch classifier loss: 0.483516; batch adversarial loss: 0.511938\n",
      "epoch 51; iter: 0; batch classifier loss: 0.479841; batch adversarial loss: 0.600569\n",
      "epoch 52; iter: 0; batch classifier loss: 0.512168; batch adversarial loss: 0.524757\n",
      "epoch 53; iter: 0; batch classifier loss: 0.458993; batch adversarial loss: 0.581606\n",
      "epoch 54; iter: 0; batch classifier loss: 0.500764; batch adversarial loss: 0.624282\n",
      "epoch 55; iter: 0; batch classifier loss: 0.558537; batch adversarial loss: 0.528058\n",
      "epoch 56; iter: 0; batch classifier loss: 0.421878; batch adversarial loss: 0.529877\n",
      "epoch 57; iter: 0; batch classifier loss: 0.490128; batch adversarial loss: 0.580182\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464698; batch adversarial loss: 0.546530\n",
      "epoch 59; iter: 0; batch classifier loss: 0.501678; batch adversarial loss: 0.565430\n",
      "epoch 60; iter: 0; batch classifier loss: 0.395902; batch adversarial loss: 0.616791\n",
      "epoch 61; iter: 0; batch classifier loss: 0.479991; batch adversarial loss: 0.615442\n",
      "epoch 62; iter: 0; batch classifier loss: 0.575390; batch adversarial loss: 0.619108\n",
      "epoch 63; iter: 0; batch classifier loss: 0.486038; batch adversarial loss: 0.635980\n",
      "epoch 64; iter: 0; batch classifier loss: 0.546410; batch adversarial loss: 0.587815\n",
      "epoch 65; iter: 0; batch classifier loss: 0.475795; batch adversarial loss: 0.622481\n",
      "epoch 66; iter: 0; batch classifier loss: 0.484712; batch adversarial loss: 0.602206\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414078; batch adversarial loss: 0.541346\n",
      "epoch 68; iter: 0; batch classifier loss: 0.558293; batch adversarial loss: 0.493606\n",
      "epoch 69; iter: 0; batch classifier loss: 0.491999; batch adversarial loss: 0.592107\n",
      "epoch 70; iter: 0; batch classifier loss: 0.429851; batch adversarial loss: 0.619560\n",
      "epoch 71; iter: 0; batch classifier loss: 0.514389; batch adversarial loss: 0.529829\n",
      "epoch 72; iter: 0; batch classifier loss: 0.504818; batch adversarial loss: 0.559570\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389659; batch adversarial loss: 0.569204\n",
      "epoch 74; iter: 0; batch classifier loss: 0.586051; batch adversarial loss: 0.585979\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377523; batch adversarial loss: 0.543769\n",
      "epoch 76; iter: 0; batch classifier loss: 0.516382; batch adversarial loss: 0.572435\n",
      "epoch 77; iter: 0; batch classifier loss: 0.490438; batch adversarial loss: 0.483972\n",
      "epoch 78; iter: 0; batch classifier loss: 0.483214; batch adversarial loss: 0.546052\n",
      "epoch 79; iter: 0; batch classifier loss: 0.438707; batch adversarial loss: 0.603875\n",
      "epoch 80; iter: 0; batch classifier loss: 0.385843; batch adversarial loss: 0.609390\n",
      "epoch 81; iter: 0; batch classifier loss: 0.479865; batch adversarial loss: 0.596811\n",
      "epoch 82; iter: 0; batch classifier loss: 0.472725; batch adversarial loss: 0.529198\n",
      "epoch 83; iter: 0; batch classifier loss: 0.483123; batch adversarial loss: 0.619822\n",
      "epoch 84; iter: 0; batch classifier loss: 0.456574; batch adversarial loss: 0.603795\n",
      "epoch 85; iter: 0; batch classifier loss: 0.374833; batch adversarial loss: 0.608425\n",
      "epoch 86; iter: 0; batch classifier loss: 0.435882; batch adversarial loss: 0.619268\n",
      "epoch 87; iter: 0; batch classifier loss: 0.452639; batch adversarial loss: 0.595243\n",
      "epoch 88; iter: 0; batch classifier loss: 0.588911; batch adversarial loss: 0.497257\n",
      "epoch 89; iter: 0; batch classifier loss: 0.471232; batch adversarial loss: 0.549071\n",
      "epoch 90; iter: 0; batch classifier loss: 0.468367; batch adversarial loss: 0.544434\n",
      "epoch 91; iter: 0; batch classifier loss: 0.471795; batch adversarial loss: 0.611242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.468003; batch adversarial loss: 0.627062\n",
      "epoch 93; iter: 0; batch classifier loss: 0.598376; batch adversarial loss: 0.555781\n",
      "epoch 94; iter: 0; batch classifier loss: 0.505852; batch adversarial loss: 0.506258\n",
      "epoch 95; iter: 0; batch classifier loss: 0.525486; batch adversarial loss: 0.582945\n",
      "epoch 96; iter: 0; batch classifier loss: 0.444143; batch adversarial loss: 0.574034\n",
      "epoch 97; iter: 0; batch classifier loss: 0.544722; batch adversarial loss: 0.634613\n",
      "epoch 98; iter: 0; batch classifier loss: 0.458354; batch adversarial loss: 0.518767\n",
      "epoch 99; iter: 0; batch classifier loss: 0.439628; batch adversarial loss: 0.550179\n",
      "epoch 100; iter: 0; batch classifier loss: 0.558765; batch adversarial loss: 0.580526\n",
      "epoch 101; iter: 0; batch classifier loss: 0.435829; batch adversarial loss: 0.621492\n",
      "epoch 102; iter: 0; batch classifier loss: 0.626232; batch adversarial loss: 0.538708\n",
      "epoch 103; iter: 0; batch classifier loss: 0.584577; batch adversarial loss: 0.565285\n",
      "epoch 104; iter: 0; batch classifier loss: 0.469912; batch adversarial loss: 0.539982\n",
      "epoch 105; iter: 0; batch classifier loss: 0.523761; batch adversarial loss: 0.644372\n",
      "epoch 106; iter: 0; batch classifier loss: 0.489568; batch adversarial loss: 0.639022\n",
      "epoch 107; iter: 0; batch classifier loss: 0.523256; batch adversarial loss: 0.561484\n",
      "epoch 108; iter: 0; batch classifier loss: 0.513191; batch adversarial loss: 0.576573\n",
      "epoch 109; iter: 0; batch classifier loss: 0.583578; batch adversarial loss: 0.495333\n",
      "epoch 110; iter: 0; batch classifier loss: 0.600083; batch adversarial loss: 0.525301\n",
      "epoch 111; iter: 0; batch classifier loss: 0.481791; batch adversarial loss: 0.592033\n",
      "epoch 112; iter: 0; batch classifier loss: 0.578900; batch adversarial loss: 0.557144\n",
      "epoch 113; iter: 0; batch classifier loss: 0.555591; batch adversarial loss: 0.558950\n",
      "epoch 114; iter: 0; batch classifier loss: 0.501121; batch adversarial loss: 0.588246\n",
      "epoch 115; iter: 0; batch classifier loss: 0.512821; batch adversarial loss: 0.515175\n",
      "epoch 116; iter: 0; batch classifier loss: 0.524217; batch adversarial loss: 0.555035\n",
      "epoch 117; iter: 0; batch classifier loss: 0.429438; batch adversarial loss: 0.599733\n",
      "epoch 118; iter: 0; batch classifier loss: 0.510046; batch adversarial loss: 0.586637\n",
      "epoch 119; iter: 0; batch classifier loss: 0.501640; batch adversarial loss: 0.606725\n",
      "epoch 120; iter: 0; batch classifier loss: 0.467601; batch adversarial loss: 0.588924\n",
      "epoch 121; iter: 0; batch classifier loss: 0.583388; batch adversarial loss: 0.636305\n",
      "epoch 122; iter: 0; batch classifier loss: 0.645690; batch adversarial loss: 0.569010\n",
      "epoch 123; iter: 0; batch classifier loss: 0.595221; batch adversarial loss: 0.601244\n",
      "epoch 124; iter: 0; batch classifier loss: 0.557765; batch adversarial loss: 0.555787\n",
      "epoch 125; iter: 0; batch classifier loss: 0.584581; batch adversarial loss: 0.615319\n",
      "epoch 126; iter: 0; batch classifier loss: 0.656265; batch adversarial loss: 0.572565\n",
      "epoch 127; iter: 0; batch classifier loss: 0.528437; batch adversarial loss: 0.521154\n",
      "epoch 128; iter: 0; batch classifier loss: 0.524585; batch adversarial loss: 0.597947\n",
      "epoch 129; iter: 0; batch classifier loss: 0.475042; batch adversarial loss: 0.635609\n",
      "epoch 130; iter: 0; batch classifier loss: 0.546227; batch adversarial loss: 0.560037\n",
      "epoch 131; iter: 0; batch classifier loss: 0.436643; batch adversarial loss: 0.599081\n",
      "epoch 132; iter: 0; batch classifier loss: 0.561378; batch adversarial loss: 0.541561\n",
      "epoch 133; iter: 0; batch classifier loss: 0.532065; batch adversarial loss: 0.624681\n",
      "epoch 134; iter: 0; batch classifier loss: 0.493446; batch adversarial loss: 0.563756\n",
      "epoch 135; iter: 0; batch classifier loss: 0.591589; batch adversarial loss: 0.631592\n",
      "epoch 136; iter: 0; batch classifier loss: 0.503172; batch adversarial loss: 0.564275\n",
      "epoch 137; iter: 0; batch classifier loss: 0.479332; batch adversarial loss: 0.646614\n",
      "epoch 138; iter: 0; batch classifier loss: 0.514594; batch adversarial loss: 0.556207\n",
      "epoch 139; iter: 0; batch classifier loss: 0.516874; batch adversarial loss: 0.548843\n",
      "epoch 140; iter: 0; batch classifier loss: 0.532175; batch adversarial loss: 0.609134\n",
      "epoch 141; iter: 0; batch classifier loss: 0.543955; batch adversarial loss: 0.496877\n",
      "epoch 142; iter: 0; batch classifier loss: 0.662993; batch adversarial loss: 0.577726\n",
      "epoch 143; iter: 0; batch classifier loss: 0.548539; batch adversarial loss: 0.494973\n",
      "epoch 144; iter: 0; batch classifier loss: 0.423118; batch adversarial loss: 0.612294\n",
      "epoch 145; iter: 0; batch classifier loss: 0.525717; batch adversarial loss: 0.519878\n",
      "epoch 146; iter: 0; batch classifier loss: 0.657154; batch adversarial loss: 0.566599\n",
      "epoch 147; iter: 0; batch classifier loss: 0.543782; batch adversarial loss: 0.512824\n",
      "epoch 148; iter: 0; batch classifier loss: 0.658850; batch adversarial loss: 0.568120\n",
      "epoch 149; iter: 0; batch classifier loss: 0.591237; batch adversarial loss: 0.553609\n",
      "epoch 150; iter: 0; batch classifier loss: 0.572049; batch adversarial loss: 0.565133\n",
      "epoch 151; iter: 0; batch classifier loss: 0.525415; batch adversarial loss: 0.536007\n",
      "epoch 152; iter: 0; batch classifier loss: 0.525847; batch adversarial loss: 0.594770\n",
      "epoch 153; iter: 0; batch classifier loss: 0.674771; batch adversarial loss: 0.547460\n",
      "epoch 154; iter: 0; batch classifier loss: 0.533087; batch adversarial loss: 0.609067\n",
      "epoch 155; iter: 0; batch classifier loss: 0.517311; batch adversarial loss: 0.604440\n",
      "epoch 156; iter: 0; batch classifier loss: 0.381723; batch adversarial loss: 0.618484\n",
      "epoch 157; iter: 0; batch classifier loss: 0.498595; batch adversarial loss: 0.514285\n",
      "epoch 158; iter: 0; batch classifier loss: 0.640632; batch adversarial loss: 0.627117\n",
      "epoch 159; iter: 0; batch classifier loss: 0.518613; batch adversarial loss: 0.586341\n",
      "epoch 160; iter: 0; batch classifier loss: 0.580827; batch adversarial loss: 0.581138\n",
      "epoch 161; iter: 0; batch classifier loss: 0.592933; batch adversarial loss: 0.554928\n",
      "epoch 162; iter: 0; batch classifier loss: 0.485209; batch adversarial loss: 0.574432\n",
      "epoch 163; iter: 0; batch classifier loss: 0.704045; batch adversarial loss: 0.543030\n",
      "epoch 164; iter: 0; batch classifier loss: 0.467472; batch adversarial loss: 0.553346\n",
      "epoch 165; iter: 0; batch classifier loss: 0.586449; batch adversarial loss: 0.562508\n",
      "epoch 166; iter: 0; batch classifier loss: 0.535388; batch adversarial loss: 0.588553\n",
      "epoch 167; iter: 0; batch classifier loss: 0.492586; batch adversarial loss: 0.568882\n",
      "epoch 168; iter: 0; batch classifier loss: 0.615322; batch adversarial loss: 0.606059\n",
      "epoch 169; iter: 0; batch classifier loss: 0.555768; batch adversarial loss: 0.590488\n",
      "epoch 170; iter: 0; batch classifier loss: 0.592327; batch adversarial loss: 0.549532\n",
      "epoch 171; iter: 0; batch classifier loss: 0.503553; batch adversarial loss: 0.521181\n",
      "epoch 172; iter: 0; batch classifier loss: 0.505708; batch adversarial loss: 0.582127\n",
      "epoch 173; iter: 0; batch classifier loss: 0.631264; batch adversarial loss: 0.547064\n",
      "epoch 174; iter: 0; batch classifier loss: 0.554119; batch adversarial loss: 0.550295\n",
      "epoch 175; iter: 0; batch classifier loss: 0.529843; batch adversarial loss: 0.551386\n",
      "epoch 176; iter: 0; batch classifier loss: 0.608063; batch adversarial loss: 0.521626\n",
      "epoch 177; iter: 0; batch classifier loss: 0.608165; batch adversarial loss: 0.603926\n",
      "epoch 178; iter: 0; batch classifier loss: 0.389411; batch adversarial loss: 0.547114\n",
      "epoch 179; iter: 0; batch classifier loss: 0.569176; batch adversarial loss: 0.608889\n",
      "epoch 180; iter: 0; batch classifier loss: 0.519629; batch adversarial loss: 0.536994\n",
      "epoch 181; iter: 0; batch classifier loss: 0.699500; batch adversarial loss: 0.638384\n",
      "epoch 182; iter: 0; batch classifier loss: 0.516937; batch adversarial loss: 0.595262\n",
      "epoch 183; iter: 0; batch classifier loss: 0.672518; batch adversarial loss: 0.644430\n",
      "epoch 184; iter: 0; batch classifier loss: 0.570840; batch adversarial loss: 0.530250\n",
      "epoch 185; iter: 0; batch classifier loss: 0.590426; batch adversarial loss: 0.624723\n",
      "epoch 186; iter: 0; batch classifier loss: 0.532930; batch adversarial loss: 0.532168\n",
      "epoch 187; iter: 0; batch classifier loss: 0.522095; batch adversarial loss: 0.553110\n",
      "epoch 188; iter: 0; batch classifier loss: 0.483534; batch adversarial loss: 0.563472\n",
      "epoch 189; iter: 0; batch classifier loss: 0.614787; batch adversarial loss: 0.564762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.545946; batch adversarial loss: 0.533112\n",
      "epoch 191; iter: 0; batch classifier loss: 0.450266; batch adversarial loss: 0.596283\n",
      "epoch 192; iter: 0; batch classifier loss: 0.501463; batch adversarial loss: 0.569181\n",
      "epoch 193; iter: 0; batch classifier loss: 0.556757; batch adversarial loss: 0.505373\n",
      "epoch 194; iter: 0; batch classifier loss: 0.477136; batch adversarial loss: 0.595494\n",
      "epoch 195; iter: 0; batch classifier loss: 0.746601; batch adversarial loss: 0.530667\n",
      "epoch 196; iter: 0; batch classifier loss: 0.594006; batch adversarial loss: 0.601866\n",
      "epoch 197; iter: 0; batch classifier loss: 0.452747; batch adversarial loss: 0.608142\n",
      "epoch 198; iter: 0; batch classifier loss: 0.573715; batch adversarial loss: 0.607937\n",
      "epoch 199; iter: 0; batch classifier loss: 0.331447; batch adversarial loss: 0.652738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.956695; batch adversarial loss: 0.915742\n",
      "epoch 2; iter: 0; batch classifier loss: 0.965162; batch adversarial loss: 0.814612\n",
      "epoch 3; iter: 0; batch classifier loss: 0.837565; batch adversarial loss: 0.785943\n",
      "epoch 4; iter: 0; batch classifier loss: 0.780721; batch adversarial loss: 0.787949\n",
      "epoch 5; iter: 0; batch classifier loss: 0.807798; batch adversarial loss: 0.687171\n",
      "epoch 6; iter: 0; batch classifier loss: 0.720674; batch adversarial loss: 0.727492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.687994; batch adversarial loss: 0.703964\n",
      "epoch 8; iter: 0; batch classifier loss: 0.642510; batch adversarial loss: 0.664211\n",
      "epoch 9; iter: 0; batch classifier loss: 0.655826; batch adversarial loss: 0.711973\n",
      "epoch 10; iter: 0; batch classifier loss: 0.672753; batch adversarial loss: 0.714702\n",
      "epoch 11; iter: 0; batch classifier loss: 0.687602; batch adversarial loss: 0.651263\n",
      "epoch 12; iter: 0; batch classifier loss: 0.707058; batch adversarial loss: 0.668162\n",
      "epoch 13; iter: 0; batch classifier loss: 0.674773; batch adversarial loss: 0.681585\n",
      "epoch 14; iter: 0; batch classifier loss: 0.683730; batch adversarial loss: 0.649832\n",
      "epoch 15; iter: 0; batch classifier loss: 0.619782; batch adversarial loss: 0.634896\n",
      "epoch 16; iter: 0; batch classifier loss: 0.650528; batch adversarial loss: 0.609988\n",
      "epoch 17; iter: 0; batch classifier loss: 0.615354; batch adversarial loss: 0.653350\n",
      "epoch 18; iter: 0; batch classifier loss: 0.606177; batch adversarial loss: 0.586363\n",
      "epoch 19; iter: 0; batch classifier loss: 0.627766; batch adversarial loss: 0.620367\n",
      "epoch 20; iter: 0; batch classifier loss: 0.659916; batch adversarial loss: 0.652428\n",
      "epoch 21; iter: 0; batch classifier loss: 0.619989; batch adversarial loss: 0.612906\n",
      "epoch 22; iter: 0; batch classifier loss: 0.560769; batch adversarial loss: 0.587591\n",
      "epoch 23; iter: 0; batch classifier loss: 0.568909; batch adversarial loss: 0.545825\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485150; batch adversarial loss: 0.543520\n",
      "epoch 25; iter: 0; batch classifier loss: 0.519482; batch adversarial loss: 0.544457\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478920; batch adversarial loss: 0.608366\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440819; batch adversarial loss: 0.600013\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538338; batch adversarial loss: 0.578709\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486223; batch adversarial loss: 0.562007\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485126; batch adversarial loss: 0.556611\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505143; batch adversarial loss: 0.550331\n",
      "epoch 32; iter: 0; batch classifier loss: 0.615366; batch adversarial loss: 0.569099\n",
      "epoch 33; iter: 0; batch classifier loss: 0.689261; batch adversarial loss: 0.603526\n",
      "epoch 34; iter: 0; batch classifier loss: 0.758948; batch adversarial loss: 0.666306\n",
      "epoch 35; iter: 0; batch classifier loss: 0.746912; batch adversarial loss: 0.603980\n",
      "epoch 36; iter: 0; batch classifier loss: 0.775955; batch adversarial loss: 0.586621\n",
      "epoch 37; iter: 0; batch classifier loss: 0.754309; batch adversarial loss: 0.622157\n",
      "epoch 38; iter: 0; batch classifier loss: 0.606002; batch adversarial loss: 0.535285\n",
      "epoch 39; iter: 0; batch classifier loss: 0.510693; batch adversarial loss: 0.632190\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481493; batch adversarial loss: 0.615809\n",
      "epoch 41; iter: 0; batch classifier loss: 0.480309; batch adversarial loss: 0.516023\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429037; batch adversarial loss: 0.583682\n",
      "epoch 43; iter: 0; batch classifier loss: 0.614008; batch adversarial loss: 0.553082\n",
      "epoch 44; iter: 0; batch classifier loss: 0.543194; batch adversarial loss: 0.695300\n",
      "epoch 45; iter: 0; batch classifier loss: 0.570540; batch adversarial loss: 0.581511\n",
      "epoch 46; iter: 0; batch classifier loss: 0.506783; batch adversarial loss: 0.560461\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435940; batch adversarial loss: 0.587739\n",
      "epoch 48; iter: 0; batch classifier loss: 0.491083; batch adversarial loss: 0.553092\n",
      "epoch 49; iter: 0; batch classifier loss: 0.473258; batch adversarial loss: 0.550302\n",
      "epoch 50; iter: 0; batch classifier loss: 0.499279; batch adversarial loss: 0.512367\n",
      "epoch 51; iter: 0; batch classifier loss: 0.494349; batch adversarial loss: 0.600907\n",
      "epoch 52; iter: 0; batch classifier loss: 0.517187; batch adversarial loss: 0.525474\n",
      "epoch 53; iter: 0; batch classifier loss: 0.477516; batch adversarial loss: 0.581933\n",
      "epoch 54; iter: 0; batch classifier loss: 0.510293; batch adversarial loss: 0.624807\n",
      "epoch 55; iter: 0; batch classifier loss: 0.564291; batch adversarial loss: 0.527964\n",
      "epoch 56; iter: 0; batch classifier loss: 0.429498; batch adversarial loss: 0.530454\n",
      "epoch 57; iter: 0; batch classifier loss: 0.487060; batch adversarial loss: 0.580141\n",
      "epoch 58; iter: 0; batch classifier loss: 0.471609; batch adversarial loss: 0.546109\n",
      "epoch 59; iter: 0; batch classifier loss: 0.499350; batch adversarial loss: 0.565474\n",
      "epoch 60; iter: 0; batch classifier loss: 0.388544; batch adversarial loss: 0.616736\n",
      "epoch 61; iter: 0; batch classifier loss: 0.468317; batch adversarial loss: 0.615275\n",
      "epoch 62; iter: 0; batch classifier loss: 0.577189; batch adversarial loss: 0.619317\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465923; batch adversarial loss: 0.635923\n",
      "epoch 64; iter: 0; batch classifier loss: 0.522343; batch adversarial loss: 0.587211\n",
      "epoch 65; iter: 0; batch classifier loss: 0.480689; batch adversarial loss: 0.622071\n",
      "epoch 66; iter: 0; batch classifier loss: 0.491223; batch adversarial loss: 0.602065\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414598; batch adversarial loss: 0.540918\n",
      "epoch 68; iter: 0; batch classifier loss: 0.558190; batch adversarial loss: 0.493511\n",
      "epoch 69; iter: 0; batch classifier loss: 0.468731; batch adversarial loss: 0.591037\n",
      "epoch 70; iter: 0; batch classifier loss: 0.410080; batch adversarial loss: 0.618336\n",
      "epoch 71; iter: 0; batch classifier loss: 0.510048; batch adversarial loss: 0.530916\n",
      "epoch 72; iter: 0; batch classifier loss: 0.499846; batch adversarial loss: 0.559277\n",
      "epoch 73; iter: 0; batch classifier loss: 0.396791; batch adversarial loss: 0.569755\n",
      "epoch 74; iter: 0; batch classifier loss: 0.589035; batch adversarial loss: 0.586185\n",
      "epoch 75; iter: 0; batch classifier loss: 0.370888; batch adversarial loss: 0.542929\n",
      "epoch 76; iter: 0; batch classifier loss: 0.492749; batch adversarial loss: 0.568807\n",
      "epoch 77; iter: 0; batch classifier loss: 0.482544; batch adversarial loss: 0.483077\n",
      "epoch 78; iter: 0; batch classifier loss: 0.487877; batch adversarial loss: 0.546794\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436879; batch adversarial loss: 0.603518\n",
      "epoch 80; iter: 0; batch classifier loss: 0.368989; batch adversarial loss: 0.608235\n",
      "epoch 81; iter: 0; batch classifier loss: 0.484277; batch adversarial loss: 0.596384\n",
      "epoch 82; iter: 0; batch classifier loss: 0.488199; batch adversarial loss: 0.528615\n",
      "epoch 83; iter: 0; batch classifier loss: 0.456901; batch adversarial loss: 0.618475\n",
      "epoch 84; iter: 0; batch classifier loss: 0.457300; batch adversarial loss: 0.598957\n",
      "epoch 85; iter: 0; batch classifier loss: 0.374170; batch adversarial loss: 0.607028\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425256; batch adversarial loss: 0.617623\n",
      "epoch 87; iter: 0; batch classifier loss: 0.417925; batch adversarial loss: 0.593946\n",
      "epoch 88; iter: 0; batch classifier loss: 0.568450; batch adversarial loss: 0.494746\n",
      "epoch 89; iter: 0; batch classifier loss: 0.441947; batch adversarial loss: 0.544651\n",
      "epoch 90; iter: 0; batch classifier loss: 0.452301; batch adversarial loss: 0.542808\n",
      "epoch 91; iter: 0; batch classifier loss: 0.469944; batch adversarial loss: 0.607581\n",
      "epoch 92; iter: 0; batch classifier loss: 0.421902; batch adversarial loss: 0.628111\n",
      "epoch 93; iter: 0; batch classifier loss: 0.589074; batch adversarial loss: 0.554088\n",
      "epoch 94; iter: 0; batch classifier loss: 0.483230; batch adversarial loss: 0.504337\n",
      "epoch 95; iter: 0; batch classifier loss: 0.505142; batch adversarial loss: 0.580539\n",
      "epoch 96; iter: 0; batch classifier loss: 0.438308; batch adversarial loss: 0.572776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.518390; batch adversarial loss: 0.633754\n",
      "epoch 98; iter: 0; batch classifier loss: 0.459105; batch adversarial loss: 0.518004\n",
      "epoch 99; iter: 0; batch classifier loss: 0.444872; batch adversarial loss: 0.549298\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.959310; batch adversarial loss: 0.915993\n",
      "epoch 2; iter: 0; batch classifier loss: 0.967623; batch adversarial loss: 0.814811\n",
      "epoch 3; iter: 0; batch classifier loss: 0.841218; batch adversarial loss: 0.786293\n",
      "epoch 4; iter: 0; batch classifier loss: 0.788291; batch adversarial loss: 0.788661\n",
      "epoch 5; iter: 0; batch classifier loss: 0.821158; batch adversarial loss: 0.687848\n",
      "epoch 6; iter: 0; batch classifier loss: 0.727994; batch adversarial loss: 0.728677\n",
      "epoch 7; iter: 0; batch classifier loss: 0.697236; batch adversarial loss: 0.705424\n",
      "epoch 8; iter: 0; batch classifier loss: 0.649983; batch adversarial loss: 0.664884\n",
      "epoch 9; iter: 0; batch classifier loss: 0.661785; batch adversarial loss: 0.712874\n",
      "epoch 10; iter: 0; batch classifier loss: 0.675042; batch adversarial loss: 0.714478\n",
      "epoch 11; iter: 0; batch classifier loss: 0.687916; batch adversarial loss: 0.651289\n",
      "epoch 12; iter: 0; batch classifier loss: 0.707442; batch adversarial loss: 0.667868\n",
      "epoch 13; iter: 0; batch classifier loss: 0.674047; batch adversarial loss: 0.681399\n",
      "epoch 14; iter: 0; batch classifier loss: 0.685763; batch adversarial loss: 0.649922\n",
      "epoch 15; iter: 0; batch classifier loss: 0.619864; batch adversarial loss: 0.634932\n",
      "epoch 16; iter: 0; batch classifier loss: 0.654002; batch adversarial loss: 0.610037\n",
      "epoch 17; iter: 0; batch classifier loss: 0.617334; batch adversarial loss: 0.653418\n",
      "epoch 18; iter: 0; batch classifier loss: 0.608925; batch adversarial loss: 0.586502\n",
      "epoch 19; iter: 0; batch classifier loss: 0.629888; batch adversarial loss: 0.620487\n",
      "epoch 20; iter: 0; batch classifier loss: 0.659416; batch adversarial loss: 0.652074\n",
      "epoch 21; iter: 0; batch classifier loss: 0.621988; batch adversarial loss: 0.613043\n",
      "epoch 22; iter: 0; batch classifier loss: 0.565821; batch adversarial loss: 0.587725\n",
      "epoch 23; iter: 0; batch classifier loss: 0.570977; batch adversarial loss: 0.546121\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484238; batch adversarial loss: 0.544327\n",
      "epoch 25; iter: 0; batch classifier loss: 0.521594; batch adversarial loss: 0.544665\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475680; batch adversarial loss: 0.608521\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440516; batch adversarial loss: 0.600144\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538230; batch adversarial loss: 0.578600\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486504; batch adversarial loss: 0.561940\n",
      "epoch 30; iter: 0; batch classifier loss: 0.484627; batch adversarial loss: 0.557171\n",
      "epoch 31; iter: 0; batch classifier loss: 0.504785; batch adversarial loss: 0.550714\n",
      "epoch 32; iter: 0; batch classifier loss: 0.618308; batch adversarial loss: 0.570071\n",
      "epoch 33; iter: 0; batch classifier loss: 0.702612; batch adversarial loss: 0.604172\n",
      "epoch 34; iter: 0; batch classifier loss: 0.765893; batch adversarial loss: 0.663833\n",
      "epoch 35; iter: 0; batch classifier loss: 0.742505; batch adversarial loss: 0.601430\n",
      "epoch 36; iter: 0; batch classifier loss: 0.771053; batch adversarial loss: 0.584705\n",
      "epoch 37; iter: 0; batch classifier loss: 0.731967; batch adversarial loss: 0.621457\n",
      "epoch 38; iter: 0; batch classifier loss: 0.594034; batch adversarial loss: 0.535797\n",
      "epoch 39; iter: 0; batch classifier loss: 0.499117; batch adversarial loss: 0.633123\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481307; batch adversarial loss: 0.616298\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481797; batch adversarial loss: 0.514748\n",
      "epoch 42; iter: 0; batch classifier loss: 0.435138; batch adversarial loss: 0.583319\n",
      "epoch 43; iter: 0; batch classifier loss: 0.621425; batch adversarial loss: 0.553143\n",
      "epoch 44; iter: 0; batch classifier loss: 0.541375; batch adversarial loss: 0.695363\n",
      "epoch 45; iter: 0; batch classifier loss: 0.567096; batch adversarial loss: 0.581541\n",
      "epoch 46; iter: 0; batch classifier loss: 0.513011; batch adversarial loss: 0.560830\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438872; batch adversarial loss: 0.587714\n",
      "epoch 48; iter: 0; batch classifier loss: 0.487007; batch adversarial loss: 0.553215\n",
      "epoch 49; iter: 0; batch classifier loss: 0.475194; batch adversarial loss: 0.550318\n",
      "epoch 50; iter: 0; batch classifier loss: 0.496293; batch adversarial loss: 0.512496\n",
      "epoch 51; iter: 0; batch classifier loss: 0.493265; batch adversarial loss: 0.600948\n",
      "epoch 52; iter: 0; batch classifier loss: 0.523659; batch adversarial loss: 0.525206\n",
      "epoch 53; iter: 0; batch classifier loss: 0.481188; batch adversarial loss: 0.581927\n",
      "epoch 54; iter: 0; batch classifier loss: 0.519130; batch adversarial loss: 0.624862\n",
      "epoch 55; iter: 0; batch classifier loss: 0.561072; batch adversarial loss: 0.528055\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434624; batch adversarial loss: 0.530400\n",
      "epoch 57; iter: 0; batch classifier loss: 0.484665; batch adversarial loss: 0.580207\n",
      "epoch 58; iter: 0; batch classifier loss: 0.472328; batch adversarial loss: 0.545723\n",
      "epoch 59; iter: 0; batch classifier loss: 0.499458; batch adversarial loss: 0.565306\n",
      "epoch 60; iter: 0; batch classifier loss: 0.389054; batch adversarial loss: 0.616956\n",
      "epoch 61; iter: 0; batch classifier loss: 0.470979; batch adversarial loss: 0.615404\n",
      "epoch 62; iter: 0; batch classifier loss: 0.581548; batch adversarial loss: 0.619182\n",
      "epoch 63; iter: 0; batch classifier loss: 0.470550; batch adversarial loss: 0.636056\n",
      "epoch 64; iter: 0; batch classifier loss: 0.527750; batch adversarial loss: 0.587104\n",
      "epoch 65; iter: 0; batch classifier loss: 0.482921; batch adversarial loss: 0.622249\n",
      "epoch 66; iter: 0; batch classifier loss: 0.486615; batch adversarial loss: 0.601973\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410538; batch adversarial loss: 0.540344\n",
      "epoch 68; iter: 0; batch classifier loss: 0.554080; batch adversarial loss: 0.493329\n",
      "epoch 69; iter: 0; batch classifier loss: 0.472077; batch adversarial loss: 0.591239\n",
      "epoch 70; iter: 0; batch classifier loss: 0.416287; batch adversarial loss: 0.618463\n",
      "epoch 71; iter: 0; batch classifier loss: 0.504498; batch adversarial loss: 0.530927\n",
      "epoch 72; iter: 0; batch classifier loss: 0.494941; batch adversarial loss: 0.558840\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389922; batch adversarial loss: 0.569741\n",
      "epoch 74; iter: 0; batch classifier loss: 0.584745; batch adversarial loss: 0.585534\n",
      "epoch 75; iter: 0; batch classifier loss: 0.361881; batch adversarial loss: 0.542566\n",
      "epoch 76; iter: 0; batch classifier loss: 0.495534; batch adversarial loss: 0.569376\n",
      "epoch 77; iter: 0; batch classifier loss: 0.488443; batch adversarial loss: 0.483450\n",
      "epoch 78; iter: 0; batch classifier loss: 0.488590; batch adversarial loss: 0.546625\n",
      "epoch 79; iter: 0; batch classifier loss: 0.442188; batch adversarial loss: 0.603430\n",
      "epoch 80; iter: 0; batch classifier loss: 0.361877; batch adversarial loss: 0.608162\n",
      "epoch 81; iter: 0; batch classifier loss: 0.488517; batch adversarial loss: 0.596236\n",
      "epoch 82; iter: 0; batch classifier loss: 0.480359; batch adversarial loss: 0.528476\n",
      "epoch 83; iter: 0; batch classifier loss: 0.458771; batch adversarial loss: 0.618632\n",
      "epoch 84; iter: 0; batch classifier loss: 0.453526; batch adversarial loss: 0.600433\n",
      "epoch 85; iter: 0; batch classifier loss: 0.380648; batch adversarial loss: 0.607179\n",
      "epoch 86; iter: 0; batch classifier loss: 0.434912; batch adversarial loss: 0.617864\n",
      "epoch 87; iter: 0; batch classifier loss: 0.424447; batch adversarial loss: 0.593393\n",
      "epoch 88; iter: 0; batch classifier loss: 0.560033; batch adversarial loss: 0.494374\n",
      "epoch 89; iter: 0; batch classifier loss: 0.443195; batch adversarial loss: 0.546143\n",
      "epoch 90; iter: 0; batch classifier loss: 0.457431; batch adversarial loss: 0.543533\n",
      "epoch 91; iter: 0; batch classifier loss: 0.475945; batch adversarial loss: 0.608512\n",
      "epoch 92; iter: 0; batch classifier loss: 0.439994; batch adversarial loss: 0.629426\n",
      "epoch 93; iter: 0; batch classifier loss: 0.580477; batch adversarial loss: 0.555898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.493850; batch adversarial loss: 0.504538\n",
      "epoch 95; iter: 0; batch classifier loss: 0.517089; batch adversarial loss: 0.580781\n",
      "epoch 96; iter: 0; batch classifier loss: 0.443626; batch adversarial loss: 0.572348\n",
      "epoch 97; iter: 0; batch classifier loss: 0.526050; batch adversarial loss: 0.632152\n",
      "epoch 98; iter: 0; batch classifier loss: 0.463982; batch adversarial loss: 0.518216\n",
      "epoch 99; iter: 0; batch classifier loss: 0.427765; batch adversarial loss: 0.548401\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.951853; batch adversarial loss: 0.915273\n",
      "epoch 2; iter: 0; batch classifier loss: 0.959600; batch adversarial loss: 0.814272\n",
      "epoch 3; iter: 0; batch classifier loss: 0.828162; batch adversarial loss: 0.785326\n",
      "epoch 4; iter: 0; batch classifier loss: 0.766284; batch adversarial loss: 0.786397\n",
      "epoch 5; iter: 0; batch classifier loss: 0.778012; batch adversarial loss: 0.685573\n",
      "epoch 6; iter: 0; batch classifier loss: 0.701277; batch adversarial loss: 0.723889\n",
      "epoch 7; iter: 0; batch classifier loss: 0.664390; batch adversarial loss: 0.700295\n",
      "epoch 8; iter: 0; batch classifier loss: 0.620119; batch adversarial loss: 0.660966\n",
      "epoch 9; iter: 0; batch classifier loss: 0.629497; batch adversarial loss: 0.707732\n",
      "epoch 10; iter: 0; batch classifier loss: 0.655391; batch adversarial loss: 0.712572\n",
      "epoch 11; iter: 0; batch classifier loss: 0.681908; batch adversarial loss: 0.650474\n",
      "epoch 12; iter: 0; batch classifier loss: 0.708438; batch adversarial loss: 0.668396\n",
      "epoch 13; iter: 0; batch classifier loss: 0.679672; batch adversarial loss: 0.682997\n",
      "epoch 14; iter: 0; batch classifier loss: 0.686175; batch adversarial loss: 0.650742\n",
      "epoch 15; iter: 0; batch classifier loss: 0.618936; batch adversarial loss: 0.635000\n",
      "epoch 16; iter: 0; batch classifier loss: 0.654865; batch adversarial loss: 0.610370\n",
      "epoch 17; iter: 0; batch classifier loss: 0.617197; batch adversarial loss: 0.654065\n",
      "epoch 18; iter: 0; batch classifier loss: 0.608649; batch adversarial loss: 0.586520\n",
      "epoch 19; iter: 0; batch classifier loss: 0.626754; batch adversarial loss: 0.620328\n",
      "epoch 20; iter: 0; batch classifier loss: 0.656948; batch adversarial loss: 0.652652\n",
      "epoch 21; iter: 0; batch classifier loss: 0.619683; batch adversarial loss: 0.613182\n",
      "epoch 22; iter: 0; batch classifier loss: 0.561380; batch adversarial loss: 0.587451\n",
      "epoch 23; iter: 0; batch classifier loss: 0.568570; batch adversarial loss: 0.545764\n",
      "epoch 24; iter: 0; batch classifier loss: 0.487728; batch adversarial loss: 0.542938\n",
      "epoch 25; iter: 0; batch classifier loss: 0.516057; batch adversarial loss: 0.544291\n",
      "epoch 26; iter: 0; batch classifier loss: 0.481284; batch adversarial loss: 0.608404\n",
      "epoch 27; iter: 0; batch classifier loss: 0.444958; batch adversarial loss: 0.600048\n",
      "epoch 28; iter: 0; batch classifier loss: 0.541233; batch adversarial loss: 0.578784\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487067; batch adversarial loss: 0.561686\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486408; batch adversarial loss: 0.556499\n",
      "epoch 31; iter: 0; batch classifier loss: 0.505876; batch adversarial loss: 0.550610\n",
      "epoch 32; iter: 0; batch classifier loss: 0.613011; batch adversarial loss: 0.568515\n",
      "epoch 33; iter: 0; batch classifier loss: 0.680852; batch adversarial loss: 0.602493\n",
      "epoch 34; iter: 0; batch classifier loss: 0.745184; batch adversarial loss: 0.667800\n",
      "epoch 35; iter: 0; batch classifier loss: 0.744697; batch adversarial loss: 0.606503\n",
      "epoch 36; iter: 0; batch classifier loss: 0.782158; batch adversarial loss: 0.588895\n",
      "epoch 37; iter: 0; batch classifier loss: 0.778239; batch adversarial loss: 0.623525\n",
      "epoch 38; iter: 0; batch classifier loss: 0.620328; batch adversarial loss: 0.534914\n",
      "epoch 39; iter: 0; batch classifier loss: 0.522263; batch adversarial loss: 0.631195\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484267; batch adversarial loss: 0.615005\n",
      "epoch 41; iter: 0; batch classifier loss: 0.473810; batch adversarial loss: 0.516700\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427973; batch adversarial loss: 0.584344\n",
      "epoch 43; iter: 0; batch classifier loss: 0.609996; batch adversarial loss: 0.553250\n",
      "epoch 44; iter: 0; batch classifier loss: 0.543817; batch adversarial loss: 0.695327\n",
      "epoch 45; iter: 0; batch classifier loss: 0.584802; batch adversarial loss: 0.581505\n",
      "epoch 46; iter: 0; batch classifier loss: 0.506543; batch adversarial loss: 0.560290\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437280; batch adversarial loss: 0.587669\n",
      "epoch 48; iter: 0; batch classifier loss: 0.493818; batch adversarial loss: 0.553176\n",
      "epoch 49; iter: 0; batch classifier loss: 0.472854; batch adversarial loss: 0.550299\n",
      "epoch 50; iter: 0; batch classifier loss: 0.497235; batch adversarial loss: 0.512249\n",
      "epoch 51; iter: 0; batch classifier loss: 0.499727; batch adversarial loss: 0.601533\n",
      "epoch 52; iter: 0; batch classifier loss: 0.530141; batch adversarial loss: 0.525977\n",
      "epoch 53; iter: 0; batch classifier loss: 0.486742; batch adversarial loss: 0.582437\n",
      "epoch 54; iter: 0; batch classifier loss: 0.521381; batch adversarial loss: 0.625753\n",
      "epoch 55; iter: 0; batch classifier loss: 0.561186; batch adversarial loss: 0.528292\n",
      "epoch 56; iter: 0; batch classifier loss: 0.433223; batch adversarial loss: 0.530552\n",
      "epoch 57; iter: 0; batch classifier loss: 0.483638; batch adversarial loss: 0.580301\n",
      "epoch 58; iter: 0; batch classifier loss: 0.467170; batch adversarial loss: 0.546000\n",
      "epoch 59; iter: 0; batch classifier loss: 0.496324; batch adversarial loss: 0.565430\n",
      "epoch 60; iter: 0; batch classifier loss: 0.392925; batch adversarial loss: 0.616576\n",
      "epoch 61; iter: 0; batch classifier loss: 0.461227; batch adversarial loss: 0.615034\n",
      "epoch 62; iter: 0; batch classifier loss: 0.576002; batch adversarial loss: 0.619248\n",
      "epoch 63; iter: 0; batch classifier loss: 0.467996; batch adversarial loss: 0.636162\n",
      "epoch 64; iter: 0; batch classifier loss: 0.529321; batch adversarial loss: 0.587151\n",
      "epoch 65; iter: 0; batch classifier loss: 0.488339; batch adversarial loss: 0.622188\n",
      "epoch 66; iter: 0; batch classifier loss: 0.485978; batch adversarial loss: 0.602605\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413076; batch adversarial loss: 0.540645\n",
      "epoch 68; iter: 0; batch classifier loss: 0.554626; batch adversarial loss: 0.492895\n",
      "epoch 69; iter: 0; batch classifier loss: 0.471356; batch adversarial loss: 0.590833\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414186; batch adversarial loss: 0.617463\n",
      "epoch 71; iter: 0; batch classifier loss: 0.505601; batch adversarial loss: 0.529897\n",
      "epoch 72; iter: 0; batch classifier loss: 0.497174; batch adversarial loss: 0.559483\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390997; batch adversarial loss: 0.569882\n",
      "epoch 74; iter: 0; batch classifier loss: 0.586556; batch adversarial loss: 0.585248\n",
      "epoch 75; iter: 0; batch classifier loss: 0.362867; batch adversarial loss: 0.542032\n",
      "epoch 76; iter: 0; batch classifier loss: 0.473445; batch adversarial loss: 0.568441\n",
      "epoch 77; iter: 0; batch classifier loss: 0.484447; batch adversarial loss: 0.483061\n",
      "epoch 78; iter: 0; batch classifier loss: 0.486888; batch adversarial loss: 0.546139\n",
      "epoch 79; iter: 0; batch classifier loss: 0.432557; batch adversarial loss: 0.603547\n",
      "epoch 80; iter: 0; batch classifier loss: 0.367740; batch adversarial loss: 0.608194\n",
      "epoch 81; iter: 0; batch classifier loss: 0.485111; batch adversarial loss: 0.596774\n",
      "epoch 82; iter: 0; batch classifier loss: 0.480217; batch adversarial loss: 0.527589\n",
      "epoch 83; iter: 0; batch classifier loss: 0.452034; batch adversarial loss: 0.617737\n",
      "epoch 84; iter: 0; batch classifier loss: 0.467495; batch adversarial loss: 0.598680\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373870; batch adversarial loss: 0.606011\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420456; batch adversarial loss: 0.618108\n",
      "epoch 87; iter: 0; batch classifier loss: 0.430359; batch adversarial loss: 0.593266\n",
      "epoch 88; iter: 0; batch classifier loss: 0.567342; batch adversarial loss: 0.494822\n",
      "epoch 89; iter: 0; batch classifier loss: 0.436917; batch adversarial loss: 0.545273\n",
      "epoch 90; iter: 0; batch classifier loss: 0.447623; batch adversarial loss: 0.542616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91; iter: 0; batch classifier loss: 0.478535; batch adversarial loss: 0.609072\n",
      "epoch 92; iter: 0; batch classifier loss: 0.426512; batch adversarial loss: 0.628303\n",
      "epoch 93; iter: 0; batch classifier loss: 0.560603; batch adversarial loss: 0.553392\n",
      "epoch 94; iter: 0; batch classifier loss: 0.491176; batch adversarial loss: 0.504448\n",
      "epoch 95; iter: 0; batch classifier loss: 0.508904; batch adversarial loss: 0.580928\n",
      "epoch 96; iter: 0; batch classifier loss: 0.440594; batch adversarial loss: 0.572022\n",
      "epoch 97; iter: 0; batch classifier loss: 0.531790; batch adversarial loss: 0.634409\n",
      "epoch 98; iter: 0; batch classifier loss: 0.465887; batch adversarial loss: 0.517968\n",
      "epoch 99; iter: 0; batch classifier loss: 0.431122; batch adversarial loss: 0.549149\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.970098; batch adversarial loss: 0.917089\n",
      "epoch 2; iter: 0; batch classifier loss: 0.979839; batch adversarial loss: 0.815576\n",
      "epoch 3; iter: 0; batch classifier loss: 0.861348; batch adversarial loss: 0.788009\n",
      "epoch 4; iter: 0; batch classifier loss: 0.825003; batch adversarial loss: 0.792166\n",
      "epoch 5; iter: 0; batch classifier loss: 0.878026; batch adversarial loss: 0.690769\n",
      "epoch 6; iter: 0; batch classifier loss: 0.755235; batch adversarial loss: 0.732912\n",
      "epoch 7; iter: 0; batch classifier loss: 0.725266; batch adversarial loss: 0.709793\n",
      "epoch 8; iter: 0; batch classifier loss: 0.672799; batch adversarial loss: 0.667532\n",
      "epoch 9; iter: 0; batch classifier loss: 0.682997; batch adversarial loss: 0.714976\n",
      "epoch 10; iter: 0; batch classifier loss: 0.683126; batch adversarial loss: 0.714835\n",
      "epoch 11; iter: 0; batch classifier loss: 0.691035; batch adversarial loss: 0.651849\n",
      "epoch 12; iter: 0; batch classifier loss: 0.708690; batch adversarial loss: 0.667915\n",
      "epoch 13; iter: 0; batch classifier loss: 0.679966; batch adversarial loss: 0.680916\n",
      "epoch 14; iter: 0; batch classifier loss: 0.684961; batch adversarial loss: 0.649637\n",
      "epoch 15; iter: 0; batch classifier loss: 0.615495; batch adversarial loss: 0.634853\n",
      "epoch 16; iter: 0; batch classifier loss: 0.657533; batch adversarial loss: 0.610230\n",
      "epoch 17; iter: 0; batch classifier loss: 0.621081; batch adversarial loss: 0.653397\n",
      "epoch 18; iter: 0; batch classifier loss: 0.614666; batch adversarial loss: 0.586810\n",
      "epoch 19; iter: 0; batch classifier loss: 0.636619; batch adversarial loss: 0.620807\n",
      "epoch 20; iter: 0; batch classifier loss: 0.672856; batch adversarial loss: 0.652595\n",
      "epoch 21; iter: 0; batch classifier loss: 0.628037; batch adversarial loss: 0.613302\n",
      "epoch 22; iter: 0; batch classifier loss: 0.577853; batch adversarial loss: 0.588470\n",
      "epoch 23; iter: 0; batch classifier loss: 0.580641; batch adversarial loss: 0.547098\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485644; batch adversarial loss: 0.546240\n",
      "epoch 25; iter: 0; batch classifier loss: 0.527299; batch adversarial loss: 0.545462\n",
      "epoch 26; iter: 0; batch classifier loss: 0.481563; batch adversarial loss: 0.608898\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441787; batch adversarial loss: 0.600557\n",
      "epoch 28; iter: 0; batch classifier loss: 0.536685; batch adversarial loss: 0.578530\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486176; batch adversarial loss: 0.562273\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485659; batch adversarial loss: 0.556135\n",
      "epoch 31; iter: 0; batch classifier loss: 0.501268; batch adversarial loss: 0.547925\n",
      "epoch 32; iter: 0; batch classifier loss: 0.618966; batch adversarial loss: 0.568289\n",
      "epoch 33; iter: 0; batch classifier loss: 0.715004; batch adversarial loss: 0.603570\n",
      "epoch 34; iter: 0; batch classifier loss: 0.769956; batch adversarial loss: 0.661530\n",
      "epoch 35; iter: 0; batch classifier loss: 0.751893; batch adversarial loss: 0.598836\n",
      "epoch 36; iter: 0; batch classifier loss: 0.756605; batch adversarial loss: 0.582279\n",
      "epoch 37; iter: 0; batch classifier loss: 0.679880; batch adversarial loss: 0.622310\n",
      "epoch 38; iter: 0; batch classifier loss: 0.579636; batch adversarial loss: 0.536515\n",
      "epoch 39; iter: 0; batch classifier loss: 0.486956; batch adversarial loss: 0.634259\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481736; batch adversarial loss: 0.616085\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465332; batch adversarial loss: 0.512131\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448329; batch adversarial loss: 0.583014\n",
      "epoch 43; iter: 0; batch classifier loss: 0.615016; batch adversarial loss: 0.553048\n",
      "epoch 44; iter: 0; batch classifier loss: 0.516191; batch adversarial loss: 0.695582\n",
      "epoch 45; iter: 0; batch classifier loss: 0.547069; batch adversarial loss: 0.581877\n",
      "epoch 46; iter: 0; batch classifier loss: 0.512019; batch adversarial loss: 0.561347\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441177; batch adversarial loss: 0.587789\n",
      "epoch 48; iter: 0; batch classifier loss: 0.485457; batch adversarial loss: 0.553322\n",
      "epoch 49; iter: 0; batch classifier loss: 0.469736; batch adversarial loss: 0.550431\n",
      "epoch 50; iter: 0; batch classifier loss: 0.491277; batch adversarial loss: 0.512258\n",
      "epoch 51; iter: 0; batch classifier loss: 0.488198; batch adversarial loss: 0.600504\n",
      "epoch 52; iter: 0; batch classifier loss: 0.520526; batch adversarial loss: 0.524947\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465767; batch adversarial loss: 0.581788\n",
      "epoch 54; iter: 0; batch classifier loss: 0.507534; batch adversarial loss: 0.624419\n",
      "epoch 55; iter: 0; batch classifier loss: 0.555159; batch adversarial loss: 0.528393\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435383; batch adversarial loss: 0.530271\n",
      "epoch 57; iter: 0; batch classifier loss: 0.485724; batch adversarial loss: 0.580447\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464331; batch adversarial loss: 0.546271\n",
      "epoch 59; iter: 0; batch classifier loss: 0.508591; batch adversarial loss: 0.565327\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394999; batch adversarial loss: 0.617100\n",
      "epoch 61; iter: 0; batch classifier loss: 0.466129; batch adversarial loss: 0.615150\n",
      "epoch 62; iter: 0; batch classifier loss: 0.578837; batch adversarial loss: 0.619709\n",
      "epoch 63; iter: 0; batch classifier loss: 0.471351; batch adversarial loss: 0.635869\n",
      "epoch 64; iter: 0; batch classifier loss: 0.533301; batch adversarial loss: 0.587430\n",
      "epoch 65; iter: 0; batch classifier loss: 0.484296; batch adversarial loss: 0.622408\n",
      "epoch 66; iter: 0; batch classifier loss: 0.487976; batch adversarial loss: 0.601958\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410707; batch adversarial loss: 0.540654\n",
      "epoch 68; iter: 0; batch classifier loss: 0.567846; batch adversarial loss: 0.493621\n",
      "epoch 69; iter: 0; batch classifier loss: 0.475249; batch adversarial loss: 0.591559\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419819; batch adversarial loss: 0.619050\n",
      "epoch 71; iter: 0; batch classifier loss: 0.508664; batch adversarial loss: 0.530877\n",
      "epoch 72; iter: 0; batch classifier loss: 0.497750; batch adversarial loss: 0.559393\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387070; batch adversarial loss: 0.570687\n",
      "epoch 74; iter: 0; batch classifier loss: 0.590611; batch adversarial loss: 0.586239\n",
      "epoch 75; iter: 0; batch classifier loss: 0.374004; batch adversarial loss: 0.543280\n",
      "epoch 76; iter: 0; batch classifier loss: 0.489625; batch adversarial loss: 0.569879\n",
      "epoch 77; iter: 0; batch classifier loss: 0.487106; batch adversarial loss: 0.483458\n",
      "epoch 78; iter: 0; batch classifier loss: 0.494580; batch adversarial loss: 0.547063\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436680; batch adversarial loss: 0.603427\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365577; batch adversarial loss: 0.608975\n",
      "epoch 81; iter: 0; batch classifier loss: 0.478714; batch adversarial loss: 0.597127\n",
      "epoch 82; iter: 0; batch classifier loss: 0.491040; batch adversarial loss: 0.528710\n",
      "epoch 83; iter: 0; batch classifier loss: 0.453700; batch adversarial loss: 0.619309\n",
      "epoch 84; iter: 0; batch classifier loss: 0.456919; batch adversarial loss: 0.602042\n",
      "epoch 85; iter: 0; batch classifier loss: 0.382982; batch adversarial loss: 0.608380\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426566; batch adversarial loss: 0.618334\n",
      "epoch 87; iter: 0; batch classifier loss: 0.425808; batch adversarial loss: 0.594848\n",
      "epoch 88; iter: 0; batch classifier loss: 0.570523; batch adversarial loss: 0.494999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.451773; batch adversarial loss: 0.547481\n",
      "epoch 90; iter: 0; batch classifier loss: 0.450110; batch adversarial loss: 0.542801\n",
      "epoch 91; iter: 0; batch classifier loss: 0.471224; batch adversarial loss: 0.607819\n",
      "epoch 92; iter: 0; batch classifier loss: 0.440579; batch adversarial loss: 0.629494\n",
      "epoch 93; iter: 0; batch classifier loss: 0.605434; batch adversarial loss: 0.557123\n",
      "epoch 94; iter: 0; batch classifier loss: 0.495071; batch adversarial loss: 0.505367\n",
      "epoch 95; iter: 0; batch classifier loss: 0.521331; batch adversarial loss: 0.581912\n",
      "epoch 96; iter: 0; batch classifier loss: 0.441238; batch adversarial loss: 0.574117\n",
      "epoch 97; iter: 0; batch classifier loss: 0.538075; batch adversarial loss: 0.635003\n",
      "epoch 98; iter: 0; batch classifier loss: 0.468383; batch adversarial loss: 0.518554\n",
      "epoch 99; iter: 0; batch classifier loss: 0.439623; batch adversarial loss: 0.547867\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.995748; batch adversarial loss: 0.919312\n",
      "epoch 2; iter: 0; batch classifier loss: 1.005391; batch adversarial loss: 0.817239\n",
      "epoch 3; iter: 0; batch classifier loss: 0.901374; batch adversarial loss: 0.791215\n",
      "epoch 4; iter: 0; batch classifier loss: 0.901665; batch adversarial loss: 0.799186\n",
      "epoch 5; iter: 0; batch classifier loss: 0.966200; batch adversarial loss: 0.694209\n",
      "epoch 6; iter: 0; batch classifier loss: 0.800888; batch adversarial loss: 0.738939\n",
      "epoch 7; iter: 0; batch classifier loss: 0.773289; batch adversarial loss: 0.715731\n",
      "epoch 8; iter: 0; batch classifier loss: 0.710398; batch adversarial loss: 0.670678\n",
      "epoch 9; iter: 0; batch classifier loss: 0.712836; batch adversarial loss: 0.717689\n",
      "epoch 10; iter: 0; batch classifier loss: 0.706334; batch adversarial loss: 0.716566\n",
      "epoch 11; iter: 0; batch classifier loss: 0.699021; batch adversarial loss: 0.653691\n",
      "epoch 12; iter: 0; batch classifier loss: 0.719154; batch adversarial loss: 0.668079\n",
      "epoch 13; iter: 0; batch classifier loss: 0.687407; batch adversarial loss: 0.680922\n",
      "epoch 14; iter: 0; batch classifier loss: 0.692710; batch adversarial loss: 0.650062\n",
      "epoch 15; iter: 0; batch classifier loss: 0.613406; batch adversarial loss: 0.635086\n",
      "epoch 16; iter: 0; batch classifier loss: 0.668883; batch adversarial loss: 0.611202\n",
      "epoch 17; iter: 0; batch classifier loss: 0.630065; batch adversarial loss: 0.653265\n",
      "epoch 18; iter: 0; batch classifier loss: 0.624468; batch adversarial loss: 0.587539\n",
      "epoch 19; iter: 0; batch classifier loss: 0.654477; batch adversarial loss: 0.621552\n",
      "epoch 20; iter: 0; batch classifier loss: 0.697694; batch adversarial loss: 0.653379\n",
      "epoch 21; iter: 0; batch classifier loss: 0.638011; batch adversarial loss: 0.613714\n",
      "epoch 22; iter: 0; batch classifier loss: 0.592420; batch adversarial loss: 0.589256\n",
      "epoch 23; iter: 0; batch classifier loss: 0.593246; batch adversarial loss: 0.548039\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494799; batch adversarial loss: 0.548381\n",
      "epoch 25; iter: 0; batch classifier loss: 0.528438; batch adversarial loss: 0.548609\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482506; batch adversarial loss: 0.610332\n",
      "epoch 27; iter: 0; batch classifier loss: 0.434443; batch adversarial loss: 0.601477\n",
      "epoch 28; iter: 0; batch classifier loss: 0.539376; batch adversarial loss: 0.578648\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480152; batch adversarial loss: 0.562634\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486211; batch adversarial loss: 0.555876\n",
      "epoch 31; iter: 0; batch classifier loss: 0.493591; batch adversarial loss: 0.544352\n",
      "epoch 32; iter: 0; batch classifier loss: 0.608115; batch adversarial loss: 0.564724\n",
      "epoch 33; iter: 0; batch classifier loss: 0.708467; batch adversarial loss: 0.598697\n",
      "epoch 34; iter: 0; batch classifier loss: 0.776649; batch adversarial loss: 0.658174\n",
      "epoch 35; iter: 0; batch classifier loss: 0.759661; batch adversarial loss: 0.595110\n",
      "epoch 36; iter: 0; batch classifier loss: 0.675083; batch adversarial loss: 0.579512\n",
      "epoch 37; iter: 0; batch classifier loss: 0.593926; batch adversarial loss: 0.625438\n",
      "epoch 38; iter: 0; batch classifier loss: 0.549326; batch adversarial loss: 0.536801\n",
      "epoch 39; iter: 0; batch classifier loss: 0.481391; batch adversarial loss: 0.634632\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459909; batch adversarial loss: 0.613221\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476348; batch adversarial loss: 0.511376\n",
      "epoch 42; iter: 0; batch classifier loss: 0.455336; batch adversarial loss: 0.582717\n",
      "epoch 43; iter: 0; batch classifier loss: 0.589432; batch adversarial loss: 0.553019\n",
      "epoch 44; iter: 0; batch classifier loss: 0.514124; batch adversarial loss: 0.696593\n",
      "epoch 45; iter: 0; batch classifier loss: 0.550779; batch adversarial loss: 0.582697\n",
      "epoch 46; iter: 0; batch classifier loss: 0.515537; batch adversarial loss: 0.561745\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440006; batch adversarial loss: 0.587549\n",
      "epoch 48; iter: 0; batch classifier loss: 0.488016; batch adversarial loss: 0.553186\n",
      "epoch 49; iter: 0; batch classifier loss: 0.474166; batch adversarial loss: 0.550464\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493099; batch adversarial loss: 0.512325\n",
      "epoch 51; iter: 0; batch classifier loss: 0.489677; batch adversarial loss: 0.601077\n",
      "epoch 52; iter: 0; batch classifier loss: 0.532030; batch adversarial loss: 0.525787\n",
      "epoch 53; iter: 0; batch classifier loss: 0.474625; batch adversarial loss: 0.582910\n",
      "epoch 54; iter: 0; batch classifier loss: 0.531441; batch adversarial loss: 0.625739\n",
      "epoch 55; iter: 0; batch classifier loss: 0.575846; batch adversarial loss: 0.528536\n",
      "epoch 56; iter: 0; batch classifier loss: 0.436066; batch adversarial loss: 0.530639\n",
      "epoch 57; iter: 0; batch classifier loss: 0.487870; batch adversarial loss: 0.580264\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469880; batch adversarial loss: 0.546203\n",
      "epoch 59; iter: 0; batch classifier loss: 0.502319; batch adversarial loss: 0.565295\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393227; batch adversarial loss: 0.616613\n",
      "epoch 61; iter: 0; batch classifier loss: 0.477292; batch adversarial loss: 0.615309\n",
      "epoch 62; iter: 0; batch classifier loss: 0.577932; batch adversarial loss: 0.620240\n",
      "epoch 63; iter: 0; batch classifier loss: 0.482299; batch adversarial loss: 0.636709\n",
      "epoch 64; iter: 0; batch classifier loss: 0.537806; batch adversarial loss: 0.588125\n",
      "epoch 65; iter: 0; batch classifier loss: 0.478950; batch adversarial loss: 0.622356\n",
      "epoch 66; iter: 0; batch classifier loss: 0.486615; batch adversarial loss: 0.602564\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412095; batch adversarial loss: 0.541416\n",
      "epoch 68; iter: 0; batch classifier loss: 0.559107; batch adversarial loss: 0.493506\n",
      "epoch 69; iter: 0; batch classifier loss: 0.482362; batch adversarial loss: 0.592308\n",
      "epoch 70; iter: 0; batch classifier loss: 0.438437; batch adversarial loss: 0.620234\n",
      "epoch 71; iter: 0; batch classifier loss: 0.518045; batch adversarial loss: 0.530549\n",
      "epoch 72; iter: 0; batch classifier loss: 0.498371; batch adversarial loss: 0.560037\n",
      "epoch 73; iter: 0; batch classifier loss: 0.388866; batch adversarial loss: 0.569640\n",
      "epoch 74; iter: 0; batch classifier loss: 0.585795; batch adversarial loss: 0.584899\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388799; batch adversarial loss: 0.544309\n",
      "epoch 76; iter: 0; batch classifier loss: 0.509625; batch adversarial loss: 0.571197\n",
      "epoch 77; iter: 0; batch classifier loss: 0.493896; batch adversarial loss: 0.483824\n",
      "epoch 78; iter: 0; batch classifier loss: 0.480063; batch adversarial loss: 0.545757\n",
      "epoch 79; iter: 0; batch classifier loss: 0.442286; batch adversarial loss: 0.604225\n",
      "epoch 80; iter: 0; batch classifier loss: 0.384007; batch adversarial loss: 0.609558\n",
      "epoch 81; iter: 0; batch classifier loss: 0.478323; batch adversarial loss: 0.596271\n",
      "epoch 82; iter: 0; batch classifier loss: 0.469404; batch adversarial loss: 0.527993\n",
      "epoch 83; iter: 0; batch classifier loss: 0.467310; batch adversarial loss: 0.619513\n",
      "epoch 84; iter: 0; batch classifier loss: 0.451185; batch adversarial loss: 0.602939\n",
      "epoch 85; iter: 0; batch classifier loss: 0.369911; batch adversarial loss: 0.607014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.425784; batch adversarial loss: 0.618952\n",
      "epoch 87; iter: 0; batch classifier loss: 0.464016; batch adversarial loss: 0.594284\n",
      "epoch 88; iter: 0; batch classifier loss: 0.585703; batch adversarial loss: 0.495549\n",
      "epoch 89; iter: 0; batch classifier loss: 0.459391; batch adversarial loss: 0.548310\n",
      "epoch 90; iter: 0; batch classifier loss: 0.466383; batch adversarial loss: 0.544030\n",
      "epoch 91; iter: 0; batch classifier loss: 0.472217; batch adversarial loss: 0.610117\n",
      "epoch 92; iter: 0; batch classifier loss: 0.472993; batch adversarial loss: 0.626818\n",
      "epoch 93; iter: 0; batch classifier loss: 0.583485; batch adversarial loss: 0.555071\n",
      "epoch 94; iter: 0; batch classifier loss: 0.496138; batch adversarial loss: 0.505397\n",
      "epoch 95; iter: 0; batch classifier loss: 0.512161; batch adversarial loss: 0.581758\n",
      "epoch 96; iter: 0; batch classifier loss: 0.430766; batch adversarial loss: 0.572486\n",
      "epoch 97; iter: 0; batch classifier loss: 0.521673; batch adversarial loss: 0.635019\n",
      "epoch 98; iter: 0; batch classifier loss: 0.453871; batch adversarial loss: 0.518196\n",
      "epoch 99; iter: 0; batch classifier loss: 0.444025; batch adversarial loss: 0.550478\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.972728; batch adversarial loss: 0.917335\n",
      "epoch 2; iter: 0; batch classifier loss: 0.982500; batch adversarial loss: 0.815870\n",
      "epoch 3; iter: 0; batch classifier loss: 0.866950; batch adversarial loss: 0.788473\n",
      "epoch 4; iter: 0; batch classifier loss: 0.836003; batch adversarial loss: 0.793221\n",
      "epoch 5; iter: 0; batch classifier loss: 0.890519; batch adversarial loss: 0.691423\n",
      "epoch 6; iter: 0; batch classifier loss: 0.761009; batch adversarial loss: 0.734033\n",
      "epoch 7; iter: 0; batch classifier loss: 0.732334; batch adversarial loss: 0.710816\n",
      "epoch 8; iter: 0; batch classifier loss: 0.677976; batch adversarial loss: 0.668199\n",
      "epoch 9; iter: 0; batch classifier loss: 0.687570; batch adversarial loss: 0.715443\n",
      "epoch 10; iter: 0; batch classifier loss: 0.685534; batch adversarial loss: 0.714982\n",
      "epoch 11; iter: 0; batch classifier loss: 0.691738; batch adversarial loss: 0.652181\n",
      "epoch 12; iter: 0; batch classifier loss: 0.709898; batch adversarial loss: 0.667754\n",
      "epoch 13; iter: 0; batch classifier loss: 0.677156; batch adversarial loss: 0.680716\n",
      "epoch 14; iter: 0; batch classifier loss: 0.686060; batch adversarial loss: 0.649777\n",
      "epoch 15; iter: 0; batch classifier loss: 0.613216; batch adversarial loss: 0.635001\n",
      "epoch 16; iter: 0; batch classifier loss: 0.658119; batch adversarial loss: 0.610088\n",
      "epoch 17; iter: 0; batch classifier loss: 0.623854; batch adversarial loss: 0.653485\n",
      "epoch 18; iter: 0; batch classifier loss: 0.613961; batch adversarial loss: 0.586877\n",
      "epoch 19; iter: 0; batch classifier loss: 0.639545; batch adversarial loss: 0.621010\n",
      "epoch 20; iter: 0; batch classifier loss: 0.680128; batch adversarial loss: 0.653094\n",
      "epoch 21; iter: 0; batch classifier loss: 0.629345; batch adversarial loss: 0.613302\n",
      "epoch 22; iter: 0; batch classifier loss: 0.578562; batch adversarial loss: 0.588576\n",
      "epoch 23; iter: 0; batch classifier loss: 0.580701; batch adversarial loss: 0.547293\n",
      "epoch 24; iter: 0; batch classifier loss: 0.486156; batch adversarial loss: 0.546488\n",
      "epoch 25; iter: 0; batch classifier loss: 0.526254; batch adversarial loss: 0.545732\n",
      "epoch 26; iter: 0; batch classifier loss: 0.477419; batch adversarial loss: 0.609099\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440810; batch adversarial loss: 0.600645\n",
      "epoch 28; iter: 0; batch classifier loss: 0.535201; batch adversarial loss: 0.578546\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487456; batch adversarial loss: 0.562176\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486318; batch adversarial loss: 0.555931\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496996; batch adversarial loss: 0.546611\n",
      "epoch 32; iter: 0; batch classifier loss: 0.615855; batch adversarial loss: 0.566920\n",
      "epoch 33; iter: 0; batch classifier loss: 0.698274; batch adversarial loss: 0.601413\n",
      "epoch 34; iter: 0; batch classifier loss: 0.768678; batch adversarial loss: 0.662315\n",
      "epoch 35; iter: 0; batch classifier loss: 0.760296; batch adversarial loss: 0.599596\n",
      "epoch 36; iter: 0; batch classifier loss: 0.761646; batch adversarial loss: 0.582595\n",
      "epoch 37; iter: 0; batch classifier loss: 0.670343; batch adversarial loss: 0.622892\n",
      "epoch 38; iter: 0; batch classifier loss: 0.578098; batch adversarial loss: 0.536496\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490524; batch adversarial loss: 0.634271\n",
      "epoch 40; iter: 0; batch classifier loss: 0.486496; batch adversarial loss: 0.615813\n",
      "epoch 41; iter: 0; batch classifier loss: 0.468135; batch adversarial loss: 0.512044\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449438; batch adversarial loss: 0.582972\n",
      "epoch 43; iter: 0; batch classifier loss: 0.615628; batch adversarial loss: 0.553041\n",
      "epoch 44; iter: 0; batch classifier loss: 0.520006; batch adversarial loss: 0.695714\n",
      "epoch 45; iter: 0; batch classifier loss: 0.551185; batch adversarial loss: 0.581809\n",
      "epoch 46; iter: 0; batch classifier loss: 0.513252; batch adversarial loss: 0.561510\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440871; batch adversarial loss: 0.587901\n",
      "epoch 48; iter: 0; batch classifier loss: 0.487741; batch adversarial loss: 0.553351\n",
      "epoch 49; iter: 0; batch classifier loss: 0.472905; batch adversarial loss: 0.550498\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493373; batch adversarial loss: 0.512299\n",
      "epoch 51; iter: 0; batch classifier loss: 0.487399; batch adversarial loss: 0.600798\n",
      "epoch 52; iter: 0; batch classifier loss: 0.523641; batch adversarial loss: 0.525270\n",
      "epoch 53; iter: 0; batch classifier loss: 0.469223; batch adversarial loss: 0.582011\n",
      "epoch 54; iter: 0; batch classifier loss: 0.511716; batch adversarial loss: 0.625330\n",
      "epoch 55; iter: 0; batch classifier loss: 0.560138; batch adversarial loss: 0.528400\n",
      "epoch 56; iter: 0; batch classifier loss: 0.440264; batch adversarial loss: 0.530758\n",
      "epoch 57; iter: 0; batch classifier loss: 0.486061; batch adversarial loss: 0.580631\n",
      "epoch 58; iter: 0; batch classifier loss: 0.464626; batch adversarial loss: 0.546665\n",
      "epoch 59; iter: 0; batch classifier loss: 0.503853; batch adversarial loss: 0.565530\n",
      "epoch 60; iter: 0; batch classifier loss: 0.392253; batch adversarial loss: 0.616964\n",
      "epoch 61; iter: 0; batch classifier loss: 0.464208; batch adversarial loss: 0.615419\n",
      "epoch 62; iter: 0; batch classifier loss: 0.586419; batch adversarial loss: 0.620639\n",
      "epoch 63; iter: 0; batch classifier loss: 0.472982; batch adversarial loss: 0.636143\n",
      "epoch 64; iter: 0; batch classifier loss: 0.535405; batch adversarial loss: 0.587835\n",
      "epoch 65; iter: 0; batch classifier loss: 0.483671; batch adversarial loss: 0.622388\n",
      "epoch 66; iter: 0; batch classifier loss: 0.489877; batch adversarial loss: 0.602874\n",
      "epoch 67; iter: 0; batch classifier loss: 0.418749; batch adversarial loss: 0.541081\n",
      "epoch 68; iter: 0; batch classifier loss: 0.562333; batch adversarial loss: 0.493794\n",
      "epoch 69; iter: 0; batch classifier loss: 0.475436; batch adversarial loss: 0.591867\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419732; batch adversarial loss: 0.618908\n",
      "epoch 71; iter: 0; batch classifier loss: 0.510172; batch adversarial loss: 0.530890\n",
      "epoch 72; iter: 0; batch classifier loss: 0.495925; batch adversarial loss: 0.560087\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393107; batch adversarial loss: 0.570024\n",
      "epoch 74; iter: 0; batch classifier loss: 0.595436; batch adversarial loss: 0.586092\n",
      "epoch 75; iter: 0; batch classifier loss: 0.369643; batch adversarial loss: 0.543247\n",
      "epoch 76; iter: 0; batch classifier loss: 0.491166; batch adversarial loss: 0.570648\n",
      "epoch 77; iter: 0; batch classifier loss: 0.488932; batch adversarial loss: 0.483555\n",
      "epoch 78; iter: 0; batch classifier loss: 0.501591; batch adversarial loss: 0.547926\n",
      "epoch 79; iter: 0; batch classifier loss: 0.424475; batch adversarial loss: 0.603678\n",
      "epoch 80; iter: 0; batch classifier loss: 0.360897; batch adversarial loss: 0.608975\n",
      "epoch 81; iter: 0; batch classifier loss: 0.485486; batch adversarial loss: 0.597513\n",
      "epoch 82; iter: 0; batch classifier loss: 0.493570; batch adversarial loss: 0.528178\n",
      "epoch 83; iter: 0; batch classifier loss: 0.466164; batch adversarial loss: 0.619836\n",
      "epoch 84; iter: 0; batch classifier loss: 0.453107; batch adversarial loss: 0.602971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85; iter: 0; batch classifier loss: 0.382049; batch adversarial loss: 0.608369\n",
      "epoch 86; iter: 0; batch classifier loss: 0.439089; batch adversarial loss: 0.620287\n",
      "epoch 87; iter: 0; batch classifier loss: 0.432712; batch adversarial loss: 0.595009\n",
      "epoch 88; iter: 0; batch classifier loss: 0.564392; batch adversarial loss: 0.493726\n",
      "epoch 89; iter: 0; batch classifier loss: 0.452573; batch adversarial loss: 0.546666\n",
      "epoch 90; iter: 0; batch classifier loss: 0.456012; batch adversarial loss: 0.543465\n",
      "epoch 91; iter: 0; batch classifier loss: 0.472896; batch adversarial loss: 0.609030\n",
      "epoch 92; iter: 0; batch classifier loss: 0.445650; batch adversarial loss: 0.629158\n",
      "epoch 93; iter: 0; batch classifier loss: 0.592017; batch adversarial loss: 0.555475\n",
      "epoch 94; iter: 0; batch classifier loss: 0.499693; batch adversarial loss: 0.505951\n",
      "epoch 95; iter: 0; batch classifier loss: 0.524262; batch adversarial loss: 0.582671\n",
      "epoch 96; iter: 0; batch classifier loss: 0.431681; batch adversarial loss: 0.573308\n",
      "epoch 97; iter: 0; batch classifier loss: 0.540515; batch adversarial loss: 0.635366\n",
      "epoch 98; iter: 0; batch classifier loss: 0.476113; batch adversarial loss: 0.519476\n",
      "epoch 99; iter: 0; batch classifier loss: 0.434127; batch adversarial loss: 0.549823\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 1.000975; batch adversarial loss: 0.919745\n",
      "epoch 2; iter: 0; batch classifier loss: 1.011615; batch adversarial loss: 0.817622\n",
      "epoch 3; iter: 0; batch classifier loss: 0.911494; batch adversarial loss: 0.791944\n",
      "epoch 4; iter: 0; batch classifier loss: 0.918932; batch adversarial loss: 0.800612\n",
      "epoch 5; iter: 0; batch classifier loss: 0.986198; batch adversarial loss: 0.694827\n",
      "epoch 6; iter: 0; batch classifier loss: 0.809531; batch adversarial loss: 0.739897\n",
      "epoch 7; iter: 0; batch classifier loss: 0.783383; batch adversarial loss: 0.716659\n",
      "epoch 8; iter: 0; batch classifier loss: 0.719051; batch adversarial loss: 0.671091\n",
      "epoch 9; iter: 0; batch classifier loss: 0.719290; batch adversarial loss: 0.717834\n",
      "epoch 10; iter: 0; batch classifier loss: 0.711521; batch adversarial loss: 0.716648\n",
      "epoch 11; iter: 0; batch classifier loss: 0.701423; batch adversarial loss: 0.654222\n",
      "epoch 12; iter: 0; batch classifier loss: 0.721393; batch adversarial loss: 0.668724\n",
      "epoch 13; iter: 0; batch classifier loss: 0.691200; batch adversarial loss: 0.681013\n",
      "epoch 14; iter: 0; batch classifier loss: 0.696647; batch adversarial loss: 0.650207\n",
      "epoch 15; iter: 0; batch classifier loss: 0.616889; batch adversarial loss: 0.635110\n",
      "epoch 16; iter: 0; batch classifier loss: 0.673043; batch adversarial loss: 0.611485\n",
      "epoch 17; iter: 0; batch classifier loss: 0.633470; batch adversarial loss: 0.653706\n",
      "epoch 18; iter: 0; batch classifier loss: 0.628691; batch adversarial loss: 0.587930\n",
      "epoch 19; iter: 0; batch classifier loss: 0.661271; batch adversarial loss: 0.621811\n",
      "epoch 20; iter: 0; batch classifier loss: 0.700003; batch adversarial loss: 0.653372\n",
      "epoch 21; iter: 0; batch classifier loss: 0.646443; batch adversarial loss: 0.613847\n",
      "epoch 22; iter: 0; batch classifier loss: 0.597307; batch adversarial loss: 0.589518\n",
      "epoch 23; iter: 0; batch classifier loss: 0.596122; batch adversarial loss: 0.548328\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497647; batch adversarial loss: 0.548948\n",
      "epoch 25; iter: 0; batch classifier loss: 0.530445; batch adversarial loss: 0.549924\n",
      "epoch 26; iter: 0; batch classifier loss: 0.486875; batch adversarial loss: 0.610752\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440903; batch adversarial loss: 0.601621\n",
      "epoch 28; iter: 0; batch classifier loss: 0.537307; batch adversarial loss: 0.578891\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479822; batch adversarial loss: 0.563076\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486353; batch adversarial loss: 0.555806\n",
      "epoch 31; iter: 0; batch classifier loss: 0.486475; batch adversarial loss: 0.542392\n",
      "epoch 32; iter: 0; batch classifier loss: 0.609233; batch adversarial loss: 0.562961\n",
      "epoch 33; iter: 0; batch classifier loss: 0.704130; batch adversarial loss: 0.597517\n",
      "epoch 34; iter: 0; batch classifier loss: 0.781855; batch adversarial loss: 0.658191\n",
      "epoch 35; iter: 0; batch classifier loss: 0.760516; batch adversarial loss: 0.594748\n",
      "epoch 36; iter: 0; batch classifier loss: 0.660575; batch adversarial loss: 0.579381\n",
      "epoch 37; iter: 0; batch classifier loss: 0.585722; batch adversarial loss: 0.625813\n",
      "epoch 38; iter: 0; batch classifier loss: 0.537416; batch adversarial loss: 0.536589\n",
      "epoch 39; iter: 0; batch classifier loss: 0.484913; batch adversarial loss: 0.634086\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468670; batch adversarial loss: 0.613112\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476257; batch adversarial loss: 0.511299\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450202; batch adversarial loss: 0.582591\n",
      "epoch 43; iter: 0; batch classifier loss: 0.593146; batch adversarial loss: 0.553185\n",
      "epoch 44; iter: 0; batch classifier loss: 0.517130; batch adversarial loss: 0.696602\n",
      "epoch 45; iter: 0; batch classifier loss: 0.546722; batch adversarial loss: 0.582685\n",
      "epoch 46; iter: 0; batch classifier loss: 0.521011; batch adversarial loss: 0.561801\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436593; batch adversarial loss: 0.587558\n",
      "epoch 48; iter: 0; batch classifier loss: 0.489602; batch adversarial loss: 0.553154\n",
      "epoch 49; iter: 0; batch classifier loss: 0.474289; batch adversarial loss: 0.550431\n",
      "epoch 50; iter: 0; batch classifier loss: 0.489467; batch adversarial loss: 0.512103\n",
      "epoch 51; iter: 0; batch classifier loss: 0.486415; batch adversarial loss: 0.600937\n",
      "epoch 52; iter: 0; batch classifier loss: 0.522994; batch adversarial loss: 0.525565\n",
      "epoch 53; iter: 0; batch classifier loss: 0.471378; batch adversarial loss: 0.582134\n",
      "epoch 54; iter: 0; batch classifier loss: 0.527447; batch adversarial loss: 0.625785\n",
      "epoch 55; iter: 0; batch classifier loss: 0.583274; batch adversarial loss: 0.528821\n",
      "epoch 56; iter: 0; batch classifier loss: 0.442380; batch adversarial loss: 0.531027\n",
      "epoch 57; iter: 0; batch classifier loss: 0.495004; batch adversarial loss: 0.580298\n",
      "epoch 58; iter: 0; batch classifier loss: 0.471256; batch adversarial loss: 0.546768\n",
      "epoch 59; iter: 0; batch classifier loss: 0.504586; batch adversarial loss: 0.565617\n",
      "epoch 60; iter: 0; batch classifier loss: 0.395291; batch adversarial loss: 0.617031\n",
      "epoch 61; iter: 0; batch classifier loss: 0.488474; batch adversarial loss: 0.616025\n",
      "epoch 62; iter: 0; batch classifier loss: 0.580025; batch adversarial loss: 0.620052\n",
      "epoch 63; iter: 0; batch classifier loss: 0.485324; batch adversarial loss: 0.636365\n",
      "epoch 64; iter: 0; batch classifier loss: 0.546414; batch adversarial loss: 0.588805\n",
      "epoch 65; iter: 0; batch classifier loss: 0.476254; batch adversarial loss: 0.622738\n",
      "epoch 66; iter: 0; batch classifier loss: 0.488949; batch adversarial loss: 0.602921\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416106; batch adversarial loss: 0.541677\n",
      "epoch 68; iter: 0; batch classifier loss: 0.574319; batch adversarial loss: 0.494979\n",
      "epoch 69; iter: 0; batch classifier loss: 0.488742; batch adversarial loss: 0.592827\n",
      "epoch 70; iter: 0; batch classifier loss: 0.436733; batch adversarial loss: 0.620696\n",
      "epoch 71; iter: 0; batch classifier loss: 0.519266; batch adversarial loss: 0.531068\n",
      "epoch 72; iter: 0; batch classifier loss: 0.506238; batch adversarial loss: 0.560601\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386465; batch adversarial loss: 0.569804\n",
      "epoch 74; iter: 0; batch classifier loss: 0.593815; batch adversarial loss: 0.586313\n",
      "epoch 75; iter: 0; batch classifier loss: 0.383376; batch adversarial loss: 0.544509\n",
      "epoch 76; iter: 0; batch classifier loss: 0.519126; batch adversarial loss: 0.572109\n",
      "epoch 77; iter: 0; batch classifier loss: 0.502658; batch adversarial loss: 0.484522\n",
      "epoch 78; iter: 0; batch classifier loss: 0.481650; batch adversarial loss: 0.546841\n",
      "epoch 79; iter: 0; batch classifier loss: 0.449798; batch adversarial loss: 0.603928\n",
      "epoch 80; iter: 0; batch classifier loss: 0.387423; batch adversarial loss: 0.609853\n",
      "epoch 81; iter: 0; batch classifier loss: 0.487815; batch adversarial loss: 0.598559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.477194; batch adversarial loss: 0.529302\n",
      "epoch 83; iter: 0; batch classifier loss: 0.478186; batch adversarial loss: 0.619846\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446659; batch adversarial loss: 0.603277\n",
      "epoch 85; iter: 0; batch classifier loss: 0.380035; batch adversarial loss: 0.608413\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432324; batch adversarial loss: 0.618834\n",
      "epoch 87; iter: 0; batch classifier loss: 0.453931; batch adversarial loss: 0.595203\n",
      "epoch 88; iter: 0; batch classifier loss: 0.581728; batch adversarial loss: 0.495994\n",
      "epoch 89; iter: 0; batch classifier loss: 0.468805; batch adversarial loss: 0.548879\n",
      "epoch 90; iter: 0; batch classifier loss: 0.461268; batch adversarial loss: 0.544201\n",
      "epoch 91; iter: 0; batch classifier loss: 0.464967; batch adversarial loss: 0.608564\n",
      "epoch 92; iter: 0; batch classifier loss: 0.469285; batch adversarial loss: 0.629444\n",
      "epoch 93; iter: 0; batch classifier loss: 0.591223; batch adversarial loss: 0.554829\n",
      "epoch 94; iter: 0; batch classifier loss: 0.513816; batch adversarial loss: 0.507022\n",
      "epoch 95; iter: 0; batch classifier loss: 0.524282; batch adversarial loss: 0.582795\n",
      "epoch 96; iter: 0; batch classifier loss: 0.439188; batch adversarial loss: 0.572833\n",
      "epoch 97; iter: 0; batch classifier loss: 0.534305; batch adversarial loss: 0.635165\n",
      "epoch 98; iter: 0; batch classifier loss: 0.459240; batch adversarial loss: 0.518529\n",
      "epoch 99; iter: 0; batch classifier loss: 0.453031; batch adversarial loss: 0.550725\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.934696; batch adversarial loss: 0.913301\n",
      "epoch 2; iter: 0; batch classifier loss: 0.940384; batch adversarial loss: 0.812737\n",
      "epoch 3; iter: 0; batch classifier loss: 0.799265; batch adversarial loss: 0.782595\n",
      "epoch 4; iter: 0; batch classifier loss: 0.712549; batch adversarial loss: 0.780802\n",
      "epoch 5; iter: 0; batch classifier loss: 0.665372; batch adversarial loss: 0.677552\n",
      "epoch 6; iter: 0; batch classifier loss: 0.601355; batch adversarial loss: 0.700124\n",
      "epoch 7; iter: 0; batch classifier loss: 0.507065; batch adversarial loss: 0.668881\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466219; batch adversarial loss: 0.639874\n",
      "epoch 9; iter: 0; batch classifier loss: 0.436363; batch adversarial loss: 0.663323\n",
      "epoch 10; iter: 0; batch classifier loss: 0.446088; batch adversarial loss: 0.661158\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544804; batch adversarial loss: 0.617638\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529337; batch adversarial loss: 0.624444\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510807; batch adversarial loss: 0.629034\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487689; batch adversarial loss: 0.606883\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481075; batch adversarial loss: 0.596582\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487330; batch adversarial loss: 0.570892\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518859; batch adversarial loss: 0.613062\n",
      "epoch 18; iter: 0; batch classifier loss: 0.470524; batch adversarial loss: 0.560283\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444265; batch adversarial loss: 0.588733\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478051; batch adversarial loss: 0.628653\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498759; batch adversarial loss: 0.601698\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525675; batch adversarial loss: 0.604130\n",
      "epoch 23; iter: 0; batch classifier loss: 0.622508; batch adversarial loss: 0.582322\n",
      "epoch 24; iter: 0; batch classifier loss: 0.481574; batch adversarial loss: 0.575335\n",
      "epoch 25; iter: 0; batch classifier loss: 0.614640; batch adversarial loss: 0.609433\n",
      "epoch 26; iter: 0; batch classifier loss: 0.866023; batch adversarial loss: 0.717145\n",
      "epoch 27; iter: 0; batch classifier loss: 0.875262; batch adversarial loss: 0.691530\n",
      "epoch 28; iter: 0; batch classifier loss: 0.863274; batch adversarial loss: 0.638649\n",
      "epoch 29; iter: 0; batch classifier loss: 0.747277; batch adversarial loss: 0.614444\n",
      "epoch 30; iter: 0; batch classifier loss: 0.607062; batch adversarial loss: 0.589645\n",
      "epoch 31; iter: 0; batch classifier loss: 0.517073; batch adversarial loss: 0.559382\n",
      "epoch 32; iter: 0; batch classifier loss: 0.554958; batch adversarial loss: 0.566443\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477963; batch adversarial loss: 0.574721\n",
      "epoch 34; iter: 0; batch classifier loss: 0.472336; batch adversarial loss: 0.615305\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390597; batch adversarial loss: 0.572825\n",
      "epoch 36; iter: 0; batch classifier loss: 0.435708; batch adversarial loss: 0.571028\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460349; batch adversarial loss: 0.622687\n",
      "epoch 38; iter: 0; batch classifier loss: 0.508860; batch adversarial loss: 0.531464\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431514; batch adversarial loss: 0.642377\n",
      "epoch 40; iter: 0; batch classifier loss: 0.487738; batch adversarial loss: 0.629781\n",
      "epoch 41; iter: 0; batch classifier loss: 0.509219; batch adversarial loss: 0.525284\n",
      "epoch 42; iter: 0; batch classifier loss: 0.578354; batch adversarial loss: 0.606753\n",
      "epoch 43; iter: 0; batch classifier loss: 0.776366; batch adversarial loss: 0.577442\n",
      "epoch 44; iter: 0; batch classifier loss: 0.877365; batch adversarial loss: 0.714854\n",
      "epoch 45; iter: 0; batch classifier loss: 0.746913; batch adversarial loss: 0.586879\n",
      "epoch 46; iter: 0; batch classifier loss: 0.450869; batch adversarial loss: 0.562767\n",
      "epoch 47; iter: 0; batch classifier loss: 0.390431; batch adversarial loss: 0.588636\n",
      "epoch 48; iter: 0; batch classifier loss: 0.444002; batch adversarial loss: 0.554143\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427074; batch adversarial loss: 0.552121\n",
      "epoch 50; iter: 0; batch classifier loss: 0.468920; batch adversarial loss: 0.514895\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466833; batch adversarial loss: 0.601760\n",
      "epoch 52; iter: 0; batch classifier loss: 0.460791; batch adversarial loss: 0.526564\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443822; batch adversarial loss: 0.582695\n",
      "epoch 54; iter: 0; batch classifier loss: 0.466609; batch adversarial loss: 0.625562\n",
      "epoch 55; iter: 0; batch classifier loss: 0.528547; batch adversarial loss: 0.528911\n",
      "epoch 56; iter: 0; batch classifier loss: 0.384657; batch adversarial loss: 0.531669\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441380; batch adversarial loss: 0.580172\n",
      "epoch 58; iter: 0; batch classifier loss: 0.422333; batch adversarial loss: 0.547325\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464251; batch adversarial loss: 0.565114\n",
      "epoch 60; iter: 0; batch classifier loss: 0.387641; batch adversarial loss: 0.617006\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451555; batch adversarial loss: 0.615231\n",
      "epoch 62; iter: 0; batch classifier loss: 0.521818; batch adversarial loss: 0.622069\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435166; batch adversarial loss: 0.637755\n",
      "epoch 64; iter: 0; batch classifier loss: 0.503847; batch adversarial loss: 0.588250\n",
      "epoch 65; iter: 0; batch classifier loss: 0.474536; batch adversarial loss: 0.624242\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439244; batch adversarial loss: 0.601814\n",
      "epoch 67; iter: 0; batch classifier loss: 0.377734; batch adversarial loss: 0.541631\n",
      "epoch 68; iter: 0; batch classifier loss: 0.539416; batch adversarial loss: 0.496542\n",
      "epoch 69; iter: 0; batch classifier loss: 0.445752; batch adversarial loss: 0.592818\n",
      "epoch 70; iter: 0; batch classifier loss: 0.430574; batch adversarial loss: 0.622545\n",
      "epoch 71; iter: 0; batch classifier loss: 0.474887; batch adversarial loss: 0.532059\n",
      "epoch 72; iter: 0; batch classifier loss: 0.462066; batch adversarial loss: 0.563750\n",
      "epoch 73; iter: 0; batch classifier loss: 0.352512; batch adversarial loss: 0.571290\n",
      "epoch 74; iter: 0; batch classifier loss: 0.564688; batch adversarial loss: 0.588197\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366546; batch adversarial loss: 0.544593\n",
      "epoch 76; iter: 0; batch classifier loss: 0.475002; batch adversarial loss: 0.571713\n",
      "epoch 77; iter: 0; batch classifier loss: 0.458075; batch adversarial loss: 0.484229\n",
      "epoch 78; iter: 0; batch classifier loss: 0.515629; batch adversarial loss: 0.550710\n",
      "epoch 79; iter: 0; batch classifier loss: 0.462408; batch adversarial loss: 0.608442\n",
      "epoch 80; iter: 0; batch classifier loss: 0.367886; batch adversarial loss: 0.612143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.486639; batch adversarial loss: 0.601788\n",
      "epoch 82; iter: 0; batch classifier loss: 0.442007; batch adversarial loss: 0.528887\n",
      "epoch 83; iter: 0; batch classifier loss: 0.470524; batch adversarial loss: 0.622911\n",
      "epoch 84; iter: 0; batch classifier loss: 0.453082; batch adversarial loss: 0.606669\n",
      "epoch 85; iter: 0; batch classifier loss: 0.360279; batch adversarial loss: 0.609824\n",
      "epoch 86; iter: 0; batch classifier loss: 0.461772; batch adversarial loss: 0.624410\n",
      "epoch 87; iter: 0; batch classifier loss: 0.445780; batch adversarial loss: 0.599086\n",
      "epoch 88; iter: 0; batch classifier loss: 0.551110; batch adversarial loss: 0.496642\n",
      "epoch 89; iter: 0; batch classifier loss: 0.434145; batch adversarial loss: 0.547966\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444839; batch adversarial loss: 0.545626\n",
      "epoch 91; iter: 0; batch classifier loss: 0.434665; batch adversarial loss: 0.612658\n",
      "epoch 92; iter: 0; batch classifier loss: 0.480896; batch adversarial loss: 0.630866\n",
      "epoch 93; iter: 0; batch classifier loss: 0.606027; batch adversarial loss: 0.559531\n",
      "epoch 94; iter: 0; batch classifier loss: 0.487934; batch adversarial loss: 0.506942\n",
      "epoch 95; iter: 0; batch classifier loss: 0.525298; batch adversarial loss: 0.587081\n",
      "epoch 96; iter: 0; batch classifier loss: 0.435965; batch adversarial loss: 0.574679\n",
      "epoch 97; iter: 0; batch classifier loss: 0.537217; batch adversarial loss: 0.642664\n",
      "epoch 98; iter: 0; batch classifier loss: 0.469543; batch adversarial loss: 0.520033\n",
      "epoch 99; iter: 0; batch classifier loss: 0.459421; batch adversarial loss: 0.549625\n",
      "epoch 100; iter: 0; batch classifier loss: 0.549717; batch adversarial loss: 0.583320\n",
      "epoch 101; iter: 0; batch classifier loss: 0.453227; batch adversarial loss: 0.626855\n",
      "epoch 102; iter: 0; batch classifier loss: 0.642839; batch adversarial loss: 0.542559\n",
      "epoch 103; iter: 0; batch classifier loss: 0.624375; batch adversarial loss: 0.569258\n",
      "epoch 104; iter: 0; batch classifier loss: 0.449232; batch adversarial loss: 0.539605\n",
      "epoch 105; iter: 0; batch classifier loss: 0.497611; batch adversarial loss: 0.648697\n",
      "epoch 106; iter: 0; batch classifier loss: 0.462422; batch adversarial loss: 0.640493\n",
      "epoch 107; iter: 0; batch classifier loss: 0.562200; batch adversarial loss: 0.566662\n",
      "epoch 108; iter: 0; batch classifier loss: 0.467297; batch adversarial loss: 0.578086\n",
      "epoch 109; iter: 0; batch classifier loss: 0.632165; batch adversarial loss: 0.500148\n",
      "epoch 110; iter: 0; batch classifier loss: 0.602865; batch adversarial loss: 0.528294\n",
      "epoch 111; iter: 0; batch classifier loss: 0.457165; batch adversarial loss: 0.590342\n",
      "epoch 112; iter: 0; batch classifier loss: 0.590808; batch adversarial loss: 0.559817\n",
      "epoch 113; iter: 0; batch classifier loss: 0.590939; batch adversarial loss: 0.560713\n",
      "epoch 114; iter: 0; batch classifier loss: 0.517042; batch adversarial loss: 0.588385\n",
      "epoch 115; iter: 0; batch classifier loss: 0.490375; batch adversarial loss: 0.515026\n",
      "epoch 116; iter: 0; batch classifier loss: 0.534398; batch adversarial loss: 0.557402\n",
      "epoch 117; iter: 0; batch classifier loss: 0.474862; batch adversarial loss: 0.602421\n",
      "epoch 118; iter: 0; batch classifier loss: 0.495317; batch adversarial loss: 0.586757\n",
      "epoch 119; iter: 0; batch classifier loss: 0.479370; batch adversarial loss: 0.609230\n",
      "epoch 120; iter: 0; batch classifier loss: 0.433242; batch adversarial loss: 0.591268\n",
      "epoch 121; iter: 0; batch classifier loss: 0.625769; batch adversarial loss: 0.638060\n",
      "epoch 122; iter: 0; batch classifier loss: 0.653366; batch adversarial loss: 0.571572\n",
      "epoch 123; iter: 0; batch classifier loss: 0.623717; batch adversarial loss: 0.603543\n",
      "epoch 124; iter: 0; batch classifier loss: 0.580325; batch adversarial loss: 0.555409\n",
      "epoch 125; iter: 0; batch classifier loss: 0.561352; batch adversarial loss: 0.615280\n",
      "epoch 126; iter: 0; batch classifier loss: 0.594973; batch adversarial loss: 0.572252\n",
      "epoch 127; iter: 0; batch classifier loss: 0.541937; batch adversarial loss: 0.521497\n",
      "epoch 128; iter: 0; batch classifier loss: 0.471776; batch adversarial loss: 0.592039\n",
      "epoch 129; iter: 0; batch classifier loss: 0.503967; batch adversarial loss: 0.635084\n",
      "epoch 130; iter: 0; batch classifier loss: 0.567080; batch adversarial loss: 0.561696\n",
      "epoch 131; iter: 0; batch classifier loss: 0.454110; batch adversarial loss: 0.602440\n",
      "epoch 132; iter: 0; batch classifier loss: 0.578508; batch adversarial loss: 0.542566\n",
      "epoch 133; iter: 0; batch classifier loss: 0.552382; batch adversarial loss: 0.626288\n",
      "epoch 134; iter: 0; batch classifier loss: 0.484514; batch adversarial loss: 0.563938\n",
      "epoch 135; iter: 0; batch classifier loss: 0.573844; batch adversarial loss: 0.630256\n",
      "epoch 136; iter: 0; batch classifier loss: 0.558879; batch adversarial loss: 0.570129\n",
      "epoch 137; iter: 0; batch classifier loss: 0.475701; batch adversarial loss: 0.649234\n",
      "epoch 138; iter: 0; batch classifier loss: 0.520775; batch adversarial loss: 0.555830\n",
      "epoch 139; iter: 0; batch classifier loss: 0.513928; batch adversarial loss: 0.549351\n",
      "epoch 140; iter: 0; batch classifier loss: 0.506571; batch adversarial loss: 0.609042\n",
      "epoch 141; iter: 0; batch classifier loss: 0.582011; batch adversarial loss: 0.500575\n",
      "epoch 142; iter: 0; batch classifier loss: 0.669938; batch adversarial loss: 0.577543\n",
      "epoch 143; iter: 0; batch classifier loss: 0.555558; batch adversarial loss: 0.497708\n",
      "epoch 144; iter: 0; batch classifier loss: 0.440058; batch adversarial loss: 0.612934\n",
      "epoch 145; iter: 0; batch classifier loss: 0.526392; batch adversarial loss: 0.520263\n",
      "epoch 146; iter: 0; batch classifier loss: 0.659121; batch adversarial loss: 0.566166\n",
      "epoch 147; iter: 0; batch classifier loss: 0.540847; batch adversarial loss: 0.511979\n",
      "epoch 148; iter: 0; batch classifier loss: 0.685549; batch adversarial loss: 0.571421\n",
      "epoch 149; iter: 0; batch classifier loss: 0.522996; batch adversarial loss: 0.549261\n",
      "epoch 150; iter: 0; batch classifier loss: 0.549119; batch adversarial loss: 0.564637\n",
      "epoch 151; iter: 0; batch classifier loss: 0.571934; batch adversarial loss: 0.539969\n",
      "epoch 152; iter: 0; batch classifier loss: 0.555610; batch adversarial loss: 0.598132\n",
      "epoch 153; iter: 0; batch classifier loss: 0.682188; batch adversarial loss: 0.548730\n",
      "epoch 154; iter: 0; batch classifier loss: 0.476813; batch adversarial loss: 0.609435\n",
      "epoch 155; iter: 0; batch classifier loss: 0.506193; batch adversarial loss: 0.605791\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373315; batch adversarial loss: 0.613087\n",
      "epoch 157; iter: 0; batch classifier loss: 0.496747; batch adversarial loss: 0.513711\n",
      "epoch 158; iter: 0; batch classifier loss: 0.648047; batch adversarial loss: 0.625951\n",
      "epoch 159; iter: 0; batch classifier loss: 0.514327; batch adversarial loss: 0.585921\n",
      "epoch 160; iter: 0; batch classifier loss: 0.571231; batch adversarial loss: 0.579748\n",
      "epoch 161; iter: 0; batch classifier loss: 0.575837; batch adversarial loss: 0.556647\n",
      "epoch 162; iter: 0; batch classifier loss: 0.535719; batch adversarial loss: 0.575076\n",
      "epoch 163; iter: 0; batch classifier loss: 0.644134; batch adversarial loss: 0.542566\n",
      "epoch 164; iter: 0; batch classifier loss: 0.464159; batch adversarial loss: 0.555427\n",
      "epoch 165; iter: 0; batch classifier loss: 0.617234; batch adversarial loss: 0.563377\n",
      "epoch 166; iter: 0; batch classifier loss: 0.564250; batch adversarial loss: 0.590795\n",
      "epoch 167; iter: 0; batch classifier loss: 0.516226; batch adversarial loss: 0.571116\n",
      "epoch 168; iter: 0; batch classifier loss: 0.590771; batch adversarial loss: 0.606435\n",
      "epoch 169; iter: 0; batch classifier loss: 0.556700; batch adversarial loss: 0.591707\n",
      "epoch 170; iter: 0; batch classifier loss: 0.666088; batch adversarial loss: 0.550403\n",
      "epoch 171; iter: 0; batch classifier loss: 0.534286; batch adversarial loss: 0.519546\n",
      "epoch 172; iter: 0; batch classifier loss: 0.502591; batch adversarial loss: 0.581019\n",
      "epoch 173; iter: 0; batch classifier loss: 0.564197; batch adversarial loss: 0.544997\n",
      "epoch 174; iter: 0; batch classifier loss: 0.627998; batch adversarial loss: 0.552174\n",
      "epoch 175; iter: 0; batch classifier loss: 0.514828; batch adversarial loss: 0.549930\n",
      "epoch 176; iter: 0; batch classifier loss: 0.626647; batch adversarial loss: 0.522043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.610258; batch adversarial loss: 0.603853\n",
      "epoch 178; iter: 0; batch classifier loss: 0.380856; batch adversarial loss: 0.545240\n",
      "epoch 179; iter: 0; batch classifier loss: 0.563970; batch adversarial loss: 0.608587\n",
      "epoch 180; iter: 0; batch classifier loss: 0.496589; batch adversarial loss: 0.536882\n",
      "epoch 181; iter: 0; batch classifier loss: 0.682866; batch adversarial loss: 0.637886\n",
      "epoch 182; iter: 0; batch classifier loss: 0.507746; batch adversarial loss: 0.594082\n",
      "epoch 183; iter: 0; batch classifier loss: 0.652712; batch adversarial loss: 0.642560\n",
      "epoch 184; iter: 0; batch classifier loss: 0.513515; batch adversarial loss: 0.528809\n",
      "epoch 185; iter: 0; batch classifier loss: 0.650449; batch adversarial loss: 0.624049\n",
      "epoch 186; iter: 0; batch classifier loss: 0.502281; batch adversarial loss: 0.530645\n",
      "epoch 187; iter: 0; batch classifier loss: 0.517489; batch adversarial loss: 0.551627\n",
      "epoch 188; iter: 0; batch classifier loss: 0.461424; batch adversarial loss: 0.562756\n",
      "epoch 189; iter: 0; batch classifier loss: 0.608488; batch adversarial loss: 0.564226\n",
      "epoch 190; iter: 0; batch classifier loss: 0.560630; batch adversarial loss: 0.533465\n",
      "epoch 191; iter: 0; batch classifier loss: 0.433271; batch adversarial loss: 0.595454\n",
      "epoch 192; iter: 0; batch classifier loss: 0.509714; batch adversarial loss: 0.569082\n",
      "epoch 193; iter: 0; batch classifier loss: 0.573819; batch adversarial loss: 0.504739\n",
      "epoch 194; iter: 0; batch classifier loss: 0.504721; batch adversarial loss: 0.595214\n",
      "epoch 195; iter: 0; batch classifier loss: 0.732442; batch adversarial loss: 0.530160\n",
      "epoch 196; iter: 0; batch classifier loss: 0.593350; batch adversarial loss: 0.601449\n",
      "epoch 197; iter: 0; batch classifier loss: 0.424853; batch adversarial loss: 0.607159\n",
      "epoch 198; iter: 0; batch classifier loss: 0.602008; batch adversarial loss: 0.607870\n",
      "epoch 199; iter: 0; batch classifier loss: 0.352569; batch adversarial loss: 0.653358\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.937896; batch adversarial loss: 0.913666\n",
      "epoch 2; iter: 0; batch classifier loss: 0.944024; batch adversarial loss: 0.813011\n",
      "epoch 3; iter: 0; batch classifier loss: 0.804139; batch adversarial loss: 0.783083\n",
      "epoch 4; iter: 0; batch classifier loss: 0.720583; batch adversarial loss: 0.781631\n",
      "epoch 5; iter: 0; batch classifier loss: 0.683865; batch adversarial loss: 0.678633\n",
      "epoch 6; iter: 0; batch classifier loss: 0.617310; batch adversarial loss: 0.704942\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533929; batch adversarial loss: 0.675014\n",
      "epoch 8; iter: 0; batch classifier loss: 0.476260; batch adversarial loss: 0.641259\n",
      "epoch 9; iter: 0; batch classifier loss: 0.438290; batch adversarial loss: 0.664174\n",
      "epoch 10; iter: 0; batch classifier loss: 0.447920; batch adversarial loss: 0.661637\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544286; batch adversarial loss: 0.618179\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530695; batch adversarial loss: 0.624359\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510269; batch adversarial loss: 0.629638\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487965; batch adversarial loss: 0.607245\n",
      "epoch 15; iter: 0; batch classifier loss: 0.478718; batch adversarial loss: 0.597086\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487450; batch adversarial loss: 0.571221\n",
      "epoch 17; iter: 0; batch classifier loss: 0.517834; batch adversarial loss: 0.613378\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466891; batch adversarial loss: 0.560453\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444744; batch adversarial loss: 0.589076\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475600; batch adversarial loss: 0.628242\n",
      "epoch 21; iter: 0; batch classifier loss: 0.496961; batch adversarial loss: 0.600632\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525522; batch adversarial loss: 0.603163\n",
      "epoch 23; iter: 0; batch classifier loss: 0.625999; batch adversarial loss: 0.582430\n",
      "epoch 24; iter: 0; batch classifier loss: 0.486900; batch adversarial loss: 0.576082\n",
      "epoch 25; iter: 0; batch classifier loss: 0.617293; batch adversarial loss: 0.608935\n",
      "epoch 26; iter: 0; batch classifier loss: 0.865157; batch adversarial loss: 0.716426\n",
      "epoch 27; iter: 0; batch classifier loss: 0.869614; batch adversarial loss: 0.690302\n",
      "epoch 28; iter: 0; batch classifier loss: 0.863660; batch adversarial loss: 0.637978\n",
      "epoch 29; iter: 0; batch classifier loss: 0.747964; batch adversarial loss: 0.613547\n",
      "epoch 30; iter: 0; batch classifier loss: 0.601902; batch adversarial loss: 0.588871\n",
      "epoch 31; iter: 0; batch classifier loss: 0.516245; batch adversarial loss: 0.558948\n",
      "epoch 32; iter: 0; batch classifier loss: 0.551524; batch adversarial loss: 0.566247\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474419; batch adversarial loss: 0.574805\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475185; batch adversarial loss: 0.615490\n",
      "epoch 35; iter: 0; batch classifier loss: 0.392335; batch adversarial loss: 0.572909\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434751; batch adversarial loss: 0.571138\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462402; batch adversarial loss: 0.622687\n",
      "epoch 38; iter: 0; batch classifier loss: 0.509975; batch adversarial loss: 0.531263\n",
      "epoch 39; iter: 0; batch classifier loss: 0.428668; batch adversarial loss: 0.641549\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484570; batch adversarial loss: 0.629182\n",
      "epoch 41; iter: 0; batch classifier loss: 0.512003; batch adversarial loss: 0.524985\n",
      "epoch 42; iter: 0; batch classifier loss: 0.572138; batch adversarial loss: 0.605627\n",
      "epoch 43; iter: 0; batch classifier loss: 0.756232; batch adversarial loss: 0.576669\n",
      "epoch 44; iter: 0; batch classifier loss: 0.868393; batch adversarial loss: 0.715646\n",
      "epoch 45; iter: 0; batch classifier loss: 0.758492; batch adversarial loss: 0.587405\n",
      "epoch 46; iter: 0; batch classifier loss: 0.453700; batch adversarial loss: 0.562747\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395792; batch adversarial loss: 0.588694\n",
      "epoch 48; iter: 0; batch classifier loss: 0.444985; batch adversarial loss: 0.554241\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432634; batch adversarial loss: 0.552100\n",
      "epoch 50; iter: 0; batch classifier loss: 0.469427; batch adversarial loss: 0.514974\n",
      "epoch 51; iter: 0; batch classifier loss: 0.471484; batch adversarial loss: 0.601849\n",
      "epoch 52; iter: 0; batch classifier loss: 0.462040; batch adversarial loss: 0.526634\n",
      "epoch 53; iter: 0; batch classifier loss: 0.445965; batch adversarial loss: 0.582867\n",
      "epoch 54; iter: 0; batch classifier loss: 0.465057; batch adversarial loss: 0.625231\n",
      "epoch 55; iter: 0; batch classifier loss: 0.533786; batch adversarial loss: 0.529043\n",
      "epoch 56; iter: 0; batch classifier loss: 0.385687; batch adversarial loss: 0.531461\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445993; batch adversarial loss: 0.580470\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426759; batch adversarial loss: 0.547309\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464289; batch adversarial loss: 0.565055\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390303; batch adversarial loss: 0.617060\n",
      "epoch 61; iter: 0; batch classifier loss: 0.446101; batch adversarial loss: 0.615050\n",
      "epoch 62; iter: 0; batch classifier loss: 0.515336; batch adversarial loss: 0.621789\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435598; batch adversarial loss: 0.637529\n",
      "epoch 64; iter: 0; batch classifier loss: 0.503192; batch adversarial loss: 0.588174\n",
      "epoch 65; iter: 0; batch classifier loss: 0.476382; batch adversarial loss: 0.624114\n",
      "epoch 66; iter: 0; batch classifier loss: 0.440471; batch adversarial loss: 0.601871\n",
      "epoch 67; iter: 0; batch classifier loss: 0.378813; batch adversarial loss: 0.541463\n",
      "epoch 68; iter: 0; batch classifier loss: 0.533171; batch adversarial loss: 0.496052\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447310; batch adversarial loss: 0.592809\n",
      "epoch 70; iter: 0; batch classifier loss: 0.429565; batch adversarial loss: 0.623098\n",
      "epoch 71; iter: 0; batch classifier loss: 0.478585; batch adversarial loss: 0.532558\n",
      "epoch 72; iter: 0; batch classifier loss: 0.471048; batch adversarial loss: 0.563759\n",
      "epoch 73; iter: 0; batch classifier loss: 0.351592; batch adversarial loss: 0.571179\n",
      "epoch 74; iter: 0; batch classifier loss: 0.563834; batch adversarial loss: 0.588409\n",
      "epoch 75; iter: 0; batch classifier loss: 0.370085; batch adversarial loss: 0.544786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.483960; batch adversarial loss: 0.572134\n",
      "epoch 77; iter: 0; batch classifier loss: 0.455239; batch adversarial loss: 0.484016\n",
      "epoch 78; iter: 0; batch classifier loss: 0.518394; batch adversarial loss: 0.550684\n",
      "epoch 79; iter: 0; batch classifier loss: 0.462827; batch adversarial loss: 0.608132\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363481; batch adversarial loss: 0.611860\n",
      "epoch 81; iter: 0; batch classifier loss: 0.483654; batch adversarial loss: 0.602032\n",
      "epoch 82; iter: 0; batch classifier loss: 0.447478; batch adversarial loss: 0.529135\n",
      "epoch 83; iter: 0; batch classifier loss: 0.481641; batch adversarial loss: 0.624085\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446915; batch adversarial loss: 0.606499\n",
      "epoch 85; iter: 0; batch classifier loss: 0.357137; batch adversarial loss: 0.609874\n",
      "epoch 86; iter: 0; batch classifier loss: 0.451528; batch adversarial loss: 0.623492\n",
      "epoch 87; iter: 0; batch classifier loss: 0.445044; batch adversarial loss: 0.599339\n",
      "epoch 88; iter: 0; batch classifier loss: 0.547074; batch adversarial loss: 0.495993\n",
      "epoch 89; iter: 0; batch classifier loss: 0.435571; batch adversarial loss: 0.547954\n",
      "epoch 90; iter: 0; batch classifier loss: 0.450634; batch adversarial loss: 0.546161\n",
      "epoch 91; iter: 0; batch classifier loss: 0.434438; batch adversarial loss: 0.612432\n",
      "epoch 92; iter: 0; batch classifier loss: 0.483400; batch adversarial loss: 0.629627\n",
      "epoch 93; iter: 0; batch classifier loss: 0.599707; batch adversarial loss: 0.559320\n",
      "epoch 94; iter: 0; batch classifier loss: 0.487511; batch adversarial loss: 0.506701\n",
      "epoch 95; iter: 0; batch classifier loss: 0.528921; batch adversarial loss: 0.587438\n",
      "epoch 96; iter: 0; batch classifier loss: 0.449731; batch adversarial loss: 0.575045\n",
      "epoch 97; iter: 0; batch classifier loss: 0.545700; batch adversarial loss: 0.641801\n",
      "epoch 98; iter: 0; batch classifier loss: 0.474723; batch adversarial loss: 0.520136\n",
      "epoch 99; iter: 0; batch classifier loss: 0.461294; batch adversarial loss: 0.549428\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.973635; batch adversarial loss: 0.917439\n",
      "epoch 2; iter: 0; batch classifier loss: 0.983606; batch adversarial loss: 0.815867\n",
      "epoch 3; iter: 0; batch classifier loss: 0.868885; batch adversarial loss: 0.788693\n",
      "epoch 4; iter: 0; batch classifier loss: 0.837429; batch adversarial loss: 0.793369\n",
      "epoch 5; iter: 0; batch classifier loss: 0.893629; batch adversarial loss: 0.691467\n",
      "epoch 6; iter: 0; batch classifier loss: 0.763099; batch adversarial loss: 0.734291\n",
      "epoch 7; iter: 0; batch classifier loss: 0.735063; batch adversarial loss: 0.711101\n",
      "epoch 8; iter: 0; batch classifier loss: 0.679667; batch adversarial loss: 0.668427\n",
      "epoch 9; iter: 0; batch classifier loss: 0.689581; batch adversarial loss: 0.715581\n",
      "epoch 10; iter: 0; batch classifier loss: 0.685714; batch adversarial loss: 0.714944\n",
      "epoch 11; iter: 0; batch classifier loss: 0.691318; batch adversarial loss: 0.652295\n",
      "epoch 12; iter: 0; batch classifier loss: 0.710551; batch adversarial loss: 0.668045\n",
      "epoch 13; iter: 0; batch classifier loss: 0.679170; batch adversarial loss: 0.680757\n",
      "epoch 14; iter: 0; batch classifier loss: 0.684627; batch adversarial loss: 0.649673\n",
      "epoch 15; iter: 0; batch classifier loss: 0.612706; batch adversarial loss: 0.634877\n",
      "epoch 16; iter: 0; batch classifier loss: 0.659077; batch adversarial loss: 0.610212\n",
      "epoch 17; iter: 0; batch classifier loss: 0.624269; batch adversarial loss: 0.653414\n",
      "epoch 18; iter: 0; batch classifier loss: 0.616058; batch adversarial loss: 0.586992\n",
      "epoch 19; iter: 0; batch classifier loss: 0.641366; batch adversarial loss: 0.620919\n",
      "epoch 20; iter: 0; batch classifier loss: 0.676514; batch adversarial loss: 0.652595\n",
      "epoch 21; iter: 0; batch classifier loss: 0.629890; batch adversarial loss: 0.613340\n",
      "epoch 22; iter: 0; batch classifier loss: 0.582163; batch adversarial loss: 0.588750\n",
      "epoch 23; iter: 0; batch classifier loss: 0.584596; batch adversarial loss: 0.547297\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485334; batch adversarial loss: 0.546938\n",
      "epoch 25; iter: 0; batch classifier loss: 0.528656; batch adversarial loss: 0.546043\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480418; batch adversarial loss: 0.609203\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437733; batch adversarial loss: 0.600663\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538626; batch adversarial loss: 0.578600\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484701; batch adversarial loss: 0.562171\n",
      "epoch 30; iter: 0; batch classifier loss: 0.486165; batch adversarial loss: 0.555925\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495107; batch adversarial loss: 0.545427\n",
      "epoch 32; iter: 0; batch classifier loss: 0.609155; batch adversarial loss: 0.564201\n",
      "epoch 33; iter: 0; batch classifier loss: 0.660416; batch adversarial loss: 0.595460\n",
      "epoch 34; iter: 0; batch classifier loss: 0.740062; batch adversarial loss: 0.664129\n",
      "epoch 35; iter: 0; batch classifier loss: 0.760917; batch adversarial loss: 0.603483\n",
      "epoch 36; iter: 0; batch classifier loss: 0.773951; batch adversarial loss: 0.585319\n",
      "epoch 37; iter: 0; batch classifier loss: 0.633315; batch adversarial loss: 0.624740\n",
      "epoch 38; iter: 0; batch classifier loss: 0.565283; batch adversarial loss: 0.537023\n",
      "epoch 39; iter: 0; batch classifier loss: 0.486091; batch adversarial loss: 0.634705\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466409; batch adversarial loss: 0.614021\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472197; batch adversarial loss: 0.511767\n",
      "epoch 42; iter: 0; batch classifier loss: 0.454440; batch adversarial loss: 0.582863\n",
      "epoch 43; iter: 0; batch classifier loss: 0.586055; batch adversarial loss: 0.553003\n",
      "epoch 44; iter: 0; batch classifier loss: 0.511206; batch adversarial loss: 0.696065\n",
      "epoch 45; iter: 0; batch classifier loss: 0.545373; batch adversarial loss: 0.582540\n",
      "epoch 46; iter: 0; batch classifier loss: 0.516544; batch adversarial loss: 0.561662\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436647; batch adversarial loss: 0.587663\n",
      "epoch 48; iter: 0; batch classifier loss: 0.480405; batch adversarial loss: 0.553120\n",
      "epoch 49; iter: 0; batch classifier loss: 0.471321; batch adversarial loss: 0.550505\n",
      "epoch 50; iter: 0; batch classifier loss: 0.490250; batch adversarial loss: 0.512219\n",
      "epoch 51; iter: 0; batch classifier loss: 0.481245; batch adversarial loss: 0.600483\n",
      "epoch 52; iter: 0; batch classifier loss: 0.509753; batch adversarial loss: 0.524517\n",
      "epoch 53; iter: 0; batch classifier loss: 0.461422; batch adversarial loss: 0.581997\n",
      "epoch 54; iter: 0; batch classifier loss: 0.497073; batch adversarial loss: 0.623819\n",
      "epoch 55; iter: 0; batch classifier loss: 0.546630; batch adversarial loss: 0.527551\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417508; batch adversarial loss: 0.529213\n",
      "epoch 57; iter: 0; batch classifier loss: 0.471906; batch adversarial loss: 0.579716\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462655; batch adversarial loss: 0.545981\n",
      "epoch 59; iter: 0; batch classifier loss: 0.503979; batch adversarial loss: 0.565613\n",
      "epoch 60; iter: 0; batch classifier loss: 0.395351; batch adversarial loss: 0.617121\n",
      "epoch 61; iter: 0; batch classifier loss: 0.473415; batch adversarial loss: 0.615149\n",
      "epoch 62; iter: 0; batch classifier loss: 0.574610; batch adversarial loss: 0.619280\n",
      "epoch 63; iter: 0; batch classifier loss: 0.481640; batch adversarial loss: 0.635769\n",
      "epoch 64; iter: 0; batch classifier loss: 0.534464; batch adversarial loss: 0.587347\n",
      "epoch 65; iter: 0; batch classifier loss: 0.474219; batch adversarial loss: 0.621933\n",
      "epoch 66; iter: 0; batch classifier loss: 0.481600; batch adversarial loss: 0.601327\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406109; batch adversarial loss: 0.541076\n",
      "epoch 68; iter: 0; batch classifier loss: 0.558317; batch adversarial loss: 0.493400\n",
      "epoch 69; iter: 0; batch classifier loss: 0.488513; batch adversarial loss: 0.591959\n",
      "epoch 70; iter: 0; batch classifier loss: 0.435707; batch adversarial loss: 0.619606\n",
      "epoch 71; iter: 0; batch classifier loss: 0.508784; batch adversarial loss: 0.530813\n",
      "epoch 72; iter: 0; batch classifier loss: 0.503882; batch adversarial loss: 0.559472\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386286; batch adversarial loss: 0.569628\n",
      "epoch 74; iter: 0; batch classifier loss: 0.583173; batch adversarial loss: 0.585698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.379515; batch adversarial loss: 0.543593\n",
      "epoch 76; iter: 0; batch classifier loss: 0.495015; batch adversarial loss: 0.570759\n",
      "epoch 77; iter: 0; batch classifier loss: 0.478185; batch adversarial loss: 0.483198\n",
      "epoch 78; iter: 0; batch classifier loss: 0.492370; batch adversarial loss: 0.546743\n",
      "epoch 79; iter: 0; batch classifier loss: 0.437247; batch adversarial loss: 0.603187\n",
      "epoch 80; iter: 0; batch classifier loss: 0.363471; batch adversarial loss: 0.608227\n",
      "epoch 81; iter: 0; batch classifier loss: 0.473394; batch adversarial loss: 0.597122\n",
      "epoch 82; iter: 0; batch classifier loss: 0.482480; batch adversarial loss: 0.528851\n",
      "epoch 83; iter: 0; batch classifier loss: 0.466232; batch adversarial loss: 0.619573\n",
      "epoch 84; iter: 0; batch classifier loss: 0.458068; batch adversarial loss: 0.601128\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378357; batch adversarial loss: 0.607648\n",
      "epoch 86; iter: 0; batch classifier loss: 0.411673; batch adversarial loss: 0.617916\n",
      "epoch 87; iter: 0; batch classifier loss: 0.428026; batch adversarial loss: 0.593194\n",
      "epoch 88; iter: 0; batch classifier loss: 0.579713; batch adversarial loss: 0.494278\n",
      "epoch 89; iter: 0; batch classifier loss: 0.448833; batch adversarial loss: 0.547062\n",
      "epoch 90; iter: 0; batch classifier loss: 0.455800; batch adversarial loss: 0.543125\n",
      "epoch 91; iter: 0; batch classifier loss: 0.460274; batch adversarial loss: 0.609345\n",
      "epoch 92; iter: 0; batch classifier loss: 0.443252; batch adversarial loss: 0.628058\n",
      "epoch 93; iter: 0; batch classifier loss: 0.596842; batch adversarial loss: 0.556243\n",
      "epoch 94; iter: 0; batch classifier loss: 0.507134; batch adversarial loss: 0.506501\n",
      "epoch 95; iter: 0; batch classifier loss: 0.510099; batch adversarial loss: 0.580935\n",
      "epoch 96; iter: 0; batch classifier loss: 0.435706; batch adversarial loss: 0.573375\n",
      "epoch 97; iter: 0; batch classifier loss: 0.537803; batch adversarial loss: 0.636451\n",
      "epoch 98; iter: 0; batch classifier loss: 0.470304; batch adversarial loss: 0.519406\n",
      "epoch 99; iter: 0; batch classifier loss: 0.441240; batch adversarial loss: 0.548478\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.973442; batch adversarial loss: 0.917426\n",
      "epoch 2; iter: 0; batch classifier loss: 0.983158; batch adversarial loss: 0.815861\n",
      "epoch 3; iter: 0; batch classifier loss: 0.867617; batch adversarial loss: 0.788603\n",
      "epoch 4; iter: 0; batch classifier loss: 0.836703; batch adversarial loss: 0.793226\n",
      "epoch 5; iter: 0; batch classifier loss: 0.892369; batch adversarial loss: 0.691380\n",
      "epoch 6; iter: 0; batch classifier loss: 0.762245; batch adversarial loss: 0.734182\n",
      "epoch 7; iter: 0; batch classifier loss: 0.734526; batch adversarial loss: 0.710990\n",
      "epoch 8; iter: 0; batch classifier loss: 0.679258; batch adversarial loss: 0.668371\n",
      "epoch 9; iter: 0; batch classifier loss: 0.688536; batch adversarial loss: 0.715655\n",
      "epoch 10; iter: 0; batch classifier loss: 0.685461; batch adversarial loss: 0.715023\n",
      "epoch 11; iter: 0; batch classifier loss: 0.691824; batch adversarial loss: 0.652333\n",
      "epoch 12; iter: 0; batch classifier loss: 0.709657; batch adversarial loss: 0.667861\n",
      "epoch 13; iter: 0; batch classifier loss: 0.679066; batch adversarial loss: 0.680759\n",
      "epoch 14; iter: 0; batch classifier loss: 0.685483; batch adversarial loss: 0.649772\n",
      "epoch 15; iter: 0; batch classifier loss: 0.613508; batch adversarial loss: 0.634971\n",
      "epoch 16; iter: 0; batch classifier loss: 0.657449; batch adversarial loss: 0.610055\n",
      "epoch 17; iter: 0; batch classifier loss: 0.621731; batch adversarial loss: 0.653380\n",
      "epoch 18; iter: 0; batch classifier loss: 0.614354; batch adversarial loss: 0.587036\n",
      "epoch 19; iter: 0; batch classifier loss: 0.638758; batch adversarial loss: 0.620934\n",
      "epoch 20; iter: 0; batch classifier loss: 0.676377; batch adversarial loss: 0.652690\n",
      "epoch 21; iter: 0; batch classifier loss: 0.626955; batch adversarial loss: 0.613201\n",
      "epoch 22; iter: 0; batch classifier loss: 0.578496; batch adversarial loss: 0.588437\n",
      "epoch 23; iter: 0; batch classifier loss: 0.581958; batch adversarial loss: 0.547135\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485978; batch adversarial loss: 0.546528\n",
      "epoch 25; iter: 0; batch classifier loss: 0.528927; batch adversarial loss: 0.545665\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478043; batch adversarial loss: 0.609129\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436106; batch adversarial loss: 0.600502\n",
      "epoch 28; iter: 0; batch classifier loss: 0.537899; batch adversarial loss: 0.578539\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483197; batch adversarial loss: 0.562265\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485870; batch adversarial loss: 0.555769\n",
      "epoch 31; iter: 0; batch classifier loss: 0.497848; batch adversarial loss: 0.547010\n",
      "epoch 32; iter: 0; batch classifier loss: 0.614782; batch adversarial loss: 0.565488\n",
      "epoch 33; iter: 0; batch classifier loss: 0.659387; batch adversarial loss: 0.595527\n",
      "epoch 34; iter: 0; batch classifier loss: 0.737557; batch adversarial loss: 0.663174\n",
      "epoch 35; iter: 0; batch classifier loss: 0.757959; batch adversarial loss: 0.602708\n",
      "epoch 36; iter: 0; batch classifier loss: 0.776028; batch adversarial loss: 0.584929\n",
      "epoch 37; iter: 0; batch classifier loss: 0.629440; batch adversarial loss: 0.624771\n",
      "epoch 38; iter: 0; batch classifier loss: 0.572580; batch adversarial loss: 0.537055\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483162; batch adversarial loss: 0.634737\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471368; batch adversarial loss: 0.614197\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470914; batch adversarial loss: 0.511746\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453070; batch adversarial loss: 0.582904\n",
      "epoch 43; iter: 0; batch classifier loss: 0.589572; batch adversarial loss: 0.552983\n",
      "epoch 44; iter: 0; batch classifier loss: 0.509861; batch adversarial loss: 0.696203\n",
      "epoch 45; iter: 0; batch classifier loss: 0.544402; batch adversarial loss: 0.582488\n",
      "epoch 46; iter: 0; batch classifier loss: 0.514091; batch adversarial loss: 0.561649\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433757; batch adversarial loss: 0.587589\n",
      "epoch 48; iter: 0; batch classifier loss: 0.483290; batch adversarial loss: 0.553160\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466764; batch adversarial loss: 0.550402\n",
      "epoch 50; iter: 0; batch classifier loss: 0.488701; batch adversarial loss: 0.512180\n",
      "epoch 51; iter: 0; batch classifier loss: 0.483561; batch adversarial loss: 0.600473\n",
      "epoch 52; iter: 0; batch classifier loss: 0.508476; batch adversarial loss: 0.524330\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466424; batch adversarial loss: 0.581682\n",
      "epoch 54; iter: 0; batch classifier loss: 0.496295; batch adversarial loss: 0.623937\n",
      "epoch 55; iter: 0; batch classifier loss: 0.543413; batch adversarial loss: 0.527293\n",
      "epoch 56; iter: 0; batch classifier loss: 0.413947; batch adversarial loss: 0.528881\n",
      "epoch 57; iter: 0; batch classifier loss: 0.475064; batch adversarial loss: 0.579518\n",
      "epoch 58; iter: 0; batch classifier loss: 0.456722; batch adversarial loss: 0.545944\n",
      "epoch 59; iter: 0; batch classifier loss: 0.503788; batch adversarial loss: 0.565400\n",
      "epoch 60; iter: 0; batch classifier loss: 0.392962; batch adversarial loss: 0.617343\n",
      "epoch 61; iter: 0; batch classifier loss: 0.468800; batch adversarial loss: 0.614741\n",
      "epoch 62; iter: 0; batch classifier loss: 0.570513; batch adversarial loss: 0.619186\n",
      "epoch 63; iter: 0; batch classifier loss: 0.478007; batch adversarial loss: 0.635991\n",
      "epoch 64; iter: 0; batch classifier loss: 0.533689; batch adversarial loss: 0.587364\n",
      "epoch 65; iter: 0; batch classifier loss: 0.475024; batch adversarial loss: 0.621726\n",
      "epoch 66; iter: 0; batch classifier loss: 0.487179; batch adversarial loss: 0.602059\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407198; batch adversarial loss: 0.541127\n",
      "epoch 68; iter: 0; batch classifier loss: 0.564764; batch adversarial loss: 0.493555\n",
      "epoch 69; iter: 0; batch classifier loss: 0.479182; batch adversarial loss: 0.591509\n",
      "epoch 70; iter: 0; batch classifier loss: 0.426435; batch adversarial loss: 0.619042\n",
      "epoch 71; iter: 0; batch classifier loss: 0.507233; batch adversarial loss: 0.530370\n",
      "epoch 72; iter: 0; batch classifier loss: 0.498542; batch adversarial loss: 0.559155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73; iter: 0; batch classifier loss: 0.392578; batch adversarial loss: 0.569719\n",
      "epoch 74; iter: 0; batch classifier loss: 0.586854; batch adversarial loss: 0.586308\n",
      "epoch 75; iter: 0; batch classifier loss: 0.373479; batch adversarial loss: 0.543116\n",
      "epoch 76; iter: 0; batch classifier loss: 0.498140; batch adversarial loss: 0.570239\n",
      "epoch 77; iter: 0; batch classifier loss: 0.480934; batch adversarial loss: 0.483072\n",
      "epoch 78; iter: 0; batch classifier loss: 0.489723; batch adversarial loss: 0.546750\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429663; batch adversarial loss: 0.602914\n",
      "epoch 80; iter: 0; batch classifier loss: 0.360061; batch adversarial loss: 0.608210\n",
      "epoch 81; iter: 0; batch classifier loss: 0.475597; batch adversarial loss: 0.597562\n",
      "epoch 82; iter: 0; batch classifier loss: 0.490547; batch adversarial loss: 0.528887\n",
      "epoch 83; iter: 0; batch classifier loss: 0.468336; batch adversarial loss: 0.619577\n",
      "epoch 84; iter: 0; batch classifier loss: 0.448687; batch adversarial loss: 0.600778\n",
      "epoch 85; iter: 0; batch classifier loss: 0.373526; batch adversarial loss: 0.607524\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416697; batch adversarial loss: 0.618115\n",
      "epoch 87; iter: 0; batch classifier loss: 0.434132; batch adversarial loss: 0.594217\n",
      "epoch 88; iter: 0; batch classifier loss: 0.574468; batch adversarial loss: 0.495256\n",
      "epoch 89; iter: 0; batch classifier loss: 0.452963; batch adversarial loss: 0.547031\n",
      "epoch 90; iter: 0; batch classifier loss: 0.460236; batch adversarial loss: 0.543361\n",
      "epoch 91; iter: 0; batch classifier loss: 0.460623; batch adversarial loss: 0.607460\n",
      "epoch 92; iter: 0; batch classifier loss: 0.441777; batch adversarial loss: 0.627616\n",
      "epoch 93; iter: 0; batch classifier loss: 0.594375; batch adversarial loss: 0.555878\n",
      "epoch 94; iter: 0; batch classifier loss: 0.507961; batch adversarial loss: 0.505979\n",
      "epoch 95; iter: 0; batch classifier loss: 0.517793; batch adversarial loss: 0.581089\n",
      "epoch 96; iter: 0; batch classifier loss: 0.429726; batch adversarial loss: 0.572605\n",
      "epoch 97; iter: 0; batch classifier loss: 0.535600; batch adversarial loss: 0.636731\n",
      "epoch 98; iter: 0; batch classifier loss: 0.470266; batch adversarial loss: 0.518957\n",
      "epoch 99; iter: 0; batch classifier loss: 0.435755; batch adversarial loss: 0.548720\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.981920; batch adversarial loss: 0.918199\n",
      "epoch 2; iter: 0; batch classifier loss: 0.991640; batch adversarial loss: 0.816374\n",
      "epoch 3; iter: 0; batch classifier loss: 0.879288; batch adversarial loss: 0.789496\n",
      "epoch 4; iter: 0; batch classifier loss: 0.862079; batch adversarial loss: 0.795632\n",
      "epoch 5; iter: 0; batch classifier loss: 0.924701; batch adversarial loss: 0.692756\n",
      "epoch 6; iter: 0; batch classifier loss: 0.779178; batch adversarial loss: 0.736372\n",
      "epoch 7; iter: 0; batch classifier loss: 0.752159; batch adversarial loss: 0.713132\n",
      "epoch 8; iter: 0; batch classifier loss: 0.691524; batch adversarial loss: 0.669359\n",
      "epoch 9; iter: 0; batch classifier loss: 0.698225; batch adversarial loss: 0.716433\n",
      "epoch 10; iter: 0; batch classifier loss: 0.696046; batch adversarial loss: 0.715513\n",
      "epoch 11; iter: 0; batch classifier loss: 0.694252; batch adversarial loss: 0.652916\n",
      "epoch 12; iter: 0; batch classifier loss: 0.713031; batch adversarial loss: 0.667821\n",
      "epoch 13; iter: 0; batch classifier loss: 0.680221; batch adversarial loss: 0.680739\n",
      "epoch 14; iter: 0; batch classifier loss: 0.687883; batch adversarial loss: 0.649576\n",
      "epoch 15; iter: 0; batch classifier loss: 0.614827; batch adversarial loss: 0.635126\n",
      "epoch 16; iter: 0; batch classifier loss: 0.662506; batch adversarial loss: 0.610771\n",
      "epoch 17; iter: 0; batch classifier loss: 0.626661; batch adversarial loss: 0.653521\n",
      "epoch 18; iter: 0; batch classifier loss: 0.618593; batch adversarial loss: 0.587288\n",
      "epoch 19; iter: 0; batch classifier loss: 0.645296; batch adversarial loss: 0.621289\n",
      "epoch 20; iter: 0; batch classifier loss: 0.686776; batch adversarial loss: 0.653225\n",
      "epoch 21; iter: 0; batch classifier loss: 0.631676; batch adversarial loss: 0.613285\n",
      "epoch 22; iter: 0; batch classifier loss: 0.583088; batch adversarial loss: 0.588737\n",
      "epoch 23; iter: 0; batch classifier loss: 0.586191; batch adversarial loss: 0.547623\n",
      "epoch 24; iter: 0; batch classifier loss: 0.488005; batch adversarial loss: 0.547394\n",
      "epoch 25; iter: 0; batch classifier loss: 0.532192; batch adversarial loss: 0.546659\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478836; batch adversarial loss: 0.609560\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436418; batch adversarial loss: 0.600985\n",
      "epoch 28; iter: 0; batch classifier loss: 0.539055; batch adversarial loss: 0.578669\n",
      "epoch 29; iter: 0; batch classifier loss: 0.481461; batch adversarial loss: 0.562334\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485654; batch adversarial loss: 0.555939\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496302; batch adversarial loss: 0.545314\n",
      "epoch 32; iter: 0; batch classifier loss: 0.617670; batch adversarial loss: 0.567327\n",
      "epoch 33; iter: 0; batch classifier loss: 0.714206; batch adversarial loss: 0.600949\n",
      "epoch 34; iter: 0; batch classifier loss: 0.777660; batch adversarial loss: 0.659220\n",
      "epoch 35; iter: 0; batch classifier loss: 0.758918; batch adversarial loss: 0.596658\n",
      "epoch 36; iter: 0; batch classifier loss: 0.721514; batch adversarial loss: 0.580488\n",
      "epoch 37; iter: 0; batch classifier loss: 0.622626; batch adversarial loss: 0.624487\n",
      "epoch 38; iter: 0; batch classifier loss: 0.564544; batch adversarial loss: 0.536985\n",
      "epoch 39; iter: 0; batch classifier loss: 0.480576; batch adversarial loss: 0.634964\n",
      "epoch 40; iter: 0; batch classifier loss: 0.462666; batch adversarial loss: 0.613953\n",
      "epoch 41; iter: 0; batch classifier loss: 0.471366; batch adversarial loss: 0.511443\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460408; batch adversarial loss: 0.582875\n",
      "epoch 43; iter: 0; batch classifier loss: 0.591256; batch adversarial loss: 0.552892\n",
      "epoch 44; iter: 0; batch classifier loss: 0.511941; batch adversarial loss: 0.696321\n",
      "epoch 45; iter: 0; batch classifier loss: 0.548335; batch adversarial loss: 0.582469\n",
      "epoch 46; iter: 0; batch classifier loss: 0.517948; batch adversarial loss: 0.561754\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438145; batch adversarial loss: 0.587722\n",
      "epoch 48; iter: 0; batch classifier loss: 0.484256; batch adversarial loss: 0.553127\n",
      "epoch 49; iter: 0; batch classifier loss: 0.473884; batch adversarial loss: 0.550579\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493469; batch adversarial loss: 0.512313\n",
      "epoch 51; iter: 0; batch classifier loss: 0.487326; batch adversarial loss: 0.600770\n",
      "epoch 52; iter: 0; batch classifier loss: 0.520208; batch adversarial loss: 0.525062\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466003; batch adversarial loss: 0.582146\n",
      "epoch 54; iter: 0; batch classifier loss: 0.520960; batch adversarial loss: 0.625143\n",
      "epoch 55; iter: 0; batch classifier loss: 0.574389; batch adversarial loss: 0.528366\n",
      "epoch 56; iter: 0; batch classifier loss: 0.434600; batch adversarial loss: 0.530661\n",
      "epoch 57; iter: 0; batch classifier loss: 0.489454; batch adversarial loss: 0.580262\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462127; batch adversarial loss: 0.546124\n",
      "epoch 59; iter: 0; batch classifier loss: 0.505891; batch adversarial loss: 0.565486\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396684; batch adversarial loss: 0.616951\n",
      "epoch 61; iter: 0; batch classifier loss: 0.478015; batch adversarial loss: 0.615367\n",
      "epoch 62; iter: 0; batch classifier loss: 0.576577; batch adversarial loss: 0.619395\n",
      "epoch 63; iter: 0; batch classifier loss: 0.478534; batch adversarial loss: 0.635966\n",
      "epoch 64; iter: 0; batch classifier loss: 0.542718; batch adversarial loss: 0.588280\n",
      "epoch 65; iter: 0; batch classifier loss: 0.478833; batch adversarial loss: 0.622204\n",
      "epoch 66; iter: 0; batch classifier loss: 0.489272; batch adversarial loss: 0.602142\n",
      "epoch 67; iter: 0; batch classifier loss: 0.414276; batch adversarial loss: 0.541465\n",
      "epoch 68; iter: 0; batch classifier loss: 0.556766; batch adversarial loss: 0.493887\n",
      "epoch 69; iter: 0; batch classifier loss: 0.483025; batch adversarial loss: 0.592162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.426857; batch adversarial loss: 0.620694\n",
      "epoch 71; iter: 0; batch classifier loss: 0.512435; batch adversarial loss: 0.530549\n",
      "epoch 72; iter: 0; batch classifier loss: 0.496887; batch adversarial loss: 0.559416\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386121; batch adversarial loss: 0.569493\n",
      "epoch 74; iter: 0; batch classifier loss: 0.589133; batch adversarial loss: 0.585333\n",
      "epoch 75; iter: 0; batch classifier loss: 0.378646; batch adversarial loss: 0.543806\n",
      "epoch 76; iter: 0; batch classifier loss: 0.501231; batch adversarial loss: 0.570507\n",
      "epoch 77; iter: 0; batch classifier loss: 0.486589; batch adversarial loss: 0.483231\n",
      "epoch 78; iter: 0; batch classifier loss: 0.490577; batch adversarial loss: 0.547200\n",
      "epoch 79; iter: 0; batch classifier loss: 0.436003; batch adversarial loss: 0.604335\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378232; batch adversarial loss: 0.609442\n",
      "epoch 81; iter: 0; batch classifier loss: 0.479856; batch adversarial loss: 0.597736\n",
      "epoch 82; iter: 0; batch classifier loss: 0.486498; batch adversarial loss: 0.529359\n",
      "epoch 83; iter: 0; batch classifier loss: 0.465545; batch adversarial loss: 0.620074\n",
      "epoch 84; iter: 0; batch classifier loss: 0.449354; batch adversarial loss: 0.602240\n",
      "epoch 85; iter: 0; batch classifier loss: 0.372987; batch adversarial loss: 0.607700\n",
      "epoch 86; iter: 0; batch classifier loss: 0.428817; batch adversarial loss: 0.619230\n",
      "epoch 87; iter: 0; batch classifier loss: 0.446142; batch adversarial loss: 0.593304\n",
      "epoch 88; iter: 0; batch classifier loss: 0.573293; batch adversarial loss: 0.495592\n",
      "epoch 89; iter: 0; batch classifier loss: 0.466703; batch adversarial loss: 0.548790\n",
      "epoch 90; iter: 0; batch classifier loss: 0.463946; batch adversarial loss: 0.543714\n",
      "epoch 91; iter: 0; batch classifier loss: 0.461789; batch adversarial loss: 0.609248\n",
      "epoch 92; iter: 0; batch classifier loss: 0.455782; batch adversarial loss: 0.628836\n",
      "epoch 93; iter: 0; batch classifier loss: 0.596611; batch adversarial loss: 0.555246\n",
      "epoch 94; iter: 0; batch classifier loss: 0.509401; batch adversarial loss: 0.506064\n",
      "epoch 95; iter: 0; batch classifier loss: 0.528354; batch adversarial loss: 0.582431\n",
      "epoch 96; iter: 0; batch classifier loss: 0.419844; batch adversarial loss: 0.572235\n",
      "epoch 97; iter: 0; batch classifier loss: 0.538410; batch adversarial loss: 0.637341\n",
      "epoch 98; iter: 0; batch classifier loss: 0.464406; batch adversarial loss: 0.518338\n",
      "epoch 99; iter: 0; batch classifier loss: 0.438467; batch adversarial loss: 0.549409\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.967786; batch adversarial loss: 0.916875\n",
      "epoch 2; iter: 0; batch classifier loss: 0.976891; batch adversarial loss: 0.815410\n",
      "epoch 3; iter: 0; batch classifier loss: 0.857065; batch adversarial loss: 0.787646\n",
      "epoch 4; iter: 0; batch classifier loss: 0.816776; batch adversarial loss: 0.791420\n",
      "epoch 5; iter: 0; batch classifier loss: 0.864945; batch adversarial loss: 0.690226\n",
      "epoch 6; iter: 0; batch classifier loss: 0.751618; batch adversarial loss: 0.732457\n",
      "epoch 7; iter: 0; batch classifier loss: 0.720230; batch adversarial loss: 0.708809\n",
      "epoch 8; iter: 0; batch classifier loss: 0.669206; batch adversarial loss: 0.667270\n",
      "epoch 9; iter: 0; batch classifier loss: 0.679180; batch adversarial loss: 0.714640\n",
      "epoch 10; iter: 0; batch classifier loss: 0.683647; batch adversarial loss: 0.714767\n",
      "epoch 11; iter: 0; batch classifier loss: 0.689619; batch adversarial loss: 0.651923\n",
      "epoch 12; iter: 0; batch classifier loss: 0.708304; batch adversarial loss: 0.667618\n",
      "epoch 13; iter: 0; batch classifier loss: 0.678056; batch adversarial loss: 0.680866\n",
      "epoch 14; iter: 0; batch classifier loss: 0.684971; batch adversarial loss: 0.649432\n",
      "epoch 15; iter: 0; batch classifier loss: 0.617743; batch adversarial loss: 0.634613\n",
      "epoch 16; iter: 0; batch classifier loss: 0.658283; batch adversarial loss: 0.610170\n",
      "epoch 17; iter: 0; batch classifier loss: 0.618384; batch adversarial loss: 0.653381\n",
      "epoch 18; iter: 0; batch classifier loss: 0.612884; batch adversarial loss: 0.586808\n",
      "epoch 19; iter: 0; batch classifier loss: 0.634313; batch adversarial loss: 0.620745\n",
      "epoch 20; iter: 0; batch classifier loss: 0.671080; batch adversarial loss: 0.652487\n",
      "epoch 21; iter: 0; batch classifier loss: 0.627666; batch adversarial loss: 0.613226\n",
      "epoch 22; iter: 0; batch classifier loss: 0.574714; batch adversarial loss: 0.588356\n",
      "epoch 23; iter: 0; batch classifier loss: 0.578817; batch adversarial loss: 0.546918\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485483; batch adversarial loss: 0.546064\n",
      "epoch 25; iter: 0; batch classifier loss: 0.525416; batch adversarial loss: 0.545524\n",
      "epoch 26; iter: 0; batch classifier loss: 0.477016; batch adversarial loss: 0.608877\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441227; batch adversarial loss: 0.600360\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538778; batch adversarial loss: 0.578516\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486476; batch adversarial loss: 0.562259\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488821; batch adversarial loss: 0.556164\n",
      "epoch 31; iter: 0; batch classifier loss: 0.500039; batch adversarial loss: 0.548102\n",
      "epoch 32; iter: 0; batch classifier loss: 0.615630; batch adversarial loss: 0.567698\n",
      "epoch 33; iter: 0; batch classifier loss: 0.689571; batch adversarial loss: 0.600432\n",
      "epoch 34; iter: 0; batch classifier loss: 0.762388; batch adversarial loss: 0.663846\n",
      "epoch 35; iter: 0; batch classifier loss: 0.753259; batch adversarial loss: 0.601558\n",
      "epoch 36; iter: 0; batch classifier loss: 0.774127; batch adversarial loss: 0.584179\n",
      "epoch 37; iter: 0; batch classifier loss: 0.668446; batch adversarial loss: 0.623337\n",
      "epoch 38; iter: 0; batch classifier loss: 0.575974; batch adversarial loss: 0.536645\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490995; batch adversarial loss: 0.634140\n",
      "epoch 40; iter: 0; batch classifier loss: 0.479616; batch adversarial loss: 0.615550\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460413; batch adversarial loss: 0.512118\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449441; batch adversarial loss: 0.583040\n",
      "epoch 43; iter: 0; batch classifier loss: 0.616480; batch adversarial loss: 0.553140\n",
      "epoch 44; iter: 0; batch classifier loss: 0.516405; batch adversarial loss: 0.695705\n",
      "epoch 45; iter: 0; batch classifier loss: 0.545607; batch adversarial loss: 0.581977\n",
      "epoch 46; iter: 0; batch classifier loss: 0.512704; batch adversarial loss: 0.561374\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441879; batch adversarial loss: 0.587737\n",
      "epoch 48; iter: 0; batch classifier loss: 0.485811; batch adversarial loss: 0.553275\n",
      "epoch 49; iter: 0; batch classifier loss: 0.471822; batch adversarial loss: 0.550358\n",
      "epoch 50; iter: 0; batch classifier loss: 0.496450; batch adversarial loss: 0.512455\n",
      "epoch 51; iter: 0; batch classifier loss: 0.485897; batch adversarial loss: 0.600744\n",
      "epoch 52; iter: 0; batch classifier loss: 0.513006; batch adversarial loss: 0.524473\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465211; batch adversarial loss: 0.581899\n",
      "epoch 54; iter: 0; batch classifier loss: 0.505169; batch adversarial loss: 0.624333\n",
      "epoch 55; iter: 0; batch classifier loss: 0.554790; batch adversarial loss: 0.527679\n",
      "epoch 56; iter: 0; batch classifier loss: 0.427225; batch adversarial loss: 0.530325\n",
      "epoch 57; iter: 0; batch classifier loss: 0.488243; batch adversarial loss: 0.579611\n",
      "epoch 58; iter: 0; batch classifier loss: 0.469919; batch adversarial loss: 0.546221\n",
      "epoch 59; iter: 0; batch classifier loss: 0.503062; batch adversarial loss: 0.565680\n",
      "epoch 60; iter: 0; batch classifier loss: 0.397172; batch adversarial loss: 0.617149\n",
      "epoch 61; iter: 0; batch classifier loss: 0.474844; batch adversarial loss: 0.615134\n",
      "epoch 62; iter: 0; batch classifier loss: 0.571079; batch adversarial loss: 0.619172\n",
      "epoch 63; iter: 0; batch classifier loss: 0.476104; batch adversarial loss: 0.636384\n",
      "epoch 64; iter: 0; batch classifier loss: 0.528842; batch adversarial loss: 0.587403\n",
      "epoch 65; iter: 0; batch classifier loss: 0.484744; batch adversarial loss: 0.621966\n",
      "epoch 66; iter: 0; batch classifier loss: 0.485931; batch adversarial loss: 0.602049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67; iter: 0; batch classifier loss: 0.410933; batch adversarial loss: 0.540859\n",
      "epoch 68; iter: 0; batch classifier loss: 0.562652; batch adversarial loss: 0.493904\n",
      "epoch 69; iter: 0; batch classifier loss: 0.480243; batch adversarial loss: 0.591617\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418960; batch adversarial loss: 0.618844\n",
      "epoch 71; iter: 0; batch classifier loss: 0.503915; batch adversarial loss: 0.530807\n",
      "epoch 72; iter: 0; batch classifier loss: 0.499688; batch adversarial loss: 0.558735\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390258; batch adversarial loss: 0.570511\n",
      "epoch 74; iter: 0; batch classifier loss: 0.591755; batch adversarial loss: 0.586332\n",
      "epoch 75; iter: 0; batch classifier loss: 0.377199; batch adversarial loss: 0.543353\n",
      "epoch 76; iter: 0; batch classifier loss: 0.493985; batch adversarial loss: 0.570366\n",
      "epoch 77; iter: 0; batch classifier loss: 0.491959; batch adversarial loss: 0.483558\n",
      "epoch 78; iter: 0; batch classifier loss: 0.493842; batch adversarial loss: 0.546939\n",
      "epoch 79; iter: 0; batch classifier loss: 0.439075; batch adversarial loss: 0.604133\n",
      "epoch 80; iter: 0; batch classifier loss: 0.371496; batch adversarial loss: 0.608705\n",
      "epoch 81; iter: 0; batch classifier loss: 0.487409; batch adversarial loss: 0.596150\n",
      "epoch 82; iter: 0; batch classifier loss: 0.487103; batch adversarial loss: 0.528590\n",
      "epoch 83; iter: 0; batch classifier loss: 0.472629; batch adversarial loss: 0.619353\n",
      "epoch 84; iter: 0; batch classifier loss: 0.450622; batch adversarial loss: 0.600831\n",
      "epoch 85; iter: 0; batch classifier loss: 0.368918; batch adversarial loss: 0.607178\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426488; batch adversarial loss: 0.617727\n",
      "epoch 87; iter: 0; batch classifier loss: 0.432904; batch adversarial loss: 0.593731\n",
      "epoch 88; iter: 0; batch classifier loss: 0.573372; batch adversarial loss: 0.495284\n",
      "epoch 89; iter: 0; batch classifier loss: 0.450588; batch adversarial loss: 0.546787\n",
      "epoch 90; iter: 0; batch classifier loss: 0.469341; batch adversarial loss: 0.544179\n",
      "epoch 91; iter: 0; batch classifier loss: 0.476302; batch adversarial loss: 0.607622\n",
      "epoch 92; iter: 0; batch classifier loss: 0.443443; batch adversarial loss: 0.627592\n",
      "epoch 93; iter: 0; batch classifier loss: 0.592910; batch adversarial loss: 0.556417\n",
      "epoch 94; iter: 0; batch classifier loss: 0.500824; batch adversarial loss: 0.505377\n",
      "epoch 95; iter: 0; batch classifier loss: 0.526141; batch adversarial loss: 0.581935\n",
      "epoch 96; iter: 0; batch classifier loss: 0.439670; batch adversarial loss: 0.572867\n",
      "epoch 97; iter: 0; batch classifier loss: 0.526432; batch adversarial loss: 0.635484\n",
      "epoch 98; iter: 0; batch classifier loss: 0.460306; batch adversarial loss: 0.518144\n",
      "epoch 99; iter: 0; batch classifier loss: 0.432799; batch adversarial loss: 0.547848\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.945879; batch adversarial loss: 0.914588\n",
      "epoch 2; iter: 0; batch classifier loss: 0.953524; batch adversarial loss: 0.813771\n",
      "epoch 3; iter: 0; batch classifier loss: 0.816874; batch adversarial loss: 0.784281\n",
      "epoch 4; iter: 0; batch classifier loss: 0.745385; batch adversarial loss: 0.784231\n",
      "epoch 5; iter: 0; batch classifier loss: 0.735206; batch adversarial loss: 0.682700\n",
      "epoch 6; iter: 0; batch classifier loss: 0.667848; batch adversarial loss: 0.716964\n",
      "epoch 7; iter: 0; batch classifier loss: 0.614859; batch adversarial loss: 0.691050\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562850; batch adversarial loss: 0.652995\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530448; batch adversarial loss: 0.687843\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528745; batch adversarial loss: 0.682477\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580219; batch adversarial loss: 0.626228\n",
      "epoch 12; iter: 0; batch classifier loss: 0.577761; batch adversarial loss: 0.628749\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509734; batch adversarial loss: 0.640222\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501403; batch adversarial loss: 0.612674\n",
      "epoch 15; iter: 0; batch classifier loss: 0.464693; batch adversarial loss: 0.602046\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489072; batch adversarial loss: 0.575485\n",
      "epoch 17; iter: 0; batch classifier loss: 0.514529; batch adversarial loss: 0.615998\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465855; batch adversarial loss: 0.562293\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462250; batch adversarial loss: 0.589799\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477092; batch adversarial loss: 0.623624\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514116; batch adversarial loss: 0.594416\n",
      "epoch 22; iter: 0; batch classifier loss: 0.480921; batch adversarial loss: 0.575585\n",
      "epoch 23; iter: 0; batch classifier loss: 0.591593; batch adversarial loss: 0.566567\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475219; batch adversarial loss: 0.565897\n",
      "epoch 25; iter: 0; batch classifier loss: 0.511550; batch adversarial loss: 0.571655\n",
      "epoch 26; iter: 0; batch classifier loss: 0.589427; batch adversarial loss: 0.668182\n",
      "epoch 27; iter: 0; batch classifier loss: 0.826103; batch adversarial loss: 0.706706\n",
      "epoch 28; iter: 0; batch classifier loss: 0.906962; batch adversarial loss: 0.653946\n",
      "epoch 29; iter: 0; batch classifier loss: 0.844854; batch adversarial loss: 0.626651\n",
      "epoch 30; iter: 0; batch classifier loss: 0.686872; batch adversarial loss: 0.594353\n",
      "epoch 31; iter: 0; batch classifier loss: 0.572634; batch adversarial loss: 0.563249\n",
      "epoch 32; iter: 0; batch classifier loss: 0.596993; batch adversarial loss: 0.568741\n",
      "epoch 33; iter: 0; batch classifier loss: 0.508056; batch adversarial loss: 0.578092\n",
      "epoch 34; iter: 0; batch classifier loss: 0.472897; batch adversarial loss: 0.620937\n",
      "epoch 35; iter: 0; batch classifier loss: 0.416028; batch adversarial loss: 0.576991\n",
      "epoch 36; iter: 0; batch classifier loss: 0.457860; batch adversarial loss: 0.572925\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460346; batch adversarial loss: 0.622227\n",
      "epoch 38; iter: 0; batch classifier loss: 0.504198; batch adversarial loss: 0.529588\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424461; batch adversarial loss: 0.635890\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459072; batch adversarial loss: 0.621379\n",
      "epoch 41; iter: 0; batch classifier loss: 0.486814; batch adversarial loss: 0.519351\n",
      "epoch 42; iter: 0; batch classifier loss: 0.525423; batch adversarial loss: 0.599098\n",
      "epoch 43; iter: 0; batch classifier loss: 0.667530; batch adversarial loss: 0.570723\n",
      "epoch 44; iter: 0; batch classifier loss: 0.749363; batch adversarial loss: 0.717410\n",
      "epoch 45; iter: 0; batch classifier loss: 0.765514; batch adversarial loss: 0.590672\n",
      "epoch 46; iter: 0; batch classifier loss: 0.487831; batch adversarial loss: 0.562740\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399916; batch adversarial loss: 0.588375\n",
      "epoch 48; iter: 0; batch classifier loss: 0.450617; batch adversarial loss: 0.553723\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428967; batch adversarial loss: 0.551898\n",
      "epoch 50; iter: 0; batch classifier loss: 0.462111; batch adversarial loss: 0.514533\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464787; batch adversarial loss: 0.601242\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466611; batch adversarial loss: 0.526191\n",
      "epoch 53; iter: 0; batch classifier loss: 0.443994; batch adversarial loss: 0.582238\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474243; batch adversarial loss: 0.625794\n",
      "epoch 55; iter: 0; batch classifier loss: 0.535681; batch adversarial loss: 0.528860\n",
      "epoch 56; iter: 0; batch classifier loss: 0.403588; batch adversarial loss: 0.531461\n",
      "epoch 57; iter: 0; batch classifier loss: 0.460999; batch adversarial loss: 0.580600\n",
      "epoch 58; iter: 0; batch classifier loss: 0.433874; batch adversarial loss: 0.547465\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464451; batch adversarial loss: 0.564811\n",
      "epoch 60; iter: 0; batch classifier loss: 0.391126; batch adversarial loss: 0.616794\n",
      "epoch 61; iter: 0; batch classifier loss: 0.457652; batch adversarial loss: 0.615951\n",
      "epoch 62; iter: 0; batch classifier loss: 0.531429; batch adversarial loss: 0.621793\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429802; batch adversarial loss: 0.637865\n",
      "epoch 64; iter: 0; batch classifier loss: 0.526670; batch adversarial loss: 0.589098\n",
      "epoch 65; iter: 0; batch classifier loss: 0.470866; batch adversarial loss: 0.623451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.451474; batch adversarial loss: 0.602106\n",
      "epoch 67; iter: 0; batch classifier loss: 0.393952; batch adversarial loss: 0.541652\n",
      "epoch 68; iter: 0; batch classifier loss: 0.556309; batch adversarial loss: 0.496861\n",
      "epoch 69; iter: 0; batch classifier loss: 0.475654; batch adversarial loss: 0.593451\n",
      "epoch 70; iter: 0; batch classifier loss: 0.442145; batch adversarial loss: 0.623617\n",
      "epoch 71; iter: 0; batch classifier loss: 0.471374; batch adversarial loss: 0.532478\n",
      "epoch 72; iter: 0; batch classifier loss: 0.475100; batch adversarial loss: 0.563193\n",
      "epoch 73; iter: 0; batch classifier loss: 0.355126; batch adversarial loss: 0.571615\n",
      "epoch 74; iter: 0; batch classifier loss: 0.566751; batch adversarial loss: 0.588003\n",
      "epoch 75; iter: 0; batch classifier loss: 0.368357; batch adversarial loss: 0.544621\n",
      "epoch 76; iter: 0; batch classifier loss: 0.495037; batch adversarial loss: 0.572635\n",
      "epoch 77; iter: 0; batch classifier loss: 0.461155; batch adversarial loss: 0.484641\n",
      "epoch 78; iter: 0; batch classifier loss: 0.515619; batch adversarial loss: 0.550767\n",
      "epoch 79; iter: 0; batch classifier loss: 0.451309; batch adversarial loss: 0.606969\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365984; batch adversarial loss: 0.611206\n",
      "epoch 81; iter: 0; batch classifier loss: 0.469021; batch adversarial loss: 0.599757\n",
      "epoch 82; iter: 0; batch classifier loss: 0.464082; batch adversarial loss: 0.530112\n",
      "epoch 83; iter: 0; batch classifier loss: 0.474173; batch adversarial loss: 0.624598\n",
      "epoch 84; iter: 0; batch classifier loss: 0.475846; batch adversarial loss: 0.608462\n",
      "epoch 85; iter: 0; batch classifier loss: 0.365255; batch adversarial loss: 0.610411\n",
      "epoch 86; iter: 0; batch classifier loss: 0.456210; batch adversarial loss: 0.623673\n",
      "epoch 87; iter: 0; batch classifier loss: 0.443325; batch adversarial loss: 0.599889\n",
      "epoch 88; iter: 0; batch classifier loss: 0.569989; batch adversarial loss: 0.499317\n",
      "epoch 89; iter: 0; batch classifier loss: 0.439432; batch adversarial loss: 0.548523\n",
      "epoch 90; iter: 0; batch classifier loss: 0.468305; batch adversarial loss: 0.546958\n",
      "epoch 91; iter: 0; batch classifier loss: 0.459089; batch adversarial loss: 0.613621\n",
      "epoch 92; iter: 0; batch classifier loss: 0.494896; batch adversarial loss: 0.631702\n",
      "epoch 93; iter: 0; batch classifier loss: 0.610374; batch adversarial loss: 0.560454\n",
      "epoch 94; iter: 0; batch classifier loss: 0.502363; batch adversarial loss: 0.507599\n",
      "epoch 95; iter: 0; batch classifier loss: 0.515149; batch adversarial loss: 0.586322\n",
      "epoch 96; iter: 0; batch classifier loss: 0.460586; batch adversarial loss: 0.574564\n",
      "epoch 97; iter: 0; batch classifier loss: 0.538823; batch adversarial loss: 0.641852\n",
      "epoch 98; iter: 0; batch classifier loss: 0.462365; batch adversarial loss: 0.519199\n",
      "epoch 99; iter: 0; batch classifier loss: 0.459749; batch adversarial loss: 0.549187\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.925184; batch adversarial loss: 0.912297\n",
      "epoch 2; iter: 0; batch classifier loss: 0.930594; batch adversarial loss: 0.811986\n",
      "epoch 3; iter: 0; batch classifier loss: 0.784690; batch adversarial loss: 0.781139\n",
      "epoch 4; iter: 0; batch classifier loss: 0.687784; batch adversarial loss: 0.778054\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621407; batch adversarial loss: 0.674027\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574010; batch adversarial loss: 0.689547\n",
      "epoch 7; iter: 0; batch classifier loss: 0.481290; batch adversarial loss: 0.663675\n",
      "epoch 8; iter: 0; batch classifier loss: 0.463874; batch adversarial loss: 0.639215\n",
      "epoch 9; iter: 0; batch classifier loss: 0.435591; batch adversarial loss: 0.662507\n",
      "epoch 10; iter: 0; batch classifier loss: 0.444910; batch adversarial loss: 0.660803\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546151; batch adversarial loss: 0.617250\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528268; batch adversarial loss: 0.624644\n",
      "epoch 13; iter: 0; batch classifier loss: 0.512642; batch adversarial loss: 0.628440\n",
      "epoch 14; iter: 0; batch classifier loss: 0.486711; batch adversarial loss: 0.606672\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484906; batch adversarial loss: 0.595279\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484971; batch adversarial loss: 0.569815\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520163; batch adversarial loss: 0.611732\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471589; batch adversarial loss: 0.559395\n",
      "epoch 19; iter: 0; batch classifier loss: 0.442335; batch adversarial loss: 0.587918\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475361; batch adversarial loss: 0.626621\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493649; batch adversarial loss: 0.598771\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516896; batch adversarial loss: 0.600595\n",
      "epoch 23; iter: 0; batch classifier loss: 0.615551; batch adversarial loss: 0.580199\n",
      "epoch 24; iter: 0; batch classifier loss: 0.474963; batch adversarial loss: 0.573466\n",
      "epoch 25; iter: 0; batch classifier loss: 0.598395; batch adversarial loss: 0.606529\n",
      "epoch 26; iter: 0; batch classifier loss: 0.865640; batch adversarial loss: 0.722038\n",
      "epoch 27; iter: 0; batch classifier loss: 0.894830; batch adversarial loss: 0.697401\n",
      "epoch 28; iter: 0; batch classifier loss: 0.890776; batch adversarial loss: 0.643474\n",
      "epoch 29; iter: 0; batch classifier loss: 0.760696; batch adversarial loss: 0.617848\n",
      "epoch 30; iter: 0; batch classifier loss: 0.621475; batch adversarial loss: 0.591980\n",
      "epoch 31; iter: 0; batch classifier loss: 0.532333; batch adversarial loss: 0.561360\n",
      "epoch 32; iter: 0; batch classifier loss: 0.566828; batch adversarial loss: 0.568260\n",
      "epoch 33; iter: 0; batch classifier loss: 0.485971; batch adversarial loss: 0.576660\n",
      "epoch 34; iter: 0; batch classifier loss: 0.463059; batch adversarial loss: 0.617110\n",
      "epoch 35; iter: 0; batch classifier loss: 0.392861; batch adversarial loss: 0.573915\n",
      "epoch 36; iter: 0; batch classifier loss: 0.442867; batch adversarial loss: 0.571258\n",
      "epoch 37; iter: 0; batch classifier loss: 0.451518; batch adversarial loss: 0.622088\n",
      "epoch 38; iter: 0; batch classifier loss: 0.501921; batch adversarial loss: 0.530362\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411286; batch adversarial loss: 0.637881\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456736; batch adversarial loss: 0.625164\n",
      "epoch 41; iter: 0; batch classifier loss: 0.484246; batch adversarial loss: 0.522445\n",
      "epoch 42; iter: 0; batch classifier loss: 0.535827; batch adversarial loss: 0.603649\n",
      "epoch 43; iter: 0; batch classifier loss: 0.705610; batch adversarial loss: 0.577342\n",
      "epoch 44; iter: 0; batch classifier loss: 0.860400; batch adversarial loss: 0.723905\n",
      "epoch 45; iter: 0; batch classifier loss: 0.807050; batch adversarial loss: 0.592713\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495294; batch adversarial loss: 0.563281\n",
      "epoch 47; iter: 0; batch classifier loss: 0.382365; batch adversarial loss: 0.588566\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443507; batch adversarial loss: 0.554158\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429460; batch adversarial loss: 0.552219\n",
      "epoch 50; iter: 0; batch classifier loss: 0.461595; batch adversarial loss: 0.514960\n",
      "epoch 51; iter: 0; batch classifier loss: 0.460480; batch adversarial loss: 0.601627\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451276; batch adversarial loss: 0.526393\n",
      "epoch 53; iter: 0; batch classifier loss: 0.437959; batch adversarial loss: 0.582362\n",
      "epoch 54; iter: 0; batch classifier loss: 0.462137; batch adversarial loss: 0.624929\n",
      "epoch 55; iter: 0; batch classifier loss: 0.522332; batch adversarial loss: 0.528689\n",
      "epoch 56; iter: 0; batch classifier loss: 0.376597; batch adversarial loss: 0.531274\n",
      "epoch 57; iter: 0; batch classifier loss: 0.445146; batch adversarial loss: 0.580099\n",
      "epoch 58; iter: 0; batch classifier loss: 0.417415; batch adversarial loss: 0.546833\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462073; batch adversarial loss: 0.564820\n",
      "epoch 60; iter: 0; batch classifier loss: 0.385326; batch adversarial loss: 0.617195\n",
      "epoch 61; iter: 0; batch classifier loss: 0.448697; batch adversarial loss: 0.615276\n",
      "epoch 62; iter: 0; batch classifier loss: 0.510670; batch adversarial loss: 0.620992\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426450; batch adversarial loss: 0.637119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.501647; batch adversarial loss: 0.587550\n",
      "epoch 65; iter: 0; batch classifier loss: 0.465030; batch adversarial loss: 0.623968\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439536; batch adversarial loss: 0.601411\n",
      "epoch 67; iter: 0; batch classifier loss: 0.380940; batch adversarial loss: 0.541913\n",
      "epoch 68; iter: 0; batch classifier loss: 0.530714; batch adversarial loss: 0.495772\n",
      "epoch 69; iter: 0; batch classifier loss: 0.450556; batch adversarial loss: 0.592495\n",
      "epoch 70; iter: 0; batch classifier loss: 0.412706; batch adversarial loss: 0.622579\n",
      "epoch 71; iter: 0; batch classifier loss: 0.484066; batch adversarial loss: 0.532538\n",
      "epoch 72; iter: 0; batch classifier loss: 0.456859; batch adversarial loss: 0.563126\n",
      "epoch 73; iter: 0; batch classifier loss: 0.351610; batch adversarial loss: 0.571360\n",
      "epoch 74; iter: 0; batch classifier loss: 0.553104; batch adversarial loss: 0.588211\n",
      "epoch 75; iter: 0; batch classifier loss: 0.364348; batch adversarial loss: 0.543848\n",
      "epoch 76; iter: 0; batch classifier loss: 0.469428; batch adversarial loss: 0.570967\n",
      "epoch 77; iter: 0; batch classifier loss: 0.439921; batch adversarial loss: 0.483209\n",
      "epoch 78; iter: 0; batch classifier loss: 0.512249; batch adversarial loss: 0.550074\n",
      "epoch 79; iter: 0; batch classifier loss: 0.449954; batch adversarial loss: 0.607975\n",
      "epoch 80; iter: 0; batch classifier loss: 0.365251; batch adversarial loss: 0.611273\n",
      "epoch 81; iter: 0; batch classifier loss: 0.478108; batch adversarial loss: 0.601168\n",
      "epoch 82; iter: 0; batch classifier loss: 0.447548; batch adversarial loss: 0.528957\n",
      "epoch 83; iter: 0; batch classifier loss: 0.473665; batch adversarial loss: 0.623020\n",
      "epoch 84; iter: 0; batch classifier loss: 0.429972; batch adversarial loss: 0.605282\n",
      "epoch 85; iter: 0; batch classifier loss: 0.354629; batch adversarial loss: 0.608967\n",
      "epoch 86; iter: 0; batch classifier loss: 0.461042; batch adversarial loss: 0.623603\n",
      "epoch 87; iter: 0; batch classifier loss: 0.428795; batch adversarial loss: 0.599105\n",
      "epoch 88; iter: 0; batch classifier loss: 0.538879; batch adversarial loss: 0.495911\n",
      "epoch 89; iter: 0; batch classifier loss: 0.425799; batch adversarial loss: 0.547183\n",
      "epoch 90; iter: 0; batch classifier loss: 0.440978; batch adversarial loss: 0.545175\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413988; batch adversarial loss: 0.610718\n",
      "epoch 92; iter: 0; batch classifier loss: 0.465398; batch adversarial loss: 0.629729\n",
      "epoch 93; iter: 0; batch classifier loss: 0.597709; batch adversarial loss: 0.558498\n",
      "epoch 94; iter: 0; batch classifier loss: 0.490937; batch adversarial loss: 0.507322\n",
      "epoch 95; iter: 0; batch classifier loss: 0.514093; batch adversarial loss: 0.585689\n",
      "epoch 96; iter: 0; batch classifier loss: 0.430459; batch adversarial loss: 0.574708\n",
      "epoch 97; iter: 0; batch classifier loss: 0.526296; batch adversarial loss: 0.642938\n",
      "epoch 98; iter: 0; batch classifier loss: 0.461452; batch adversarial loss: 0.519701\n",
      "epoch 99; iter: 0; batch classifier loss: 0.457106; batch adversarial loss: 0.550699\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709988; batch adversarial loss: 0.791750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.867640; batch adversarial loss: 0.916442\n",
      "epoch 2; iter: 0; batch classifier loss: 0.930744; batch adversarial loss: 0.818905\n",
      "epoch 3; iter: 0; batch classifier loss: 0.750170; batch adversarial loss: 0.788232\n",
      "epoch 4; iter: 0; batch classifier loss: 0.668632; batch adversarial loss: 0.782287\n",
      "epoch 5; iter: 0; batch classifier loss: 0.661693; batch adversarial loss: 0.679722\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570637; batch adversarial loss: 0.710018\n",
      "epoch 7; iter: 0; batch classifier loss: 0.525746; batch adversarial loss: 0.674135\n",
      "epoch 8; iter: 0; batch classifier loss: 0.468928; batch adversarial loss: 0.645837\n",
      "epoch 9; iter: 0; batch classifier loss: 0.436553; batch adversarial loss: 0.664960\n",
      "epoch 10; iter: 0; batch classifier loss: 0.446140; batch adversarial loss: 0.661887\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536362; batch adversarial loss: 0.618555\n",
      "epoch 12; iter: 0; batch classifier loss: 0.510595; batch adversarial loss: 0.626257\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485325; batch adversarial loss: 0.630744\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470628; batch adversarial loss: 0.610095\n",
      "epoch 15; iter: 0; batch classifier loss: 0.449776; batch adversarial loss: 0.599717\n",
      "epoch 16; iter: 0; batch classifier loss: 0.467951; batch adversarial loss: 0.572705\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489853; batch adversarial loss: 0.614188\n",
      "epoch 18; iter: 0; batch classifier loss: 0.464321; batch adversarial loss: 0.560930\n",
      "epoch 19; iter: 0; batch classifier loss: 0.486253; batch adversarial loss: 0.630123\n",
      "epoch 20; iter: 0; batch classifier loss: 0.681997; batch adversarial loss: 0.706850\n",
      "epoch 21; iter: 0; batch classifier loss: 0.836559; batch adversarial loss: 0.703309\n",
      "epoch 22; iter: 0; batch classifier loss: 0.814432; batch adversarial loss: 0.668774\n",
      "epoch 23; iter: 0; batch classifier loss: 0.834142; batch adversarial loss: 0.602584\n",
      "epoch 24; iter: 0; batch classifier loss: 0.636808; batch adversarial loss: 0.591325\n",
      "epoch 25; iter: 0; batch classifier loss: 0.658735; batch adversarial loss: 0.591159\n",
      "epoch 26; iter: 0; batch classifier loss: 0.657907; batch adversarial loss: 0.650415\n",
      "epoch 27; iter: 0; batch classifier loss: 0.636273; batch adversarial loss: 0.637150\n",
      "epoch 28; iter: 0; batch classifier loss: 0.547592; batch adversarial loss: 0.604530\n",
      "epoch 29; iter: 0; batch classifier loss: 0.436848; batch adversarial loss: 0.585115\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431931; batch adversarial loss: 0.568300\n",
      "epoch 31; iter: 0; batch classifier loss: 0.409601; batch adversarial loss: 0.537164\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499807; batch adversarial loss: 0.547279\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412033; batch adversarial loss: 0.560852\n",
      "epoch 34; iter: 0; batch classifier loss: 0.367673; batch adversarial loss: 0.614773\n",
      "epoch 35; iter: 0; batch classifier loss: 0.364298; batch adversarial loss: 0.576809\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465735; batch adversarial loss: 0.591974\n",
      "epoch 37; iter: 0; batch classifier loss: 0.813870; batch adversarial loss: 0.682132\n",
      "epoch 38; iter: 0; batch classifier loss: 0.964472; batch adversarial loss: 0.567203\n",
      "epoch 39; iter: 0; batch classifier loss: 0.930180; batch adversarial loss: 0.659350\n",
      "epoch 40; iter: 0; batch classifier loss: 0.837961; batch adversarial loss: 0.620091\n",
      "epoch 41; iter: 0; batch classifier loss: 0.370189; batch adversarial loss: 0.515762\n",
      "epoch 42; iter: 0; batch classifier loss: 0.374420; batch adversarial loss: 0.585078\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474103; batch adversarial loss: 0.554413\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433797; batch adversarial loss: 0.694987\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458048; batch adversarial loss: 0.584125\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433488; batch adversarial loss: 0.562609\n",
      "epoch 47; iter: 0; batch classifier loss: 0.360776; batch adversarial loss: 0.588630\n",
      "epoch 48; iter: 0; batch classifier loss: 0.433627; batch adversarial loss: 0.555288\n",
      "epoch 49; iter: 0; batch classifier loss: 0.414465; batch adversarial loss: 0.552415\n",
      "epoch 50; iter: 0; batch classifier loss: 0.404202; batch adversarial loss: 0.513713\n",
      "epoch 51; iter: 0; batch classifier loss: 0.426467; batch adversarial loss: 0.603520\n",
      "epoch 52; iter: 0; batch classifier loss: 0.468854; batch adversarial loss: 0.528707\n",
      "epoch 53; iter: 0; batch classifier loss: 0.401636; batch adversarial loss: 0.586169\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474947; batch adversarial loss: 0.629504\n",
      "epoch 55; iter: 0; batch classifier loss: 0.460109; batch adversarial loss: 0.527957\n",
      "epoch 56; iter: 0; batch classifier loss: 0.368852; batch adversarial loss: 0.532688\n",
      "epoch 57; iter: 0; batch classifier loss: 0.454813; batch adversarial loss: 0.581373\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398297; batch adversarial loss: 0.548001\n",
      "epoch 59; iter: 0; batch classifier loss: 0.418246; batch adversarial loss: 0.567302\n",
      "epoch 60; iter: 0; batch classifier loss: 0.319094; batch adversarial loss: 0.617397\n",
      "epoch 61; iter: 0; batch classifier loss: 0.445830; batch adversarial loss: 0.618678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.519751; batch adversarial loss: 0.627742\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406424; batch adversarial loss: 0.639495\n",
      "epoch 64; iter: 0; batch classifier loss: 0.522983; batch adversarial loss: 0.591983\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442768; batch adversarial loss: 0.626205\n",
      "epoch 66; iter: 0; batch classifier loss: 0.476868; batch adversarial loss: 0.605777\n",
      "epoch 67; iter: 0; batch classifier loss: 0.337501; batch adversarial loss: 0.542233\n",
      "epoch 68; iter: 0; batch classifier loss: 0.565695; batch adversarial loss: 0.501890\n",
      "epoch 69; iter: 0; batch classifier loss: 0.458007; batch adversarial loss: 0.596762\n",
      "epoch 70; iter: 0; batch classifier loss: 0.486711; batch adversarial loss: 0.630905\n",
      "epoch 71; iter: 0; batch classifier loss: 0.521064; batch adversarial loss: 0.537970\n",
      "epoch 72; iter: 0; batch classifier loss: 0.470330; batch adversarial loss: 0.569501\n",
      "epoch 73; iter: 0; batch classifier loss: 0.359944; batch adversarial loss: 0.572780\n",
      "epoch 74; iter: 0; batch classifier loss: 0.560106; batch adversarial loss: 0.593441\n",
      "epoch 75; iter: 0; batch classifier loss: 0.371462; batch adversarial loss: 0.549394\n",
      "epoch 76; iter: 0; batch classifier loss: 0.518082; batch adversarial loss: 0.575653\n",
      "epoch 77; iter: 0; batch classifier loss: 0.476673; batch adversarial loss: 0.487786\n",
      "epoch 78; iter: 0; batch classifier loss: 0.517220; batch adversarial loss: 0.553543\n",
      "epoch 79; iter: 0; batch classifier loss: 0.499154; batch adversarial loss: 0.613390\n",
      "epoch 80; iter: 0; batch classifier loss: 0.398116; batch adversarial loss: 0.617750\n",
      "epoch 81; iter: 0; batch classifier loss: 0.486572; batch adversarial loss: 0.604734\n",
      "epoch 82; iter: 0; batch classifier loss: 0.530200; batch adversarial loss: 0.534666\n",
      "epoch 83; iter: 0; batch classifier loss: 0.503782; batch adversarial loss: 0.630729\n",
      "epoch 84; iter: 0; batch classifier loss: 0.520010; batch adversarial loss: 0.612215\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392441; batch adversarial loss: 0.614826\n",
      "epoch 86; iter: 0; batch classifier loss: 0.508983; batch adversarial loss: 0.626044\n",
      "epoch 87; iter: 0; batch classifier loss: 0.510100; batch adversarial loss: 0.608742\n",
      "epoch 88; iter: 0; batch classifier loss: 0.587837; batch adversarial loss: 0.502747\n",
      "epoch 89; iter: 0; batch classifier loss: 0.462926; batch adversarial loss: 0.553638\n",
      "epoch 90; iter: 0; batch classifier loss: 0.484258; batch adversarial loss: 0.550637\n",
      "epoch 91; iter: 0; batch classifier loss: 0.456086; batch adversarial loss: 0.618852\n",
      "epoch 92; iter: 0; batch classifier loss: 0.484585; batch adversarial loss: 0.633299\n",
      "epoch 93; iter: 0; batch classifier loss: 0.624495; batch adversarial loss: 0.563158\n",
      "epoch 94; iter: 0; batch classifier loss: 0.581484; batch adversarial loss: 0.513065\n",
      "epoch 95; iter: 0; batch classifier loss: 0.560030; batch adversarial loss: 0.594435\n",
      "epoch 96; iter: 0; batch classifier loss: 0.486974; batch adversarial loss: 0.572685\n",
      "epoch 97; iter: 0; batch classifier loss: 0.549237; batch adversarial loss: 0.642777\n",
      "epoch 98; iter: 0; batch classifier loss: 0.522084; batch adversarial loss: 0.523729\n",
      "epoch 99; iter: 0; batch classifier loss: 0.511110; batch adversarial loss: 0.551916\n",
      "epoch 100; iter: 0; batch classifier loss: 0.620414; batch adversarial loss: 0.590305\n",
      "epoch 101; iter: 0; batch classifier loss: 0.512351; batch adversarial loss: 0.628062\n",
      "epoch 102; iter: 0; batch classifier loss: 0.738337; batch adversarial loss: 0.551101\n",
      "epoch 103; iter: 0; batch classifier loss: 0.683076; batch adversarial loss: 0.575262\n",
      "epoch 104; iter: 0; batch classifier loss: 0.489363; batch adversarial loss: 0.541691\n",
      "epoch 105; iter: 0; batch classifier loss: 0.549446; batch adversarial loss: 0.656871\n",
      "epoch 106; iter: 0; batch classifier loss: 0.500007; batch adversarial loss: 0.641893\n",
      "epoch 107; iter: 0; batch classifier loss: 0.633669; batch adversarial loss: 0.572303\n",
      "epoch 108; iter: 0; batch classifier loss: 0.559809; batch adversarial loss: 0.583179\n",
      "epoch 109; iter: 0; batch classifier loss: 0.650594; batch adversarial loss: 0.505508\n",
      "epoch 110; iter: 0; batch classifier loss: 0.676377; batch adversarial loss: 0.534762\n",
      "epoch 111; iter: 0; batch classifier loss: 0.457504; batch adversarial loss: 0.589911\n",
      "epoch 112; iter: 0; batch classifier loss: 0.621461; batch adversarial loss: 0.566480\n",
      "epoch 113; iter: 0; batch classifier loss: 0.597343; batch adversarial loss: 0.557570\n",
      "epoch 114; iter: 0; batch classifier loss: 0.524235; batch adversarial loss: 0.588389\n",
      "epoch 115; iter: 0; batch classifier loss: 0.563051; batch adversarial loss: 0.515975\n",
      "epoch 116; iter: 0; batch classifier loss: 0.508636; batch adversarial loss: 0.560469\n",
      "epoch 117; iter: 0; batch classifier loss: 0.491679; batch adversarial loss: 0.602806\n",
      "epoch 118; iter: 0; batch classifier loss: 0.574523; batch adversarial loss: 0.593509\n",
      "epoch 119; iter: 0; batch classifier loss: 0.484696; batch adversarial loss: 0.615468\n",
      "epoch 120; iter: 0; batch classifier loss: 0.575638; batch adversarial loss: 0.601979\n",
      "epoch 121; iter: 0; batch classifier loss: 0.708510; batch adversarial loss: 0.643058\n",
      "epoch 122; iter: 0; batch classifier loss: 0.683788; batch adversarial loss: 0.576817\n",
      "epoch 123; iter: 0; batch classifier loss: 0.668077; batch adversarial loss: 0.609530\n",
      "epoch 124; iter: 0; batch classifier loss: 0.622957; batch adversarial loss: 0.556845\n",
      "epoch 125; iter: 0; batch classifier loss: 0.576755; batch adversarial loss: 0.617957\n",
      "epoch 126; iter: 0; batch classifier loss: 0.710891; batch adversarial loss: 0.578215\n",
      "epoch 127; iter: 0; batch classifier loss: 0.570194; batch adversarial loss: 0.523504\n",
      "epoch 128; iter: 0; batch classifier loss: 0.527940; batch adversarial loss: 0.578099\n",
      "epoch 129; iter: 0; batch classifier loss: 0.506127; batch adversarial loss: 0.635424\n",
      "epoch 130; iter: 0; batch classifier loss: 0.566451; batch adversarial loss: 0.563128\n",
      "epoch 131; iter: 0; batch classifier loss: 0.476549; batch adversarial loss: 0.609332\n",
      "epoch 132; iter: 0; batch classifier loss: 0.624403; batch adversarial loss: 0.540136\n",
      "epoch 133; iter: 0; batch classifier loss: 0.564993; batch adversarial loss: 0.626881\n",
      "epoch 134; iter: 0; batch classifier loss: 0.576841; batch adversarial loss: 0.570498\n",
      "epoch 135; iter: 0; batch classifier loss: 0.670504; batch adversarial loss: 0.627833\n",
      "epoch 136; iter: 0; batch classifier loss: 0.553548; batch adversarial loss: 0.577406\n",
      "epoch 137; iter: 0; batch classifier loss: 0.528146; batch adversarial loss: 0.650809\n",
      "epoch 138; iter: 0; batch classifier loss: 0.537935; batch adversarial loss: 0.555269\n",
      "epoch 139; iter: 0; batch classifier loss: 0.488788; batch adversarial loss: 0.554015\n",
      "epoch 140; iter: 0; batch classifier loss: 0.499805; batch adversarial loss: 0.603941\n",
      "epoch 141; iter: 0; batch classifier loss: 0.506698; batch adversarial loss: 0.505982\n",
      "epoch 142; iter: 0; batch classifier loss: 0.624326; batch adversarial loss: 0.578444\n",
      "epoch 143; iter: 0; batch classifier loss: 0.621647; batch adversarial loss: 0.506132\n",
      "epoch 144; iter: 0; batch classifier loss: 0.370940; batch adversarial loss: 0.617715\n",
      "epoch 145; iter: 0; batch classifier loss: 0.562353; batch adversarial loss: 0.522492\n",
      "epoch 146; iter: 0; batch classifier loss: 0.523920; batch adversarial loss: 0.569677\n",
      "epoch 147; iter: 0; batch classifier loss: 0.582180; batch adversarial loss: 0.507949\n",
      "epoch 148; iter: 0; batch classifier loss: 0.734001; batch adversarial loss: 0.577774\n",
      "epoch 149; iter: 0; batch classifier loss: 0.452618; batch adversarial loss: 0.546475\n",
      "epoch 150; iter: 0; batch classifier loss: 0.555251; batch adversarial loss: 0.569270\n",
      "epoch 151; iter: 0; batch classifier loss: 0.513056; batch adversarial loss: 0.545028\n",
      "epoch 152; iter: 0; batch classifier loss: 0.466450; batch adversarial loss: 0.595453\n",
      "epoch 153; iter: 0; batch classifier loss: 0.660444; batch adversarial loss: 0.553192\n",
      "epoch 154; iter: 0; batch classifier loss: 0.545637; batch adversarial loss: 0.598927\n",
      "epoch 155; iter: 0; batch classifier loss: 0.486215; batch adversarial loss: 0.609609\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380458; batch adversarial loss: 0.605814\n",
      "epoch 157; iter: 0; batch classifier loss: 0.489237; batch adversarial loss: 0.514775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.489595; batch adversarial loss: 0.619465\n",
      "epoch 159; iter: 0; batch classifier loss: 0.520519; batch adversarial loss: 0.586972\n",
      "epoch 160; iter: 0; batch classifier loss: 0.548443; batch adversarial loss: 0.578917\n",
      "epoch 161; iter: 0; batch classifier loss: 0.541951; batch adversarial loss: 0.561222\n",
      "epoch 162; iter: 0; batch classifier loss: 0.510096; batch adversarial loss: 0.571779\n",
      "epoch 163; iter: 0; batch classifier loss: 0.570695; batch adversarial loss: 0.545458\n",
      "epoch 164; iter: 0; batch classifier loss: 0.470377; batch adversarial loss: 0.561352\n",
      "epoch 165; iter: 0; batch classifier loss: 0.469576; batch adversarial loss: 0.562416\n",
      "epoch 166; iter: 0; batch classifier loss: 0.507422; batch adversarial loss: 0.593776\n",
      "epoch 167; iter: 0; batch classifier loss: 0.528711; batch adversarial loss: 0.571188\n",
      "epoch 168; iter: 0; batch classifier loss: 0.509691; batch adversarial loss: 0.609049\n",
      "epoch 169; iter: 0; batch classifier loss: 0.545557; batch adversarial loss: 0.593880\n",
      "epoch 170; iter: 0; batch classifier loss: 0.597052; batch adversarial loss: 0.547575\n",
      "epoch 171; iter: 0; batch classifier loss: 0.431485; batch adversarial loss: 0.515802\n",
      "epoch 172; iter: 0; batch classifier loss: 0.494246; batch adversarial loss: 0.579763\n",
      "epoch 173; iter: 0; batch classifier loss: 0.662049; batch adversarial loss: 0.547004\n",
      "epoch 174; iter: 0; batch classifier loss: 0.530490; batch adversarial loss: 0.553412\n",
      "epoch 175; iter: 0; batch classifier loss: 0.507833; batch adversarial loss: 0.548030\n",
      "epoch 176; iter: 0; batch classifier loss: 0.607287; batch adversarial loss: 0.522669\n",
      "epoch 177; iter: 0; batch classifier loss: 0.520848; batch adversarial loss: 0.602808\n",
      "epoch 178; iter: 0; batch classifier loss: 0.383542; batch adversarial loss: 0.541256\n",
      "epoch 179; iter: 0; batch classifier loss: 0.534050; batch adversarial loss: 0.610235\n",
      "epoch 180; iter: 0; batch classifier loss: 0.491578; batch adversarial loss: 0.538116\n",
      "epoch 181; iter: 0; batch classifier loss: 0.731244; batch adversarial loss: 0.641925\n",
      "epoch 182; iter: 0; batch classifier loss: 0.511962; batch adversarial loss: 0.594936\n",
      "epoch 183; iter: 0; batch classifier loss: 0.659132; batch adversarial loss: 0.643215\n",
      "epoch 184; iter: 0; batch classifier loss: 0.551731; batch adversarial loss: 0.530690\n",
      "epoch 185; iter: 0; batch classifier loss: 0.524384; batch adversarial loss: 0.626112\n",
      "epoch 186; iter: 0; batch classifier loss: 0.449185; batch adversarial loss: 0.530752\n",
      "epoch 187; iter: 0; batch classifier loss: 0.399389; batch adversarial loss: 0.547832\n",
      "epoch 188; iter: 0; batch classifier loss: 0.442727; batch adversarial loss: 0.562836\n",
      "epoch 189; iter: 0; batch classifier loss: 0.665547; batch adversarial loss: 0.563978\n",
      "epoch 190; iter: 0; batch classifier loss: 0.482051; batch adversarial loss: 0.536275\n",
      "epoch 191; iter: 0; batch classifier loss: 0.432629; batch adversarial loss: 0.595346\n",
      "epoch 192; iter: 0; batch classifier loss: 0.481406; batch adversarial loss: 0.570216\n",
      "epoch 193; iter: 0; batch classifier loss: 0.465481; batch adversarial loss: 0.505534\n",
      "epoch 194; iter: 0; batch classifier loss: 0.506270; batch adversarial loss: 0.595530\n",
      "epoch 195; iter: 0; batch classifier loss: 0.669269; batch adversarial loss: 0.530391\n",
      "epoch 196; iter: 0; batch classifier loss: 0.552710; batch adversarial loss: 0.602229\n",
      "epoch 197; iter: 0; batch classifier loss: 0.417932; batch adversarial loss: 0.604871\n",
      "epoch 198; iter: 0; batch classifier loss: 0.535421; batch adversarial loss: 0.609758\n",
      "epoch 199; iter: 0; batch classifier loss: 0.325892; batch adversarial loss: 0.651929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.963904; batch adversarial loss: 0.916479\n",
      "epoch 2; iter: 0; batch classifier loss: 0.972642; batch adversarial loss: 0.815202\n",
      "epoch 3; iter: 0; batch classifier loss: 0.849541; batch adversarial loss: 0.787076\n",
      "epoch 4; iter: 0; batch classifier loss: 0.802388; batch adversarial loss: 0.790070\n",
      "epoch 5; iter: 0; batch classifier loss: 0.845693; batch adversarial loss: 0.689309\n",
      "epoch 6; iter: 0; batch classifier loss: 0.741185; batch adversarial loss: 0.730717\n",
      "epoch 7; iter: 0; batch classifier loss: 0.710237; batch adversarial loss: 0.707528\n",
      "epoch 8; iter: 0; batch classifier loss: 0.661111; batch adversarial loss: 0.666038\n",
      "epoch 9; iter: 0; batch classifier loss: 0.672543; batch adversarial loss: 0.713938\n",
      "epoch 10; iter: 0; batch classifier loss: 0.677185; batch adversarial loss: 0.714354\n",
      "epoch 11; iter: 0; batch classifier loss: 0.688888; batch adversarial loss: 0.651832\n",
      "epoch 12; iter: 0; batch classifier loss: 0.706857; batch adversarial loss: 0.667593\n",
      "epoch 13; iter: 0; batch classifier loss: 0.674995; batch adversarial loss: 0.681147\n",
      "epoch 14; iter: 0; batch classifier loss: 0.684628; batch adversarial loss: 0.649659\n",
      "epoch 15; iter: 0; batch classifier loss: 0.614784; batch adversarial loss: 0.634938\n",
      "epoch 16; iter: 0; batch classifier loss: 0.651920; batch adversarial loss: 0.609522\n",
      "epoch 17; iter: 0; batch classifier loss: 0.615684; batch adversarial loss: 0.653087\n",
      "epoch 18; iter: 0; batch classifier loss: 0.609151; batch adversarial loss: 0.586478\n",
      "epoch 19; iter: 0; batch classifier loss: 0.631634; batch adversarial loss: 0.620482\n",
      "epoch 20; iter: 0; batch classifier loss: 0.663268; batch adversarial loss: 0.652222\n",
      "epoch 21; iter: 0; batch classifier loss: 0.624907; batch adversarial loss: 0.613158\n",
      "epoch 22; iter: 0; batch classifier loss: 0.571538; batch adversarial loss: 0.588108\n",
      "epoch 23; iter: 0; batch classifier loss: 0.573827; batch adversarial loss: 0.546483\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483517; batch adversarial loss: 0.545299\n",
      "epoch 25; iter: 0; batch classifier loss: 0.522214; batch adversarial loss: 0.544950\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478433; batch adversarial loss: 0.608577\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437689; batch adversarial loss: 0.600058\n",
      "epoch 28; iter: 0; batch classifier loss: 0.540987; batch adversarial loss: 0.578478\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482633; batch adversarial loss: 0.561952\n",
      "epoch 30; iter: 0; batch classifier loss: 0.484422; batch adversarial loss: 0.556153\n",
      "epoch 31; iter: 0; batch classifier loss: 0.500614; batch adversarial loss: 0.548771\n",
      "epoch 32; iter: 0; batch classifier loss: 0.618355; batch adversarial loss: 0.566697\n",
      "epoch 33; iter: 0; batch classifier loss: 0.672822; batch adversarial loss: 0.600385\n",
      "epoch 34; iter: 0; batch classifier loss: 0.768867; batch adversarial loss: 0.667044\n",
      "epoch 35; iter: 0; batch classifier loss: 0.757427; batch adversarial loss: 0.603798\n",
      "epoch 36; iter: 0; batch classifier loss: 0.782549; batch adversarial loss: 0.585799\n",
      "epoch 37; iter: 0; batch classifier loss: 0.699945; batch adversarial loss: 0.622794\n",
      "epoch 38; iter: 0; batch classifier loss: 0.593900; batch adversarial loss: 0.536330\n",
      "epoch 39; iter: 0; batch classifier loss: 0.500126; batch adversarial loss: 0.633551\n",
      "epoch 40; iter: 0; batch classifier loss: 0.478633; batch adversarial loss: 0.615875\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469453; batch adversarial loss: 0.513350\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436314; batch adversarial loss: 0.583111\n",
      "epoch 43; iter: 0; batch classifier loss: 0.618530; batch adversarial loss: 0.553232\n",
      "epoch 44; iter: 0; batch classifier loss: 0.531555; batch adversarial loss: 0.695441\n",
      "epoch 45; iter: 0; batch classifier loss: 0.546997; batch adversarial loss: 0.581767\n",
      "epoch 46; iter: 0; batch classifier loss: 0.509992; batch adversarial loss: 0.560939\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432233; batch adversarial loss: 0.587494\n",
      "epoch 48; iter: 0; batch classifier loss: 0.487202; batch adversarial loss: 0.553438\n",
      "epoch 49; iter: 0; batch classifier loss: 0.468996; batch adversarial loss: 0.550309\n",
      "epoch 50; iter: 0; batch classifier loss: 0.493154; batch adversarial loss: 0.512318\n",
      "epoch 51; iter: 0; batch classifier loss: 0.484540; batch adversarial loss: 0.600480\n",
      "epoch 52; iter: 0; batch classifier loss: 0.507684; batch adversarial loss: 0.524322\n",
      "epoch 53; iter: 0; batch classifier loss: 0.471920; batch adversarial loss: 0.581693\n",
      "epoch 54; iter: 0; batch classifier loss: 0.497852; batch adversarial loss: 0.623795\n",
      "epoch 55; iter: 0; batch classifier loss: 0.534871; batch adversarial loss: 0.527042\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416695; batch adversarial loss: 0.529026\n",
      "epoch 57; iter: 0; batch classifier loss: 0.475916; batch adversarial loss: 0.579704\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462639; batch adversarial loss: 0.546086\n",
      "epoch 59; iter: 0; batch classifier loss: 0.505024; batch adversarial loss: 0.565519\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398615; batch adversarial loss: 0.616836\n",
      "epoch 61; iter: 0; batch classifier loss: 0.471031; batch adversarial loss: 0.614993\n",
      "epoch 62; iter: 0; batch classifier loss: 0.575827; batch adversarial loss: 0.618501\n",
      "epoch 63; iter: 0; batch classifier loss: 0.469492; batch adversarial loss: 0.635718\n",
      "epoch 64; iter: 0; batch classifier loss: 0.527499; batch adversarial loss: 0.586915\n",
      "epoch 65; iter: 0; batch classifier loss: 0.484751; batch adversarial loss: 0.622208\n",
      "epoch 66; iter: 0; batch classifier loss: 0.483257; batch adversarial loss: 0.601385\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412879; batch adversarial loss: 0.540431\n",
      "epoch 68; iter: 0; batch classifier loss: 0.554428; batch adversarial loss: 0.493343\n",
      "epoch 69; iter: 0; batch classifier loss: 0.477148; batch adversarial loss: 0.591147\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418800; batch adversarial loss: 0.618380\n",
      "epoch 71; iter: 0; batch classifier loss: 0.505426; batch adversarial loss: 0.529894\n",
      "epoch 72; iter: 0; batch classifier loss: 0.493498; batch adversarial loss: 0.558820\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393582; batch adversarial loss: 0.571642\n",
      "epoch 74; iter: 0; batch classifier loss: 0.579768; batch adversarial loss: 0.586744\n",
      "epoch 75; iter: 0; batch classifier loss: 0.366942; batch adversarial loss: 0.542603\n",
      "epoch 76; iter: 0; batch classifier loss: 0.495637; batch adversarial loss: 0.570170\n",
      "epoch 77; iter: 0; batch classifier loss: 0.480470; batch adversarial loss: 0.483184\n",
      "epoch 78; iter: 0; batch classifier loss: 0.496060; batch adversarial loss: 0.546649\n",
      "epoch 79; iter: 0; batch classifier loss: 0.434468; batch adversarial loss: 0.603459\n",
      "epoch 80; iter: 0; batch classifier loss: 0.364435; batch adversarial loss: 0.608385\n",
      "epoch 81; iter: 0; batch classifier loss: 0.480473; batch adversarial loss: 0.596979\n",
      "epoch 82; iter: 0; batch classifier loss: 0.486909; batch adversarial loss: 0.528997\n",
      "epoch 83; iter: 0; batch classifier loss: 0.470616; batch adversarial loss: 0.619626\n",
      "epoch 84; iter: 0; batch classifier loss: 0.449963; batch adversarial loss: 0.600720\n",
      "epoch 85; iter: 0; batch classifier loss: 0.378260; batch adversarial loss: 0.607917\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425653; batch adversarial loss: 0.617293\n",
      "epoch 87; iter: 0; batch classifier loss: 0.421423; batch adversarial loss: 0.593738\n",
      "epoch 88; iter: 0; batch classifier loss: 0.565807; batch adversarial loss: 0.494768\n",
      "epoch 89; iter: 0; batch classifier loss: 0.450194; batch adversarial loss: 0.546673\n",
      "epoch 90; iter: 0; batch classifier loss: 0.456538; batch adversarial loss: 0.543255\n",
      "epoch 91; iter: 0; batch classifier loss: 0.465570; batch adversarial loss: 0.609346\n",
      "epoch 92; iter: 0; batch classifier loss: 0.435670; batch adversarial loss: 0.629101\n",
      "epoch 93; iter: 0; batch classifier loss: 0.599935; batch adversarial loss: 0.556006\n",
      "epoch 94; iter: 0; batch classifier loss: 0.496497; batch adversarial loss: 0.505325\n",
      "epoch 95; iter: 0; batch classifier loss: 0.514998; batch adversarial loss: 0.581367\n",
      "epoch 96; iter: 0; batch classifier loss: 0.430946; batch adversarial loss: 0.573249\n",
      "epoch 97; iter: 0; batch classifier loss: 0.532181; batch adversarial loss: 0.637525\n",
      "epoch 98; iter: 0; batch classifier loss: 0.478888; batch adversarial loss: 0.519739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.451103; batch adversarial loss: 0.549746\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.984916; batch adversarial loss: 0.918457\n",
      "epoch 2; iter: 0; batch classifier loss: 0.994854; batch adversarial loss: 0.816548\n",
      "epoch 3; iter: 0; batch classifier loss: 0.884242; batch adversarial loss: 0.789958\n",
      "epoch 4; iter: 0; batch classifier loss: 0.870208; batch adversarial loss: 0.796362\n",
      "epoch 5; iter: 0; batch classifier loss: 0.935452; batch adversarial loss: 0.693210\n",
      "epoch 6; iter: 0; batch classifier loss: 0.785388; batch adversarial loss: 0.737060\n",
      "epoch 7; iter: 0; batch classifier loss: 0.758409; batch adversarial loss: 0.713945\n",
      "epoch 8; iter: 0; batch classifier loss: 0.697314; batch adversarial loss: 0.669778\n",
      "epoch 9; iter: 0; batch classifier loss: 0.704297; batch adversarial loss: 0.716801\n",
      "epoch 10; iter: 0; batch classifier loss: 0.699284; batch adversarial loss: 0.715768\n",
      "epoch 11; iter: 0; batch classifier loss: 0.694644; batch adversarial loss: 0.653298\n",
      "epoch 12; iter: 0; batch classifier loss: 0.717070; batch adversarial loss: 0.667962\n",
      "epoch 13; iter: 0; batch classifier loss: 0.684294; batch adversarial loss: 0.680802\n",
      "epoch 14; iter: 0; batch classifier loss: 0.688889; batch adversarial loss: 0.650064\n",
      "epoch 15; iter: 0; batch classifier loss: 0.613825; batch adversarial loss: 0.635006\n",
      "epoch 16; iter: 0; batch classifier loss: 0.665681; batch adversarial loss: 0.610588\n",
      "epoch 17; iter: 0; batch classifier loss: 0.627584; batch adversarial loss: 0.653549\n",
      "epoch 18; iter: 0; batch classifier loss: 0.619792; batch adversarial loss: 0.587560\n",
      "epoch 19; iter: 0; batch classifier loss: 0.646127; batch adversarial loss: 0.621439\n",
      "epoch 20; iter: 0; batch classifier loss: 0.688463; batch adversarial loss: 0.652944\n",
      "epoch 21; iter: 0; batch classifier loss: 0.633853; batch adversarial loss: 0.613435\n",
      "epoch 22; iter: 0; batch classifier loss: 0.587149; batch adversarial loss: 0.589017\n",
      "epoch 23; iter: 0; batch classifier loss: 0.588085; batch adversarial loss: 0.547801\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491983; batch adversarial loss: 0.547706\n",
      "epoch 25; iter: 0; batch classifier loss: 0.532020; batch adversarial loss: 0.547160\n",
      "epoch 26; iter: 0; batch classifier loss: 0.480694; batch adversarial loss: 0.609691\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436861; batch adversarial loss: 0.600982\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538013; batch adversarial loss: 0.578435\n",
      "epoch 29; iter: 0; batch classifier loss: 0.481172; batch adversarial loss: 0.562405\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485015; batch adversarial loss: 0.555791\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495433; batch adversarial loss: 0.544781\n",
      "epoch 32; iter: 0; batch classifier loss: 0.617346; batch adversarial loss: 0.566094\n",
      "epoch 33; iter: 0; batch classifier loss: 0.704228; batch adversarial loss: 0.599706\n",
      "epoch 34; iter: 0; batch classifier loss: 0.779344; batch adversarial loss: 0.659868\n",
      "epoch 35; iter: 0; batch classifier loss: 0.760255; batch adversarial loss: 0.596959\n",
      "epoch 36; iter: 0; batch classifier loss: 0.721448; batch adversarial loss: 0.580461\n",
      "epoch 37; iter: 0; batch classifier loss: 0.606765; batch adversarial loss: 0.625282\n",
      "epoch 38; iter: 0; batch classifier loss: 0.556833; batch adversarial loss: 0.536995\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479879; batch adversarial loss: 0.634943\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458013; batch adversarial loss: 0.613457\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472186; batch adversarial loss: 0.511434\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457566; batch adversarial loss: 0.582790\n",
      "epoch 43; iter: 0; batch classifier loss: 0.586215; batch adversarial loss: 0.552928\n",
      "epoch 44; iter: 0; batch classifier loss: 0.513628; batch adversarial loss: 0.696551\n",
      "epoch 45; iter: 0; batch classifier loss: 0.546433; batch adversarial loss: 0.582530\n",
      "epoch 46; iter: 0; batch classifier loss: 0.521897; batch adversarial loss: 0.561844\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438154; batch adversarial loss: 0.587576\n",
      "epoch 48; iter: 0; batch classifier loss: 0.480653; batch adversarial loss: 0.553101\n",
      "epoch 49; iter: 0; batch classifier loss: 0.473881; batch adversarial loss: 0.550481\n",
      "epoch 50; iter: 0; batch classifier loss: 0.490061; batch adversarial loss: 0.512185\n",
      "epoch 51; iter: 0; batch classifier loss: 0.485578; batch adversarial loss: 0.600545\n",
      "epoch 52; iter: 0; batch classifier loss: 0.518308; batch adversarial loss: 0.524806\n",
      "epoch 53; iter: 0; batch classifier loss: 0.467135; batch adversarial loss: 0.581949\n",
      "epoch 54; iter: 0; batch classifier loss: 0.514682; batch adversarial loss: 0.624889\n",
      "epoch 55; iter: 0; batch classifier loss: 0.569297; batch adversarial loss: 0.528512\n",
      "epoch 56; iter: 0; batch classifier loss: 0.435846; batch adversarial loss: 0.530663\n",
      "epoch 57; iter: 0; batch classifier loss: 0.491453; batch adversarial loss: 0.580166\n",
      "epoch 58; iter: 0; batch classifier loss: 0.465762; batch adversarial loss: 0.546254\n",
      "epoch 59; iter: 0; batch classifier loss: 0.504829; batch adversarial loss: 0.565532\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398522; batch adversarial loss: 0.617073\n",
      "epoch 61; iter: 0; batch classifier loss: 0.477420; batch adversarial loss: 0.615154\n",
      "epoch 62; iter: 0; batch classifier loss: 0.568117; batch adversarial loss: 0.619323\n",
      "epoch 63; iter: 0; batch classifier loss: 0.480907; batch adversarial loss: 0.636275\n",
      "epoch 64; iter: 0; batch classifier loss: 0.542978; batch adversarial loss: 0.588048\n",
      "epoch 65; iter: 0; batch classifier loss: 0.473437; batch adversarial loss: 0.621910\n",
      "epoch 66; iter: 0; batch classifier loss: 0.491628; batch adversarial loss: 0.602155\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412690; batch adversarial loss: 0.541127\n",
      "epoch 68; iter: 0; batch classifier loss: 0.559843; batch adversarial loss: 0.493879\n",
      "epoch 69; iter: 0; batch classifier loss: 0.489281; batch adversarial loss: 0.592329\n",
      "epoch 70; iter: 0; batch classifier loss: 0.428519; batch adversarial loss: 0.619885\n",
      "epoch 71; iter: 0; batch classifier loss: 0.513859; batch adversarial loss: 0.530717\n",
      "epoch 72; iter: 0; batch classifier loss: 0.501456; batch adversarial loss: 0.559228\n",
      "epoch 73; iter: 0; batch classifier loss: 0.384759; batch adversarial loss: 0.569164\n",
      "epoch 74; iter: 0; batch classifier loss: 0.585997; batch adversarial loss: 0.584936\n",
      "epoch 75; iter: 0; batch classifier loss: 0.380901; batch adversarial loss: 0.543890\n",
      "epoch 76; iter: 0; batch classifier loss: 0.516967; batch adversarial loss: 0.571286\n",
      "epoch 77; iter: 0; batch classifier loss: 0.484939; batch adversarial loss: 0.483383\n",
      "epoch 78; iter: 0; batch classifier loss: 0.487225; batch adversarial loss: 0.546713\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433620; batch adversarial loss: 0.603529\n",
      "epoch 80; iter: 0; batch classifier loss: 0.380885; batch adversarial loss: 0.609038\n",
      "epoch 81; iter: 0; batch classifier loss: 0.482222; batch adversarial loss: 0.597084\n",
      "epoch 82; iter: 0; batch classifier loss: 0.474796; batch adversarial loss: 0.528741\n",
      "epoch 83; iter: 0; batch classifier loss: 0.468934; batch adversarial loss: 0.619636\n",
      "epoch 84; iter: 0; batch classifier loss: 0.447704; batch adversarial loss: 0.602705\n",
      "epoch 85; iter: 0; batch classifier loss: 0.372869; batch adversarial loss: 0.607523\n",
      "epoch 86; iter: 0; batch classifier loss: 0.432815; batch adversarial loss: 0.619660\n",
      "epoch 87; iter: 0; batch classifier loss: 0.444694; batch adversarial loss: 0.594067\n",
      "epoch 88; iter: 0; batch classifier loss: 0.576815; batch adversarial loss: 0.496468\n",
      "epoch 89; iter: 0; batch classifier loss: 0.462175; batch adversarial loss: 0.548549\n",
      "epoch 90; iter: 0; batch classifier loss: 0.462402; batch adversarial loss: 0.543915\n",
      "epoch 91; iter: 0; batch classifier loss: 0.469621; batch adversarial loss: 0.608125\n",
      "epoch 92; iter: 0; batch classifier loss: 0.456411; batch adversarial loss: 0.627697\n",
      "epoch 93; iter: 0; batch classifier loss: 0.592318; batch adversarial loss: 0.555183\n",
      "epoch 94; iter: 0; batch classifier loss: 0.500704; batch adversarial loss: 0.505582\n",
      "epoch 95; iter: 0; batch classifier loss: 0.513200; batch adversarial loss: 0.581234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.426186; batch adversarial loss: 0.571620\n",
      "epoch 97; iter: 0; batch classifier loss: 0.535800; batch adversarial loss: 0.637676\n",
      "epoch 98; iter: 0; batch classifier loss: 0.455604; batch adversarial loss: 0.518324\n",
      "epoch 99; iter: 0; batch classifier loss: 0.432129; batch adversarial loss: 0.548981\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709988; batch adversarial loss: 0.791750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610699; batch adversarial loss: 0.799196\n",
      "epoch 2; iter: 0; batch classifier loss: 0.565109; batch adversarial loss: 0.744651\n",
      "epoch 3; iter: 0; batch classifier loss: 0.443266; batch adversarial loss: 0.710405\n",
      "epoch 4; iter: 0; batch classifier loss: 0.489512; batch adversarial loss: 0.699795\n",
      "epoch 5; iter: 0; batch classifier loss: 0.496309; batch adversarial loss: 0.651890\n",
      "epoch 6; iter: 0; batch classifier loss: 0.605175; batch adversarial loss: 0.657594\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522005; batch adversarial loss: 0.647731\n",
      "epoch 8; iter: 0; batch classifier loss: 0.498662; batch adversarial loss: 0.631312\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501637; batch adversarial loss: 0.648573\n",
      "epoch 10; iter: 0; batch classifier loss: 0.468601; batch adversarial loss: 0.657192\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576446; batch adversarial loss: 0.612014\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558172; batch adversarial loss: 0.619954\n",
      "epoch 13; iter: 0; batch classifier loss: 0.503577; batch adversarial loss: 0.631157\n",
      "epoch 14; iter: 0; batch classifier loss: 0.484510; batch adversarial loss: 0.612786\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500765; batch adversarial loss: 0.591743\n",
      "epoch 16; iter: 0; batch classifier loss: 0.479282; batch adversarial loss: 0.558713\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500219; batch adversarial loss: 0.580310\n",
      "epoch 18; iter: 0; batch classifier loss: 0.502207; batch adversarial loss: 0.504454\n",
      "epoch 19; iter: 0; batch classifier loss: 0.421720; batch adversarial loss: 0.548414\n",
      "epoch 20; iter: 0; batch classifier loss: 0.414104; batch adversarial loss: 0.589550\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477606; batch adversarial loss: 0.559634\n",
      "epoch 22; iter: 0; batch classifier loss: 0.414309; batch adversarial loss: 0.522324\n",
      "epoch 23; iter: 0; batch classifier loss: 0.445937; batch adversarial loss: 0.507102\n",
      "epoch 24; iter: 0; batch classifier loss: 0.405121; batch adversarial loss: 0.496244\n",
      "epoch 25; iter: 0; batch classifier loss: 0.409539; batch adversarial loss: 0.500551\n",
      "epoch 26; iter: 0; batch classifier loss: 0.371346; batch adversarial loss: 0.571821\n",
      "epoch 27; iter: 0; batch classifier loss: 0.379403; batch adversarial loss: 0.574132\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450310; batch adversarial loss: 0.540531\n",
      "epoch 29; iter: 0; batch classifier loss: 0.376189; batch adversarial loss: 0.518867\n",
      "epoch 30; iter: 0; batch classifier loss: 0.365867; batch adversarial loss: 0.524232\n",
      "epoch 31; iter: 0; batch classifier loss: 0.374877; batch adversarial loss: 0.510751\n",
      "epoch 32; iter: 0; batch classifier loss: 0.419517; batch adversarial loss: 0.518540\n",
      "epoch 33; iter: 0; batch classifier loss: 0.392724; batch adversarial loss: 0.533249\n",
      "epoch 34; iter: 0; batch classifier loss: 0.373632; batch adversarial loss: 0.624717\n",
      "epoch 35; iter: 0; batch classifier loss: 0.330596; batch adversarial loss: 0.575396\n",
      "epoch 36; iter: 0; batch classifier loss: 0.382080; batch adversarial loss: 0.588364\n",
      "epoch 37; iter: 0; batch classifier loss: 0.468017; batch adversarial loss: 0.695528\n",
      "epoch 38; iter: 0; batch classifier loss: 0.517220; batch adversarial loss: 0.570461\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483874; batch adversarial loss: 0.712416\n",
      "epoch 40; iter: 0; batch classifier loss: 0.512887; batch adversarial loss: 0.708107\n",
      "epoch 41; iter: 0; batch classifier loss: 0.434100; batch adversarial loss: 0.581417\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469833; batch adversarial loss: 0.649725\n",
      "epoch 43; iter: 0; batch classifier loss: 0.540348; batch adversarial loss: 0.616348\n",
      "epoch 44; iter: 0; batch classifier loss: 0.544714; batch adversarial loss: 0.781426\n",
      "epoch 45; iter: 0; batch classifier loss: 0.639039; batch adversarial loss: 0.659414\n",
      "epoch 46; iter: 0; batch classifier loss: 0.625117; batch adversarial loss: 0.628833\n",
      "epoch 47; iter: 0; batch classifier loss: 0.599137; batch adversarial loss: 0.632511\n",
      "epoch 48; iter: 0; batch classifier loss: 0.663817; batch adversarial loss: 0.598470\n",
      "epoch 49; iter: 0; batch classifier loss: 0.696207; batch adversarial loss: 0.577524\n",
      "epoch 50; iter: 0; batch classifier loss: 0.552644; batch adversarial loss: 0.530369\n",
      "epoch 51; iter: 0; batch classifier loss: 0.374909; batch adversarial loss: 0.593591\n",
      "epoch 52; iter: 0; batch classifier loss: 0.388818; batch adversarial loss: 0.529571\n",
      "epoch 53; iter: 0; batch classifier loss: 0.319640; batch adversarial loss: 0.582395\n",
      "epoch 54; iter: 0; batch classifier loss: 0.357069; batch adversarial loss: 0.617366\n",
      "epoch 55; iter: 0; batch classifier loss: 0.390485; batch adversarial loss: 0.528102\n",
      "epoch 56; iter: 0; batch classifier loss: 0.291371; batch adversarial loss: 0.523969\n",
      "epoch 57; iter: 0; batch classifier loss: 0.333860; batch adversarial loss: 0.571910\n",
      "epoch 58; iter: 0; batch classifier loss: 0.294854; batch adversarial loss: 0.546590\n",
      "epoch 59; iter: 0; batch classifier loss: 0.348839; batch adversarial loss: 0.560748\n",
      "epoch 60; iter: 0; batch classifier loss: 0.237969; batch adversarial loss: 0.612846\n",
      "epoch 61; iter: 0; batch classifier loss: 0.355650; batch adversarial loss: 0.607691\n",
      "epoch 62; iter: 0; batch classifier loss: 0.421049; batch adversarial loss: 0.612087\n",
      "epoch 63; iter: 0; batch classifier loss: 0.323248; batch adversarial loss: 0.632898\n",
      "epoch 64; iter: 0; batch classifier loss: 0.451119; batch adversarial loss: 0.578519\n",
      "epoch 65; iter: 0; batch classifier loss: 0.349546; batch adversarial loss: 0.612185\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405172; batch adversarial loss: 0.597411\n",
      "epoch 67; iter: 0; batch classifier loss: 0.275574; batch adversarial loss: 0.536444\n",
      "epoch 68; iter: 0; batch classifier loss: 0.456207; batch adversarial loss: 0.492921\n",
      "epoch 69; iter: 0; batch classifier loss: 0.335455; batch adversarial loss: 0.582182\n",
      "epoch 70; iter: 0; batch classifier loss: 0.358807; batch adversarial loss: 0.618715\n",
      "epoch 71; iter: 0; batch classifier loss: 0.399527; batch adversarial loss: 0.525338\n",
      "epoch 72; iter: 0; batch classifier loss: 0.346567; batch adversarial loss: 0.552367\n",
      "epoch 73; iter: 0; batch classifier loss: 0.263773; batch adversarial loss: 0.570512\n",
      "epoch 74; iter: 0; batch classifier loss: 0.381996; batch adversarial loss: 0.585272\n",
      "epoch 75; iter: 0; batch classifier loss: 0.279731; batch adversarial loss: 0.537744\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384519; batch adversarial loss: 0.563777\n",
      "epoch 77; iter: 0; batch classifier loss: 0.326319; batch adversarial loss: 0.479105\n",
      "epoch 78; iter: 0; batch classifier loss: 0.420027; batch adversarial loss: 0.546869\n",
      "epoch 79; iter: 0; batch classifier loss: 0.362442; batch adversarial loss: 0.607187\n",
      "epoch 80; iter: 0; batch classifier loss: 0.353895; batch adversarial loss: 0.606324\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403792; batch adversarial loss: 0.593582\n",
      "epoch 82; iter: 0; batch classifier loss: 0.411305; batch adversarial loss: 0.533199\n",
      "epoch 83; iter: 0; batch classifier loss: 0.397729; batch adversarial loss: 0.621313\n",
      "epoch 84; iter: 0; batch classifier loss: 0.412902; batch adversarial loss: 0.607634\n",
      "epoch 85; iter: 0; batch classifier loss: 0.322663; batch adversarial loss: 0.606003\n",
      "epoch 86; iter: 0; batch classifier loss: 0.356498; batch adversarial loss: 0.624841\n",
      "epoch 87; iter: 0; batch classifier loss: 0.396015; batch adversarial loss: 0.600552\n",
      "epoch 88; iter: 0; batch classifier loss: 0.526150; batch adversarial loss: 0.499831\n",
      "epoch 89; iter: 0; batch classifier loss: 0.371008; batch adversarial loss: 0.547228\n",
      "epoch 90; iter: 0; batch classifier loss: 0.386120; batch adversarial loss: 0.542181\n",
      "epoch 91; iter: 0; batch classifier loss: 0.401217; batch adversarial loss: 0.614941\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384855; batch adversarial loss: 0.633435\n",
      "epoch 93; iter: 0; batch classifier loss: 0.517825; batch adversarial loss: 0.556485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.441622; batch adversarial loss: 0.504640\n",
      "epoch 95; iter: 0; batch classifier loss: 0.452037; batch adversarial loss: 0.577252\n",
      "epoch 96; iter: 0; batch classifier loss: 0.395482; batch adversarial loss: 0.577061\n",
      "epoch 97; iter: 0; batch classifier loss: 0.473651; batch adversarial loss: 0.648751\n",
      "epoch 98; iter: 0; batch classifier loss: 0.428573; batch adversarial loss: 0.520926\n",
      "epoch 99; iter: 0; batch classifier loss: 0.416931; batch adversarial loss: 0.554599\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.751807; batch adversarial loss: 0.873886\n",
      "epoch 2; iter: 0; batch classifier loss: 0.740154; batch adversarial loss: 0.786230\n",
      "epoch 3; iter: 0; batch classifier loss: 0.559592; batch adversarial loss: 0.746614\n",
      "epoch 4; iter: 0; batch classifier loss: 0.484421; batch adversarial loss: 0.736539\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495971; batch adversarial loss: 0.658489\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599615; batch adversarial loss: 0.670659\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485877; batch adversarial loss: 0.660829\n",
      "epoch 8; iter: 0; batch classifier loss: 0.478693; batch adversarial loss: 0.636490\n",
      "epoch 9; iter: 0; batch classifier loss: 0.457175; batch adversarial loss: 0.656941\n",
      "epoch 10; iter: 0; batch classifier loss: 0.460376; batch adversarial loss: 0.657448\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571131; batch adversarial loss: 0.612855\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548249; batch adversarial loss: 0.622769\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540949; batch adversarial loss: 0.625011\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500641; batch adversarial loss: 0.605921\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529353; batch adversarial loss: 0.585430\n",
      "epoch 16; iter: 0; batch classifier loss: 0.494145; batch adversarial loss: 0.558672\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510010; batch adversarial loss: 0.595105\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472154; batch adversarial loss: 0.540327\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437523; batch adversarial loss: 0.571426\n",
      "epoch 20; iter: 0; batch classifier loss: 0.457847; batch adversarial loss: 0.607641\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494278; batch adversarial loss: 0.581074\n",
      "epoch 22; iter: 0; batch classifier loss: 0.435821; batch adversarial loss: 0.549170\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477998; batch adversarial loss: 0.521555\n",
      "epoch 24; iter: 0; batch classifier loss: 0.401689; batch adversarial loss: 0.515538\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432582; batch adversarial loss: 0.517639\n",
      "epoch 26; iter: 0; batch classifier loss: 0.398091; batch adversarial loss: 0.585663\n",
      "epoch 27; iter: 0; batch classifier loss: 0.454400; batch adversarial loss: 0.618116\n",
      "epoch 28; iter: 0; batch classifier loss: 0.570469; batch adversarial loss: 0.601864\n",
      "epoch 29; iter: 0; batch classifier loss: 0.521659; batch adversarial loss: 0.589160\n",
      "epoch 30; iter: 0; batch classifier loss: 0.518890; batch adversarial loss: 0.607765\n",
      "epoch 31; iter: 0; batch classifier loss: 0.520391; batch adversarial loss: 0.581828\n",
      "epoch 32; iter: 0; batch classifier loss: 0.600395; batch adversarial loss: 0.604596\n",
      "epoch 33; iter: 0; batch classifier loss: 0.685216; batch adversarial loss: 0.649535\n",
      "epoch 34; iter: 0; batch classifier loss: 0.677512; batch adversarial loss: 0.720071\n",
      "epoch 35; iter: 0; batch classifier loss: 0.739317; batch adversarial loss: 0.671446\n",
      "epoch 36; iter: 0; batch classifier loss: 0.733601; batch adversarial loss: 0.647313\n",
      "epoch 37; iter: 0; batch classifier loss: 0.833799; batch adversarial loss: 0.686608\n",
      "epoch 38; iter: 0; batch classifier loss: 0.778117; batch adversarial loss: 0.569089\n",
      "epoch 39; iter: 0; batch classifier loss: 0.678096; batch adversarial loss: 0.660130\n",
      "epoch 40; iter: 0; batch classifier loss: 0.696139; batch adversarial loss: 0.631440\n",
      "epoch 41; iter: 0; batch classifier loss: 0.563334; batch adversarial loss: 0.526760\n",
      "epoch 42; iter: 0; batch classifier loss: 0.541097; batch adversarial loss: 0.586307\n",
      "epoch 43; iter: 0; batch classifier loss: 0.505779; batch adversarial loss: 0.557501\n",
      "epoch 44; iter: 0; batch classifier loss: 0.465838; batch adversarial loss: 0.689188\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471393; batch adversarial loss: 0.582891\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436155; batch adversarial loss: 0.562437\n",
      "epoch 47; iter: 0; batch classifier loss: 0.365574; batch adversarial loss: 0.586775\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430694; batch adversarial loss: 0.554917\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406708; batch adversarial loss: 0.551144\n",
      "epoch 50; iter: 0; batch classifier loss: 0.441294; batch adversarial loss: 0.514434\n",
      "epoch 51; iter: 0; batch classifier loss: 0.422988; batch adversarial loss: 0.599520\n",
      "epoch 52; iter: 0; batch classifier loss: 0.423943; batch adversarial loss: 0.524745\n",
      "epoch 53; iter: 0; batch classifier loss: 0.419130; batch adversarial loss: 0.582029\n",
      "epoch 54; iter: 0; batch classifier loss: 0.439191; batch adversarial loss: 0.622817\n",
      "epoch 55; iter: 0; batch classifier loss: 0.494638; batch adversarial loss: 0.528136\n",
      "epoch 56; iter: 0; batch classifier loss: 0.350632; batch adversarial loss: 0.527761\n",
      "epoch 57; iter: 0; batch classifier loss: 0.406247; batch adversarial loss: 0.578076\n",
      "epoch 58; iter: 0; batch classifier loss: 0.394837; batch adversarial loss: 0.545799\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408217; batch adversarial loss: 0.561936\n",
      "epoch 60; iter: 0; batch classifier loss: 0.373006; batch adversarial loss: 0.617779\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407540; batch adversarial loss: 0.610813\n",
      "epoch 62; iter: 0; batch classifier loss: 0.456037; batch adversarial loss: 0.615941\n",
      "epoch 63; iter: 0; batch classifier loss: 0.390430; batch adversarial loss: 0.634290\n",
      "epoch 64; iter: 0; batch classifier loss: 0.452919; batch adversarial loss: 0.580490\n",
      "epoch 65; iter: 0; batch classifier loss: 0.429453; batch adversarial loss: 0.619696\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415846; batch adversarial loss: 0.597153\n",
      "epoch 67; iter: 0; batch classifier loss: 0.340932; batch adversarial loss: 0.537279\n",
      "epoch 68; iter: 0; batch classifier loss: 0.486537; batch adversarial loss: 0.491209\n",
      "epoch 69; iter: 0; batch classifier loss: 0.407709; batch adversarial loss: 0.586107\n",
      "epoch 70; iter: 0; batch classifier loss: 0.354735; batch adversarial loss: 0.615755\n",
      "epoch 71; iter: 0; batch classifier loss: 0.438434; batch adversarial loss: 0.527454\n",
      "epoch 72; iter: 0; batch classifier loss: 0.385473; batch adversarial loss: 0.555252\n",
      "epoch 73; iter: 0; batch classifier loss: 0.291243; batch adversarial loss: 0.566952\n",
      "epoch 74; iter: 0; batch classifier loss: 0.503887; batch adversarial loss: 0.583847\n",
      "epoch 75; iter: 0; batch classifier loss: 0.329253; batch adversarial loss: 0.537960\n",
      "epoch 76; iter: 0; batch classifier loss: 0.389396; batch adversarial loss: 0.561379\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388040; batch adversarial loss: 0.478684\n",
      "epoch 78; iter: 0; batch classifier loss: 0.460632; batch adversarial loss: 0.545445\n",
      "epoch 79; iter: 0; batch classifier loss: 0.383141; batch adversarial loss: 0.598864\n",
      "epoch 80; iter: 0; batch classifier loss: 0.302951; batch adversarial loss: 0.601545\n",
      "epoch 81; iter: 0; batch classifier loss: 0.418805; batch adversarial loss: 0.593519\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384529; batch adversarial loss: 0.525657\n",
      "epoch 83; iter: 0; batch classifier loss: 0.414011; batch adversarial loss: 0.614749\n",
      "epoch 84; iter: 0; batch classifier loss: 0.405745; batch adversarial loss: 0.601814\n",
      "epoch 85; iter: 0; batch classifier loss: 0.281866; batch adversarial loss: 0.600803\n",
      "epoch 86; iter: 0; batch classifier loss: 0.355686; batch adversarial loss: 0.617073\n",
      "epoch 87; iter: 0; batch classifier loss: 0.388394; batch adversarial loss: 0.592813\n",
      "epoch 88; iter: 0; batch classifier loss: 0.473138; batch adversarial loss: 0.489532\n",
      "epoch 89; iter: 0; batch classifier loss: 0.373188; batch adversarial loss: 0.540633\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383778; batch adversarial loss: 0.539172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91; iter: 0; batch classifier loss: 0.387824; batch adversarial loss: 0.605489\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379999; batch adversarial loss: 0.622581\n",
      "epoch 93; iter: 0; batch classifier loss: 0.506360; batch adversarial loss: 0.548695\n",
      "epoch 94; iter: 0; batch classifier loss: 0.394930; batch adversarial loss: 0.497316\n",
      "epoch 95; iter: 0; batch classifier loss: 0.453507; batch adversarial loss: 0.573518\n",
      "epoch 96; iter: 0; batch classifier loss: 0.383413; batch adversarial loss: 0.574946\n",
      "epoch 97; iter: 0; batch classifier loss: 0.445472; batch adversarial loss: 0.639283\n",
      "epoch 98; iter: 0; batch classifier loss: 0.394799; batch adversarial loss: 0.511900\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424861; batch adversarial loss: 0.545595\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.775056; batch adversarial loss: 0.882024\n",
      "epoch 2; iter: 0; batch classifier loss: 0.764475; batch adversarial loss: 0.790732\n",
      "epoch 3; iter: 0; batch classifier loss: 0.580735; batch adversarial loss: 0.751877\n",
      "epoch 4; iter: 0; batch classifier loss: 0.497005; batch adversarial loss: 0.742838\n",
      "epoch 5; iter: 0; batch classifier loss: 0.496572; batch adversarial loss: 0.659891\n",
      "epoch 6; iter: 0; batch classifier loss: 0.594818; batch adversarial loss: 0.672145\n",
      "epoch 7; iter: 0; batch classifier loss: 0.484297; batch adversarial loss: 0.661533\n",
      "epoch 8; iter: 0; batch classifier loss: 0.476218; batch adversarial loss: 0.637453\n",
      "epoch 9; iter: 0; batch classifier loss: 0.452556; batch adversarial loss: 0.658423\n",
      "epoch 10; iter: 0; batch classifier loss: 0.457594; batch adversarial loss: 0.658005\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568259; batch adversarial loss: 0.613494\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545880; batch adversarial loss: 0.623195\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539511; batch adversarial loss: 0.625179\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500580; batch adversarial loss: 0.605824\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527805; batch adversarial loss: 0.586135\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491658; batch adversarial loss: 0.560127\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510064; batch adversarial loss: 0.597266\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471263; batch adversarial loss: 0.543730\n",
      "epoch 19; iter: 0; batch classifier loss: 0.436564; batch adversarial loss: 0.574121\n",
      "epoch 20; iter: 0; batch classifier loss: 0.460447; batch adversarial loss: 0.609914\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494645; batch adversarial loss: 0.582630\n",
      "epoch 22; iter: 0; batch classifier loss: 0.436426; batch adversarial loss: 0.551862\n",
      "epoch 23; iter: 0; batch classifier loss: 0.478042; batch adversarial loss: 0.525142\n",
      "epoch 24; iter: 0; batch classifier loss: 0.400159; batch adversarial loss: 0.518190\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432941; batch adversarial loss: 0.520812\n",
      "epoch 26; iter: 0; batch classifier loss: 0.402661; batch adversarial loss: 0.592444\n",
      "epoch 27; iter: 0; batch classifier loss: 0.486410; batch adversarial loss: 0.641178\n",
      "epoch 28; iter: 0; batch classifier loss: 0.595344; batch adversarial loss: 0.615079\n",
      "epoch 29; iter: 0; batch classifier loss: 0.543199; batch adversarial loss: 0.598995\n",
      "epoch 30; iter: 0; batch classifier loss: 0.546738; batch adversarial loss: 0.617830\n",
      "epoch 31; iter: 0; batch classifier loss: 0.553056; batch adversarial loss: 0.590528\n",
      "epoch 32; iter: 0; batch classifier loss: 0.676783; batch adversarial loss: 0.625049\n",
      "epoch 33; iter: 0; batch classifier loss: 0.787043; batch adversarial loss: 0.659960\n",
      "epoch 34; iter: 0; batch classifier loss: 0.729493; batch adversarial loss: 0.709729\n",
      "epoch 35; iter: 0; batch classifier loss: 0.731714; batch adversarial loss: 0.651270\n",
      "epoch 36; iter: 0; batch classifier loss: 0.701900; batch adversarial loss: 0.629347\n",
      "epoch 37; iter: 0; batch classifier loss: 0.774107; batch adversarial loss: 0.667393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.723695; batch adversarial loss: 0.559492\n",
      "epoch 39; iter: 0; batch classifier loss: 0.612691; batch adversarial loss: 0.649509\n",
      "epoch 40; iter: 0; batch classifier loss: 0.615564; batch adversarial loss: 0.623535\n",
      "epoch 41; iter: 0; batch classifier loss: 0.524726; batch adversarial loss: 0.522538\n",
      "epoch 42; iter: 0; batch classifier loss: 0.421299; batch adversarial loss: 0.585783\n",
      "epoch 43; iter: 0; batch classifier loss: 0.515784; batch adversarial loss: 0.556796\n",
      "epoch 44; iter: 0; batch classifier loss: 0.458413; batch adversarial loss: 0.690987\n",
      "epoch 45; iter: 0; batch classifier loss: 0.475613; batch adversarial loss: 0.583054\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440106; batch adversarial loss: 0.562487\n",
      "epoch 47; iter: 0; batch classifier loss: 0.360522; batch adversarial loss: 0.587203\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423504; batch adversarial loss: 0.554846\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404130; batch adversarial loss: 0.551201\n",
      "epoch 50; iter: 0; batch classifier loss: 0.439277; batch adversarial loss: 0.514135\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416950; batch adversarial loss: 0.599820\n",
      "epoch 52; iter: 0; batch classifier loss: 0.425026; batch adversarial loss: 0.524457\n",
      "epoch 53; iter: 0; batch classifier loss: 0.410534; batch adversarial loss: 0.582090\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435916; batch adversarial loss: 0.623167\n",
      "epoch 55; iter: 0; batch classifier loss: 0.484896; batch adversarial loss: 0.528061\n",
      "epoch 56; iter: 0; batch classifier loss: 0.345665; batch adversarial loss: 0.527687\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401319; batch adversarial loss: 0.578210\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396079; batch adversarial loss: 0.545650\n",
      "epoch 59; iter: 0; batch classifier loss: 0.415010; batch adversarial loss: 0.562992\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376164; batch adversarial loss: 0.618185\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406883; batch adversarial loss: 0.610596\n",
      "epoch 62; iter: 0; batch classifier loss: 0.456823; batch adversarial loss: 0.616110\n",
      "epoch 63; iter: 0; batch classifier loss: 0.388033; batch adversarial loss: 0.634071\n",
      "epoch 64; iter: 0; batch classifier loss: 0.458961; batch adversarial loss: 0.581025\n",
      "epoch 65; iter: 0; batch classifier loss: 0.424967; batch adversarial loss: 0.619549\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416360; batch adversarial loss: 0.597893\n",
      "epoch 67; iter: 0; batch classifier loss: 0.339214; batch adversarial loss: 0.537556\n",
      "epoch 68; iter: 0; batch classifier loss: 0.501904; batch adversarial loss: 0.492127\n",
      "epoch 69; iter: 0; batch classifier loss: 0.417657; batch adversarial loss: 0.586915\n",
      "epoch 70; iter: 0; batch classifier loss: 0.355391; batch adversarial loss: 0.616179\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437842; batch adversarial loss: 0.527677\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381747; batch adversarial loss: 0.555696\n",
      "epoch 73; iter: 0; batch classifier loss: 0.303546; batch adversarial loss: 0.567709\n",
      "epoch 74; iter: 0; batch classifier loss: 0.511034; batch adversarial loss: 0.583173\n",
      "epoch 75; iter: 0; batch classifier loss: 0.325656; batch adversarial loss: 0.538077\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384413; batch adversarial loss: 0.561917\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392099; batch adversarial loss: 0.478231\n",
      "epoch 78; iter: 0; batch classifier loss: 0.473131; batch adversarial loss: 0.545572\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381291; batch adversarial loss: 0.599633\n",
      "epoch 80; iter: 0; batch classifier loss: 0.306113; batch adversarial loss: 0.602854\n",
      "epoch 81; iter: 0; batch classifier loss: 0.420537; batch adversarial loss: 0.594766\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393640; batch adversarial loss: 0.527166\n",
      "epoch 83; iter: 0; batch classifier loss: 0.428386; batch adversarial loss: 0.615910\n",
      "epoch 84; iter: 0; batch classifier loss: 0.407551; batch adversarial loss: 0.602578\n",
      "epoch 85; iter: 0; batch classifier loss: 0.296586; batch adversarial loss: 0.602251\n",
      "epoch 86; iter: 0; batch classifier loss: 0.395165; batch adversarial loss: 0.620480\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390874; batch adversarial loss: 0.592450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.494577; batch adversarial loss: 0.491130\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389713; batch adversarial loss: 0.541921\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387896; batch adversarial loss: 0.539785\n",
      "epoch 91; iter: 0; batch classifier loss: 0.379351; batch adversarial loss: 0.604854\n",
      "epoch 92; iter: 0; batch classifier loss: 0.379500; batch adversarial loss: 0.625585\n",
      "epoch 93; iter: 0; batch classifier loss: 0.515991; batch adversarial loss: 0.549309\n",
      "epoch 94; iter: 0; batch classifier loss: 0.404752; batch adversarial loss: 0.499013\n",
      "epoch 95; iter: 0; batch classifier loss: 0.473240; batch adversarial loss: 0.575385\n",
      "epoch 96; iter: 0; batch classifier loss: 0.390604; batch adversarial loss: 0.574986\n",
      "epoch 97; iter: 0; batch classifier loss: 0.450560; batch adversarial loss: 0.640692\n",
      "epoch 98; iter: 0; batch classifier loss: 0.397045; batch adversarial loss: 0.513336\n",
      "epoch 99; iter: 0; batch classifier loss: 0.421779; batch adversarial loss: 0.547258\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.745254; batch adversarial loss: 0.871327\n",
      "epoch 2; iter: 0; batch classifier loss: 0.734995; batch adversarial loss: 0.784827\n",
      "epoch 3; iter: 0; batch classifier loss: 0.552990; batch adversarial loss: 0.745505\n",
      "epoch 4; iter: 0; batch classifier loss: 0.482427; batch adversarial loss: 0.734659\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495086; batch adversarial loss: 0.658203\n",
      "epoch 6; iter: 0; batch classifier loss: 0.600681; batch adversarial loss: 0.670318\n",
      "epoch 7; iter: 0; batch classifier loss: 0.487006; batch adversarial loss: 0.660456\n",
      "epoch 8; iter: 0; batch classifier loss: 0.479123; batch adversarial loss: 0.636305\n",
      "epoch 9; iter: 0; batch classifier loss: 0.458764; batch adversarial loss: 0.656456\n",
      "epoch 10; iter: 0; batch classifier loss: 0.461673; batch adversarial loss: 0.657284\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571811; batch adversarial loss: 0.612689\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548496; batch adversarial loss: 0.622699\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541304; batch adversarial loss: 0.624926\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501198; batch adversarial loss: 0.605696\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529812; batch adversarial loss: 0.585109\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495263; batch adversarial loss: 0.557948\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510255; batch adversarial loss: 0.594316\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472938; batch adversarial loss: 0.538951\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437188; batch adversarial loss: 0.570991\n",
      "epoch 20; iter: 0; batch classifier loss: 0.457752; batch adversarial loss: 0.606750\n",
      "epoch 21; iter: 0; batch classifier loss: 0.496746; batch adversarial loss: 0.580543\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437232; batch adversarial loss: 0.548250\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476397; batch adversarial loss: 0.521282\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402060; batch adversarial loss: 0.514775\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432625; batch adversarial loss: 0.516618\n",
      "epoch 26; iter: 0; batch classifier loss: 0.397769; batch adversarial loss: 0.584208\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450587; batch adversarial loss: 0.615188\n",
      "epoch 28; iter: 0; batch classifier loss: 0.561712; batch adversarial loss: 0.597062\n",
      "epoch 29; iter: 0; batch classifier loss: 0.512209; batch adversarial loss: 0.583697\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510530; batch adversarial loss: 0.604375\n",
      "epoch 31; iter: 0; batch classifier loss: 0.514087; batch adversarial loss: 0.579104\n",
      "epoch 32; iter: 0; batch classifier loss: 0.590928; batch adversarial loss: 0.600634\n",
      "epoch 33; iter: 0; batch classifier loss: 0.635726; batch adversarial loss: 0.635069\n",
      "epoch 34; iter: 0; batch classifier loss: 0.620774; batch adversarial loss: 0.711460\n",
      "epoch 35; iter: 0; batch classifier loss: 0.709442; batch adversarial loss: 0.675062\n",
      "epoch 36; iter: 0; batch classifier loss: 0.724305; batch adversarial loss: 0.653213\n",
      "epoch 37; iter: 0; batch classifier loss: 0.842250; batch adversarial loss: 0.694595\n",
      "epoch 38; iter: 0; batch classifier loss: 0.787829; batch adversarial loss: 0.573523\n",
      "epoch 39; iter: 0; batch classifier loss: 0.695400; batch adversarial loss: 0.665415\n",
      "epoch 40; iter: 0; batch classifier loss: 0.729744; batch adversarial loss: 0.636098\n",
      "epoch 41; iter: 0; batch classifier loss: 0.577850; batch adversarial loss: 0.529116\n",
      "epoch 42; iter: 0; batch classifier loss: 0.630534; batch adversarial loss: 0.587385\n",
      "epoch 43; iter: 0; batch classifier loss: 0.493039; batch adversarial loss: 0.557629\n",
      "epoch 44; iter: 0; batch classifier loss: 0.473065; batch adversarial loss: 0.688514\n",
      "epoch 45; iter: 0; batch classifier loss: 0.477265; batch adversarial loss: 0.582966\n",
      "epoch 46; iter: 0; batch classifier loss: 0.427275; batch adversarial loss: 0.562337\n",
      "epoch 47; iter: 0; batch classifier loss: 0.365131; batch adversarial loss: 0.586692\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432595; batch adversarial loss: 0.554800\n",
      "epoch 49; iter: 0; batch classifier loss: 0.409724; batch adversarial loss: 0.551470\n",
      "epoch 50; iter: 0; batch classifier loss: 0.435210; batch adversarial loss: 0.514544\n",
      "epoch 51; iter: 0; batch classifier loss: 0.423632; batch adversarial loss: 0.599348\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421587; batch adversarial loss: 0.524824\n",
      "epoch 53; iter: 0; batch classifier loss: 0.420818; batch adversarial loss: 0.582268\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442918; batch adversarial loss: 0.622750\n",
      "epoch 55; iter: 0; batch classifier loss: 0.486618; batch adversarial loss: 0.528351\n",
      "epoch 56; iter: 0; batch classifier loss: 0.351143; batch adversarial loss: 0.527952\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409117; batch adversarial loss: 0.578023\n",
      "epoch 58; iter: 0; batch classifier loss: 0.392077; batch adversarial loss: 0.545822\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404738; batch adversarial loss: 0.562371\n",
      "epoch 60; iter: 0; batch classifier loss: 0.367023; batch adversarial loss: 0.617392\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404223; batch adversarial loss: 0.610147\n",
      "epoch 62; iter: 0; batch classifier loss: 0.453180; batch adversarial loss: 0.616268\n",
      "epoch 63; iter: 0; batch classifier loss: 0.387143; batch adversarial loss: 0.634718\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449071; batch adversarial loss: 0.580095\n",
      "epoch 65; iter: 0; batch classifier loss: 0.418896; batch adversarial loss: 0.618980\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412096; batch adversarial loss: 0.597328\n",
      "epoch 67; iter: 0; batch classifier loss: 0.340753; batch adversarial loss: 0.537737\n",
      "epoch 68; iter: 0; batch classifier loss: 0.490559; batch adversarial loss: 0.491325\n",
      "epoch 69; iter: 0; batch classifier loss: 0.408538; batch adversarial loss: 0.585815\n",
      "epoch 70; iter: 0; batch classifier loss: 0.360543; batch adversarial loss: 0.616285\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436237; batch adversarial loss: 0.526675\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379965; batch adversarial loss: 0.554609\n",
      "epoch 73; iter: 0; batch classifier loss: 0.282441; batch adversarial loss: 0.566304\n",
      "epoch 74; iter: 0; batch classifier loss: 0.498537; batch adversarial loss: 0.583755\n",
      "epoch 75; iter: 0; batch classifier loss: 0.330674; batch adversarial loss: 0.538148\n",
      "epoch 76; iter: 0; batch classifier loss: 0.385990; batch adversarial loss: 0.561186\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398589; batch adversarial loss: 0.479483\n",
      "epoch 78; iter: 0; batch classifier loss: 0.454582; batch adversarial loss: 0.545244\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388208; batch adversarial loss: 0.599773\n",
      "epoch 80; iter: 0; batch classifier loss: 0.306388; batch adversarial loss: 0.601631\n",
      "epoch 81; iter: 0; batch classifier loss: 0.420330; batch adversarial loss: 0.593779\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377674; batch adversarial loss: 0.525258\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413716; batch adversarial loss: 0.614146\n",
      "epoch 84; iter: 0; batch classifier loss: 0.390497; batch adversarial loss: 0.601176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85; iter: 0; batch classifier loss: 0.280889; batch adversarial loss: 0.600592\n",
      "epoch 86; iter: 0; batch classifier loss: 0.357432; batch adversarial loss: 0.616120\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405134; batch adversarial loss: 0.591495\n",
      "epoch 88; iter: 0; batch classifier loss: 0.445377; batch adversarial loss: 0.486394\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382951; batch adversarial loss: 0.541158\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363741; batch adversarial loss: 0.537414\n",
      "epoch 91; iter: 0; batch classifier loss: 0.376404; batch adversarial loss: 0.604328\n",
      "epoch 92; iter: 0; batch classifier loss: 0.360784; batch adversarial loss: 0.621910\n",
      "epoch 93; iter: 0; batch classifier loss: 0.510758; batch adversarial loss: 0.549827\n",
      "epoch 94; iter: 0; batch classifier loss: 0.392870; batch adversarial loss: 0.496552\n",
      "epoch 95; iter: 0; batch classifier loss: 0.447285; batch adversarial loss: 0.572299\n",
      "epoch 96; iter: 0; batch classifier loss: 0.389982; batch adversarial loss: 0.574967\n",
      "epoch 97; iter: 0; batch classifier loss: 0.446690; batch adversarial loss: 0.638448\n",
      "epoch 98; iter: 0; batch classifier loss: 0.396812; batch adversarial loss: 0.513047\n",
      "epoch 99; iter: 0; batch classifier loss: 0.424446; batch adversarial loss: 0.545315\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.754785; batch adversarial loss: 0.875070\n",
      "epoch 2; iter: 0; batch classifier loss: 0.744287; batch adversarial loss: 0.786744\n",
      "epoch 3; iter: 0; batch classifier loss: 0.560459; batch adversarial loss: 0.747508\n",
      "epoch 4; iter: 0; batch classifier loss: 0.486623; batch adversarial loss: 0.737302\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495148; batch adversarial loss: 0.658758\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598773; batch adversarial loss: 0.670898\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486038; batch adversarial loss: 0.660910\n",
      "epoch 8; iter: 0; batch classifier loss: 0.478640; batch adversarial loss: 0.636634\n",
      "epoch 9; iter: 0; batch classifier loss: 0.456675; batch adversarial loss: 0.657140\n",
      "epoch 10; iter: 0; batch classifier loss: 0.460189; batch adversarial loss: 0.657522\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570795; batch adversarial loss: 0.612918\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547859; batch adversarial loss: 0.622781\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540368; batch adversarial loss: 0.625061\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500978; batch adversarial loss: 0.605773\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529099; batch adversarial loss: 0.585483\n",
      "epoch 16; iter: 0; batch classifier loss: 0.494071; batch adversarial loss: 0.558724\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510116; batch adversarial loss: 0.595329\n",
      "epoch 18; iter: 0; batch classifier loss: 0.472485; batch adversarial loss: 0.540494\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437492; batch adversarial loss: 0.571884\n",
      "epoch 20; iter: 0; batch classifier loss: 0.458165; batch adversarial loss: 0.608039\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497347; batch adversarial loss: 0.581233\n",
      "epoch 22; iter: 0; batch classifier loss: 0.436627; batch adversarial loss: 0.549547\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477566; batch adversarial loss: 0.522236\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402382; batch adversarial loss: 0.516198\n",
      "epoch 25; iter: 0; batch classifier loss: 0.433147; batch adversarial loss: 0.518336\n",
      "epoch 26; iter: 0; batch classifier loss: 0.397833; batch adversarial loss: 0.586706\n",
      "epoch 27; iter: 0; batch classifier loss: 0.459114; batch adversarial loss: 0.621103\n",
      "epoch 28; iter: 0; batch classifier loss: 0.570049; batch adversarial loss: 0.602682\n",
      "epoch 29; iter: 0; batch classifier loss: 0.523955; batch adversarial loss: 0.588769\n",
      "epoch 30; iter: 0; batch classifier loss: 0.521678; batch adversarial loss: 0.608740\n",
      "epoch 31; iter: 0; batch classifier loss: 0.523503; batch adversarial loss: 0.581529\n",
      "epoch 32; iter: 0; batch classifier loss: 0.608565; batch adversarial loss: 0.605941\n",
      "epoch 33; iter: 0; batch classifier loss: 0.693631; batch adversarial loss: 0.651537\n",
      "epoch 34; iter: 0; batch classifier loss: 0.688630; batch adversarial loss: 0.721464\n",
      "epoch 35; iter: 0; batch classifier loss: 0.747778; batch adversarial loss: 0.670570\n",
      "epoch 36; iter: 0; batch classifier loss: 0.732097; batch adversarial loss: 0.645152\n",
      "epoch 37; iter: 0; batch classifier loss: 0.834013; batch adversarial loss: 0.685055\n",
      "epoch 38; iter: 0; batch classifier loss: 0.773863; batch adversarial loss: 0.568210\n",
      "epoch 39; iter: 0; batch classifier loss: 0.671121; batch adversarial loss: 0.658784\n",
      "epoch 40; iter: 0; batch classifier loss: 0.689995; batch adversarial loss: 0.630507\n",
      "epoch 41; iter: 0; batch classifier loss: 0.557975; batch adversarial loss: 0.526152\n",
      "epoch 42; iter: 0; batch classifier loss: 0.514152; batch adversarial loss: 0.586193\n",
      "epoch 43; iter: 0; batch classifier loss: 0.509501; batch adversarial loss: 0.557452\n",
      "epoch 44; iter: 0; batch classifier loss: 0.460979; batch adversarial loss: 0.689415\n",
      "epoch 45; iter: 0; batch classifier loss: 0.471691; batch adversarial loss: 0.582930\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436649; batch adversarial loss: 0.562351\n",
      "epoch 47; iter: 0; batch classifier loss: 0.363793; batch adversarial loss: 0.586901\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427074; batch adversarial loss: 0.554994\n",
      "epoch 49; iter: 0; batch classifier loss: 0.405961; batch adversarial loss: 0.551213\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442486; batch adversarial loss: 0.514439\n",
      "epoch 51; iter: 0; batch classifier loss: 0.425203; batch adversarial loss: 0.599731\n",
      "epoch 52; iter: 0; batch classifier loss: 0.422288; batch adversarial loss: 0.524725\n",
      "epoch 53; iter: 0; batch classifier loss: 0.417439; batch adversarial loss: 0.582309\n",
      "epoch 54; iter: 0; batch classifier loss: 0.442899; batch adversarial loss: 0.622988\n",
      "epoch 55; iter: 0; batch classifier loss: 0.486846; batch adversarial loss: 0.528245\n",
      "epoch 56; iter: 0; batch classifier loss: 0.347448; batch adversarial loss: 0.527792\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405740; batch adversarial loss: 0.578206\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398337; batch adversarial loss: 0.545326\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409431; batch adversarial loss: 0.562284\n",
      "epoch 60; iter: 0; batch classifier loss: 0.376231; batch adversarial loss: 0.617503\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410343; batch adversarial loss: 0.610839\n",
      "epoch 62; iter: 0; batch classifier loss: 0.453311; batch adversarial loss: 0.615593\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392409; batch adversarial loss: 0.634228\n",
      "epoch 64; iter: 0; batch classifier loss: 0.462612; batch adversarial loss: 0.580880\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419646; batch adversarial loss: 0.619368\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412326; batch adversarial loss: 0.597114\n",
      "epoch 67; iter: 0; batch classifier loss: 0.340414; batch adversarial loss: 0.537246\n",
      "epoch 68; iter: 0; batch classifier loss: 0.492874; batch adversarial loss: 0.491604\n",
      "epoch 69; iter: 0; batch classifier loss: 0.408096; batch adversarial loss: 0.586031\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359161; batch adversarial loss: 0.615385\n",
      "epoch 71; iter: 0; batch classifier loss: 0.424900; batch adversarial loss: 0.526519\n",
      "epoch 72; iter: 0; batch classifier loss: 0.383773; batch adversarial loss: 0.554978\n",
      "epoch 73; iter: 0; batch classifier loss: 0.288271; batch adversarial loss: 0.566634\n",
      "epoch 74; iter: 0; batch classifier loss: 0.494721; batch adversarial loss: 0.582661\n",
      "epoch 75; iter: 0; batch classifier loss: 0.330377; batch adversarial loss: 0.537947\n",
      "epoch 76; iter: 0; batch classifier loss: 0.395591; batch adversarial loss: 0.561830\n",
      "epoch 77; iter: 0; batch classifier loss: 0.386255; batch adversarial loss: 0.478153\n",
      "epoch 78; iter: 0; batch classifier loss: 0.458278; batch adversarial loss: 0.544613\n",
      "epoch 79; iter: 0; batch classifier loss: 0.383684; batch adversarial loss: 0.598566\n",
      "epoch 80; iter: 0; batch classifier loss: 0.306591; batch adversarial loss: 0.601782\n",
      "epoch 81; iter: 0; batch classifier loss: 0.412413; batch adversarial loss: 0.592462\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381396; batch adversarial loss: 0.525382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.410053; batch adversarial loss: 0.613906\n",
      "epoch 84; iter: 0; batch classifier loss: 0.404964; batch adversarial loss: 0.601419\n",
      "epoch 85; iter: 0; batch classifier loss: 0.279319; batch adversarial loss: 0.600445\n",
      "epoch 86; iter: 0; batch classifier loss: 0.343317; batch adversarial loss: 0.615268\n",
      "epoch 87; iter: 0; batch classifier loss: 0.390197; batch adversarial loss: 0.591927\n",
      "epoch 88; iter: 0; batch classifier loss: 0.464663; batch adversarial loss: 0.488398\n",
      "epoch 89; iter: 0; batch classifier loss: 0.373594; batch adversarial loss: 0.539842\n",
      "epoch 90; iter: 0; batch classifier loss: 0.368886; batch adversarial loss: 0.537482\n",
      "epoch 91; iter: 0; batch classifier loss: 0.369976; batch adversarial loss: 0.603104\n",
      "epoch 92; iter: 0; batch classifier loss: 0.367918; batch adversarial loss: 0.621260\n",
      "epoch 93; iter: 0; batch classifier loss: 0.505834; batch adversarial loss: 0.548532\n",
      "epoch 94; iter: 0; batch classifier loss: 0.382170; batch adversarial loss: 0.496237\n",
      "epoch 95; iter: 0; batch classifier loss: 0.446135; batch adversarial loss: 0.572410\n",
      "epoch 96; iter: 0; batch classifier loss: 0.379799; batch adversarial loss: 0.574737\n",
      "epoch 97; iter: 0; batch classifier loss: 0.448661; batch adversarial loss: 0.639312\n",
      "epoch 98; iter: 0; batch classifier loss: 0.392522; batch adversarial loss: 0.512036\n",
      "epoch 99; iter: 0; batch classifier loss: 0.429560; batch adversarial loss: 0.546955\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.766787; batch adversarial loss: 0.879383\n",
      "epoch 2; iter: 0; batch classifier loss: 0.756419; batch adversarial loss: 0.789369\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572646; batch adversarial loss: 0.750235\n",
      "epoch 4; iter: 0; batch classifier loss: 0.493129; batch adversarial loss: 0.741097\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495728; batch adversarial loss: 0.659461\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596627; batch adversarial loss: 0.671614\n",
      "epoch 7; iter: 0; batch classifier loss: 0.484769; batch adversarial loss: 0.661313\n",
      "epoch 8; iter: 0; batch classifier loss: 0.477173; batch adversarial loss: 0.637110\n",
      "epoch 9; iter: 0; batch classifier loss: 0.453961; batch adversarial loss: 0.657918\n",
      "epoch 10; iter: 0; batch classifier loss: 0.458009; batch adversarial loss: 0.657899\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569421; batch adversarial loss: 0.613275\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545819; batch adversarial loss: 0.623187\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539786; batch adversarial loss: 0.625161\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500628; batch adversarial loss: 0.605870\n",
      "epoch 15; iter: 0; batch classifier loss: 0.528558; batch adversarial loss: 0.585869\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493042; batch adversarial loss: 0.559517\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510455; batch adversarial loss: 0.596320\n",
      "epoch 18; iter: 0; batch classifier loss: 0.470394; batch adversarial loss: 0.542832\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437606; batch adversarial loss: 0.573155\n",
      "epoch 20; iter: 0; batch classifier loss: 0.459841; batch adversarial loss: 0.609255\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497205; batch adversarial loss: 0.582178\n",
      "epoch 22; iter: 0; batch classifier loss: 0.436445; batch adversarial loss: 0.551196\n",
      "epoch 23; iter: 0; batch classifier loss: 0.478303; batch adversarial loss: 0.523917\n",
      "epoch 24; iter: 0; batch classifier loss: 0.401315; batch adversarial loss: 0.517433\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432165; batch adversarial loss: 0.519940\n",
      "epoch 26; iter: 0; batch classifier loss: 0.400517; batch adversarial loss: 0.590508\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474502; batch adversarial loss: 0.634168\n",
      "epoch 28; iter: 0; batch classifier loss: 0.589050; batch adversarial loss: 0.610901\n",
      "epoch 29; iter: 0; batch classifier loss: 0.537947; batch adversarial loss: 0.596100\n",
      "epoch 30; iter: 0; batch classifier loss: 0.540218; batch adversarial loss: 0.615812\n",
      "epoch 31; iter: 0; batch classifier loss: 0.539448; batch adversarial loss: 0.586635\n",
      "epoch 32; iter: 0; batch classifier loss: 0.639560; batch adversarial loss: 0.615691\n",
      "epoch 33; iter: 0; batch classifier loss: 0.755540; batch adversarial loss: 0.659099\n",
      "epoch 34; iter: 0; batch classifier loss: 0.716991; batch adversarial loss: 0.714456\n",
      "epoch 35; iter: 0; batch classifier loss: 0.741573; batch adversarial loss: 0.658468\n",
      "epoch 36; iter: 0; batch classifier loss: 0.712634; batch adversarial loss: 0.634943\n",
      "epoch 37; iter: 0; batch classifier loss: 0.794206; batch adversarial loss: 0.672911\n",
      "epoch 38; iter: 0; batch classifier loss: 0.746412; batch adversarial loss: 0.562131\n",
      "epoch 39; iter: 0; batch classifier loss: 0.634836; batch adversarial loss: 0.652334\n",
      "epoch 40; iter: 0; batch classifier loss: 0.644811; batch adversarial loss: 0.625565\n",
      "epoch 41; iter: 0; batch classifier loss: 0.534218; batch adversarial loss: 0.523537\n",
      "epoch 42; iter: 0; batch classifier loss: 0.437744; batch adversarial loss: 0.585848\n",
      "epoch 43; iter: 0; batch classifier loss: 0.518737; batch adversarial loss: 0.557051\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461455; batch adversarial loss: 0.690385\n",
      "epoch 45; iter: 0; batch classifier loss: 0.476571; batch adversarial loss: 0.583051\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436511; batch adversarial loss: 0.562458\n",
      "epoch 47; iter: 0; batch classifier loss: 0.365629; batch adversarial loss: 0.587030\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426609; batch adversarial loss: 0.554742\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406716; batch adversarial loss: 0.551140\n",
      "epoch 50; iter: 0; batch classifier loss: 0.440928; batch adversarial loss: 0.514156\n",
      "epoch 51; iter: 0; batch classifier loss: 0.423929; batch adversarial loss: 0.599825\n",
      "epoch 52; iter: 0; batch classifier loss: 0.420976; batch adversarial loss: 0.524579\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413358; batch adversarial loss: 0.581945\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434881; batch adversarial loss: 0.623188\n",
      "epoch 55; iter: 0; batch classifier loss: 0.489200; batch adversarial loss: 0.528060\n",
      "epoch 56; iter: 0; batch classifier loss: 0.346232; batch adversarial loss: 0.527892\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401329; batch adversarial loss: 0.578351\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396840; batch adversarial loss: 0.545493\n",
      "epoch 59; iter: 0; batch classifier loss: 0.413077; batch adversarial loss: 0.562374\n",
      "epoch 60; iter: 0; batch classifier loss: 0.378118; batch adversarial loss: 0.617863\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407695; batch adversarial loss: 0.610680\n",
      "epoch 62; iter: 0; batch classifier loss: 0.455983; batch adversarial loss: 0.615963\n",
      "epoch 63; iter: 0; batch classifier loss: 0.389932; batch adversarial loss: 0.634302\n",
      "epoch 64; iter: 0; batch classifier loss: 0.457516; batch adversarial loss: 0.581015\n",
      "epoch 65; iter: 0; batch classifier loss: 0.429094; batch adversarial loss: 0.619655\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412017; batch adversarial loss: 0.597192\n",
      "epoch 67; iter: 0; batch classifier loss: 0.339798; batch adversarial loss: 0.537998\n",
      "epoch 68; iter: 0; batch classifier loss: 0.490653; batch adversarial loss: 0.491348\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410162; batch adversarial loss: 0.586858\n",
      "epoch 70; iter: 0; batch classifier loss: 0.354843; batch adversarial loss: 0.616454\n",
      "epoch 71; iter: 0; batch classifier loss: 0.440501; batch adversarial loss: 0.528066\n",
      "epoch 72; iter: 0; batch classifier loss: 0.382871; batch adversarial loss: 0.555840\n",
      "epoch 73; iter: 0; batch classifier loss: 0.299861; batch adversarial loss: 0.567228\n",
      "epoch 74; iter: 0; batch classifier loss: 0.502774; batch adversarial loss: 0.583174\n",
      "epoch 75; iter: 0; batch classifier loss: 0.328623; batch adversarial loss: 0.538140\n",
      "epoch 76; iter: 0; batch classifier loss: 0.394573; batch adversarial loss: 0.562500\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389275; batch adversarial loss: 0.478495\n",
      "epoch 78; iter: 0; batch classifier loss: 0.460867; batch adversarial loss: 0.544915\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384257; batch adversarial loss: 0.600841\n",
      "epoch 80; iter: 0; batch classifier loss: 0.309484; batch adversarial loss: 0.602553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.428931; batch adversarial loss: 0.594676\n",
      "epoch 82; iter: 0; batch classifier loss: 0.402525; batch adversarial loss: 0.527607\n",
      "epoch 83; iter: 0; batch classifier loss: 0.425826; batch adversarial loss: 0.616617\n",
      "epoch 84; iter: 0; batch classifier loss: 0.413517; batch adversarial loss: 0.602539\n",
      "epoch 85; iter: 0; batch classifier loss: 0.287124; batch adversarial loss: 0.601729\n",
      "epoch 86; iter: 0; batch classifier loss: 0.380869; batch adversarial loss: 0.619977\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376173; batch adversarial loss: 0.592016\n",
      "epoch 88; iter: 0; batch classifier loss: 0.465856; batch adversarial loss: 0.489215\n",
      "epoch 89; iter: 0; batch classifier loss: 0.377598; batch adversarial loss: 0.541379\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384033; batch adversarial loss: 0.538924\n",
      "epoch 91; iter: 0; batch classifier loss: 0.375853; batch adversarial loss: 0.604703\n",
      "epoch 92; iter: 0; batch classifier loss: 0.389150; batch adversarial loss: 0.626411\n",
      "epoch 93; iter: 0; batch classifier loss: 0.515414; batch adversarial loss: 0.550170\n",
      "epoch 94; iter: 0; batch classifier loss: 0.409821; batch adversarial loss: 0.498503\n",
      "epoch 95; iter: 0; batch classifier loss: 0.468835; batch adversarial loss: 0.574937\n",
      "epoch 96; iter: 0; batch classifier loss: 0.391391; batch adversarial loss: 0.574751\n",
      "epoch 97; iter: 0; batch classifier loss: 0.450508; batch adversarial loss: 0.641178\n",
      "epoch 98; iter: 0; batch classifier loss: 0.409793; batch adversarial loss: 0.514194\n",
      "epoch 99; iter: 0; batch classifier loss: 0.419419; batch adversarial loss: 0.547491\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709988; batch adversarial loss: 0.791750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.734602; batch adversarial loss: 0.890248\n",
      "epoch 2; iter: 0; batch classifier loss: 0.697835; batch adversarial loss: 0.791674\n",
      "epoch 3; iter: 0; batch classifier loss: 0.503516; batch adversarial loss: 0.754536\n",
      "epoch 4; iter: 0; batch classifier loss: 0.474508; batch adversarial loss: 0.743717\n",
      "epoch 5; iter: 0; batch classifier loss: 0.480418; batch adversarial loss: 0.660900\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553401; batch adversarial loss: 0.682192\n",
      "epoch 7; iter: 0; batch classifier loss: 0.477956; batch adversarial loss: 0.663949\n",
      "epoch 8; iter: 0; batch classifier loss: 0.464880; batch adversarial loss: 0.640828\n",
      "epoch 9; iter: 0; batch classifier loss: 0.457260; batch adversarial loss: 0.659919\n",
      "epoch 10; iter: 0; batch classifier loss: 0.454077; batch adversarial loss: 0.660518\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567860; batch adversarial loss: 0.614339\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539528; batch adversarial loss: 0.623650\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511396; batch adversarial loss: 0.628999\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487071; batch adversarial loss: 0.610912\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498107; batch adversarial loss: 0.592099\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476434; batch adversarial loss: 0.565840\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491604; batch adversarial loss: 0.598265\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471884; batch adversarial loss: 0.539102\n",
      "epoch 19; iter: 0; batch classifier loss: 0.404169; batch adversarial loss: 0.577835\n",
      "epoch 20; iter: 0; batch classifier loss: 0.423475; batch adversarial loss: 0.613088\n",
      "epoch 21; iter: 0; batch classifier loss: 0.474949; batch adversarial loss: 0.579014\n",
      "epoch 22; iter: 0; batch classifier loss: 0.410028; batch adversarial loss: 0.545053\n",
      "epoch 23; iter: 0; batch classifier loss: 0.458996; batch adversarial loss: 0.521171\n",
      "epoch 24; iter: 0; batch classifier loss: 0.401598; batch adversarial loss: 0.515849\n",
      "epoch 25; iter: 0; batch classifier loss: 0.415337; batch adversarial loss: 0.523552\n",
      "epoch 26; iter: 0; batch classifier loss: 0.376120; batch adversarial loss: 0.594433\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457995; batch adversarial loss: 0.639200\n",
      "epoch 28; iter: 0; batch classifier loss: 0.515980; batch adversarial loss: 0.600029\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480915; batch adversarial loss: 0.598653\n",
      "epoch 30; iter: 0; batch classifier loss: 0.485991; batch adversarial loss: 0.611480\n",
      "epoch 31; iter: 0; batch classifier loss: 0.538082; batch adversarial loss: 0.598328\n",
      "epoch 32; iter: 0; batch classifier loss: 0.576119; batch adversarial loss: 0.601451\n",
      "epoch 33; iter: 0; batch classifier loss: 0.645006; batch adversarial loss: 0.644722\n",
      "epoch 34; iter: 0; batch classifier loss: 0.666643; batch adversarial loss: 0.715726\n",
      "epoch 35; iter: 0; batch classifier loss: 0.661710; batch adversarial loss: 0.655984\n",
      "epoch 36; iter: 0; batch classifier loss: 0.612468; batch adversarial loss: 0.628382\n",
      "epoch 37; iter: 0; batch classifier loss: 0.722982; batch adversarial loss: 0.678283\n",
      "epoch 38; iter: 0; batch classifier loss: 0.727047; batch adversarial loss: 0.567472\n",
      "epoch 39; iter: 0; batch classifier loss: 0.639572; batch adversarial loss: 0.657930\n",
      "epoch 40; iter: 0; batch classifier loss: 0.659128; batch adversarial loss: 0.630343\n",
      "epoch 41; iter: 0; batch classifier loss: 0.538559; batch adversarial loss: 0.524701\n",
      "epoch 42; iter: 0; batch classifier loss: 0.390606; batch adversarial loss: 0.585528\n",
      "epoch 43; iter: 0; batch classifier loss: 0.431316; batch adversarial loss: 0.555616\n",
      "epoch 44; iter: 0; batch classifier loss: 0.383561; batch adversarial loss: 0.689628\n",
      "epoch 45; iter: 0; batch classifier loss: 0.391927; batch adversarial loss: 0.582551\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388325; batch adversarial loss: 0.562868\n",
      "epoch 47; iter: 0; batch classifier loss: 0.308419; batch adversarial loss: 0.585628\n",
      "epoch 48; iter: 0; batch classifier loss: 0.379719; batch adversarial loss: 0.555517\n",
      "epoch 49; iter: 0; batch classifier loss: 0.351570; batch adversarial loss: 0.549893\n",
      "epoch 50; iter: 0; batch classifier loss: 0.348265; batch adversarial loss: 0.512280\n",
      "epoch 51; iter: 0; batch classifier loss: 0.358392; batch adversarial loss: 0.598272\n",
      "epoch 52; iter: 0; batch classifier loss: 0.397024; batch adversarial loss: 0.526202\n",
      "epoch 53; iter: 0; batch classifier loss: 0.347012; batch adversarial loss: 0.585546\n",
      "epoch 54; iter: 0; batch classifier loss: 0.394006; batch adversarial loss: 0.626066\n",
      "epoch 55; iter: 0; batch classifier loss: 0.436478; batch adversarial loss: 0.528631\n",
      "epoch 56; iter: 0; batch classifier loss: 0.293662; batch adversarial loss: 0.526917\n",
      "epoch 57; iter: 0; batch classifier loss: 0.356262; batch adversarial loss: 0.577955\n",
      "epoch 58; iter: 0; batch classifier loss: 0.321285; batch adversarial loss: 0.547313\n",
      "epoch 59; iter: 0; batch classifier loss: 0.378511; batch adversarial loss: 0.564865\n",
      "epoch 60; iter: 0; batch classifier loss: 0.264774; batch adversarial loss: 0.615895\n",
      "epoch 61; iter: 0; batch classifier loss: 0.410567; batch adversarial loss: 0.615135\n",
      "epoch 62; iter: 0; batch classifier loss: 0.443317; batch adversarial loss: 0.621837\n",
      "epoch 63; iter: 0; batch classifier loss: 0.356817; batch adversarial loss: 0.637488\n",
      "epoch 64; iter: 0; batch classifier loss: 0.455441; batch adversarial loss: 0.585110\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386038; batch adversarial loss: 0.620632\n",
      "epoch 66; iter: 0; batch classifier loss: 0.463693; batch adversarial loss: 0.604642\n",
      "epoch 67; iter: 0; batch classifier loss: 0.297189; batch adversarial loss: 0.538835\n",
      "epoch 68; iter: 0; batch classifier loss: 0.500482; batch adversarial loss: 0.498180\n",
      "epoch 69; iter: 0; batch classifier loss: 0.366179; batch adversarial loss: 0.588832\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414958; batch adversarial loss: 0.626434\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410880; batch adversarial loss: 0.531264\n",
      "epoch 72; iter: 0; batch classifier loss: 0.397705; batch adversarial loss: 0.563907\n",
      "epoch 73; iter: 0; batch classifier loss: 0.300908; batch adversarial loss: 0.571329\n",
      "epoch 74; iter: 0; batch classifier loss: 0.447625; batch adversarial loss: 0.591733\n",
      "epoch 75; iter: 0; batch classifier loss: 0.334377; batch adversarial loss: 0.545579\n",
      "epoch 76; iter: 0; batch classifier loss: 0.465889; batch adversarial loss: 0.572987\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383382; batch adversarial loss: 0.483836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.440793; batch adversarial loss: 0.549803\n",
      "epoch 79; iter: 0; batch classifier loss: 0.420011; batch adversarial loss: 0.610344\n",
      "epoch 80; iter: 0; batch classifier loss: 0.378150; batch adversarial loss: 0.612372\n",
      "epoch 81; iter: 0; batch classifier loss: 0.429582; batch adversarial loss: 0.597942\n",
      "epoch 82; iter: 0; batch classifier loss: 0.448874; batch adversarial loss: 0.533353\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420942; batch adversarial loss: 0.625268\n",
      "epoch 84; iter: 0; batch classifier loss: 0.498527; batch adversarial loss: 0.611900\n",
      "epoch 85; iter: 0; batch classifier loss: 0.369305; batch adversarial loss: 0.612140\n",
      "epoch 86; iter: 0; batch classifier loss: 0.429835; batch adversarial loss: 0.626217\n",
      "epoch 87; iter: 0; batch classifier loss: 0.423867; batch adversarial loss: 0.604000\n",
      "epoch 88; iter: 0; batch classifier loss: 0.532540; batch adversarial loss: 0.500312\n",
      "epoch 89; iter: 0; batch classifier loss: 0.405092; batch adversarial loss: 0.550536\n",
      "epoch 90; iter: 0; batch classifier loss: 0.449179; batch adversarial loss: 0.547931\n",
      "epoch 91; iter: 0; batch classifier loss: 0.427391; batch adversarial loss: 0.617343\n",
      "epoch 92; iter: 0; batch classifier loss: 0.413723; batch adversarial loss: 0.632016\n",
      "epoch 93; iter: 0; batch classifier loss: 0.574044; batch adversarial loss: 0.560771\n",
      "epoch 94; iter: 0; batch classifier loss: 0.452705; batch adversarial loss: 0.506725\n",
      "epoch 95; iter: 0; batch classifier loss: 0.508997; batch adversarial loss: 0.587332\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414705; batch adversarial loss: 0.573142\n",
      "epoch 97; iter: 0; batch classifier loss: 0.488934; batch adversarial loss: 0.645156\n",
      "epoch 98; iter: 0; batch classifier loss: 0.482222; batch adversarial loss: 0.523658\n",
      "epoch 99; iter: 0; batch classifier loss: 0.459319; batch adversarial loss: 0.553297\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.807163; batch adversarial loss: 0.891207\n",
      "epoch 2; iter: 0; batch classifier loss: 0.797728; batch adversarial loss: 0.796409\n",
      "epoch 3; iter: 0; batch classifier loss: 0.616093; batch adversarial loss: 0.758456\n",
      "epoch 4; iter: 0; batch classifier loss: 0.519619; batch adversarial loss: 0.751006\n",
      "epoch 5; iter: 0; batch classifier loss: 0.502566; batch adversarial loss: 0.661545\n",
      "epoch 6; iter: 0; batch classifier loss: 0.589123; batch adversarial loss: 0.673840\n",
      "epoch 7; iter: 0; batch classifier loss: 0.480170; batch adversarial loss: 0.662698\n",
      "epoch 8; iter: 0; batch classifier loss: 0.473845; batch adversarial loss: 0.638244\n",
      "epoch 9; iter: 0; batch classifier loss: 0.447374; batch adversarial loss: 0.659985\n",
      "epoch 10; iter: 0; batch classifier loss: 0.452905; batch adversarial loss: 0.658906\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562912; batch adversarial loss: 0.614789\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542868; batch adversarial loss: 0.623530\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536639; batch adversarial loss: 0.625548\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499041; batch adversarial loss: 0.605872\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523361; batch adversarial loss: 0.587132\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487824; batch adversarial loss: 0.561941\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509559; batch adversarial loss: 0.600233\n",
      "epoch 18; iter: 0; batch classifier loss: 0.468778; batch adversarial loss: 0.548606\n",
      "epoch 19; iter: 0; batch classifier loss: 0.434434; batch adversarial loss: 0.577381\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462956; batch adversarial loss: 0.612479\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494714; batch adversarial loss: 0.585181\n",
      "epoch 22; iter: 0; batch classifier loss: 0.436325; batch adversarial loss: 0.556188\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484319; batch adversarial loss: 0.529411\n",
      "epoch 24; iter: 0; batch classifier loss: 0.403378; batch adversarial loss: 0.522130\n",
      "epoch 25; iter: 0; batch classifier loss: 0.437127; batch adversarial loss: 0.525935\n",
      "epoch 26; iter: 0; batch classifier loss: 0.422936; batch adversarial loss: 0.608585\n",
      "epoch 27; iter: 0; batch classifier loss: 0.555364; batch adversarial loss: 0.675714\n",
      "epoch 28; iter: 0; batch classifier loss: 0.623180; batch adversarial loss: 0.623598\n",
      "epoch 29; iter: 0; batch classifier loss: 0.592267; batch adversarial loss: 0.617391\n",
      "epoch 30; iter: 0; batch classifier loss: 0.630484; batch adversarial loss: 0.636434\n",
      "epoch 31; iter: 0; batch classifier loss: 0.729390; batch adversarial loss: 0.627500\n",
      "epoch 32; iter: 0; batch classifier loss: 0.858278; batch adversarial loss: 0.637621\n",
      "epoch 33; iter: 0; batch classifier loss: 0.811194; batch adversarial loss: 0.637056\n",
      "epoch 34; iter: 0; batch classifier loss: 0.715341; batch adversarial loss: 0.678186\n",
      "epoch 35; iter: 0; batch classifier loss: 0.659231; batch adversarial loss: 0.622363\n",
      "epoch 36; iter: 0; batch classifier loss: 0.624176; batch adversarial loss: 0.607478\n",
      "epoch 37; iter: 0; batch classifier loss: 0.649012; batch adversarial loss: 0.647015\n",
      "epoch 38; iter: 0; batch classifier loss: 0.614287; batch adversarial loss: 0.549271\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483959; batch adversarial loss: 0.640491\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484712; batch adversarial loss: 0.618902\n",
      "epoch 41; iter: 0; batch classifier loss: 0.443479; batch adversarial loss: 0.519495\n",
      "epoch 42; iter: 0; batch classifier loss: 0.476548; batch adversarial loss: 0.587519\n",
      "epoch 43; iter: 0; batch classifier loss: 0.615797; batch adversarial loss: 0.557576\n",
      "epoch 44; iter: 0; batch classifier loss: 0.479718; batch adversarial loss: 0.692350\n",
      "epoch 45; iter: 0; batch classifier loss: 0.466735; batch adversarial loss: 0.582816\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429288; batch adversarial loss: 0.561859\n",
      "epoch 47; iter: 0; batch classifier loss: 0.350563; batch adversarial loss: 0.586896\n",
      "epoch 48; iter: 0; batch classifier loss: 0.419611; batch adversarial loss: 0.553874\n",
      "epoch 49; iter: 0; batch classifier loss: 0.395969; batch adversarial loss: 0.550651\n",
      "epoch 50; iter: 0; batch classifier loss: 0.444671; batch adversarial loss: 0.513726\n",
      "epoch 51; iter: 0; batch classifier loss: 0.420644; batch adversarial loss: 0.600015\n",
      "epoch 52; iter: 0; batch classifier loss: 0.422611; batch adversarial loss: 0.524286\n",
      "epoch 53; iter: 0; batch classifier loss: 0.405993; batch adversarial loss: 0.582458\n",
      "epoch 54; iter: 0; batch classifier loss: 0.432715; batch adversarial loss: 0.623725\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487158; batch adversarial loss: 0.528024\n",
      "epoch 56; iter: 0; batch classifier loss: 0.350282; batch adversarial loss: 0.527388\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407171; batch adversarial loss: 0.578736\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395939; batch adversarial loss: 0.545347\n",
      "epoch 59; iter: 0; batch classifier loss: 0.418193; batch adversarial loss: 0.562970\n",
      "epoch 60; iter: 0; batch classifier loss: 0.377456; batch adversarial loss: 0.618049\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403441; batch adversarial loss: 0.611143\n",
      "epoch 62; iter: 0; batch classifier loss: 0.459573; batch adversarial loss: 0.616230\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392448; batch adversarial loss: 0.634173\n",
      "epoch 64; iter: 0; batch classifier loss: 0.466635; batch adversarial loss: 0.582116\n",
      "epoch 65; iter: 0; batch classifier loss: 0.430436; batch adversarial loss: 0.619941\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415460; batch adversarial loss: 0.597837\n",
      "epoch 67; iter: 0; batch classifier loss: 0.352817; batch adversarial loss: 0.538641\n",
      "epoch 68; iter: 0; batch classifier loss: 0.497576; batch adversarial loss: 0.491831\n",
      "epoch 69; iter: 0; batch classifier loss: 0.414420; batch adversarial loss: 0.587132\n",
      "epoch 70; iter: 0; batch classifier loss: 0.356695; batch adversarial loss: 0.617237\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436149; batch adversarial loss: 0.528458\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379285; batch adversarial loss: 0.555840\n",
      "epoch 73; iter: 0; batch classifier loss: 0.301347; batch adversarial loss: 0.567390\n",
      "epoch 74; iter: 0; batch classifier loss: 0.507250; batch adversarial loss: 0.584709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.330737; batch adversarial loss: 0.538535\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390209; batch adversarial loss: 0.562743\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398794; batch adversarial loss: 0.479068\n",
      "epoch 78; iter: 0; batch classifier loss: 0.477237; batch adversarial loss: 0.546779\n",
      "epoch 79; iter: 0; batch classifier loss: 0.395397; batch adversarial loss: 0.602422\n",
      "epoch 80; iter: 0; batch classifier loss: 0.320766; batch adversarial loss: 0.604177\n",
      "epoch 81; iter: 0; batch classifier loss: 0.445362; batch adversarial loss: 0.597763\n",
      "epoch 82; iter: 0; batch classifier loss: 0.419254; batch adversarial loss: 0.528984\n",
      "epoch 83; iter: 0; batch classifier loss: 0.430470; batch adversarial loss: 0.617142\n",
      "epoch 84; iter: 0; batch classifier loss: 0.410410; batch adversarial loss: 0.603179\n",
      "epoch 85; iter: 0; batch classifier loss: 0.306749; batch adversarial loss: 0.604084\n",
      "epoch 86; iter: 0; batch classifier loss: 0.401819; batch adversarial loss: 0.620551\n",
      "epoch 87; iter: 0; batch classifier loss: 0.397099; batch adversarial loss: 0.594795\n",
      "epoch 88; iter: 0; batch classifier loss: 0.490490; batch adversarial loss: 0.491782\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385708; batch adversarial loss: 0.541783\n",
      "epoch 90; iter: 0; batch classifier loss: 0.403935; batch adversarial loss: 0.541097\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380475; batch adversarial loss: 0.606134\n",
      "epoch 92; iter: 0; batch classifier loss: 0.400702; batch adversarial loss: 0.627709\n",
      "epoch 93; iter: 0; batch classifier loss: 0.534780; batch adversarial loss: 0.551011\n",
      "epoch 94; iter: 0; batch classifier loss: 0.429016; batch adversarial loss: 0.501503\n",
      "epoch 95; iter: 0; batch classifier loss: 0.493849; batch adversarial loss: 0.578704\n",
      "epoch 96; iter: 0; batch classifier loss: 0.400098; batch adversarial loss: 0.574677\n",
      "epoch 97; iter: 0; batch classifier loss: 0.455270; batch adversarial loss: 0.641622\n",
      "epoch 98; iter: 0; batch classifier loss: 0.402577; batch adversarial loss: 0.513977\n",
      "epoch 99; iter: 0; batch classifier loss: 0.440308; batch adversarial loss: 0.547278\n",
      "epoch 100; iter: 0; batch classifier loss: 0.516184; batch adversarial loss: 0.576676\n",
      "epoch 101; iter: 0; batch classifier loss: 0.411193; batch adversarial loss: 0.623578\n",
      "epoch 102; iter: 0; batch classifier loss: 0.598207; batch adversarial loss: 0.536584\n",
      "epoch 103; iter: 0; batch classifier loss: 0.537702; batch adversarial loss: 0.560980\n",
      "epoch 104; iter: 0; batch classifier loss: 0.413733; batch adversarial loss: 0.538185\n",
      "epoch 105; iter: 0; batch classifier loss: 0.464531; batch adversarial loss: 0.644275\n",
      "epoch 106; iter: 0; batch classifier loss: 0.417222; batch adversarial loss: 0.640219\n",
      "epoch 107; iter: 0; batch classifier loss: 0.536324; batch adversarial loss: 0.565516\n",
      "epoch 108; iter: 0; batch classifier loss: 0.421324; batch adversarial loss: 0.578714\n",
      "epoch 109; iter: 0; batch classifier loss: 0.543327; batch adversarial loss: 0.492997\n",
      "epoch 110; iter: 0; batch classifier loss: 0.535209; batch adversarial loss: 0.520716\n",
      "epoch 111; iter: 0; batch classifier loss: 0.414380; batch adversarial loss: 0.588952\n",
      "epoch 112; iter: 0; batch classifier loss: 0.510655; batch adversarial loss: 0.550647\n",
      "epoch 113; iter: 0; batch classifier loss: 0.517016; batch adversarial loss: 0.555792\n",
      "epoch 114; iter: 0; batch classifier loss: 0.481319; batch adversarial loss: 0.586280\n",
      "epoch 115; iter: 0; batch classifier loss: 0.434191; batch adversarial loss: 0.512516\n",
      "epoch 116; iter: 0; batch classifier loss: 0.490770; batch adversarial loss: 0.552469\n",
      "epoch 117; iter: 0; batch classifier loss: 0.402860; batch adversarial loss: 0.597611\n",
      "epoch 118; iter: 0; batch classifier loss: 0.452649; batch adversarial loss: 0.578571\n",
      "epoch 119; iter: 0; batch classifier loss: 0.424177; batch adversarial loss: 0.600652\n",
      "epoch 120; iter: 0; batch classifier loss: 0.376019; batch adversarial loss: 0.581911\n",
      "epoch 121; iter: 0; batch classifier loss: 0.585513; batch adversarial loss: 0.631349\n",
      "epoch 122; iter: 0; batch classifier loss: 0.629435; batch adversarial loss: 0.567246\n",
      "epoch 123; iter: 0; batch classifier loss: 0.606580; batch adversarial loss: 0.600143\n",
      "epoch 124; iter: 0; batch classifier loss: 0.487582; batch adversarial loss: 0.550679\n",
      "epoch 125; iter: 0; batch classifier loss: 0.500831; batch adversarial loss: 0.608230\n",
      "epoch 126; iter: 0; batch classifier loss: 0.581378; batch adversarial loss: 0.567397\n",
      "epoch 127; iter: 0; batch classifier loss: 0.473510; batch adversarial loss: 0.517978\n",
      "epoch 128; iter: 0; batch classifier loss: 0.422777; batch adversarial loss: 0.601462\n",
      "epoch 129; iter: 0; batch classifier loss: 0.461071; batch adversarial loss: 0.633643\n",
      "epoch 130; iter: 0; batch classifier loss: 0.527133; batch adversarial loss: 0.559289\n",
      "epoch 131; iter: 0; batch classifier loss: 0.428413; batch adversarial loss: 0.596081\n",
      "epoch 132; iter: 0; batch classifier loss: 0.549118; batch adversarial loss: 0.544610\n",
      "epoch 133; iter: 0; batch classifier loss: 0.467057; batch adversarial loss: 0.620407\n",
      "epoch 134; iter: 0; batch classifier loss: 0.432771; batch adversarial loss: 0.556229\n",
      "epoch 135; iter: 0; batch classifier loss: 0.541427; batch adversarial loss: 0.629307\n",
      "epoch 136; iter: 0; batch classifier loss: 0.499432; batch adversarial loss: 0.562326\n",
      "epoch 137; iter: 0; batch classifier loss: 0.389604; batch adversarial loss: 0.642817\n",
      "epoch 138; iter: 0; batch classifier loss: 0.473143; batch adversarial loss: 0.554447\n",
      "epoch 139; iter: 0; batch classifier loss: 0.474268; batch adversarial loss: 0.543613\n",
      "epoch 140; iter: 0; batch classifier loss: 0.523739; batch adversarial loss: 0.616185\n",
      "epoch 141; iter: 0; batch classifier loss: 0.504068; batch adversarial loss: 0.492873\n",
      "epoch 142; iter: 0; batch classifier loss: 0.568546; batch adversarial loss: 0.572084\n",
      "epoch 143; iter: 0; batch classifier loss: 0.509770; batch adversarial loss: 0.491023\n",
      "epoch 144; iter: 0; batch classifier loss: 0.405502; batch adversarial loss: 0.607747\n",
      "epoch 145; iter: 0; batch classifier loss: 0.463467; batch adversarial loss: 0.514965\n",
      "epoch 146; iter: 0; batch classifier loss: 0.602883; batch adversarial loss: 0.558804\n",
      "epoch 147; iter: 0; batch classifier loss: 0.510335; batch adversarial loss: 0.514933\n",
      "epoch 148; iter: 0; batch classifier loss: 0.626568; batch adversarial loss: 0.564803\n",
      "epoch 149; iter: 0; batch classifier loss: 0.501298; batch adversarial loss: 0.550382\n",
      "epoch 150; iter: 0; batch classifier loss: 0.499039; batch adversarial loss: 0.558531\n",
      "epoch 151; iter: 0; batch classifier loss: 0.546148; batch adversarial loss: 0.534101\n",
      "epoch 152; iter: 0; batch classifier loss: 0.502925; batch adversarial loss: 0.596519\n",
      "epoch 153; iter: 0; batch classifier loss: 0.640954; batch adversarial loss: 0.541731\n",
      "epoch 154; iter: 0; batch classifier loss: 0.467851; batch adversarial loss: 0.623052\n",
      "epoch 155; iter: 0; batch classifier loss: 0.513981; batch adversarial loss: 0.602612\n",
      "epoch 156; iter: 0; batch classifier loss: 0.312645; batch adversarial loss: 0.620993\n",
      "epoch 157; iter: 0; batch classifier loss: 0.464737; batch adversarial loss: 0.512524\n",
      "epoch 158; iter: 0; batch classifier loss: 0.597110; batch adversarial loss: 0.630195\n",
      "epoch 159; iter: 0; batch classifier loss: 0.444682; batch adversarial loss: 0.582597\n",
      "epoch 160; iter: 0; batch classifier loss: 0.481609; batch adversarial loss: 0.575742\n",
      "epoch 161; iter: 0; batch classifier loss: 0.603071; batch adversarial loss: 0.551799\n",
      "epoch 162; iter: 0; batch classifier loss: 0.462197; batch adversarial loss: 0.574857\n",
      "epoch 163; iter: 0; batch classifier loss: 0.574413; batch adversarial loss: 0.535242\n",
      "epoch 164; iter: 0; batch classifier loss: 0.418803; batch adversarial loss: 0.547216\n",
      "epoch 165; iter: 0; batch classifier loss: 0.582326; batch adversarial loss: 0.562847\n",
      "epoch 166; iter: 0; batch classifier loss: 0.532053; batch adversarial loss: 0.585884\n",
      "epoch 167; iter: 0; batch classifier loss: 0.487525; batch adversarial loss: 0.570566\n",
      "epoch 168; iter: 0; batch classifier loss: 0.549849; batch adversarial loss: 0.597939\n",
      "epoch 169; iter: 0; batch classifier loss: 0.538064; batch adversarial loss: 0.587160\n",
      "epoch 170; iter: 0; batch classifier loss: 0.607326; batch adversarial loss: 0.553101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.444618; batch adversarial loss: 0.521703\n",
      "epoch 172; iter: 0; batch classifier loss: 0.461900; batch adversarial loss: 0.581105\n",
      "epoch 173; iter: 0; batch classifier loss: 0.529362; batch adversarial loss: 0.541909\n",
      "epoch 174; iter: 0; batch classifier loss: 0.545647; batch adversarial loss: 0.545763\n",
      "epoch 175; iter: 0; batch classifier loss: 0.496736; batch adversarial loss: 0.553701\n",
      "epoch 176; iter: 0; batch classifier loss: 0.606027; batch adversarial loss: 0.520203\n",
      "epoch 177; iter: 0; batch classifier loss: 0.549529; batch adversarial loss: 0.602018\n",
      "epoch 178; iter: 0; batch classifier loss: 0.353669; batch adversarial loss: 0.553414\n",
      "epoch 179; iter: 0; batch classifier loss: 0.490111; batch adversarial loss: 0.602240\n",
      "epoch 180; iter: 0; batch classifier loss: 0.464832; batch adversarial loss: 0.532900\n",
      "epoch 181; iter: 0; batch classifier loss: 0.628482; batch adversarial loss: 0.631644\n",
      "epoch 182; iter: 0; batch classifier loss: 0.512393; batch adversarial loss: 0.594010\n",
      "epoch 183; iter: 0; batch classifier loss: 0.640072; batch adversarial loss: 0.643591\n",
      "epoch 184; iter: 0; batch classifier loss: 0.483224; batch adversarial loss: 0.525957\n",
      "epoch 185; iter: 0; batch classifier loss: 0.566540; batch adversarial loss: 0.617376\n",
      "epoch 186; iter: 0; batch classifier loss: 0.420032; batch adversarial loss: 0.528283\n",
      "epoch 187; iter: 0; batch classifier loss: 0.477211; batch adversarial loss: 0.558352\n",
      "epoch 188; iter: 0; batch classifier loss: 0.423563; batch adversarial loss: 0.561569\n",
      "epoch 189; iter: 0; batch classifier loss: 0.558957; batch adversarial loss: 0.565924\n",
      "epoch 190; iter: 0; batch classifier loss: 0.488920; batch adversarial loss: 0.523074\n",
      "epoch 191; iter: 0; batch classifier loss: 0.391709; batch adversarial loss: 0.596212\n",
      "epoch 192; iter: 0; batch classifier loss: 0.458437; batch adversarial loss: 0.565015\n",
      "epoch 193; iter: 0; batch classifier loss: 0.509217; batch adversarial loss: 0.501270\n",
      "epoch 194; iter: 0; batch classifier loss: 0.463606; batch adversarial loss: 0.595004\n",
      "epoch 195; iter: 0; batch classifier loss: 0.650276; batch adversarial loss: 0.526608\n",
      "epoch 196; iter: 0; batch classifier loss: 0.534804; batch adversarial loss: 0.597424\n",
      "epoch 197; iter: 0; batch classifier loss: 0.405468; batch adversarial loss: 0.613577\n",
      "epoch 198; iter: 0; batch classifier loss: 0.573561; batch adversarial loss: 0.602639\n",
      "epoch 199; iter: 0; batch classifier loss: 0.332563; batch adversarial loss: 0.657220\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.704331; batch adversarial loss: 0.851006\n",
      "epoch 2; iter: 0; batch classifier loss: 0.688887; batch adversarial loss: 0.773432\n",
      "epoch 3; iter: 0; batch classifier loss: 0.521704; batch adversarial loss: 0.735540\n",
      "epoch 4; iter: 0; batch classifier loss: 0.469855; batch adversarial loss: 0.721614\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495753; batch adversarial loss: 0.655801\n",
      "epoch 6; iter: 0; batch classifier loss: 0.608881; batch adversarial loss: 0.667228\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494583; batch adversarial loss: 0.658004\n",
      "epoch 8; iter: 0; batch classifier loss: 0.485487; batch adversarial loss: 0.634344\n",
      "epoch 9; iter: 0; batch classifier loss: 0.468504; batch adversarial loss: 0.653989\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464787; batch adversarial loss: 0.656937\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576569; batch adversarial loss: 0.611689\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550818; batch adversarial loss: 0.622211\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540509; batch adversarial loss: 0.625048\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501329; batch adversarial loss: 0.605363\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530625; batch adversarial loss: 0.583390\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498627; batch adversarial loss: 0.553881\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511369; batch adversarial loss: 0.588825\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478420; batch adversarial loss: 0.531333\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438799; batch adversarial loss: 0.565820\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448814; batch adversarial loss: 0.602849\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490465; batch adversarial loss: 0.576614\n",
      "epoch 22; iter: 0; batch classifier loss: 0.431548; batch adversarial loss: 0.543792\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474147; batch adversarial loss: 0.515824\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402450; batch adversarial loss: 0.510181\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428985; batch adversarial loss: 0.512152\n",
      "epoch 26; iter: 0; batch classifier loss: 0.388912; batch adversarial loss: 0.576921\n",
      "epoch 27; iter: 0; batch classifier loss: 0.431304; batch adversarial loss: 0.601522\n",
      "epoch 28; iter: 0; batch classifier loss: 0.532609; batch adversarial loss: 0.582355\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476438; batch adversarial loss: 0.564528\n",
      "epoch 30; iter: 0; batch classifier loss: 0.466223; batch adversarial loss: 0.579075\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480778; batch adversarial loss: 0.566866\n",
      "epoch 32; iter: 0; batch classifier loss: 0.545729; batch adversarial loss: 0.589937\n",
      "epoch 33; iter: 0; batch classifier loss: 0.560171; batch adversarial loss: 0.609183\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471145; batch adversarial loss: 0.661507\n",
      "epoch 35; iter: 0; batch classifier loss: 0.480689; batch adversarial loss: 0.631760\n",
      "epoch 36; iter: 0; batch classifier loss: 0.587230; batch adversarial loss: 0.653246\n",
      "epoch 37; iter: 0; batch classifier loss: 0.788302; batch adversarial loss: 0.729438\n",
      "epoch 38; iter: 0; batch classifier loss: 0.786094; batch adversarial loss: 0.597201\n",
      "epoch 39; iter: 0; batch classifier loss: 0.739604; batch adversarial loss: 0.700616\n",
      "epoch 40; iter: 0; batch classifier loss: 0.779628; batch adversarial loss: 0.669240\n",
      "epoch 41; iter: 0; batch classifier loss: 0.611233; batch adversarial loss: 0.548548\n",
      "epoch 42; iter: 0; batch classifier loss: 0.688627; batch adversarial loss: 0.607027\n",
      "epoch 43; iter: 0; batch classifier loss: 0.812358; batch adversarial loss: 0.569004\n",
      "epoch 44; iter: 0; batch classifier loss: 0.649978; batch adversarial loss: 0.687289\n",
      "epoch 45; iter: 0; batch classifier loss: 0.483821; batch adversarial loss: 0.583006\n",
      "epoch 46; iter: 0; batch classifier loss: 0.416855; batch adversarial loss: 0.563057\n",
      "epoch 47; iter: 0; batch classifier loss: 0.360782; batch adversarial loss: 0.585226\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434903; batch adversarial loss: 0.554835\n",
      "epoch 49; iter: 0; batch classifier loss: 0.405136; batch adversarial loss: 0.551116\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428977; batch adversarial loss: 0.514839\n",
      "epoch 51; iter: 0; batch classifier loss: 0.413463; batch adversarial loss: 0.597305\n",
      "epoch 52; iter: 0; batch classifier loss: 0.409412; batch adversarial loss: 0.523553\n",
      "epoch 53; iter: 0; batch classifier loss: 0.411999; batch adversarial loss: 0.581077\n",
      "epoch 54; iter: 0; batch classifier loss: 0.433342; batch adversarial loss: 0.620574\n",
      "epoch 55; iter: 0; batch classifier loss: 0.479441; batch adversarial loss: 0.528353\n",
      "epoch 56; iter: 0; batch classifier loss: 0.345961; batch adversarial loss: 0.526632\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402051; batch adversarial loss: 0.576873\n",
      "epoch 58; iter: 0; batch classifier loss: 0.388242; batch adversarial loss: 0.546203\n",
      "epoch 59; iter: 0; batch classifier loss: 0.404986; batch adversarial loss: 0.561065\n",
      "epoch 60; iter: 0; batch classifier loss: 0.366011; batch adversarial loss: 0.617535\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407800; batch adversarial loss: 0.609192\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445459; batch adversarial loss: 0.614500\n",
      "epoch 63; iter: 0; batch classifier loss: 0.379467; batch adversarial loss: 0.632423\n",
      "epoch 64; iter: 0; batch classifier loss: 0.440767; batch adversarial loss: 0.578104\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420089; batch adversarial loss: 0.618089\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409594; batch adversarial loss: 0.596423\n",
      "epoch 67; iter: 0; batch classifier loss: 0.329796; batch adversarial loss: 0.536987\n",
      "epoch 68; iter: 0; batch classifier loss: 0.482290; batch adversarial loss: 0.491016\n",
      "epoch 69; iter: 0; batch classifier loss: 0.396209; batch adversarial loss: 0.583639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.357521; batch adversarial loss: 0.615938\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431083; batch adversarial loss: 0.525872\n",
      "epoch 72; iter: 0; batch classifier loss: 0.374955; batch adversarial loss: 0.552589\n",
      "epoch 73; iter: 0; batch classifier loss: 0.279826; batch adversarial loss: 0.566256\n",
      "epoch 74; iter: 0; batch classifier loss: 0.489205; batch adversarial loss: 0.582683\n",
      "epoch 75; iter: 0; batch classifier loss: 0.324068; batch adversarial loss: 0.536419\n",
      "epoch 76; iter: 0; batch classifier loss: 0.381382; batch adversarial loss: 0.559128\n",
      "epoch 77; iter: 0; batch classifier loss: 0.383410; batch adversarial loss: 0.477686\n",
      "epoch 78; iter: 0; batch classifier loss: 0.440983; batch adversarial loss: 0.544707\n",
      "epoch 79; iter: 0; batch classifier loss: 0.366151; batch adversarial loss: 0.598275\n",
      "epoch 80; iter: 0; batch classifier loss: 0.293243; batch adversarial loss: 0.599596\n",
      "epoch 81; iter: 0; batch classifier loss: 0.416078; batch adversarial loss: 0.591234\n",
      "epoch 82; iter: 0; batch classifier loss: 0.366429; batch adversarial loss: 0.524171\n",
      "epoch 83; iter: 0; batch classifier loss: 0.399738; batch adversarial loss: 0.612626\n",
      "epoch 84; iter: 0; batch classifier loss: 0.383276; batch adversarial loss: 0.600607\n",
      "epoch 85; iter: 0; batch classifier loss: 0.283839; batch adversarial loss: 0.599628\n",
      "epoch 86; iter: 0; batch classifier loss: 0.325888; batch adversarial loss: 0.613397\n",
      "epoch 87; iter: 0; batch classifier loss: 0.391850; batch adversarial loss: 0.590456\n",
      "epoch 88; iter: 0; batch classifier loss: 0.435089; batch adversarial loss: 0.484259\n",
      "epoch 89; iter: 0; batch classifier loss: 0.371344; batch adversarial loss: 0.539324\n",
      "epoch 90; iter: 0; batch classifier loss: 0.367019; batch adversarial loss: 0.536720\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373494; batch adversarial loss: 0.602405\n",
      "epoch 92; iter: 0; batch classifier loss: 0.342710; batch adversarial loss: 0.619529\n",
      "epoch 93; iter: 0; batch classifier loss: 0.500512; batch adversarial loss: 0.546996\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387681; batch adversarial loss: 0.495086\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416409; batch adversarial loss: 0.567696\n",
      "epoch 96; iter: 0; batch classifier loss: 0.373258; batch adversarial loss: 0.573110\n",
      "epoch 97; iter: 0; batch classifier loss: 0.400079; batch adversarial loss: 0.633980\n",
      "epoch 98; iter: 0; batch classifier loss: 0.361435; batch adversarial loss: 0.509036\n",
      "epoch 99; iter: 0; batch classifier loss: 0.371973; batch adversarial loss: 0.540922\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.681363; batch adversarial loss: 0.834723\n",
      "epoch 2; iter: 0; batch classifier loss: 0.658308; batch adversarial loss: 0.763574\n",
      "epoch 3; iter: 0; batch classifier loss: 0.505237; batch adversarial loss: 0.728175\n",
      "epoch 4; iter: 0; batch classifier loss: 0.471634; batch adversarial loss: 0.713189\n",
      "epoch 5; iter: 0; batch classifier loss: 0.498275; batch adversarial loss: 0.654075\n",
      "epoch 6; iter: 0; batch classifier loss: 0.615105; batch adversarial loss: 0.664195\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501657; batch adversarial loss: 0.655557\n",
      "epoch 8; iter: 0; batch classifier loss: 0.491396; batch adversarial loss: 0.632771\n",
      "epoch 9; iter: 0; batch classifier loss: 0.475283; batch adversarial loss: 0.652566\n",
      "epoch 10; iter: 0; batch classifier loss: 0.467634; batch adversarial loss: 0.656607\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577263; batch adversarial loss: 0.611474\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551268; batch adversarial loss: 0.622025\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540819; batch adversarial loss: 0.624837\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500265; batch adversarial loss: 0.605190\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531142; batch adversarial loss: 0.581658\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501866; batch adversarial loss: 0.549852\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509428; batch adversarial loss: 0.584533\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482393; batch adversarial loss: 0.524957\n",
      "epoch 19; iter: 0; batch classifier loss: 0.440679; batch adversarial loss: 0.562421\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448202; batch adversarial loss: 0.599384\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488171; batch adversarial loss: 0.574048\n",
      "epoch 22; iter: 0; batch classifier loss: 0.435056; batch adversarial loss: 0.540122\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473755; batch adversarial loss: 0.513625\n",
      "epoch 24; iter: 0; batch classifier loss: 0.396996; batch adversarial loss: 0.507238\n",
      "epoch 25; iter: 0; batch classifier loss: 0.427329; batch adversarial loss: 0.507964\n",
      "epoch 26; iter: 0; batch classifier loss: 0.389231; batch adversarial loss: 0.573616\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427559; batch adversarial loss: 0.595030\n",
      "epoch 28; iter: 0; batch classifier loss: 0.520166; batch adversarial loss: 0.572802\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456582; batch adversarial loss: 0.547218\n",
      "epoch 30; iter: 0; batch classifier loss: 0.443814; batch adversarial loss: 0.557125\n",
      "epoch 31; iter: 0; batch classifier loss: 0.456750; batch adversarial loss: 0.552761\n",
      "epoch 32; iter: 0; batch classifier loss: 0.522363; batch adversarial loss: 0.580728\n",
      "epoch 33; iter: 0; batch classifier loss: 0.531099; batch adversarial loss: 0.596075\n",
      "epoch 34; iter: 0; batch classifier loss: 0.443730; batch adversarial loss: 0.648942\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426847; batch adversarial loss: 0.609625\n",
      "epoch 36; iter: 0; batch classifier loss: 0.514792; batch adversarial loss: 0.633987\n",
      "epoch 37; iter: 0; batch classifier loss: 0.639833; batch adversarial loss: 0.712613\n",
      "epoch 38; iter: 0; batch classifier loss: 0.692589; batch adversarial loss: 0.596089\n",
      "epoch 39; iter: 0; batch classifier loss: 0.675846; batch adversarial loss: 0.721226\n",
      "epoch 40; iter: 0; batch classifier loss: 0.766219; batch adversarial loss: 0.699467\n",
      "epoch 41; iter: 0; batch classifier loss: 0.610401; batch adversarial loss: 0.566764\n",
      "epoch 42; iter: 0; batch classifier loss: 0.693209; batch adversarial loss: 0.629153\n",
      "epoch 43; iter: 0; batch classifier loss: 0.787429; batch adversarial loss: 0.587028\n",
      "epoch 44; iter: 0; batch classifier loss: 0.805754; batch adversarial loss: 0.711348\n",
      "epoch 45; iter: 0; batch classifier loss: 0.754657; batch adversarial loss: 0.593797\n",
      "epoch 46; iter: 0; batch classifier loss: 0.490267; batch adversarial loss: 0.566238\n",
      "epoch 47; iter: 0; batch classifier loss: 0.367624; batch adversarial loss: 0.585062\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435356; batch adversarial loss: 0.555602\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412948; batch adversarial loss: 0.551634\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431821; batch adversarial loss: 0.516086\n",
      "epoch 51; iter: 0; batch classifier loss: 0.406616; batch adversarial loss: 0.595669\n",
      "epoch 52; iter: 0; batch classifier loss: 0.403697; batch adversarial loss: 0.522792\n",
      "epoch 53; iter: 0; batch classifier loss: 0.406526; batch adversarial loss: 0.579977\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431844; batch adversarial loss: 0.619276\n",
      "epoch 55; iter: 0; batch classifier loss: 0.467910; batch adversarial loss: 0.527837\n",
      "epoch 56; iter: 0; batch classifier loss: 0.337731; batch adversarial loss: 0.525107\n",
      "epoch 57; iter: 0; batch classifier loss: 0.391503; batch adversarial loss: 0.575565\n",
      "epoch 58; iter: 0; batch classifier loss: 0.386789; batch adversarial loss: 0.545753\n",
      "epoch 59; iter: 0; batch classifier loss: 0.401979; batch adversarial loss: 0.559529\n",
      "epoch 60; iter: 0; batch classifier loss: 0.368733; batch adversarial loss: 0.617457\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403211; batch adversarial loss: 0.607946\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444104; batch adversarial loss: 0.612617\n",
      "epoch 63; iter: 0; batch classifier loss: 0.375491; batch adversarial loss: 0.631983\n",
      "epoch 64; iter: 0; batch classifier loss: 0.431867; batch adversarial loss: 0.576375\n",
      "epoch 65; iter: 0; batch classifier loss: 0.413743; batch adversarial loss: 0.616282\n",
      "epoch 66; iter: 0; batch classifier loss: 0.404785; batch adversarial loss: 0.596259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67; iter: 0; batch classifier loss: 0.332401; batch adversarial loss: 0.536356\n",
      "epoch 68; iter: 0; batch classifier loss: 0.480577; batch adversarial loss: 0.489579\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395381; batch adversarial loss: 0.583123\n",
      "epoch 70; iter: 0; batch classifier loss: 0.348190; batch adversarial loss: 0.614339\n",
      "epoch 71; iter: 0; batch classifier loss: 0.425447; batch adversarial loss: 0.525412\n",
      "epoch 72; iter: 0; batch classifier loss: 0.380494; batch adversarial loss: 0.551703\n",
      "epoch 73; iter: 0; batch classifier loss: 0.283651; batch adversarial loss: 0.565786\n",
      "epoch 74; iter: 0; batch classifier loss: 0.475884; batch adversarial loss: 0.581633\n",
      "epoch 75; iter: 0; batch classifier loss: 0.314377; batch adversarial loss: 0.535516\n",
      "epoch 76; iter: 0; batch classifier loss: 0.380096; batch adversarial loss: 0.558359\n",
      "epoch 77; iter: 0; batch classifier loss: 0.378814; batch adversarial loss: 0.477054\n",
      "epoch 78; iter: 0; batch classifier loss: 0.439769; batch adversarial loss: 0.544308\n",
      "epoch 79; iter: 0; batch classifier loss: 0.361169; batch adversarial loss: 0.597701\n",
      "epoch 80; iter: 0; batch classifier loss: 0.299037; batch adversarial loss: 0.598815\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397199; batch adversarial loss: 0.589442\n",
      "epoch 82; iter: 0; batch classifier loss: 0.352283; batch adversarial loss: 0.523543\n",
      "epoch 83; iter: 0; batch classifier loss: 0.401459; batch adversarial loss: 0.610864\n",
      "epoch 84; iter: 0; batch classifier loss: 0.385992; batch adversarial loss: 0.599911\n",
      "epoch 85; iter: 0; batch classifier loss: 0.277727; batch adversarial loss: 0.598021\n",
      "epoch 86; iter: 0; batch classifier loss: 0.316044; batch adversarial loss: 0.613580\n",
      "epoch 87; iter: 0; batch classifier loss: 0.379588; batch adversarial loss: 0.590346\n",
      "epoch 88; iter: 0; batch classifier loss: 0.428452; batch adversarial loss: 0.482855\n",
      "epoch 89; iter: 0; batch classifier loss: 0.350125; batch adversarial loss: 0.538639\n",
      "epoch 90; iter: 0; batch classifier loss: 0.353599; batch adversarial loss: 0.535082\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356353; batch adversarial loss: 0.600168\n",
      "epoch 92; iter: 0; batch classifier loss: 0.343928; batch adversarial loss: 0.619047\n",
      "epoch 93; iter: 0; batch classifier loss: 0.477106; batch adversarial loss: 0.545270\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378791; batch adversarial loss: 0.493624\n",
      "epoch 95; iter: 0; batch classifier loss: 0.419885; batch adversarial loss: 0.566785\n",
      "epoch 96; iter: 0; batch classifier loss: 0.352529; batch adversarial loss: 0.572942\n",
      "epoch 97; iter: 0; batch classifier loss: 0.395439; batch adversarial loss: 0.634003\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368258; batch adversarial loss: 0.510322\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366763; batch adversarial loss: 0.539656\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709988; batch adversarial loss: 0.791750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.651667; batch adversarial loss: 0.848815\n",
      "epoch 2; iter: 0; batch classifier loss: 0.615829; batch adversarial loss: 0.768810\n",
      "epoch 3; iter: 0; batch classifier loss: 0.452976; batch adversarial loss: 0.729632\n",
      "epoch 4; iter: 0; batch classifier loss: 0.468828; batch adversarial loss: 0.712179\n",
      "epoch 5; iter: 0; batch classifier loss: 0.486966; batch adversarial loss: 0.655370\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573411; batch adversarial loss: 0.673797\n",
      "epoch 7; iter: 0; batch classifier loss: 0.499087; batch adversarial loss: 0.656149\n",
      "epoch 8; iter: 0; batch classifier loss: 0.484726; batch adversarial loss: 0.634489\n",
      "epoch 9; iter: 0; batch classifier loss: 0.490548; batch adversarial loss: 0.650930\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462872; batch adversarial loss: 0.658599\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573568; batch adversarial loss: 0.613475\n",
      "epoch 12; iter: 0; batch classifier loss: 0.549349; batch adversarial loss: 0.621933\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506641; batch adversarial loss: 0.629921\n",
      "epoch 14; iter: 0; batch classifier loss: 0.482046; batch adversarial loss: 0.612029\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502834; batch adversarial loss: 0.591147\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482565; batch adversarial loss: 0.561679\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498838; batch adversarial loss: 0.589723\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493815; batch adversarial loss: 0.521096\n",
      "epoch 19; iter: 0; batch classifier loss: 0.419024; batch adversarial loss: 0.560725\n",
      "epoch 20; iter: 0; batch classifier loss: 0.417363; batch adversarial loss: 0.599831\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478826; batch adversarial loss: 0.566651\n",
      "epoch 22; iter: 0; batch classifier loss: 0.414001; batch adversarial loss: 0.531326\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452016; batch adversarial loss: 0.511527\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402974; batch adversarial loss: 0.503440\n",
      "epoch 25; iter: 0; batch classifier loss: 0.413960; batch adversarial loss: 0.508577\n",
      "epoch 26; iter: 0; batch classifier loss: 0.366149; batch adversarial loss: 0.576364\n",
      "epoch 27; iter: 0; batch classifier loss: 0.395738; batch adversarial loss: 0.592836\n",
      "epoch 28; iter: 0; batch classifier loss: 0.451706; batch adversarial loss: 0.559314\n",
      "epoch 29; iter: 0; batch classifier loss: 0.399277; batch adversarial loss: 0.543566\n",
      "epoch 30; iter: 0; batch classifier loss: 0.388020; batch adversarial loss: 0.556770\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417875; batch adversarial loss: 0.550485\n",
      "epoch 32; iter: 0; batch classifier loss: 0.463217; batch adversarial loss: 0.563619\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433389; batch adversarial loss: 0.591814\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433034; batch adversarial loss: 0.660139\n",
      "epoch 35; iter: 0; batch classifier loss: 0.412254; batch adversarial loss: 0.613393\n",
      "epoch 36; iter: 0; batch classifier loss: 0.437256; batch adversarial loss: 0.609616\n",
      "epoch 37; iter: 0; batch classifier loss: 0.556894; batch adversarial loss: 0.701751\n",
      "epoch 38; iter: 0; batch classifier loss: 0.622266; batch adversarial loss: 0.591849\n",
      "epoch 39; iter: 0; batch classifier loss: 0.586355; batch adversarial loss: 0.713714\n",
      "epoch 40; iter: 0; batch classifier loss: 0.726224; batch adversarial loss: 0.714414\n",
      "epoch 41; iter: 0; batch classifier loss: 0.554051; batch adversarial loss: 0.573844\n",
      "epoch 42; iter: 0; batch classifier loss: 0.643737; batch adversarial loss: 0.635813\n",
      "epoch 43; iter: 0; batch classifier loss: 0.652282; batch adversarial loss: 0.588150\n",
      "epoch 44; iter: 0; batch classifier loss: 0.694918; batch adversarial loss: 0.721279\n",
      "epoch 45; iter: 0; batch classifier loss: 0.745842; batch adversarial loss: 0.601837\n",
      "epoch 46; iter: 0; batch classifier loss: 0.618972; batch adversarial loss: 0.570823\n",
      "epoch 47; iter: 0; batch classifier loss: 0.337903; batch adversarial loss: 0.584216\n",
      "epoch 48; iter: 0; batch classifier loss: 0.389481; batch adversarial loss: 0.557075\n",
      "epoch 49; iter: 0; batch classifier loss: 0.332008; batch adversarial loss: 0.549577\n",
      "epoch 50; iter: 0; batch classifier loss: 0.329497; batch adversarial loss: 0.513168\n",
      "epoch 51; iter: 0; batch classifier loss: 0.338566; batch adversarial loss: 0.594586\n",
      "epoch 52; iter: 0; batch classifier loss: 0.386061; batch adversarial loss: 0.525282\n",
      "epoch 53; iter: 0; batch classifier loss: 0.321191; batch adversarial loss: 0.582669\n",
      "epoch 54; iter: 0; batch classifier loss: 0.372965; batch adversarial loss: 0.621773\n",
      "epoch 55; iter: 0; batch classifier loss: 0.403056; batch adversarial loss: 0.527977\n",
      "epoch 56; iter: 0; batch classifier loss: 0.291552; batch adversarial loss: 0.524634\n",
      "epoch 57; iter: 0; batch classifier loss: 0.351147; batch adversarial loss: 0.575601\n",
      "epoch 58; iter: 0; batch classifier loss: 0.312848; batch adversarial loss: 0.547978\n",
      "epoch 59; iter: 0; batch classifier loss: 0.368459; batch adversarial loss: 0.563904\n",
      "epoch 60; iter: 0; batch classifier loss: 0.241356; batch adversarial loss: 0.614790\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382953; batch adversarial loss: 0.611686\n",
      "epoch 62; iter: 0; batch classifier loss: 0.416664; batch adversarial loss: 0.617017\n",
      "epoch 63; iter: 0; batch classifier loss: 0.334548; batch adversarial loss: 0.635078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.452078; batch adversarial loss: 0.581924\n",
      "epoch 65; iter: 0; batch classifier loss: 0.363608; batch adversarial loss: 0.615891\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417850; batch adversarial loss: 0.599664\n",
      "epoch 67; iter: 0; batch classifier loss: 0.270311; batch adversarial loss: 0.536608\n",
      "epoch 68; iter: 0; batch classifier loss: 0.502327; batch adversarial loss: 0.498165\n",
      "epoch 69; iter: 0; batch classifier loss: 0.365788; batch adversarial loss: 0.586963\n",
      "epoch 70; iter: 0; batch classifier loss: 0.396196; batch adversarial loss: 0.624479\n",
      "epoch 71; iter: 0; batch classifier loss: 0.442858; batch adversarial loss: 0.531543\n",
      "epoch 72; iter: 0; batch classifier loss: 0.395064; batch adversarial loss: 0.560645\n",
      "epoch 73; iter: 0; batch classifier loss: 0.290674; batch adversarial loss: 0.572075\n",
      "epoch 74; iter: 0; batch classifier loss: 0.439234; batch adversarial loss: 0.591393\n",
      "epoch 75; iter: 0; batch classifier loss: 0.334110; batch adversarial loss: 0.544039\n",
      "epoch 76; iter: 0; batch classifier loss: 0.433884; batch adversarial loss: 0.569659\n",
      "epoch 77; iter: 0; batch classifier loss: 0.369921; batch adversarial loss: 0.482558\n",
      "epoch 78; iter: 0; batch classifier loss: 0.428379; batch adversarial loss: 0.548783\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396686; batch adversarial loss: 0.610855\n",
      "epoch 80; iter: 0; batch classifier loss: 0.358250; batch adversarial loss: 0.608704\n",
      "epoch 81; iter: 0; batch classifier loss: 0.426596; batch adversarial loss: 0.596388\n",
      "epoch 82; iter: 0; batch classifier loss: 0.429066; batch adversarial loss: 0.532835\n",
      "epoch 83; iter: 0; batch classifier loss: 0.428237; batch adversarial loss: 0.624760\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437110; batch adversarial loss: 0.609353\n",
      "epoch 85; iter: 0; batch classifier loss: 0.330971; batch adversarial loss: 0.608079\n",
      "epoch 86; iter: 0; batch classifier loss: 0.399402; batch adversarial loss: 0.626943\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373138; batch adversarial loss: 0.600049\n",
      "epoch 88; iter: 0; batch classifier loss: 0.505125; batch adversarial loss: 0.498437\n",
      "epoch 89; iter: 0; batch classifier loss: 0.363852; batch adversarial loss: 0.547173\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398799; batch adversarial loss: 0.544445\n",
      "epoch 91; iter: 0; batch classifier loss: 0.407133; batch adversarial loss: 0.617304\n",
      "epoch 92; iter: 0; batch classifier loss: 0.418740; batch adversarial loss: 0.634365\n",
      "epoch 93; iter: 0; batch classifier loss: 0.557379; batch adversarial loss: 0.559484\n",
      "epoch 94; iter: 0; batch classifier loss: 0.462537; batch adversarial loss: 0.507087\n",
      "epoch 95; iter: 0; batch classifier loss: 0.459868; batch adversarial loss: 0.582022\n",
      "epoch 96; iter: 0; batch classifier loss: 0.414578; batch adversarial loss: 0.575275\n",
      "epoch 97; iter: 0; batch classifier loss: 0.497828; batch adversarial loss: 0.648691\n",
      "epoch 98; iter: 0; batch classifier loss: 0.444156; batch adversarial loss: 0.521648\n",
      "epoch 99; iter: 0; batch classifier loss: 0.431500; batch adversarial loss: 0.553670\n",
      "epoch 100; iter: 0; batch classifier loss: 0.517178; batch adversarial loss: 0.581972\n",
      "epoch 101; iter: 0; batch classifier loss: 0.441743; batch adversarial loss: 0.625723\n",
      "epoch 102; iter: 0; batch classifier loss: 0.553301; batch adversarial loss: 0.538952\n",
      "epoch 103; iter: 0; batch classifier loss: 0.513478; batch adversarial loss: 0.564140\n",
      "epoch 104; iter: 0; batch classifier loss: 0.414207; batch adversarial loss: 0.542270\n",
      "epoch 105; iter: 0; batch classifier loss: 0.416443; batch adversarial loss: 0.646309\n",
      "epoch 106; iter: 0; batch classifier loss: 0.464848; batch adversarial loss: 0.647929\n",
      "epoch 107; iter: 0; batch classifier loss: 0.485959; batch adversarial loss: 0.566624\n",
      "epoch 108; iter: 0; batch classifier loss: 0.450815; batch adversarial loss: 0.583694\n",
      "epoch 109; iter: 0; batch classifier loss: 0.539142; batch adversarial loss: 0.499980\n",
      "epoch 110; iter: 0; batch classifier loss: 0.566990; batch adversarial loss: 0.522581\n",
      "epoch 111; iter: 0; batch classifier loss: 0.346974; batch adversarial loss: 0.587425\n",
      "epoch 112; iter: 0; batch classifier loss: 0.488345; batch adversarial loss: 0.553378\n",
      "epoch 113; iter: 0; batch classifier loss: 0.504487; batch adversarial loss: 0.557736\n",
      "epoch 114; iter: 0; batch classifier loss: 0.450066; batch adversarial loss: 0.586961\n",
      "epoch 115; iter: 0; batch classifier loss: 0.451020; batch adversarial loss: 0.514273\n",
      "epoch 116; iter: 0; batch classifier loss: 0.441115; batch adversarial loss: 0.553620\n",
      "epoch 117; iter: 0; batch classifier loss: 0.374580; batch adversarial loss: 0.597332\n",
      "epoch 118; iter: 0; batch classifier loss: 0.450610; batch adversarial loss: 0.584767\n",
      "epoch 119; iter: 0; batch classifier loss: 0.407539; batch adversarial loss: 0.604801\n",
      "epoch 120; iter: 0; batch classifier loss: 0.468348; batch adversarial loss: 0.596276\n",
      "epoch 121; iter: 0; batch classifier loss: 0.611268; batch adversarial loss: 0.640575\n",
      "epoch 122; iter: 0; batch classifier loss: 0.577423; batch adversarial loss: 0.568321\n",
      "epoch 123; iter: 0; batch classifier loss: 0.557903; batch adversarial loss: 0.601670\n",
      "epoch 124; iter: 0; batch classifier loss: 0.520103; batch adversarial loss: 0.557119\n",
      "epoch 125; iter: 0; batch classifier loss: 0.474825; batch adversarial loss: 0.609444\n",
      "epoch 126; iter: 0; batch classifier loss: 0.552029; batch adversarial loss: 0.569603\n",
      "epoch 127; iter: 0; batch classifier loss: 0.496199; batch adversarial loss: 0.521868\n",
      "epoch 128; iter: 0; batch classifier loss: 0.485535; batch adversarial loss: 0.600041\n",
      "epoch 129; iter: 0; batch classifier loss: 0.436491; batch adversarial loss: 0.635096\n",
      "epoch 130; iter: 0; batch classifier loss: 0.440578; batch adversarial loss: 0.558081\n",
      "epoch 131; iter: 0; batch classifier loss: 0.394249; batch adversarial loss: 0.599690\n",
      "epoch 132; iter: 0; batch classifier loss: 0.535399; batch adversarial loss: 0.542789\n",
      "epoch 133; iter: 0; batch classifier loss: 0.502036; batch adversarial loss: 0.625986\n",
      "epoch 134; iter: 0; batch classifier loss: 0.522439; batch adversarial loss: 0.567619\n",
      "epoch 135; iter: 0; batch classifier loss: 0.569725; batch adversarial loss: 0.630157\n",
      "epoch 136; iter: 0; batch classifier loss: 0.470772; batch adversarial loss: 0.565328\n",
      "epoch 137; iter: 0; batch classifier loss: 0.453279; batch adversarial loss: 0.647443\n",
      "epoch 138; iter: 0; batch classifier loss: 0.430309; batch adversarial loss: 0.553729\n",
      "epoch 139; iter: 0; batch classifier loss: 0.479121; batch adversarial loss: 0.548996\n",
      "epoch 140; iter: 0; batch classifier loss: 0.447171; batch adversarial loss: 0.609826\n",
      "epoch 141; iter: 0; batch classifier loss: 0.472345; batch adversarial loss: 0.496778\n",
      "epoch 142; iter: 0; batch classifier loss: 0.585644; batch adversarial loss: 0.575046\n",
      "epoch 143; iter: 0; batch classifier loss: 0.544023; batch adversarial loss: 0.498103\n",
      "epoch 144; iter: 0; batch classifier loss: 0.357199; batch adversarial loss: 0.611730\n",
      "epoch 145; iter: 0; batch classifier loss: 0.510710; batch adversarial loss: 0.519863\n",
      "epoch 146; iter: 0; batch classifier loss: 0.581851; batch adversarial loss: 0.566582\n",
      "epoch 147; iter: 0; batch classifier loss: 0.542514; batch adversarial loss: 0.513881\n",
      "epoch 148; iter: 0; batch classifier loss: 0.549566; batch adversarial loss: 0.564791\n",
      "epoch 149; iter: 0; batch classifier loss: 0.513942; batch adversarial loss: 0.550129\n",
      "epoch 150; iter: 0; batch classifier loss: 0.481132; batch adversarial loss: 0.561883\n",
      "epoch 151; iter: 0; batch classifier loss: 0.468834; batch adversarial loss: 0.536130\n",
      "epoch 152; iter: 0; batch classifier loss: 0.485707; batch adversarial loss: 0.598901\n",
      "epoch 153; iter: 0; batch classifier loss: 0.609837; batch adversarial loss: 0.545104\n",
      "epoch 154; iter: 0; batch classifier loss: 0.458434; batch adversarial loss: 0.614697\n",
      "epoch 155; iter: 0; batch classifier loss: 0.447300; batch adversarial loss: 0.603085\n",
      "epoch 156; iter: 0; batch classifier loss: 0.321269; batch adversarial loss: 0.616866\n",
      "epoch 157; iter: 0; batch classifier loss: 0.459060; batch adversarial loss: 0.513431\n",
      "epoch 158; iter: 0; batch classifier loss: 0.460268; batch adversarial loss: 0.622685\n",
      "epoch 159; iter: 0; batch classifier loss: 0.446973; batch adversarial loss: 0.585133\n",
      "epoch 160; iter: 0; batch classifier loss: 0.544649; batch adversarial loss: 0.579393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.489743; batch adversarial loss: 0.551550\n",
      "epoch 162; iter: 0; batch classifier loss: 0.449841; batch adversarial loss: 0.573878\n",
      "epoch 163; iter: 0; batch classifier loss: 0.578031; batch adversarial loss: 0.539847\n",
      "epoch 164; iter: 0; batch classifier loss: 0.368235; batch adversarial loss: 0.550111\n",
      "epoch 165; iter: 0; batch classifier loss: 0.506235; batch adversarial loss: 0.561416\n",
      "epoch 166; iter: 0; batch classifier loss: 0.450220; batch adversarial loss: 0.587183\n",
      "epoch 167; iter: 0; batch classifier loss: 0.442929; batch adversarial loss: 0.569736\n",
      "epoch 168; iter: 0; batch classifier loss: 0.511289; batch adversarial loss: 0.602748\n",
      "epoch 169; iter: 0; batch classifier loss: 0.555886; batch adversarial loss: 0.591357\n",
      "epoch 170; iter: 0; batch classifier loss: 0.541525; batch adversarial loss: 0.550045\n",
      "epoch 171; iter: 0; batch classifier loss: 0.430818; batch adversarial loss: 0.520050\n",
      "epoch 172; iter: 0; batch classifier loss: 0.457535; batch adversarial loss: 0.581897\n",
      "epoch 173; iter: 0; batch classifier loss: 0.560947; batch adversarial loss: 0.545875\n",
      "epoch 174; iter: 0; batch classifier loss: 0.577660; batch adversarial loss: 0.550684\n",
      "epoch 175; iter: 0; batch classifier loss: 0.483037; batch adversarial loss: 0.551348\n",
      "epoch 176; iter: 0; batch classifier loss: 0.552824; batch adversarial loss: 0.520860\n",
      "epoch 177; iter: 0; batch classifier loss: 0.522093; batch adversarial loss: 0.603491\n",
      "epoch 178; iter: 0; batch classifier loss: 0.358443; batch adversarial loss: 0.548747\n",
      "epoch 179; iter: 0; batch classifier loss: 0.497871; batch adversarial loss: 0.606466\n",
      "epoch 180; iter: 0; batch classifier loss: 0.448906; batch adversarial loss: 0.534842\n",
      "epoch 181; iter: 0; batch classifier loss: 0.619423; batch adversarial loss: 0.635460\n",
      "epoch 182; iter: 0; batch classifier loss: 0.470831; batch adversarial loss: 0.593273\n",
      "epoch 183; iter: 0; batch classifier loss: 0.557991; batch adversarial loss: 0.641663\n",
      "epoch 184; iter: 0; batch classifier loss: 0.463376; batch adversarial loss: 0.527297\n",
      "epoch 185; iter: 0; batch classifier loss: 0.546075; batch adversarial loss: 0.622655\n",
      "epoch 186; iter: 0; batch classifier loss: 0.431456; batch adversarial loss: 0.530390\n",
      "epoch 187; iter: 0; batch classifier loss: 0.457815; batch adversarial loss: 0.554425\n",
      "epoch 188; iter: 0; batch classifier loss: 0.416292; batch adversarial loss: 0.561963\n",
      "epoch 189; iter: 0; batch classifier loss: 0.577356; batch adversarial loss: 0.566335\n",
      "epoch 190; iter: 0; batch classifier loss: 0.535728; batch adversarial loss: 0.530909\n",
      "epoch 191; iter: 0; batch classifier loss: 0.416579; batch adversarial loss: 0.595783\n",
      "epoch 192; iter: 0; batch classifier loss: 0.444633; batch adversarial loss: 0.567247\n",
      "epoch 193; iter: 0; batch classifier loss: 0.485563; batch adversarial loss: 0.502802\n",
      "epoch 194; iter: 0; batch classifier loss: 0.421394; batch adversarial loss: 0.594792\n",
      "epoch 195; iter: 0; batch classifier loss: 0.566974; batch adversarial loss: 0.525780\n",
      "epoch 196; iter: 0; batch classifier loss: 0.582443; batch adversarial loss: 0.601433\n",
      "epoch 197; iter: 0; batch classifier loss: 0.400760; batch adversarial loss: 0.611550\n",
      "epoch 198; iter: 0; batch classifier loss: 0.516097; batch adversarial loss: 0.604490\n",
      "epoch 199; iter: 0; batch classifier loss: 0.279089; batch adversarial loss: 0.654812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.704031; batch adversarial loss: 0.850800\n",
      "epoch 2; iter: 0; batch classifier loss: 0.688554; batch adversarial loss: 0.773245\n",
      "epoch 3; iter: 0; batch classifier loss: 0.521337; batch adversarial loss: 0.735434\n",
      "epoch 4; iter: 0; batch classifier loss: 0.469511; batch adversarial loss: 0.721533\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495758; batch adversarial loss: 0.655691\n",
      "epoch 6; iter: 0; batch classifier loss: 0.608619; batch adversarial loss: 0.667215\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494823; batch adversarial loss: 0.657951\n",
      "epoch 8; iter: 0; batch classifier loss: 0.485404; batch adversarial loss: 0.634331\n",
      "epoch 9; iter: 0; batch classifier loss: 0.468938; batch adversarial loss: 0.653899\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464913; batch adversarial loss: 0.656921\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576907; batch adversarial loss: 0.611650\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550992; batch adversarial loss: 0.622221\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540743; batch adversarial loss: 0.625042\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500950; batch adversarial loss: 0.605459\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530269; batch adversarial loss: 0.583534\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499120; batch adversarial loss: 0.553862\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510863; batch adversarial loss: 0.589114\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477949; batch adversarial loss: 0.531605\n",
      "epoch 19; iter: 0; batch classifier loss: 0.439375; batch adversarial loss: 0.565960\n",
      "epoch 20; iter: 0; batch classifier loss: 0.450475; batch adversarial loss: 0.602668\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490481; batch adversarial loss: 0.576633\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433241; batch adversarial loss: 0.543550\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476771; batch adversarial loss: 0.515997\n",
      "epoch 24; iter: 0; batch classifier loss: 0.400996; batch adversarial loss: 0.510296\n",
      "epoch 25; iter: 0; batch classifier loss: 0.430176; batch adversarial loss: 0.512394\n",
      "epoch 26; iter: 0; batch classifier loss: 0.389413; batch adversarial loss: 0.577407\n",
      "epoch 27; iter: 0; batch classifier loss: 0.430818; batch adversarial loss: 0.602610\n",
      "epoch 28; iter: 0; batch classifier loss: 0.532091; batch adversarial loss: 0.581648\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474846; batch adversarial loss: 0.562802\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465439; batch adversarial loss: 0.577695\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481746; batch adversarial loss: 0.567046\n",
      "epoch 32; iter: 0; batch classifier loss: 0.546505; batch adversarial loss: 0.589338\n",
      "epoch 33; iter: 0; batch classifier loss: 0.564061; batch adversarial loss: 0.609114\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473463; batch adversarial loss: 0.662206\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485576; batch adversarial loss: 0.634107\n",
      "epoch 36; iter: 0; batch classifier loss: 0.599775; batch adversarial loss: 0.656628\n",
      "epoch 37; iter: 0; batch classifier loss: 0.794852; batch adversarial loss: 0.729990\n",
      "epoch 38; iter: 0; batch classifier loss: 0.780397; batch adversarial loss: 0.596717\n",
      "epoch 39; iter: 0; batch classifier loss: 0.735835; batch adversarial loss: 0.699887\n",
      "epoch 40; iter: 0; batch classifier loss: 0.775735; batch adversarial loss: 0.668040\n",
      "epoch 41; iter: 0; batch classifier loss: 0.612140; batch adversarial loss: 0.548012\n",
      "epoch 42; iter: 0; batch classifier loss: 0.691511; batch adversarial loss: 0.606540\n",
      "epoch 43; iter: 0; batch classifier loss: 0.815945; batch adversarial loss: 0.568698\n",
      "epoch 44; iter: 0; batch classifier loss: 0.637690; batch adversarial loss: 0.686959\n",
      "epoch 45; iter: 0; batch classifier loss: 0.480712; batch adversarial loss: 0.583013\n",
      "epoch 46; iter: 0; batch classifier loss: 0.421841; batch adversarial loss: 0.563039\n",
      "epoch 47; iter: 0; batch classifier loss: 0.357926; batch adversarial loss: 0.585136\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431953; batch adversarial loss: 0.554863\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403781; batch adversarial loss: 0.551039\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431496; batch adversarial loss: 0.514874\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414053; batch adversarial loss: 0.597184\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414219; batch adversarial loss: 0.523676\n",
      "epoch 53; iter: 0; batch classifier loss: 0.419430; batch adversarial loss: 0.581210\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434606; batch adversarial loss: 0.620562\n",
      "epoch 55; iter: 0; batch classifier loss: 0.478552; batch adversarial loss: 0.528234\n",
      "epoch 56; iter: 0; batch classifier loss: 0.342942; batch adversarial loss: 0.526410\n",
      "epoch 57; iter: 0; batch classifier loss: 0.407450; batch adversarial loss: 0.577238\n",
      "epoch 58; iter: 0; batch classifier loss: 0.391660; batch adversarial loss: 0.546183\n",
      "epoch 59; iter: 0; batch classifier loss: 0.401675; batch adversarial loss: 0.560623\n",
      "epoch 60; iter: 0; batch classifier loss: 0.371257; batch adversarial loss: 0.617636\n",
      "epoch 61; iter: 0; batch classifier loss: 0.405785; batch adversarial loss: 0.608894\n",
      "epoch 62; iter: 0; batch classifier loss: 0.443896; batch adversarial loss: 0.614483\n",
      "epoch 63; iter: 0; batch classifier loss: 0.381784; batch adversarial loss: 0.632892\n",
      "epoch 64; iter: 0; batch classifier loss: 0.450933; batch adversarial loss: 0.578683\n",
      "epoch 65; iter: 0; batch classifier loss: 0.417695; batch adversarial loss: 0.617804\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407813; batch adversarial loss: 0.596371\n",
      "epoch 67; iter: 0; batch classifier loss: 0.328335; batch adversarial loss: 0.536791\n",
      "epoch 68; iter: 0; batch classifier loss: 0.482531; batch adversarial loss: 0.490384\n",
      "epoch 69; iter: 0; batch classifier loss: 0.401254; batch adversarial loss: 0.584071\n",
      "epoch 70; iter: 0; batch classifier loss: 0.356355; batch adversarial loss: 0.615447\n",
      "epoch 71; iter: 0; batch classifier loss: 0.432405; batch adversarial loss: 0.526268\n",
      "epoch 72; iter: 0; batch classifier loss: 0.376855; batch adversarial loss: 0.552521\n",
      "epoch 73; iter: 0; batch classifier loss: 0.281654; batch adversarial loss: 0.566534\n",
      "epoch 74; iter: 0; batch classifier loss: 0.494070; batch adversarial loss: 0.582713\n",
      "epoch 75; iter: 0; batch classifier loss: 0.326612; batch adversarial loss: 0.536702\n",
      "epoch 76; iter: 0; batch classifier loss: 0.379743; batch adversarial loss: 0.559043\n",
      "epoch 77; iter: 0; batch classifier loss: 0.376127; batch adversarial loss: 0.477434\n",
      "epoch 78; iter: 0; batch classifier loss: 0.438985; batch adversarial loss: 0.544470\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375856; batch adversarial loss: 0.598352\n",
      "epoch 80; iter: 0; batch classifier loss: 0.299472; batch adversarial loss: 0.599593\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408541; batch adversarial loss: 0.591265\n",
      "epoch 82; iter: 0; batch classifier loss: 0.375128; batch adversarial loss: 0.524261\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404386; batch adversarial loss: 0.612001\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380392; batch adversarial loss: 0.599786\n",
      "epoch 85; iter: 0; batch classifier loss: 0.280978; batch adversarial loss: 0.599344\n",
      "epoch 86; iter: 0; batch classifier loss: 0.321848; batch adversarial loss: 0.612801\n",
      "epoch 87; iter: 0; batch classifier loss: 0.394592; batch adversarial loss: 0.590352\n",
      "epoch 88; iter: 0; batch classifier loss: 0.433888; batch adversarial loss: 0.483548\n",
      "epoch 89; iter: 0; batch classifier loss: 0.366335; batch adversarial loss: 0.538576\n",
      "epoch 90; iter: 0; batch classifier loss: 0.363807; batch adversarial loss: 0.537068\n",
      "epoch 91; iter: 0; batch classifier loss: 0.374854; batch adversarial loss: 0.601404\n",
      "epoch 92; iter: 0; batch classifier loss: 0.346251; batch adversarial loss: 0.619852\n",
      "epoch 93; iter: 0; batch classifier loss: 0.497428; batch adversarial loss: 0.547303\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384474; batch adversarial loss: 0.495309\n",
      "epoch 95; iter: 0; batch classifier loss: 0.418681; batch adversarial loss: 0.567856\n",
      "epoch 96; iter: 0; batch classifier loss: 0.362563; batch adversarial loss: 0.573641\n",
      "epoch 97; iter: 0; batch classifier loss: 0.402158; batch adversarial loss: 0.631508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.360093; batch adversarial loss: 0.509334\n",
      "epoch 99; iter: 0; batch classifier loss: 0.373036; batch adversarial loss: 0.539438\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.707096; batch adversarial loss: 0.852766\n",
      "epoch 2; iter: 0; batch classifier loss: 0.692292; batch adversarial loss: 0.774329\n",
      "epoch 3; iter: 0; batch classifier loss: 0.523076; batch adversarial loss: 0.736114\n",
      "epoch 4; iter: 0; batch classifier loss: 0.469810; batch adversarial loss: 0.722665\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495663; batch adversarial loss: 0.655951\n",
      "epoch 6; iter: 0; batch classifier loss: 0.607755; batch adversarial loss: 0.667556\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494111; batch adversarial loss: 0.658243\n",
      "epoch 8; iter: 0; batch classifier loss: 0.484834; batch adversarial loss: 0.634490\n",
      "epoch 9; iter: 0; batch classifier loss: 0.467608; batch adversarial loss: 0.654164\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464957; batch adversarial loss: 0.656883\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576298; batch adversarial loss: 0.611752\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551587; batch adversarial loss: 0.622065\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540371; batch adversarial loss: 0.625068\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500717; batch adversarial loss: 0.605566\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530653; batch adversarial loss: 0.583588\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498442; batch adversarial loss: 0.554240\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510077; batch adversarial loss: 0.589529\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477384; batch adversarial loss: 0.532208\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438854; batch adversarial loss: 0.566610\n",
      "epoch 20; iter: 0; batch classifier loss: 0.450095; batch adversarial loss: 0.602822\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490918; batch adversarial loss: 0.576964\n",
      "epoch 22; iter: 0; batch classifier loss: 0.432528; batch adversarial loss: 0.544037\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475776; batch adversarial loss: 0.516772\n",
      "epoch 24; iter: 0; batch classifier loss: 0.400985; batch adversarial loss: 0.510753\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428638; batch adversarial loss: 0.512927\n",
      "epoch 26; iter: 0; batch classifier loss: 0.389626; batch adversarial loss: 0.578318\n",
      "epoch 27; iter: 0; batch classifier loss: 0.432344; batch adversarial loss: 0.601755\n",
      "epoch 28; iter: 0; batch classifier loss: 0.532757; batch adversarial loss: 0.581575\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477883; batch adversarial loss: 0.564283\n",
      "epoch 30; iter: 0; batch classifier loss: 0.466940; batch adversarial loss: 0.579978\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484006; batch adversarial loss: 0.568249\n",
      "epoch 32; iter: 0; batch classifier loss: 0.546770; batch adversarial loss: 0.588028\n",
      "epoch 33; iter: 0; batch classifier loss: 0.563257; batch adversarial loss: 0.609236\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471821; batch adversarial loss: 0.661904\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485994; batch adversarial loss: 0.633195\n",
      "epoch 36; iter: 0; batch classifier loss: 0.600917; batch adversarial loss: 0.655953\n",
      "epoch 37; iter: 0; batch classifier loss: 0.802126; batch adversarial loss: 0.730457\n",
      "epoch 38; iter: 0; batch classifier loss: 0.784670; batch adversarial loss: 0.596773\n",
      "epoch 39; iter: 0; batch classifier loss: 0.737074; batch adversarial loss: 0.699037\n",
      "epoch 40; iter: 0; batch classifier loss: 0.779823; batch adversarial loss: 0.667747\n",
      "epoch 41; iter: 0; batch classifier loss: 0.606276; batch adversarial loss: 0.547211\n",
      "epoch 42; iter: 0; batch classifier loss: 0.691374; batch adversarial loss: 0.605887\n",
      "epoch 43; iter: 0; batch classifier loss: 0.819678; batch adversarial loss: 0.568127\n",
      "epoch 44; iter: 0; batch classifier loss: 0.613134; batch adversarial loss: 0.686571\n",
      "epoch 45; iter: 0; batch classifier loss: 0.481748; batch adversarial loss: 0.583040\n",
      "epoch 46; iter: 0; batch classifier loss: 0.418589; batch adversarial loss: 0.562935\n",
      "epoch 47; iter: 0; batch classifier loss: 0.358900; batch adversarial loss: 0.585313\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429393; batch adversarial loss: 0.554817\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403779; batch adversarial loss: 0.551091\n",
      "epoch 50; iter: 0; batch classifier loss: 0.431881; batch adversarial loss: 0.514876\n",
      "epoch 51; iter: 0; batch classifier loss: 0.411492; batch adversarial loss: 0.597297\n",
      "epoch 52; iter: 0; batch classifier loss: 0.414913; batch adversarial loss: 0.523724\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412947; batch adversarial loss: 0.580912\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435476; batch adversarial loss: 0.620900\n",
      "epoch 55; iter: 0; batch classifier loss: 0.478539; batch adversarial loss: 0.528237\n",
      "epoch 56; iter: 0; batch classifier loss: 0.346302; batch adversarial loss: 0.526605\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403996; batch adversarial loss: 0.577272\n",
      "epoch 58; iter: 0; batch classifier loss: 0.393888; batch adversarial loss: 0.546330\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408320; batch adversarial loss: 0.560941\n",
      "epoch 60; iter: 0; batch classifier loss: 0.365426; batch adversarial loss: 0.617348\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406147; batch adversarial loss: 0.609084\n",
      "epoch 62; iter: 0; batch classifier loss: 0.453572; batch adversarial loss: 0.615107\n",
      "epoch 63; iter: 0; batch classifier loss: 0.384432; batch adversarial loss: 0.633259\n",
      "epoch 64; iter: 0; batch classifier loss: 0.444640; batch adversarial loss: 0.578296\n",
      "epoch 65; iter: 0; batch classifier loss: 0.422083; batch adversarial loss: 0.618044\n",
      "epoch 66; iter: 0; batch classifier loss: 0.398970; batch adversarial loss: 0.596034\n",
      "epoch 67; iter: 0; batch classifier loss: 0.330532; batch adversarial loss: 0.536492\n",
      "epoch 68; iter: 0; batch classifier loss: 0.488661; batch adversarial loss: 0.490330\n",
      "epoch 69; iter: 0; batch classifier loss: 0.394432; batch adversarial loss: 0.583437\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359355; batch adversarial loss: 0.615248\n",
      "epoch 71; iter: 0; batch classifier loss: 0.422089; batch adversarial loss: 0.525561\n",
      "epoch 72; iter: 0; batch classifier loss: 0.383067; batch adversarial loss: 0.552884\n",
      "epoch 73; iter: 0; batch classifier loss: 0.281764; batch adversarial loss: 0.566568\n",
      "epoch 74; iter: 0; batch classifier loss: 0.494143; batch adversarial loss: 0.583103\n",
      "epoch 75; iter: 0; batch classifier loss: 0.329690; batch adversarial loss: 0.536691\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384958; batch adversarial loss: 0.559233\n",
      "epoch 77; iter: 0; batch classifier loss: 0.382304; batch adversarial loss: 0.477866\n",
      "epoch 78; iter: 0; batch classifier loss: 0.436022; batch adversarial loss: 0.544443\n",
      "epoch 79; iter: 0; batch classifier loss: 0.362138; batch adversarial loss: 0.598400\n",
      "epoch 80; iter: 0; batch classifier loss: 0.291932; batch adversarial loss: 0.599247\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414845; batch adversarial loss: 0.590132\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368985; batch adversarial loss: 0.523973\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412185; batch adversarial loss: 0.611997\n",
      "epoch 84; iter: 0; batch classifier loss: 0.377947; batch adversarial loss: 0.599782\n",
      "epoch 85; iter: 0; batch classifier loss: 0.290442; batch adversarial loss: 0.599843\n",
      "epoch 86; iter: 0; batch classifier loss: 0.322370; batch adversarial loss: 0.613554\n",
      "epoch 87; iter: 0; batch classifier loss: 0.385148; batch adversarial loss: 0.591336\n",
      "epoch 88; iter: 0; batch classifier loss: 0.437188; batch adversarial loss: 0.483915\n",
      "epoch 89; iter: 0; batch classifier loss: 0.360293; batch adversarial loss: 0.538414\n",
      "epoch 90; iter: 0; batch classifier loss: 0.365872; batch adversarial loss: 0.536953\n",
      "epoch 91; iter: 0; batch classifier loss: 0.370167; batch adversarial loss: 0.601755\n",
      "epoch 92; iter: 0; batch classifier loss: 0.346077; batch adversarial loss: 0.619907\n",
      "epoch 93; iter: 0; batch classifier loss: 0.492032; batch adversarial loss: 0.547569\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384107; batch adversarial loss: 0.495046\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420384; batch adversarial loss: 0.567896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.362225; batch adversarial loss: 0.573122\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399479; batch adversarial loss: 0.633840\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368463; batch adversarial loss: 0.509805\n",
      "epoch 99; iter: 0; batch classifier loss: 0.362658; batch adversarial loss: 0.540078\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.702359; batch adversarial loss: 0.849689\n",
      "epoch 2; iter: 0; batch classifier loss: 0.686655; batch adversarial loss: 0.772649\n",
      "epoch 3; iter: 0; batch classifier loss: 0.519583; batch adversarial loss: 0.734987\n",
      "epoch 4; iter: 0; batch classifier loss: 0.469750; batch adversarial loss: 0.720776\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495583; batch adversarial loss: 0.655626\n",
      "epoch 6; iter: 0; batch classifier loss: 0.608457; batch adversarial loss: 0.667181\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495767; batch adversarial loss: 0.657686\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486365; batch adversarial loss: 0.634141\n",
      "epoch 9; iter: 0; batch classifier loss: 0.469404; batch adversarial loss: 0.653815\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464973; batch adversarial loss: 0.656943\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576774; batch adversarial loss: 0.611658\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550833; batch adversarial loss: 0.622229\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540088; batch adversarial loss: 0.625136\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500866; batch adversarial loss: 0.605474\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530748; batch adversarial loss: 0.583353\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498968; batch adversarial loss: 0.553671\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511931; batch adversarial loss: 0.588632\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477449; batch adversarial loss: 0.531306\n",
      "epoch 19; iter: 0; batch classifier loss: 0.439634; batch adversarial loss: 0.565397\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448714; batch adversarial loss: 0.602334\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491254; batch adversarial loss: 0.576638\n",
      "epoch 22; iter: 0; batch classifier loss: 0.432313; batch adversarial loss: 0.543734\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476155; batch adversarial loss: 0.515783\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402865; batch adversarial loss: 0.509761\n",
      "epoch 25; iter: 0; batch classifier loss: 0.430832; batch adversarial loss: 0.511499\n",
      "epoch 26; iter: 0; batch classifier loss: 0.387927; batch adversarial loss: 0.576350\n",
      "epoch 27; iter: 0; batch classifier loss: 0.430508; batch adversarial loss: 0.600920\n",
      "epoch 28; iter: 0; batch classifier loss: 0.528936; batch adversarial loss: 0.579611\n",
      "epoch 29; iter: 0; batch classifier loss: 0.473953; batch adversarial loss: 0.561892\n",
      "epoch 30; iter: 0; batch classifier loss: 0.461270; batch adversarial loss: 0.575517\n",
      "epoch 31; iter: 0; batch classifier loss: 0.477951; batch adversarial loss: 0.566189\n",
      "epoch 32; iter: 0; batch classifier loss: 0.543794; batch adversarial loss: 0.587649\n",
      "epoch 33; iter: 0; batch classifier loss: 0.558028; batch adversarial loss: 0.607388\n",
      "epoch 34; iter: 0; batch classifier loss: 0.468274; batch adversarial loss: 0.659916\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472930; batch adversarial loss: 0.629590\n",
      "epoch 36; iter: 0; batch classifier loss: 0.580258; batch adversarial loss: 0.651528\n",
      "epoch 37; iter: 0; batch classifier loss: 0.782099; batch adversarial loss: 0.731651\n",
      "epoch 38; iter: 0; batch classifier loss: 0.778124; batch adversarial loss: 0.598930\n",
      "epoch 39; iter: 0; batch classifier loss: 0.740658; batch adversarial loss: 0.704153\n",
      "epoch 40; iter: 0; batch classifier loss: 0.784624; batch adversarial loss: 0.672247\n",
      "epoch 41; iter: 0; batch classifier loss: 0.610573; batch adversarial loss: 0.550171\n",
      "epoch 42; iter: 0; batch classifier loss: 0.689145; batch adversarial loss: 0.608617\n",
      "epoch 43; iter: 0; batch classifier loss: 0.815489; batch adversarial loss: 0.570474\n",
      "epoch 44; iter: 0; batch classifier loss: 0.701396; batch adversarial loss: 0.688402\n",
      "epoch 45; iter: 0; batch classifier loss: 0.484810; batch adversarial loss: 0.583143\n",
      "epoch 46; iter: 0; batch classifier loss: 0.421234; batch adversarial loss: 0.563269\n",
      "epoch 47; iter: 0; batch classifier loss: 0.361121; batch adversarial loss: 0.585260\n",
      "epoch 48; iter: 0; batch classifier loss: 0.433040; batch adversarial loss: 0.554957\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406740; batch adversarial loss: 0.551132\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428270; batch adversarial loss: 0.514826\n",
      "epoch 51; iter: 0; batch classifier loss: 0.412298; batch adversarial loss: 0.597282\n",
      "epoch 52; iter: 0; batch classifier loss: 0.406242; batch adversarial loss: 0.523509\n",
      "epoch 53; iter: 0; batch classifier loss: 0.413600; batch adversarial loss: 0.580959\n",
      "epoch 54; iter: 0; batch classifier loss: 0.432581; batch adversarial loss: 0.621117\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476752; batch adversarial loss: 0.528365\n",
      "epoch 56; iter: 0; batch classifier loss: 0.339401; batch adversarial loss: 0.526133\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401717; batch adversarial loss: 0.577180\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389541; batch adversarial loss: 0.546186\n",
      "epoch 59; iter: 0; batch classifier loss: 0.401182; batch adversarial loss: 0.560616\n",
      "epoch 60; iter: 0; batch classifier loss: 0.370040; batch adversarial loss: 0.617598\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407229; batch adversarial loss: 0.608860\n",
      "epoch 62; iter: 0; batch classifier loss: 0.448462; batch adversarial loss: 0.614126\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385805; batch adversarial loss: 0.632971\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449107; batch adversarial loss: 0.578522\n",
      "epoch 65; iter: 0; batch classifier loss: 0.410919; batch adversarial loss: 0.617436\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407050; batch adversarial loss: 0.596013\n",
      "epoch 67; iter: 0; batch classifier loss: 0.334217; batch adversarial loss: 0.537531\n",
      "epoch 68; iter: 0; batch classifier loss: 0.485044; batch adversarial loss: 0.490741\n",
      "epoch 69; iter: 0; batch classifier loss: 0.398921; batch adversarial loss: 0.583872\n",
      "epoch 70; iter: 0; batch classifier loss: 0.363059; batch adversarial loss: 0.615604\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431960; batch adversarial loss: 0.525882\n",
      "epoch 72; iter: 0; batch classifier loss: 0.384832; batch adversarial loss: 0.553086\n",
      "epoch 73; iter: 0; batch classifier loss: 0.283967; batch adversarial loss: 0.567065\n",
      "epoch 74; iter: 0; batch classifier loss: 0.493634; batch adversarial loss: 0.582788\n",
      "epoch 75; iter: 0; batch classifier loss: 0.326206; batch adversarial loss: 0.536997\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384866; batch adversarial loss: 0.559142\n",
      "epoch 77; iter: 0; batch classifier loss: 0.379946; batch adversarial loss: 0.477328\n",
      "epoch 78; iter: 0; batch classifier loss: 0.441038; batch adversarial loss: 0.544118\n",
      "epoch 79; iter: 0; batch classifier loss: 0.371571; batch adversarial loss: 0.598465\n",
      "epoch 80; iter: 0; batch classifier loss: 0.302960; batch adversarial loss: 0.599845\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417726; batch adversarial loss: 0.591332\n",
      "epoch 82; iter: 0; batch classifier loss: 0.370057; batch adversarial loss: 0.524595\n",
      "epoch 83; iter: 0; batch classifier loss: 0.414306; batch adversarial loss: 0.612541\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382659; batch adversarial loss: 0.599555\n",
      "epoch 85; iter: 0; batch classifier loss: 0.299345; batch adversarial loss: 0.600899\n",
      "epoch 86; iter: 0; batch classifier loss: 0.321698; batch adversarial loss: 0.613948\n",
      "epoch 87; iter: 0; batch classifier loss: 0.386866; batch adversarial loss: 0.591433\n",
      "epoch 88; iter: 0; batch classifier loss: 0.446693; batch adversarial loss: 0.485819\n",
      "epoch 89; iter: 0; batch classifier loss: 0.361383; batch adversarial loss: 0.538817\n",
      "epoch 90; iter: 0; batch classifier loss: 0.364971; batch adversarial loss: 0.536858\n",
      "epoch 91; iter: 0; batch classifier loss: 0.373842; batch adversarial loss: 0.601722\n",
      "epoch 92; iter: 0; batch classifier loss: 0.344672; batch adversarial loss: 0.620324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.491748; batch adversarial loss: 0.546930\n",
      "epoch 94; iter: 0; batch classifier loss: 0.391202; batch adversarial loss: 0.495486\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407737; batch adversarial loss: 0.566649\n",
      "epoch 96; iter: 0; batch classifier loss: 0.367567; batch adversarial loss: 0.573442\n",
      "epoch 97; iter: 0; batch classifier loss: 0.409237; batch adversarial loss: 0.632533\n",
      "epoch 98; iter: 0; batch classifier loss: 0.366160; batch adversarial loss: 0.510448\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376739; batch adversarial loss: 0.540093\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.694676; batch adversarial loss: 0.844783\n",
      "epoch 2; iter: 0; batch classifier loss: 0.676909; batch adversarial loss: 0.769633\n",
      "epoch 3; iter: 0; batch classifier loss: 0.514611; batch adversarial loss: 0.732562\n",
      "epoch 4; iter: 0; batch classifier loss: 0.468754; batch adversarial loss: 0.718388\n",
      "epoch 5; iter: 0; batch classifier loss: 0.496396; batch adversarial loss: 0.655101\n",
      "epoch 6; iter: 0; batch classifier loss: 0.610943; batch adversarial loss: 0.666054\n",
      "epoch 7; iter: 0; batch classifier loss: 0.497387; batch adversarial loss: 0.657103\n",
      "epoch 8; iter: 0; batch classifier loss: 0.487460; batch adversarial loss: 0.633766\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471347; batch adversarial loss: 0.653336\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466104; batch adversarial loss: 0.656737\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577451; batch adversarial loss: 0.611491\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551560; batch adversarial loss: 0.621999\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540540; batch adversarial loss: 0.625037\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500809; batch adversarial loss: 0.605351\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530372; batch adversarial loss: 0.582857\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500494; batch adversarial loss: 0.552357\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510097; batch adversarial loss: 0.587297\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479418; batch adversarial loss: 0.528991\n",
      "epoch 19; iter: 0; batch classifier loss: 0.439504; batch adversarial loss: 0.564292\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448976; batch adversarial loss: 0.601181\n",
      "epoch 21; iter: 0; batch classifier loss: 0.489950; batch adversarial loss: 0.575613\n",
      "epoch 22; iter: 0; batch classifier loss: 0.431888; batch adversarial loss: 0.542222\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474509; batch adversarial loss: 0.514797\n",
      "epoch 24; iter: 0; batch classifier loss: 0.400716; batch adversarial loss: 0.508397\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428317; batch adversarial loss: 0.510813\n",
      "epoch 26; iter: 0; batch classifier loss: 0.388766; batch adversarial loss: 0.576073\n",
      "epoch 27; iter: 0; batch classifier loss: 0.428209; batch adversarial loss: 0.598568\n",
      "epoch 28; iter: 0; batch classifier loss: 0.524771; batch adversarial loss: 0.577614\n",
      "epoch 29; iter: 0; batch classifier loss: 0.464850; batch adversarial loss: 0.557346\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454731; batch adversarial loss: 0.569076\n",
      "epoch 31; iter: 0; batch classifier loss: 0.468913; batch adversarial loss: 0.561356\n",
      "epoch 32; iter: 0; batch classifier loss: 0.537391; batch adversarial loss: 0.585773\n",
      "epoch 33; iter: 0; batch classifier loss: 0.545693; batch adversarial loss: 0.602224\n",
      "epoch 34; iter: 0; batch classifier loss: 0.455275; batch adversarial loss: 0.653961\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442799; batch adversarial loss: 0.616217\n",
      "epoch 36; iter: 0; batch classifier loss: 0.537465; batch adversarial loss: 0.638148\n",
      "epoch 37; iter: 0; batch classifier loss: 0.688892; batch adversarial loss: 0.720865\n",
      "epoch 38; iter: 0; batch classifier loss: 0.736492; batch adversarial loss: 0.598796\n",
      "epoch 39; iter: 0; batch classifier loss: 0.709365; batch adversarial loss: 0.713013\n",
      "epoch 40; iter: 0; batch classifier loss: 0.774847; batch adversarial loss: 0.684835\n",
      "epoch 41; iter: 0; batch classifier loss: 0.609808; batch adversarial loss: 0.557615\n",
      "epoch 42; iter: 0; batch classifier loss: 0.691522; batch adversarial loss: 0.617493\n",
      "epoch 43; iter: 0; batch classifier loss: 0.794358; batch adversarial loss: 0.577456\n",
      "epoch 44; iter: 0; batch classifier loss: 0.798271; batch adversarial loss: 0.697701\n",
      "epoch 45; iter: 0; batch classifier loss: 0.580074; batch adversarial loss: 0.585311\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431437; batch adversarial loss: 0.563887\n",
      "epoch 47; iter: 0; batch classifier loss: 0.363763; batch adversarial loss: 0.585170\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434191; batch adversarial loss: 0.554984\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407425; batch adversarial loss: 0.551364\n",
      "epoch 50; iter: 0; batch classifier loss: 0.426289; batch adversarial loss: 0.515251\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414362; batch adversarial loss: 0.596464\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408742; batch adversarial loss: 0.523511\n",
      "epoch 53; iter: 0; batch classifier loss: 0.411113; batch adversarial loss: 0.580172\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434806; batch adversarial loss: 0.620247\n",
      "epoch 55; iter: 0; batch classifier loss: 0.474413; batch adversarial loss: 0.528257\n",
      "epoch 56; iter: 0; batch classifier loss: 0.343029; batch adversarial loss: 0.526078\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404107; batch adversarial loss: 0.576945\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390486; batch adversarial loss: 0.546564\n",
      "epoch 59; iter: 0; batch classifier loss: 0.401154; batch adversarial loss: 0.559367\n",
      "epoch 60; iter: 0; batch classifier loss: 0.361879; batch adversarial loss: 0.617224\n",
      "epoch 61; iter: 0; batch classifier loss: 0.398845; batch adversarial loss: 0.607852\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445259; batch adversarial loss: 0.613590\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374096; batch adversarial loss: 0.632161\n",
      "epoch 64; iter: 0; batch classifier loss: 0.441999; batch adversarial loss: 0.577393\n",
      "epoch 65; iter: 0; batch classifier loss: 0.423291; batch adversarial loss: 0.617619\n",
      "epoch 66; iter: 0; batch classifier loss: 0.403972; batch adversarial loss: 0.595968\n",
      "epoch 67; iter: 0; batch classifier loss: 0.330524; batch adversarial loss: 0.537069\n",
      "epoch 68; iter: 0; batch classifier loss: 0.490947; batch adversarial loss: 0.490291\n",
      "epoch 69; iter: 0; batch classifier loss: 0.402110; batch adversarial loss: 0.583512\n",
      "epoch 70; iter: 0; batch classifier loss: 0.353342; batch adversarial loss: 0.614721\n",
      "epoch 71; iter: 0; batch classifier loss: 0.431309; batch adversarial loss: 0.525799\n",
      "epoch 72; iter: 0; batch classifier loss: 0.381067; batch adversarial loss: 0.551864\n",
      "epoch 73; iter: 0; batch classifier loss: 0.286687; batch adversarial loss: 0.566256\n",
      "epoch 74; iter: 0; batch classifier loss: 0.485290; batch adversarial loss: 0.582340\n",
      "epoch 75; iter: 0; batch classifier loss: 0.316753; batch adversarial loss: 0.536067\n",
      "epoch 76; iter: 0; batch classifier loss: 0.379585; batch adversarial loss: 0.559190\n",
      "epoch 77; iter: 0; batch classifier loss: 0.381080; batch adversarial loss: 0.477513\n",
      "epoch 78; iter: 0; batch classifier loss: 0.448629; batch adversarial loss: 0.544480\n",
      "epoch 79; iter: 0; batch classifier loss: 0.365436; batch adversarial loss: 0.598458\n",
      "epoch 80; iter: 0; batch classifier loss: 0.297955; batch adversarial loss: 0.598812\n",
      "epoch 81; iter: 0; batch classifier loss: 0.413431; batch adversarial loss: 0.589690\n",
      "epoch 82; iter: 0; batch classifier loss: 0.361474; batch adversarial loss: 0.524110\n",
      "epoch 83; iter: 0; batch classifier loss: 0.415128; batch adversarial loss: 0.611618\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371949; batch adversarial loss: 0.599031\n",
      "epoch 85; iter: 0; batch classifier loss: 0.291062; batch adversarial loss: 0.599241\n",
      "epoch 86; iter: 0; batch classifier loss: 0.328270; batch adversarial loss: 0.614317\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380973; batch adversarial loss: 0.589102\n",
      "epoch 88; iter: 0; batch classifier loss: 0.437808; batch adversarial loss: 0.483619\n",
      "epoch 89; iter: 0; batch classifier loss: 0.357407; batch adversarial loss: 0.538679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.373505; batch adversarial loss: 0.537105\n",
      "epoch 91; iter: 0; batch classifier loss: 0.366416; batch adversarial loss: 0.600963\n",
      "epoch 92; iter: 0; batch classifier loss: 0.333389; batch adversarial loss: 0.619726\n",
      "epoch 93; iter: 0; batch classifier loss: 0.491942; batch adversarial loss: 0.547417\n",
      "epoch 94; iter: 0; batch classifier loss: 0.382632; batch adversarial loss: 0.494917\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417441; batch adversarial loss: 0.566650\n",
      "epoch 96; iter: 0; batch classifier loss: 0.356362; batch adversarial loss: 0.573077\n",
      "epoch 97; iter: 0; batch classifier loss: 0.395426; batch adversarial loss: 0.633056\n",
      "epoch 98; iter: 0; batch classifier loss: 0.361458; batch adversarial loss: 0.509453\n",
      "epoch 99; iter: 0; batch classifier loss: 0.372718; batch adversarial loss: 0.541252\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.817269; batch adversarial loss: 0.893717\n",
      "epoch 2; iter: 0; batch classifier loss: 0.807510; batch adversarial loss: 0.797995\n",
      "epoch 3; iter: 0; batch classifier loss: 0.626539; batch adversarial loss: 0.760666\n",
      "epoch 4; iter: 0; batch classifier loss: 0.526958; batch adversarial loss: 0.753261\n",
      "epoch 5; iter: 0; batch classifier loss: 0.505684; batch adversarial loss: 0.662141\n",
      "epoch 6; iter: 0; batch classifier loss: 0.586761; batch adversarial loss: 0.674572\n",
      "epoch 7; iter: 0; batch classifier loss: 0.479864; batch adversarial loss: 0.662883\n",
      "epoch 8; iter: 0; batch classifier loss: 0.472304; batch adversarial loss: 0.638517\n",
      "epoch 9; iter: 0; batch classifier loss: 0.444839; batch adversarial loss: 0.660676\n",
      "epoch 10; iter: 0; batch classifier loss: 0.452288; batch adversarial loss: 0.659117\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560240; batch adversarial loss: 0.615339\n",
      "epoch 12; iter: 0; batch classifier loss: 0.541305; batch adversarial loss: 0.623766\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536704; batch adversarial loss: 0.625549\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499520; batch adversarial loss: 0.605698\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521967; batch adversarial loss: 0.587348\n",
      "epoch 16; iter: 0; batch classifier loss: 0.486779; batch adversarial loss: 0.562406\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509517; batch adversarial loss: 0.601181\n",
      "epoch 18; iter: 0; batch classifier loss: 0.468079; batch adversarial loss: 0.549954\n",
      "epoch 19; iter: 0; batch classifier loss: 0.434093; batch adversarial loss: 0.578368\n",
      "epoch 20; iter: 0; batch classifier loss: 0.464632; batch adversarial loss: 0.613160\n",
      "epoch 21; iter: 0; batch classifier loss: 0.496780; batch adversarial loss: 0.585726\n",
      "epoch 22; iter: 0; batch classifier loss: 0.435577; batch adversarial loss: 0.557036\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484819; batch adversarial loss: 0.530024\n",
      "epoch 24; iter: 0; batch classifier loss: 0.404392; batch adversarial loss: 0.523657\n",
      "epoch 25; iter: 0; batch classifier loss: 0.438485; batch adversarial loss: 0.527923\n",
      "epoch 26; iter: 0; batch classifier loss: 0.431552; batch adversarial loss: 0.613872\n",
      "epoch 27; iter: 0; batch classifier loss: 0.575681; batch adversarial loss: 0.682794\n",
      "epoch 28; iter: 0; batch classifier loss: 0.626556; batch adversarial loss: 0.625528\n",
      "epoch 29; iter: 0; batch classifier loss: 0.609428; batch adversarial loss: 0.625550\n",
      "epoch 30; iter: 0; batch classifier loss: 0.685200; batch adversarial loss: 0.645637\n",
      "epoch 31; iter: 0; batch classifier loss: 0.767798; batch adversarial loss: 0.628113\n",
      "epoch 32; iter: 0; batch classifier loss: 0.856562; batch adversarial loss: 0.630501\n",
      "epoch 33; iter: 0; batch classifier loss: 0.799802; batch adversarial loss: 0.629991\n",
      "epoch 34; iter: 0; batch classifier loss: 0.697081; batch adversarial loss: 0.670062\n",
      "epoch 35; iter: 0; batch classifier loss: 0.633511; batch adversarial loss: 0.616313\n",
      "epoch 36; iter: 0; batch classifier loss: 0.597578; batch adversarial loss: 0.602908\n",
      "epoch 37; iter: 0; batch classifier loss: 0.609711; batch adversarial loss: 0.643280\n",
      "epoch 38; iter: 0; batch classifier loss: 0.587486; batch adversarial loss: 0.547403\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459441; batch adversarial loss: 0.639224\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456891; batch adversarial loss: 0.617914\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430529; batch adversarial loss: 0.518302\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446813; batch adversarial loss: 0.587476\n",
      "epoch 43; iter: 0; batch classifier loss: 0.578787; batch adversarial loss: 0.558661\n",
      "epoch 44; iter: 0; batch classifier loss: 0.553154; batch adversarial loss: 0.696090\n",
      "epoch 45; iter: 0; batch classifier loss: 0.502798; batch adversarial loss: 0.583862\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430089; batch adversarial loss: 0.561924\n",
      "epoch 47; iter: 0; batch classifier loss: 0.348135; batch adversarial loss: 0.587103\n",
      "epoch 48; iter: 0; batch classifier loss: 0.422678; batch adversarial loss: 0.553707\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392890; batch adversarial loss: 0.550409\n",
      "epoch 50; iter: 0; batch classifier loss: 0.442674; batch adversarial loss: 0.513661\n",
      "epoch 51; iter: 0; batch classifier loss: 0.417389; batch adversarial loss: 0.599963\n",
      "epoch 52; iter: 0; batch classifier loss: 0.422177; batch adversarial loss: 0.523892\n",
      "epoch 53; iter: 0; batch classifier loss: 0.404282; batch adversarial loss: 0.582506\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428018; batch adversarial loss: 0.623704\n",
      "epoch 55; iter: 0; batch classifier loss: 0.489523; batch adversarial loss: 0.527940\n",
      "epoch 56; iter: 0; batch classifier loss: 0.347602; batch adversarial loss: 0.527561\n",
      "epoch 57; iter: 0; batch classifier loss: 0.406140; batch adversarial loss: 0.578578\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398066; batch adversarial loss: 0.545245\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420148; batch adversarial loss: 0.563068\n",
      "epoch 60; iter: 0; batch classifier loss: 0.375153; batch adversarial loss: 0.618014\n",
      "epoch 61; iter: 0; batch classifier loss: 0.404515; batch adversarial loss: 0.611029\n",
      "epoch 62; iter: 0; batch classifier loss: 0.457692; batch adversarial loss: 0.615979\n",
      "epoch 63; iter: 0; batch classifier loss: 0.385971; batch adversarial loss: 0.634247\n",
      "epoch 64; iter: 0; batch classifier loss: 0.464282; batch adversarial loss: 0.581939\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431210; batch adversarial loss: 0.619672\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411471; batch adversarial loss: 0.597705\n",
      "epoch 67; iter: 0; batch classifier loss: 0.345122; batch adversarial loss: 0.538277\n",
      "epoch 68; iter: 0; batch classifier loss: 0.487434; batch adversarial loss: 0.491283\n",
      "epoch 69; iter: 0; batch classifier loss: 0.413315; batch adversarial loss: 0.587164\n",
      "epoch 70; iter: 0; batch classifier loss: 0.363118; batch adversarial loss: 0.617043\n",
      "epoch 71; iter: 0; batch classifier loss: 0.446767; batch adversarial loss: 0.528337\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379489; batch adversarial loss: 0.555681\n",
      "epoch 73; iter: 0; batch classifier loss: 0.308298; batch adversarial loss: 0.568165\n",
      "epoch 74; iter: 0; batch classifier loss: 0.494219; batch adversarial loss: 0.584110\n",
      "epoch 75; iter: 0; batch classifier loss: 0.323517; batch adversarial loss: 0.538307\n",
      "epoch 76; iter: 0; batch classifier loss: 0.390568; batch adversarial loss: 0.562882\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395746; batch adversarial loss: 0.478800\n",
      "epoch 78; iter: 0; batch classifier loss: 0.477477; batch adversarial loss: 0.546094\n",
      "epoch 79; iter: 0; batch classifier loss: 0.378097; batch adversarial loss: 0.600111\n",
      "epoch 80; iter: 0; batch classifier loss: 0.311788; batch adversarial loss: 0.603066\n",
      "epoch 81; iter: 0; batch classifier loss: 0.447341; batch adversarial loss: 0.597587\n",
      "epoch 82; iter: 0; batch classifier loss: 0.426795; batch adversarial loss: 0.528991\n",
      "epoch 83; iter: 0; batch classifier loss: 0.434761; batch adversarial loss: 0.617567\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435221; batch adversarial loss: 0.604097\n",
      "epoch 85; iter: 0; batch classifier loss: 0.316966; batch adversarial loss: 0.604776\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412511; batch adversarial loss: 0.620874\n",
      "epoch 87; iter: 0; batch classifier loss: 0.407978; batch adversarial loss: 0.595055\n",
      "epoch 88; iter: 0; batch classifier loss: 0.496436; batch adversarial loss: 0.493048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.398928; batch adversarial loss: 0.543325\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404699; batch adversarial loss: 0.541157\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380417; batch adversarial loss: 0.606768\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402746; batch adversarial loss: 0.628274\n",
      "epoch 93; iter: 0; batch classifier loss: 0.535551; batch adversarial loss: 0.551671\n",
      "epoch 94; iter: 0; batch classifier loss: 0.429702; batch adversarial loss: 0.501365\n",
      "epoch 95; iter: 0; batch classifier loss: 0.481938; batch adversarial loss: 0.577854\n",
      "epoch 96; iter: 0; batch classifier loss: 0.399315; batch adversarial loss: 0.574748\n",
      "epoch 97; iter: 0; batch classifier loss: 0.446040; batch adversarial loss: 0.640450\n",
      "epoch 98; iter: 0; batch classifier loss: 0.411467; batch adversarial loss: 0.514169\n",
      "epoch 99; iter: 0; batch classifier loss: 0.434119; batch adversarial loss: 0.548224\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.713578; batch adversarial loss: 0.856431\n",
      "epoch 2; iter: 0; batch classifier loss: 0.700231; batch adversarial loss: 0.776417\n",
      "epoch 3; iter: 0; batch classifier loss: 0.528695; batch adversarial loss: 0.737930\n",
      "epoch 4; iter: 0; batch classifier loss: 0.470948; batch adversarial loss: 0.724823\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495414; batch adversarial loss: 0.656345\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606451; batch adversarial loss: 0.668139\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492625; batch adversarial loss: 0.658657\n",
      "epoch 8; iter: 0; batch classifier loss: 0.483407; batch adversarial loss: 0.634907\n",
      "epoch 9; iter: 0; batch classifier loss: 0.466451; batch adversarial loss: 0.654449\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464062; batch adversarial loss: 0.656962\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575342; batch adversarial loss: 0.612001\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551002; batch adversarial loss: 0.622226\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540090; batch adversarial loss: 0.625111\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500528; batch adversarial loss: 0.605619\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530946; batch adversarial loss: 0.583869\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498041; batch adversarial loss: 0.555036\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510366; batch adversarial loss: 0.590440\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477711; batch adversarial loss: 0.532790\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438467; batch adversarial loss: 0.566768\n",
      "epoch 20; iter: 0; batch classifier loss: 0.453230; batch adversarial loss: 0.603507\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495127; batch adversarial loss: 0.577576\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437245; batch adversarial loss: 0.544079\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476051; batch adversarial loss: 0.517681\n",
      "epoch 24; iter: 0; batch classifier loss: 0.403521; batch adversarial loss: 0.510474\n",
      "epoch 25; iter: 0; batch classifier loss: 0.431620; batch adversarial loss: 0.512656\n",
      "epoch 26; iter: 0; batch classifier loss: 0.393852; batch adversarial loss: 0.579433\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439504; batch adversarial loss: 0.605181\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538499; batch adversarial loss: 0.584961\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485532; batch adversarial loss: 0.567369\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477669; batch adversarial loss: 0.585075\n",
      "epoch 31; iter: 0; batch classifier loss: 0.488358; batch adversarial loss: 0.570881\n",
      "epoch 32; iter: 0; batch classifier loss: 0.549657; batch adversarial loss: 0.592241\n",
      "epoch 33; iter: 0; batch classifier loss: 0.570064; batch adversarial loss: 0.612511\n",
      "epoch 34; iter: 0; batch classifier loss: 0.493652; batch adversarial loss: 0.669629\n",
      "epoch 35; iter: 0; batch classifier loss: 0.522137; batch adversarial loss: 0.647360\n",
      "epoch 36; iter: 0; batch classifier loss: 0.642662; batch adversarial loss: 0.663990\n",
      "epoch 37; iter: 0; batch classifier loss: 0.836669; batch adversarial loss: 0.727291\n",
      "epoch 38; iter: 0; batch classifier loss: 0.792188; batch adversarial loss: 0.591476\n",
      "epoch 39; iter: 0; batch classifier loss: 0.740532; batch adversarial loss: 0.691363\n",
      "epoch 40; iter: 0; batch classifier loss: 0.776990; batch adversarial loss: 0.659424\n",
      "epoch 41; iter: 0; batch classifier loss: 0.609015; batch adversarial loss: 0.542795\n",
      "epoch 42; iter: 0; batch classifier loss: 0.686772; batch adversarial loss: 0.600529\n",
      "epoch 43; iter: 0; batch classifier loss: 0.813265; batch adversarial loss: 0.563883\n",
      "epoch 44; iter: 0; batch classifier loss: 0.505951; batch adversarial loss: 0.685691\n",
      "epoch 45; iter: 0; batch classifier loss: 0.476371; batch adversarial loss: 0.582998\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420043; batch adversarial loss: 0.562838\n",
      "epoch 47; iter: 0; batch classifier loss: 0.359060; batch adversarial loss: 0.585631\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429161; batch adversarial loss: 0.554809\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401673; batch adversarial loss: 0.551167\n",
      "epoch 50; iter: 0; batch classifier loss: 0.439120; batch adversarial loss: 0.514902\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416846; batch adversarial loss: 0.597760\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415802; batch adversarial loss: 0.524068\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412041; batch adversarial loss: 0.581669\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438233; batch adversarial loss: 0.621579\n",
      "epoch 55; iter: 0; batch classifier loss: 0.480818; batch adversarial loss: 0.528474\n",
      "epoch 56; iter: 0; batch classifier loss: 0.347352; batch adversarial loss: 0.526642\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409350; batch adversarial loss: 0.577691\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396135; batch adversarial loss: 0.546420\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410936; batch adversarial loss: 0.561518\n",
      "epoch 60; iter: 0; batch classifier loss: 0.365199; batch adversarial loss: 0.617508\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409016; batch adversarial loss: 0.609288\n",
      "epoch 62; iter: 0; batch classifier loss: 0.443276; batch adversarial loss: 0.614613\n",
      "epoch 63; iter: 0; batch classifier loss: 0.377573; batch adversarial loss: 0.633200\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449510; batch adversarial loss: 0.579219\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420189; batch adversarial loss: 0.618699\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409691; batch adversarial loss: 0.596662\n",
      "epoch 67; iter: 0; batch classifier loss: 0.327699; batch adversarial loss: 0.536881\n",
      "epoch 68; iter: 0; batch classifier loss: 0.487094; batch adversarial loss: 0.490819\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400845; batch adversarial loss: 0.584684\n",
      "epoch 70; iter: 0; batch classifier loss: 0.354090; batch adversarial loss: 0.615430\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427278; batch adversarial loss: 0.526416\n",
      "epoch 72; iter: 0; batch classifier loss: 0.377447; batch adversarial loss: 0.553453\n",
      "epoch 73; iter: 0; batch classifier loss: 0.279407; batch adversarial loss: 0.566863\n",
      "epoch 74; iter: 0; batch classifier loss: 0.492122; batch adversarial loss: 0.583390\n",
      "epoch 75; iter: 0; batch classifier loss: 0.329710; batch adversarial loss: 0.537276\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382581; batch adversarial loss: 0.559805\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392828; batch adversarial loss: 0.478576\n",
      "epoch 78; iter: 0; batch classifier loss: 0.453151; batch adversarial loss: 0.545100\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374842; batch adversarial loss: 0.599122\n",
      "epoch 80; iter: 0; batch classifier loss: 0.297922; batch adversarial loss: 0.600392\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415601; batch adversarial loss: 0.592326\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368807; batch adversarial loss: 0.524593\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413661; batch adversarial loss: 0.614187\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393728; batch adversarial loss: 0.601044\n",
      "epoch 85; iter: 0; batch classifier loss: 0.282536; batch adversarial loss: 0.600196\n",
      "epoch 86; iter: 0; batch classifier loss: 0.320517; batch adversarial loss: 0.614020\n",
      "epoch 87; iter: 0; batch classifier loss: 0.397416; batch adversarial loss: 0.590407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.434785; batch adversarial loss: 0.484128\n",
      "epoch 89; iter: 0; batch classifier loss: 0.366433; batch adversarial loss: 0.539255\n",
      "epoch 90; iter: 0; batch classifier loss: 0.358152; batch adversarial loss: 0.536133\n",
      "epoch 91; iter: 0; batch classifier loss: 0.365702; batch adversarial loss: 0.601796\n",
      "epoch 92; iter: 0; batch classifier loss: 0.348512; batch adversarial loss: 0.620762\n",
      "epoch 93; iter: 0; batch classifier loss: 0.491775; batch adversarial loss: 0.548703\n",
      "epoch 94; iter: 0; batch classifier loss: 0.399135; batch adversarial loss: 0.496502\n",
      "epoch 95; iter: 0; batch classifier loss: 0.429722; batch adversarial loss: 0.569954\n",
      "epoch 96; iter: 0; batch classifier loss: 0.366123; batch adversarial loss: 0.573329\n",
      "epoch 97; iter: 0; batch classifier loss: 0.412921; batch adversarial loss: 0.633086\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378547; batch adversarial loss: 0.511013\n",
      "epoch 99; iter: 0; batch classifier loss: 0.392707; batch adversarial loss: 0.541010\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.843218; batch adversarial loss: 0.899468\n",
      "epoch 2; iter: 0; batch classifier loss: 0.837776; batch adversarial loss: 0.802376\n",
      "epoch 3; iter: 0; batch classifier loss: 0.659521; batch adversarial loss: 0.765839\n",
      "epoch 4; iter: 0; batch classifier loss: 0.552681; batch adversarial loss: 0.759308\n",
      "epoch 5; iter: 0; batch classifier loss: 0.514207; batch adversarial loss: 0.663776\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581537; batch adversarial loss: 0.676126\n",
      "epoch 7; iter: 0; batch classifier loss: 0.477686; batch adversarial loss: 0.663644\n",
      "epoch 8; iter: 0; batch classifier loss: 0.469468; batch adversarial loss: 0.638929\n",
      "epoch 9; iter: 0; batch classifier loss: 0.440709; batch adversarial loss: 0.661643\n",
      "epoch 10; iter: 0; batch classifier loss: 0.449525; batch adversarial loss: 0.659850\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555533; batch adversarial loss: 0.616350\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535667; batch adversarial loss: 0.624568\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532837; batch adversarial loss: 0.625942\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497602; batch adversarial loss: 0.605576\n",
      "epoch 15; iter: 0; batch classifier loss: 0.515601; batch adversarial loss: 0.588349\n",
      "epoch 16; iter: 0; batch classifier loss: 0.485062; batch adversarial loss: 0.563455\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510863; batch adversarial loss: 0.603459\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466895; batch adversarial loss: 0.553222\n",
      "epoch 19; iter: 0; batch classifier loss: 0.432470; batch adversarial loss: 0.581126\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468844; batch adversarial loss: 0.615460\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493241; batch adversarial loss: 0.587753\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437966; batch adversarial loss: 0.561045\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493822; batch adversarial loss: 0.534762\n",
      "epoch 24; iter: 0; batch classifier loss: 0.403700; batch adversarial loss: 0.529418\n",
      "epoch 25; iter: 0; batch classifier loss: 0.445799; batch adversarial loss: 0.538104\n",
      "epoch 26; iter: 0; batch classifier loss: 0.462212; batch adversarial loss: 0.633383\n",
      "epoch 27; iter: 0; batch classifier loss: 0.609667; batch adversarial loss: 0.687834\n",
      "epoch 28; iter: 0; batch classifier loss: 0.674856; batch adversarial loss: 0.640277\n",
      "epoch 29; iter: 0; batch classifier loss: 0.797297; batch adversarial loss: 0.679919\n",
      "epoch 30; iter: 0; batch classifier loss: 0.819309; batch adversarial loss: 0.649211\n",
      "epoch 31; iter: 0; batch classifier loss: 0.769539; batch adversarial loss: 0.613007\n",
      "epoch 32; iter: 0; batch classifier loss: 0.829132; batch adversarial loss: 0.611332\n",
      "epoch 33; iter: 0; batch classifier loss: 0.744956; batch adversarial loss: 0.611933\n",
      "epoch 34; iter: 0; batch classifier loss: 0.638949; batch adversarial loss: 0.651792\n",
      "epoch 35; iter: 0; batch classifier loss: 0.531928; batch adversarial loss: 0.601095\n",
      "epoch 36; iter: 0; batch classifier loss: 0.517306; batch adversarial loss: 0.592523\n",
      "epoch 37; iter: 0; batch classifier loss: 0.523729; batch adversarial loss: 0.635491\n",
      "epoch 38; iter: 0; batch classifier loss: 0.511496; batch adversarial loss: 0.541460\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403512; batch adversarial loss: 0.634009\n",
      "epoch 40; iter: 0; batch classifier loss: 0.397909; batch adversarial loss: 0.613014\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403396; batch adversarial loss: 0.512225\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398218; batch adversarial loss: 0.584071\n",
      "epoch 43; iter: 0; batch classifier loss: 0.498230; batch adversarial loss: 0.556755\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485025; batch adversarial loss: 0.703663\n",
      "epoch 45; iter: 0; batch classifier loss: 0.538214; batch adversarial loss: 0.591733\n",
      "epoch 46; iter: 0; batch classifier loss: 0.574944; batch adversarial loss: 0.571975\n",
      "epoch 47; iter: 0; batch classifier loss: 0.529942; batch adversarial loss: 0.594119\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473647; batch adversarial loss: 0.556316\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428792; batch adversarial loss: 0.551941\n",
      "epoch 50; iter: 0; batch classifier loss: 0.446917; batch adversarial loss: 0.514727\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414561; batch adversarial loss: 0.599722\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421700; batch adversarial loss: 0.524074\n",
      "epoch 53; iter: 0; batch classifier loss: 0.410781; batch adversarial loss: 0.580846\n",
      "epoch 54; iter: 0; batch classifier loss: 0.425120; batch adversarial loss: 0.622184\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487415; batch adversarial loss: 0.527265\n",
      "epoch 56; iter: 0; batch classifier loss: 0.348749; batch adversarial loss: 0.527234\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405286; batch adversarial loss: 0.577702\n",
      "epoch 58; iter: 0; batch classifier loss: 0.399222; batch adversarial loss: 0.545078\n",
      "epoch 59; iter: 0; batch classifier loss: 0.425209; batch adversarial loss: 0.562698\n",
      "epoch 60; iter: 0; batch classifier loss: 0.381449; batch adversarial loss: 0.617210\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406728; batch adversarial loss: 0.611062\n",
      "epoch 62; iter: 0; batch classifier loss: 0.462487; batch adversarial loss: 0.616024\n",
      "epoch 63; iter: 0; batch classifier loss: 0.392542; batch adversarial loss: 0.634125\n",
      "epoch 64; iter: 0; batch classifier loss: 0.473754; batch adversarial loss: 0.582715\n",
      "epoch 65; iter: 0; batch classifier loss: 0.437708; batch adversarial loss: 0.619889\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408539; batch adversarial loss: 0.596928\n",
      "epoch 67; iter: 0; batch classifier loss: 0.346323; batch adversarial loss: 0.537901\n",
      "epoch 68; iter: 0; batch classifier loss: 0.486044; batch adversarial loss: 0.491456\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418481; batch adversarial loss: 0.587291\n",
      "epoch 70; iter: 0; batch classifier loss: 0.370285; batch adversarial loss: 0.617149\n",
      "epoch 71; iter: 0; batch classifier loss: 0.436364; batch adversarial loss: 0.527385\n",
      "epoch 72; iter: 0; batch classifier loss: 0.373724; batch adversarial loss: 0.554819\n",
      "epoch 73; iter: 0; batch classifier loss: 0.306546; batch adversarial loss: 0.567862\n",
      "epoch 74; iter: 0; batch classifier loss: 0.511366; batch adversarial loss: 0.583633\n",
      "epoch 75; iter: 0; batch classifier loss: 0.331026; batch adversarial loss: 0.538862\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384366; batch adversarial loss: 0.562765\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395117; batch adversarial loss: 0.479405\n",
      "epoch 78; iter: 0; batch classifier loss: 0.472728; batch adversarial loss: 0.546248\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380945; batch adversarial loss: 0.600970\n",
      "epoch 80; iter: 0; batch classifier loss: 0.309303; batch adversarial loss: 0.603717\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422857; batch adversarial loss: 0.595871\n",
      "epoch 82; iter: 0; batch classifier loss: 0.418276; batch adversarial loss: 0.527808\n",
      "epoch 83; iter: 0; batch classifier loss: 0.414371; batch adversarial loss: 0.615681\n",
      "epoch 84; iter: 0; batch classifier loss: 0.419499; batch adversarial loss: 0.603182\n",
      "epoch 85; iter: 0; batch classifier loss: 0.309559; batch adversarial loss: 0.604402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.418385; batch adversarial loss: 0.620794\n",
      "epoch 87; iter: 0; batch classifier loss: 0.405785; batch adversarial loss: 0.595162\n",
      "epoch 88; iter: 0; batch classifier loss: 0.500837; batch adversarial loss: 0.491914\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387913; batch adversarial loss: 0.542283\n",
      "epoch 90; iter: 0; batch classifier loss: 0.401809; batch adversarial loss: 0.541073\n",
      "epoch 91; iter: 0; batch classifier loss: 0.381741; batch adversarial loss: 0.606162\n",
      "epoch 92; iter: 0; batch classifier loss: 0.425773; batch adversarial loss: 0.625921\n",
      "epoch 93; iter: 0; batch classifier loss: 0.552294; batch adversarial loss: 0.553172\n",
      "epoch 94; iter: 0; batch classifier loss: 0.430010; batch adversarial loss: 0.500831\n",
      "epoch 95; iter: 0; batch classifier loss: 0.482531; batch adversarial loss: 0.578920\n",
      "epoch 96; iter: 0; batch classifier loss: 0.405498; batch adversarial loss: 0.575555\n",
      "epoch 97; iter: 0; batch classifier loss: 0.488529; batch adversarial loss: 0.639873\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401406; batch adversarial loss: 0.513455\n",
      "epoch 99; iter: 0; batch classifier loss: 0.422354; batch adversarial loss: 0.547933\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709988; batch adversarial loss: 0.791750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.803203; batch adversarial loss: 0.906940\n",
      "epoch 2; iter: 0; batch classifier loss: 0.806947; batch adversarial loss: 0.808793\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591818; batch adversarial loss: 0.774273\n",
      "epoch 4; iter: 0; batch classifier loss: 0.541684; batch adversarial loss: 0.768168\n",
      "epoch 5; iter: 0; batch classifier loss: 0.511061; batch adversarial loss: 0.668907\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538927; batch adversarial loss: 0.688209\n",
      "epoch 7; iter: 0; batch classifier loss: 0.469881; batch adversarial loss: 0.666476\n",
      "epoch 8; iter: 0; batch classifier loss: 0.458875; batch adversarial loss: 0.641809\n",
      "epoch 9; iter: 0; batch classifier loss: 0.435092; batch adversarial loss: 0.664329\n",
      "epoch 10; iter: 0; batch classifier loss: 0.434500; batch adversarial loss: 0.664725\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538492; batch adversarial loss: 0.620603\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513045; batch adversarial loss: 0.627087\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489116; batch adversarial loss: 0.630531\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476310; batch adversarial loss: 0.608755\n",
      "epoch 15; iter: 0; batch classifier loss: 0.457856; batch adversarial loss: 0.594283\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454951; batch adversarial loss: 0.566488\n",
      "epoch 17; iter: 0; batch classifier loss: 0.479673; batch adversarial loss: 0.605217\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452500; batch adversarial loss: 0.552912\n",
      "epoch 19; iter: 0; batch classifier loss: 0.396659; batch adversarial loss: 0.589308\n",
      "epoch 20; iter: 0; batch classifier loss: 0.435863; batch adversarial loss: 0.623132\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477743; batch adversarial loss: 0.591683\n",
      "epoch 22; iter: 0; batch classifier loss: 0.427473; batch adversarial loss: 0.563924\n",
      "epoch 23; iter: 0; batch classifier loss: 0.545713; batch adversarial loss: 0.560937\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455107; batch adversarial loss: 0.569645\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506220; batch adversarial loss: 0.581014\n",
      "epoch 26; iter: 0; batch classifier loss: 0.617499; batch adversarial loss: 0.703005\n",
      "epoch 27; iter: 0; batch classifier loss: 0.910553; batch adversarial loss: 0.732698\n",
      "epoch 28; iter: 0; batch classifier loss: 0.848562; batch adversarial loss: 0.659562\n",
      "epoch 29; iter: 0; batch classifier loss: 0.796030; batch adversarial loss: 0.638445\n",
      "epoch 30; iter: 0; batch classifier loss: 0.589288; batch adversarial loss: 0.600913\n",
      "epoch 31; iter: 0; batch classifier loss: 0.550299; batch adversarial loss: 0.571636\n",
      "epoch 32; iter: 0; batch classifier loss: 0.557309; batch adversarial loss: 0.574493\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465859; batch adversarial loss: 0.579273\n",
      "epoch 34; iter: 0; batch classifier loss: 0.386495; batch adversarial loss: 0.617249\n",
      "epoch 35; iter: 0; batch classifier loss: 0.349284; batch adversarial loss: 0.571663\n",
      "epoch 36; iter: 0; batch classifier loss: 0.392188; batch adversarial loss: 0.567946\n",
      "epoch 37; iter: 0; batch classifier loss: 0.389419; batch adversarial loss: 0.619835\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446643; batch adversarial loss: 0.527732\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392887; batch adversarial loss: 0.640174\n",
      "epoch 40; iter: 0; batch classifier loss: 0.488458; batch adversarial loss: 0.638819\n",
      "epoch 41; iter: 0; batch classifier loss: 0.519075; batch adversarial loss: 0.537854\n",
      "epoch 42; iter: 0; batch classifier loss: 0.692285; batch adversarial loss: 0.616284\n",
      "epoch 43; iter: 0; batch classifier loss: 0.768737; batch adversarial loss: 0.571974\n",
      "epoch 44; iter: 0; batch classifier loss: 0.765290; batch adversarial loss: 0.700699\n",
      "epoch 45; iter: 0; batch classifier loss: 0.431406; batch adversarial loss: 0.583433\n",
      "epoch 46; iter: 0; batch classifier loss: 0.395242; batch adversarial loss: 0.561953\n",
      "epoch 47; iter: 0; batch classifier loss: 0.321606; batch adversarial loss: 0.586086\n",
      "epoch 48; iter: 0; batch classifier loss: 0.392246; batch adversarial loss: 0.554542\n",
      "epoch 49; iter: 0; batch classifier loss: 0.363959; batch adversarial loss: 0.550002\n",
      "epoch 50; iter: 0; batch classifier loss: 0.351884; batch adversarial loss: 0.512551\n",
      "epoch 51; iter: 0; batch classifier loss: 0.370401; batch adversarial loss: 0.599522\n",
      "epoch 52; iter: 0; batch classifier loss: 0.385786; batch adversarial loss: 0.525471\n",
      "epoch 53; iter: 0; batch classifier loss: 0.350557; batch adversarial loss: 0.584475\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408579; batch adversarial loss: 0.626257\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454756; batch adversarial loss: 0.528996\n",
      "epoch 56; iter: 0; batch classifier loss: 0.345633; batch adversarial loss: 0.530475\n",
      "epoch 57; iter: 0; batch classifier loss: 0.397960; batch adversarial loss: 0.579277\n",
      "epoch 58; iter: 0; batch classifier loss: 0.359390; batch adversarial loss: 0.547136\n",
      "epoch 59; iter: 0; batch classifier loss: 0.385338; batch adversarial loss: 0.565461\n",
      "epoch 60; iter: 0; batch classifier loss: 0.282500; batch adversarial loss: 0.615993\n",
      "epoch 61; iter: 0; batch classifier loss: 0.439009; batch adversarial loss: 0.616377\n",
      "epoch 62; iter: 0; batch classifier loss: 0.467664; batch adversarial loss: 0.624314\n",
      "epoch 63; iter: 0; batch classifier loss: 0.368533; batch adversarial loss: 0.637783\n",
      "epoch 64; iter: 0; batch classifier loss: 0.473405; batch adversarial loss: 0.587648\n",
      "epoch 65; iter: 0; batch classifier loss: 0.426865; batch adversarial loss: 0.622952\n",
      "epoch 66; iter: 0; batch classifier loss: 0.452912; batch adversarial loss: 0.604157\n",
      "epoch 67; iter: 0; batch classifier loss: 0.319804; batch adversarial loss: 0.540783\n",
      "epoch 68; iter: 0; batch classifier loss: 0.534962; batch adversarial loss: 0.499727\n",
      "epoch 69; iter: 0; batch classifier loss: 0.393475; batch adversarial loss: 0.592565\n",
      "epoch 70; iter: 0; batch classifier loss: 0.443490; batch adversarial loss: 0.628124\n",
      "epoch 71; iter: 0; batch classifier loss: 0.454794; batch adversarial loss: 0.533648\n",
      "epoch 72; iter: 0; batch classifier loss: 0.425941; batch adversarial loss: 0.566087\n",
      "epoch 73; iter: 0; batch classifier loss: 0.327034; batch adversarial loss: 0.572814\n",
      "epoch 74; iter: 0; batch classifier loss: 0.521020; batch adversarial loss: 0.594752\n",
      "epoch 75; iter: 0; batch classifier loss: 0.359347; batch adversarial loss: 0.547773\n",
      "epoch 76; iter: 0; batch classifier loss: 0.516161; batch adversarial loss: 0.575532\n",
      "epoch 77; iter: 0; batch classifier loss: 0.410432; batch adversarial loss: 0.485627\n",
      "epoch 78; iter: 0; batch classifier loss: 0.482310; batch adversarial loss: 0.552331\n",
      "epoch 79; iter: 0; batch classifier loss: 0.452326; batch adversarial loss: 0.611274\n",
      "epoch 80; iter: 0; batch classifier loss: 0.395709; batch adversarial loss: 0.615098\n",
      "epoch 81; iter: 0; batch classifier loss: 0.464064; batch adversarial loss: 0.601299\n",
      "epoch 82; iter: 0; batch classifier loss: 0.476789; batch adversarial loss: 0.533578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.448221; batch adversarial loss: 0.627573\n",
      "epoch 84; iter: 0; batch classifier loss: 0.499828; batch adversarial loss: 0.611900\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385199; batch adversarial loss: 0.613007\n",
      "epoch 86; iter: 0; batch classifier loss: 0.493866; batch adversarial loss: 0.627473\n",
      "epoch 87; iter: 0; batch classifier loss: 0.441247; batch adversarial loss: 0.605270\n",
      "epoch 88; iter: 0; batch classifier loss: 0.543497; batch adversarial loss: 0.501281\n",
      "epoch 89; iter: 0; batch classifier loss: 0.438422; batch adversarial loss: 0.552466\n",
      "epoch 90; iter: 0; batch classifier loss: 0.499549; batch adversarial loss: 0.551165\n",
      "epoch 91; iter: 0; batch classifier loss: 0.424618; batch adversarial loss: 0.617185\n",
      "epoch 92; iter: 0; batch classifier loss: 0.461798; batch adversarial loss: 0.633526\n",
      "epoch 93; iter: 0; batch classifier loss: 0.613818; batch adversarial loss: 0.562261\n",
      "epoch 94; iter: 0; batch classifier loss: 0.539457; batch adversarial loss: 0.511350\n",
      "epoch 95; iter: 0; batch classifier loss: 0.542026; batch adversarial loss: 0.591498\n",
      "epoch 96; iter: 0; batch classifier loss: 0.444254; batch adversarial loss: 0.574167\n",
      "epoch 97; iter: 0; batch classifier loss: 0.530485; batch adversarial loss: 0.645618\n",
      "epoch 98; iter: 0; batch classifier loss: 0.489511; batch adversarial loss: 0.523266\n",
      "epoch 99; iter: 0; batch classifier loss: 0.465601; batch adversarial loss: 0.552070\n",
      "epoch 100; iter: 0; batch classifier loss: 0.552360; batch adversarial loss: 0.586893\n",
      "epoch 101; iter: 0; batch classifier loss: 0.481558; batch adversarial loss: 0.628589\n",
      "epoch 102; iter: 0; batch classifier loss: 0.686582; batch adversarial loss: 0.548399\n",
      "epoch 103; iter: 0; batch classifier loss: 0.584380; batch adversarial loss: 0.571104\n",
      "epoch 104; iter: 0; batch classifier loss: 0.505112; batch adversarial loss: 0.543595\n",
      "epoch 105; iter: 0; batch classifier loss: 0.516145; batch adversarial loss: 0.653845\n",
      "epoch 106; iter: 0; batch classifier loss: 0.491151; batch adversarial loss: 0.644458\n",
      "epoch 107; iter: 0; batch classifier loss: 0.553230; batch adversarial loss: 0.570493\n",
      "epoch 108; iter: 0; batch classifier loss: 0.509496; batch adversarial loss: 0.584024\n",
      "epoch 109; iter: 0; batch classifier loss: 0.612461; batch adversarial loss: 0.503811\n",
      "epoch 110; iter: 0; batch classifier loss: 0.648136; batch adversarial loss: 0.532502\n",
      "epoch 111; iter: 0; batch classifier loss: 0.437939; batch adversarial loss: 0.590802\n",
      "epoch 112; iter: 0; batch classifier loss: 0.544465; batch adversarial loss: 0.562240\n",
      "epoch 113; iter: 0; batch classifier loss: 0.568164; batch adversarial loss: 0.558313\n",
      "epoch 114; iter: 0; batch classifier loss: 0.487582; batch adversarial loss: 0.588181\n",
      "epoch 115; iter: 0; batch classifier loss: 0.539352; batch adversarial loss: 0.516383\n",
      "epoch 116; iter: 0; batch classifier loss: 0.485918; batch adversarial loss: 0.558125\n",
      "epoch 117; iter: 0; batch classifier loss: 0.449283; batch adversarial loss: 0.602128\n",
      "epoch 118; iter: 0; batch classifier loss: 0.561216; batch adversarial loss: 0.592718\n",
      "epoch 119; iter: 0; batch classifier loss: 0.443407; batch adversarial loss: 0.611875\n",
      "epoch 120; iter: 0; batch classifier loss: 0.533213; batch adversarial loss: 0.600383\n",
      "epoch 121; iter: 0; batch classifier loss: 0.695613; batch adversarial loss: 0.643287\n",
      "epoch 122; iter: 0; batch classifier loss: 0.631263; batch adversarial loss: 0.574356\n",
      "epoch 123; iter: 0; batch classifier loss: 0.640975; batch adversarial loss: 0.608032\n",
      "epoch 124; iter: 0; batch classifier loss: 0.615615; batch adversarial loss: 0.558185\n",
      "epoch 125; iter: 0; batch classifier loss: 0.558951; batch adversarial loss: 0.616624\n",
      "epoch 126; iter: 0; batch classifier loss: 0.614653; batch adversarial loss: 0.575534\n",
      "epoch 127; iter: 0; batch classifier loss: 0.552494; batch adversarial loss: 0.523389\n",
      "epoch 128; iter: 0; batch classifier loss: 0.518471; batch adversarial loss: 0.585709\n",
      "epoch 129; iter: 0; batch classifier loss: 0.471940; batch adversarial loss: 0.635632\n",
      "epoch 130; iter: 0; batch classifier loss: 0.518618; batch adversarial loss: 0.562333\n",
      "epoch 131; iter: 0; batch classifier loss: 0.432169; batch adversarial loss: 0.606554\n",
      "epoch 132; iter: 0; batch classifier loss: 0.631834; batch adversarial loss: 0.541965\n",
      "epoch 133; iter: 0; batch classifier loss: 0.578583; batch adversarial loss: 0.627692\n",
      "epoch 134; iter: 0; batch classifier loss: 0.534416; batch adversarial loss: 0.569304\n",
      "epoch 135; iter: 0; batch classifier loss: 0.648727; batch adversarial loss: 0.629751\n",
      "epoch 136; iter: 0; batch classifier loss: 0.569475; batch adversarial loss: 0.575280\n",
      "epoch 137; iter: 0; batch classifier loss: 0.518751; batch adversarial loss: 0.651151\n",
      "epoch 138; iter: 0; batch classifier loss: 0.503547; batch adversarial loss: 0.555536\n",
      "epoch 139; iter: 0; batch classifier loss: 0.513910; batch adversarial loss: 0.552783\n",
      "epoch 140; iter: 0; batch classifier loss: 0.495424; batch adversarial loss: 0.606214\n",
      "epoch 141; iter: 0; batch classifier loss: 0.543927; batch adversarial loss: 0.503933\n",
      "epoch 142; iter: 0; batch classifier loss: 0.686238; batch adversarial loss: 0.578734\n",
      "epoch 143; iter: 0; batch classifier loss: 0.582006; batch adversarial loss: 0.503847\n",
      "epoch 144; iter: 0; batch classifier loss: 0.408757; batch adversarial loss: 0.617061\n",
      "epoch 145; iter: 0; batch classifier loss: 0.546450; batch adversarial loss: 0.522270\n",
      "epoch 146; iter: 0; batch classifier loss: 0.664651; batch adversarial loss: 0.570216\n",
      "epoch 147; iter: 0; batch classifier loss: 0.590608; batch adversarial loss: 0.509526\n",
      "epoch 148; iter: 0; batch classifier loss: 0.620448; batch adversarial loss: 0.575388\n",
      "epoch 149; iter: 0; batch classifier loss: 0.560164; batch adversarial loss: 0.548254\n",
      "epoch 150; iter: 0; batch classifier loss: 0.537277; batch adversarial loss: 0.568504\n",
      "epoch 151; iter: 0; batch classifier loss: 0.506394; batch adversarial loss: 0.544060\n",
      "epoch 152; iter: 0; batch classifier loss: 0.514645; batch adversarial loss: 0.596164\n",
      "epoch 153; iter: 0; batch classifier loss: 0.628628; batch adversarial loss: 0.552477\n",
      "epoch 154; iter: 0; batch classifier loss: 0.515772; batch adversarial loss: 0.600545\n",
      "epoch 155; iter: 0; batch classifier loss: 0.512345; batch adversarial loss: 0.609344\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362553; batch adversarial loss: 0.606673\n",
      "epoch 157; iter: 0; batch classifier loss: 0.467670; batch adversarial loss: 0.514519\n",
      "epoch 158; iter: 0; batch classifier loss: 0.523333; batch adversarial loss: 0.620203\n",
      "epoch 159; iter: 0; batch classifier loss: 0.490716; batch adversarial loss: 0.586786\n",
      "epoch 160; iter: 0; batch classifier loss: 0.613412; batch adversarial loss: 0.579529\n",
      "epoch 161; iter: 0; batch classifier loss: 0.532492; batch adversarial loss: 0.560860\n",
      "epoch 162; iter: 0; batch classifier loss: 0.497495; batch adversarial loss: 0.571827\n",
      "epoch 163; iter: 0; batch classifier loss: 0.664830; batch adversarial loss: 0.545873\n",
      "epoch 164; iter: 0; batch classifier loss: 0.453504; batch adversarial loss: 0.561248\n",
      "epoch 165; iter: 0; batch classifier loss: 0.519967; batch adversarial loss: 0.562568\n",
      "epoch 166; iter: 0; batch classifier loss: 0.532525; batch adversarial loss: 0.593776\n",
      "epoch 167; iter: 0; batch classifier loss: 0.402019; batch adversarial loss: 0.570272\n",
      "epoch 168; iter: 0; batch classifier loss: 0.512941; batch adversarial loss: 0.609025\n",
      "epoch 169; iter: 0; batch classifier loss: 0.578125; batch adversarial loss: 0.594310\n",
      "epoch 170; iter: 0; batch classifier loss: 0.526949; batch adversarial loss: 0.547272\n",
      "epoch 171; iter: 0; batch classifier loss: 0.448661; batch adversarial loss: 0.516227\n",
      "epoch 172; iter: 0; batch classifier loss: 0.469987; batch adversarial loss: 0.579533\n",
      "epoch 173; iter: 0; batch classifier loss: 0.569630; batch adversarial loss: 0.546247\n",
      "epoch 174; iter: 0; batch classifier loss: 0.622635; batch adversarial loss: 0.553999\n",
      "epoch 175; iter: 0; batch classifier loss: 0.475989; batch adversarial loss: 0.547925\n",
      "epoch 176; iter: 0; batch classifier loss: 0.556395; batch adversarial loss: 0.521970\n",
      "epoch 177; iter: 0; batch classifier loss: 0.553291; batch adversarial loss: 0.603161\n",
      "epoch 178; iter: 0; batch classifier loss: 0.346651; batch adversarial loss: 0.541249\n",
      "epoch 179; iter: 0; batch classifier loss: 0.504793; batch adversarial loss: 0.609800\n",
      "epoch 180; iter: 0; batch classifier loss: 0.490992; batch adversarial loss: 0.537968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 181; iter: 0; batch classifier loss: 0.644759; batch adversarial loss: 0.641043\n",
      "epoch 182; iter: 0; batch classifier loss: 0.520336; batch adversarial loss: 0.594934\n",
      "epoch 183; iter: 0; batch classifier loss: 0.614094; batch adversarial loss: 0.643010\n",
      "epoch 184; iter: 0; batch classifier loss: 0.467718; batch adversarial loss: 0.529657\n",
      "epoch 185; iter: 0; batch classifier loss: 0.586777; batch adversarial loss: 0.626169\n",
      "epoch 186; iter: 0; batch classifier loss: 0.406667; batch adversarial loss: 0.530441\n",
      "epoch 187; iter: 0; batch classifier loss: 0.450493; batch adversarial loss: 0.548935\n",
      "epoch 188; iter: 0; batch classifier loss: 0.479233; batch adversarial loss: 0.563188\n",
      "epoch 189; iter: 0; batch classifier loss: 0.581529; batch adversarial loss: 0.563677\n",
      "epoch 190; iter: 0; batch classifier loss: 0.550338; batch adversarial loss: 0.536299\n",
      "epoch 191; iter: 0; batch classifier loss: 0.446276; batch adversarial loss: 0.595200\n",
      "epoch 192; iter: 0; batch classifier loss: 0.463708; batch adversarial loss: 0.569837\n",
      "epoch 193; iter: 0; batch classifier loss: 0.547670; batch adversarial loss: 0.506071\n",
      "epoch 194; iter: 0; batch classifier loss: 0.494417; batch adversarial loss: 0.595432\n",
      "epoch 195; iter: 0; batch classifier loss: 0.607784; batch adversarial loss: 0.529804\n",
      "epoch 196; iter: 0; batch classifier loss: 0.574934; batch adversarial loss: 0.602417\n",
      "epoch 197; iter: 0; batch classifier loss: 0.438630; batch adversarial loss: 0.605416\n",
      "epoch 198; iter: 0; batch classifier loss: 0.488234; batch adversarial loss: 0.608772\n",
      "epoch 199; iter: 0; batch classifier loss: 0.314483; batch adversarial loss: 0.652520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.648325; batch adversarial loss: 0.794387\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594834; batch adversarial loss: 0.732255\n",
      "epoch 3; iter: 0; batch classifier loss: 0.480895; batch adversarial loss: 0.707494\n",
      "epoch 4; iter: 0; batch classifier loss: 0.497611; batch adversarial loss: 0.695117\n",
      "epoch 5; iter: 0; batch classifier loss: 0.508197; batch adversarial loss: 0.649613\n",
      "epoch 6; iter: 0; batch classifier loss: 0.641195; batch adversarial loss: 0.652790\n",
      "epoch 7; iter: 0; batch classifier loss: 0.525150; batch adversarial loss: 0.648242\n",
      "epoch 8; iter: 0; batch classifier loss: 0.501837; batch adversarial loss: 0.631309\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488021; batch adversarial loss: 0.650408\n",
      "epoch 10; iter: 0; batch classifier loss: 0.476120; batch adversarial loss: 0.655881\n",
      "epoch 11; iter: 0; batch classifier loss: 0.585344; batch adversarial loss: 0.611108\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562737; batch adversarial loss: 0.621301\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539061; batch adversarial loss: 0.628453\n",
      "epoch 14; iter: 0; batch classifier loss: 0.495901; batch adversarial loss: 0.609958\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525911; batch adversarial loss: 0.585261\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506497; batch adversarial loss: 0.546994\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511996; batch adversarial loss: 0.575051\n",
      "epoch 18; iter: 0; batch classifier loss: 0.503925; batch adversarial loss: 0.502824\n",
      "epoch 19; iter: 0; batch classifier loss: 0.448117; batch adversarial loss: 0.547849\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441494; batch adversarial loss: 0.592489\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484310; batch adversarial loss: 0.568569\n",
      "epoch 22; iter: 0; batch classifier loss: 0.436220; batch adversarial loss: 0.530945\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470436; batch adversarial loss: 0.509007\n",
      "epoch 24; iter: 0; batch classifier loss: 0.398786; batch adversarial loss: 0.501007\n",
      "epoch 25; iter: 0; batch classifier loss: 0.429100; batch adversarial loss: 0.502501\n",
      "epoch 26; iter: 0; batch classifier loss: 0.389377; batch adversarial loss: 0.568247\n",
      "epoch 27; iter: 0; batch classifier loss: 0.414064; batch adversarial loss: 0.575011\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495890; batch adversarial loss: 0.548961\n",
      "epoch 29; iter: 0; batch classifier loss: 0.430321; batch adversarial loss: 0.518127\n",
      "epoch 30; iter: 0; batch classifier loss: 0.416815; batch adversarial loss: 0.520703\n",
      "epoch 31; iter: 0; batch classifier loss: 0.414118; batch adversarial loss: 0.516401\n",
      "epoch 32; iter: 0; batch classifier loss: 0.480309; batch adversarial loss: 0.541803\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469397; batch adversarial loss: 0.546312\n",
      "epoch 34; iter: 0; batch classifier loss: 0.394269; batch adversarial loss: 0.619004\n",
      "epoch 35; iter: 0; batch classifier loss: 0.363290; batch adversarial loss: 0.576943\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462228; batch adversarial loss: 0.623689\n",
      "epoch 37; iter: 0; batch classifier loss: 0.520998; batch adversarial loss: 0.690181\n",
      "epoch 38; iter: 0; batch classifier loss: 0.563865; batch adversarial loss: 0.568686\n",
      "epoch 39; iter: 0; batch classifier loss: 0.489783; batch adversarial loss: 0.696232\n",
      "epoch 40; iter: 0; batch classifier loss: 0.556417; batch adversarial loss: 0.698061\n",
      "epoch 41; iter: 0; batch classifier loss: 0.481323; batch adversarial loss: 0.571992\n",
      "epoch 42; iter: 0; batch classifier loss: 0.520016; batch adversarial loss: 0.651363\n",
      "epoch 43; iter: 0; batch classifier loss: 0.624870; batch adversarial loss: 0.623545\n",
      "epoch 44; iter: 0; batch classifier loss: 0.669483; batch adversarial loss: 0.790766\n",
      "epoch 45; iter: 0; batch classifier loss: 0.686790; batch adversarial loss: 0.654841\n",
      "epoch 46; iter: 0; batch classifier loss: 0.650157; batch adversarial loss: 0.619391\n",
      "epoch 47; iter: 0; batch classifier loss: 0.618950; batch adversarial loss: 0.629291\n",
      "epoch 48; iter: 0; batch classifier loss: 0.678574; batch adversarial loss: 0.592231\n",
      "epoch 49; iter: 0; batch classifier loss: 0.699148; batch adversarial loss: 0.574389\n",
      "epoch 50; iter: 0; batch classifier loss: 0.598912; batch adversarial loss: 0.530192\n",
      "epoch 51; iter: 0; batch classifier loss: 0.448611; batch adversarial loss: 0.595664\n",
      "epoch 52; iter: 0; batch classifier loss: 0.408881; batch adversarial loss: 0.527055\n",
      "epoch 53; iter: 0; batch classifier loss: 0.411160; batch adversarial loss: 0.578704\n",
      "epoch 54; iter: 0; batch classifier loss: 0.434485; batch adversarial loss: 0.613859\n",
      "epoch 55; iter: 0; batch classifier loss: 0.454876; batch adversarial loss: 0.527780\n",
      "epoch 56; iter: 0; batch classifier loss: 0.325669; batch adversarial loss: 0.523903\n",
      "epoch 57; iter: 0; batch classifier loss: 0.382434; batch adversarial loss: 0.573011\n",
      "epoch 58; iter: 0; batch classifier loss: 0.371218; batch adversarial loss: 0.544932\n",
      "epoch 59; iter: 0; batch classifier loss: 0.387367; batch adversarial loss: 0.556380\n",
      "epoch 60; iter: 0; batch classifier loss: 0.344975; batch adversarial loss: 0.614409\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380345; batch adversarial loss: 0.601480\n",
      "epoch 62; iter: 0; batch classifier loss: 0.419315; batch adversarial loss: 0.607184\n",
      "epoch 63; iter: 0; batch classifier loss: 0.376267; batch adversarial loss: 0.629269\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405731; batch adversarial loss: 0.570478\n",
      "epoch 65; iter: 0; batch classifier loss: 0.409974; batch adversarial loss: 0.613570\n",
      "epoch 66; iter: 0; batch classifier loss: 0.393014; batch adversarial loss: 0.592516\n",
      "epoch 67; iter: 0; batch classifier loss: 0.321770; batch adversarial loss: 0.534961\n",
      "epoch 68; iter: 0; batch classifier loss: 0.451186; batch adversarial loss: 0.484711\n",
      "epoch 69; iter: 0; batch classifier loss: 0.395633; batch adversarial loss: 0.580792\n",
      "epoch 70; iter: 0; batch classifier loss: 0.354462; batch adversarial loss: 0.612016\n",
      "epoch 71; iter: 0; batch classifier loss: 0.398224; batch adversarial loss: 0.522327\n",
      "epoch 72; iter: 0; batch classifier loss: 0.372075; batch adversarial loss: 0.549007\n",
      "epoch 73; iter: 0; batch classifier loss: 0.289623; batch adversarial loss: 0.566249\n",
      "epoch 74; iter: 0; batch classifier loss: 0.475476; batch adversarial loss: 0.580949\n",
      "epoch 75; iter: 0; batch classifier loss: 0.303450; batch adversarial loss: 0.534349\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370529; batch adversarial loss: 0.556998\n",
      "epoch 77; iter: 0; batch classifier loss: 0.356827; batch adversarial loss: 0.475500\n",
      "epoch 78; iter: 0; batch classifier loss: 0.432169; batch adversarial loss: 0.542770\n",
      "epoch 79; iter: 0; batch classifier loss: 0.358802; batch adversarial loss: 0.595968\n",
      "epoch 80; iter: 0; batch classifier loss: 0.288048; batch adversarial loss: 0.595821\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394459; batch adversarial loss: 0.586409\n",
      "epoch 82; iter: 0; batch classifier loss: 0.348669; batch adversarial loss: 0.524059\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382269; batch adversarial loss: 0.607685\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382718; batch adversarial loss: 0.599050\n",
      "epoch 85; iter: 0; batch classifier loss: 0.280860; batch adversarial loss: 0.596545\n",
      "epoch 86; iter: 0; batch classifier loss: 0.302448; batch adversarial loss: 0.613779\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369231; batch adversarial loss: 0.586109\n",
      "epoch 88; iter: 0; batch classifier loss: 0.440328; batch adversarial loss: 0.481280\n",
      "epoch 89; iter: 0; batch classifier loss: 0.358705; batch adversarial loss: 0.538303\n",
      "epoch 90; iter: 0; batch classifier loss: 0.345973; batch adversarial loss: 0.532595\n",
      "epoch 91; iter: 0; batch classifier loss: 0.341537; batch adversarial loss: 0.597728\n",
      "epoch 92; iter: 0; batch classifier loss: 0.329488; batch adversarial loss: 0.619745\n",
      "epoch 93; iter: 0; batch classifier loss: 0.471899; batch adversarial loss: 0.542376\n",
      "epoch 94; iter: 0; batch classifier loss: 0.387214; batch adversarial loss: 0.493538\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422361; batch adversarial loss: 0.563685\n",
      "epoch 96; iter: 0; batch classifier loss: 0.347641; batch adversarial loss: 0.574828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.376838; batch adversarial loss: 0.635784\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362342; batch adversarial loss: 0.509264\n",
      "epoch 99; iter: 0; batch classifier loss: 0.358278; batch adversarial loss: 0.543275\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.796153; batch adversarial loss: 0.888319\n",
      "epoch 2; iter: 0; batch classifier loss: 0.785187; batch adversarial loss: 0.794567\n",
      "epoch 3; iter: 0; batch classifier loss: 0.602869; batch adversarial loss: 0.755963\n",
      "epoch 4; iter: 0; batch classifier loss: 0.510562; batch adversarial loss: 0.748337\n",
      "epoch 5; iter: 0; batch classifier loss: 0.500736; batch adversarial loss: 0.660893\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591297; batch adversarial loss: 0.673216\n",
      "epoch 7; iter: 0; batch classifier loss: 0.480930; batch adversarial loss: 0.662409\n",
      "epoch 8; iter: 0; batch classifier loss: 0.474386; batch adversarial loss: 0.637977\n",
      "epoch 9; iter: 0; batch classifier loss: 0.448311; batch adversarial loss: 0.659636\n",
      "epoch 10; iter: 0; batch classifier loss: 0.455124; batch adversarial loss: 0.658460\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565359; batch adversarial loss: 0.614285\n",
      "epoch 12; iter: 0; batch classifier loss: 0.543529; batch adversarial loss: 0.623504\n",
      "epoch 13; iter: 0; batch classifier loss: 0.538337; batch adversarial loss: 0.625406\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499781; batch adversarial loss: 0.605909\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525206; batch adversarial loss: 0.586752\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489833; batch adversarial loss: 0.561292\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510644; batch adversarial loss: 0.599106\n",
      "epoch 18; iter: 0; batch classifier loss: 0.469447; batch adversarial loss: 0.546735\n",
      "epoch 19; iter: 0; batch classifier loss: 0.434487; batch adversarial loss: 0.576172\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462409; batch adversarial loss: 0.611323\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497421; batch adversarial loss: 0.584187\n",
      "epoch 22; iter: 0; batch classifier loss: 0.435029; batch adversarial loss: 0.554672\n",
      "epoch 23; iter: 0; batch classifier loss: 0.482855; batch adversarial loss: 0.527210\n",
      "epoch 24; iter: 0; batch classifier loss: 0.401703; batch adversarial loss: 0.520594\n",
      "epoch 25; iter: 0; batch classifier loss: 0.434184; batch adversarial loss: 0.523884\n",
      "epoch 26; iter: 0; batch classifier loss: 0.411941; batch adversarial loss: 0.600488\n",
      "epoch 27; iter: 0; batch classifier loss: 0.523635; batch adversarial loss: 0.663520\n",
      "epoch 28; iter: 0; batch classifier loss: 0.614482; batch adversarial loss: 0.620813\n",
      "epoch 29; iter: 0; batch classifier loss: 0.568868; batch adversarial loss: 0.609200\n",
      "epoch 30; iter: 0; batch classifier loss: 0.583006; batch adversarial loss: 0.627476\n",
      "epoch 31; iter: 0; batch classifier loss: 0.638375; batch adversarial loss: 0.614414\n",
      "epoch 32; iter: 0; batch classifier loss: 0.828253; batch adversarial loss: 0.645063\n",
      "epoch 33; iter: 0; batch classifier loss: 0.829505; batch adversarial loss: 0.648963\n",
      "epoch 34; iter: 0; batch classifier loss: 0.733655; batch adversarial loss: 0.690369\n",
      "epoch 35; iter: 0; batch classifier loss: 0.698071; batch adversarial loss: 0.632866\n",
      "epoch 36; iter: 0; batch classifier loss: 0.659504; batch adversarial loss: 0.614892\n",
      "epoch 37; iter: 0; batch classifier loss: 0.700698; batch adversarial loss: 0.653507\n",
      "epoch 38; iter: 0; batch classifier loss: 0.654235; batch adversarial loss: 0.552416\n",
      "epoch 39; iter: 0; batch classifier loss: 0.528065; batch adversarial loss: 0.642902\n",
      "epoch 40; iter: 0; batch classifier loss: 0.528261; batch adversarial loss: 0.620003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467334; batch adversarial loss: 0.520634\n",
      "epoch 42; iter: 0; batch classifier loss: 0.510839; batch adversarial loss: 0.586327\n",
      "epoch 43; iter: 0; batch classifier loss: 0.501122; batch adversarial loss: 0.556511\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461160; batch adversarial loss: 0.691842\n",
      "epoch 45; iter: 0; batch classifier loss: 0.466304; batch adversarial loss: 0.582722\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436700; batch adversarial loss: 0.562111\n",
      "epoch 47; iter: 0; batch classifier loss: 0.350612; batch adversarial loss: 0.587180\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424501; batch adversarial loss: 0.554331\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401001; batch adversarial loss: 0.550774\n",
      "epoch 50; iter: 0; batch classifier loss: 0.445831; batch adversarial loss: 0.514037\n",
      "epoch 51; iter: 0; batch classifier loss: 0.419699; batch adversarial loss: 0.600033\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421160; batch adversarial loss: 0.524246\n",
      "epoch 53; iter: 0; batch classifier loss: 0.410287; batch adversarial loss: 0.582459\n",
      "epoch 54; iter: 0; batch classifier loss: 0.435242; batch adversarial loss: 0.623642\n",
      "epoch 55; iter: 0; batch classifier loss: 0.489163; batch adversarial loss: 0.528211\n",
      "epoch 56; iter: 0; batch classifier loss: 0.348807; batch adversarial loss: 0.527510\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404620; batch adversarial loss: 0.578687\n",
      "epoch 58; iter: 0; batch classifier loss: 0.392226; batch adversarial loss: 0.545168\n",
      "epoch 59; iter: 0; batch classifier loss: 0.413326; batch adversarial loss: 0.563019\n",
      "epoch 60; iter: 0; batch classifier loss: 0.370843; batch adversarial loss: 0.617990\n",
      "epoch 61; iter: 0; batch classifier loss: 0.398636; batch adversarial loss: 0.611079\n",
      "epoch 62; iter: 0; batch classifier loss: 0.466115; batch adversarial loss: 0.616148\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383747; batch adversarial loss: 0.634144\n",
      "epoch 64; iter: 0; batch classifier loss: 0.465953; batch adversarial loss: 0.582022\n",
      "epoch 65; iter: 0; batch classifier loss: 0.431735; batch adversarial loss: 0.619883\n",
      "epoch 66; iter: 0; batch classifier loss: 0.410093; batch adversarial loss: 0.597703\n",
      "epoch 67; iter: 0; batch classifier loss: 0.345926; batch adversarial loss: 0.538219\n",
      "epoch 68; iter: 0; batch classifier loss: 0.480760; batch adversarial loss: 0.490536\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415557; batch adversarial loss: 0.587023\n",
      "epoch 70; iter: 0; batch classifier loss: 0.357085; batch adversarial loss: 0.616841\n",
      "epoch 71; iter: 0; batch classifier loss: 0.448448; batch adversarial loss: 0.528768\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379428; batch adversarial loss: 0.556155\n",
      "epoch 73; iter: 0; batch classifier loss: 0.303644; batch adversarial loss: 0.567507\n",
      "epoch 74; iter: 0; batch classifier loss: 0.501334; batch adversarial loss: 0.583824\n",
      "epoch 75; iter: 0; batch classifier loss: 0.322934; batch adversarial loss: 0.538390\n",
      "epoch 76; iter: 0; batch classifier loss: 0.391171; batch adversarial loss: 0.563192\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398181; batch adversarial loss: 0.479084\n",
      "epoch 78; iter: 0; batch classifier loss: 0.478521; batch adversarial loss: 0.547689\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400525; batch adversarial loss: 0.602613\n",
      "epoch 80; iter: 0; batch classifier loss: 0.318728; batch adversarial loss: 0.604005\n",
      "epoch 81; iter: 0; batch classifier loss: 0.440582; batch adversarial loss: 0.596663\n",
      "epoch 82; iter: 0; batch classifier loss: 0.408534; batch adversarial loss: 0.528429\n",
      "epoch 83; iter: 0; batch classifier loss: 0.420932; batch adversarial loss: 0.616422\n",
      "epoch 84; iter: 0; batch classifier loss: 0.411402; batch adversarial loss: 0.603201\n",
      "epoch 85; iter: 0; batch classifier loss: 0.298092; batch adversarial loss: 0.603479\n",
      "epoch 86; iter: 0; batch classifier loss: 0.400750; batch adversarial loss: 0.620765\n",
      "epoch 87; iter: 0; batch classifier loss: 0.402827; batch adversarial loss: 0.595073\n",
      "epoch 88; iter: 0; batch classifier loss: 0.487459; batch adversarial loss: 0.491712\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387627; batch adversarial loss: 0.542785\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402429; batch adversarial loss: 0.541107\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380630; batch adversarial loss: 0.606316\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404514; batch adversarial loss: 0.627659\n",
      "epoch 93; iter: 0; batch classifier loss: 0.527764; batch adversarial loss: 0.550686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.417820; batch adversarial loss: 0.500119\n",
      "epoch 95; iter: 0; batch classifier loss: 0.477905; batch adversarial loss: 0.577281\n",
      "epoch 96; iter: 0; batch classifier loss: 0.401993; batch adversarial loss: 0.575464\n",
      "epoch 97; iter: 0; batch classifier loss: 0.462749; batch adversarial loss: 0.642394\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401730; batch adversarial loss: 0.514013\n",
      "epoch 99; iter: 0; batch classifier loss: 0.432401; batch adversarial loss: 0.547945\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748935; batch adversarial loss: 0.807700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.713578; batch adversarial loss: 0.856431\n",
      "epoch 2; iter: 0; batch classifier loss: 0.700231; batch adversarial loss: 0.776417\n",
      "epoch 3; iter: 0; batch classifier loss: 0.528695; batch adversarial loss: 0.737930\n",
      "epoch 4; iter: 0; batch classifier loss: 0.470948; batch adversarial loss: 0.724823\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495414; batch adversarial loss: 0.656345\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606451; batch adversarial loss: 0.668139\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492625; batch adversarial loss: 0.658657\n",
      "epoch 8; iter: 0; batch classifier loss: 0.483407; batch adversarial loss: 0.634907\n",
      "epoch 9; iter: 0; batch classifier loss: 0.466451; batch adversarial loss: 0.654449\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464062; batch adversarial loss: 0.656962\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575342; batch adversarial loss: 0.612001\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551002; batch adversarial loss: 0.622226\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540090; batch adversarial loss: 0.625111\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500528; batch adversarial loss: 0.605619\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530946; batch adversarial loss: 0.583869\n",
      "epoch 16; iter: 0; batch classifier loss: 0.498041; batch adversarial loss: 0.555036\n",
      "epoch 17; iter: 0; batch classifier loss: 0.510366; batch adversarial loss: 0.590440\n",
      "epoch 18; iter: 0; batch classifier loss: 0.477711; batch adversarial loss: 0.532790\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438467; batch adversarial loss: 0.566768\n",
      "epoch 20; iter: 0; batch classifier loss: 0.453230; batch adversarial loss: 0.603507\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495127; batch adversarial loss: 0.577576\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437245; batch adversarial loss: 0.544079\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476051; batch adversarial loss: 0.517681\n",
      "epoch 24; iter: 0; batch classifier loss: 0.403521; batch adversarial loss: 0.510474\n",
      "epoch 25; iter: 0; batch classifier loss: 0.431620; batch adversarial loss: 0.512656\n",
      "epoch 26; iter: 0; batch classifier loss: 0.393852; batch adversarial loss: 0.579433\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439504; batch adversarial loss: 0.605181\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538499; batch adversarial loss: 0.584961\n",
      "epoch 29; iter: 0; batch classifier loss: 0.485532; batch adversarial loss: 0.567369\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477669; batch adversarial loss: 0.585075\n",
      "epoch 31; iter: 0; batch classifier loss: 0.488358; batch adversarial loss: 0.570881\n",
      "epoch 32; iter: 0; batch classifier loss: 0.549657; batch adversarial loss: 0.592241\n",
      "epoch 33; iter: 0; batch classifier loss: 0.570064; batch adversarial loss: 0.612511\n",
      "epoch 34; iter: 0; batch classifier loss: 0.493652; batch adversarial loss: 0.669629\n",
      "epoch 35; iter: 0; batch classifier loss: 0.522137; batch adversarial loss: 0.647360\n",
      "epoch 36; iter: 0; batch classifier loss: 0.642662; batch adversarial loss: 0.663990\n",
      "epoch 37; iter: 0; batch classifier loss: 0.836669; batch adversarial loss: 0.727291\n",
      "epoch 38; iter: 0; batch classifier loss: 0.792188; batch adversarial loss: 0.591476\n",
      "epoch 39; iter: 0; batch classifier loss: 0.740532; batch adversarial loss: 0.691363\n",
      "epoch 40; iter: 0; batch classifier loss: 0.776990; batch adversarial loss: 0.659424\n",
      "epoch 41; iter: 0; batch classifier loss: 0.609015; batch adversarial loss: 0.542795\n",
      "epoch 42; iter: 0; batch classifier loss: 0.686772; batch adversarial loss: 0.600529\n",
      "epoch 43; iter: 0; batch classifier loss: 0.813265; batch adversarial loss: 0.563883\n",
      "epoch 44; iter: 0; batch classifier loss: 0.505951; batch adversarial loss: 0.685691\n",
      "epoch 45; iter: 0; batch classifier loss: 0.476371; batch adversarial loss: 0.582998\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420043; batch adversarial loss: 0.562838\n",
      "epoch 47; iter: 0; batch classifier loss: 0.359060; batch adversarial loss: 0.585631\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429161; batch adversarial loss: 0.554809\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401673; batch adversarial loss: 0.551167\n",
      "epoch 50; iter: 0; batch classifier loss: 0.439120; batch adversarial loss: 0.514902\n",
      "epoch 51; iter: 0; batch classifier loss: 0.416846; batch adversarial loss: 0.597760\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415802; batch adversarial loss: 0.524068\n",
      "epoch 53; iter: 0; batch classifier loss: 0.412041; batch adversarial loss: 0.581669\n",
      "epoch 54; iter: 0; batch classifier loss: 0.438233; batch adversarial loss: 0.621579\n",
      "epoch 55; iter: 0; batch classifier loss: 0.480818; batch adversarial loss: 0.528474\n",
      "epoch 56; iter: 0; batch classifier loss: 0.347352; batch adversarial loss: 0.526642\n",
      "epoch 57; iter: 0; batch classifier loss: 0.409350; batch adversarial loss: 0.577691\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396135; batch adversarial loss: 0.546420\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410936; batch adversarial loss: 0.561518\n",
      "epoch 60; iter: 0; batch classifier loss: 0.365199; batch adversarial loss: 0.617508\n",
      "epoch 61; iter: 0; batch classifier loss: 0.409016; batch adversarial loss: 0.609288\n",
      "epoch 62; iter: 0; batch classifier loss: 0.443276; batch adversarial loss: 0.614613\n",
      "epoch 63; iter: 0; batch classifier loss: 0.377573; batch adversarial loss: 0.633200\n",
      "epoch 64; iter: 0; batch classifier loss: 0.449510; batch adversarial loss: 0.579219\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420189; batch adversarial loss: 0.618699\n",
      "epoch 66; iter: 0; batch classifier loss: 0.409691; batch adversarial loss: 0.596662\n",
      "epoch 67; iter: 0; batch classifier loss: 0.327699; batch adversarial loss: 0.536881\n",
      "epoch 68; iter: 0; batch classifier loss: 0.487094; batch adversarial loss: 0.490819\n",
      "epoch 69; iter: 0; batch classifier loss: 0.400845; batch adversarial loss: 0.584684\n",
      "epoch 70; iter: 0; batch classifier loss: 0.354090; batch adversarial loss: 0.615430\n",
      "epoch 71; iter: 0; batch classifier loss: 0.427278; batch adversarial loss: 0.526416\n",
      "epoch 72; iter: 0; batch classifier loss: 0.377447; batch adversarial loss: 0.553453\n",
      "epoch 73; iter: 0; batch classifier loss: 0.279407; batch adversarial loss: 0.566863\n",
      "epoch 74; iter: 0; batch classifier loss: 0.492122; batch adversarial loss: 0.583390\n",
      "epoch 75; iter: 0; batch classifier loss: 0.329710; batch adversarial loss: 0.537276\n",
      "epoch 76; iter: 0; batch classifier loss: 0.382581; batch adversarial loss: 0.559805\n",
      "epoch 77; iter: 0; batch classifier loss: 0.392828; batch adversarial loss: 0.478576\n",
      "epoch 78; iter: 0; batch classifier loss: 0.453151; batch adversarial loss: 0.545100\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374842; batch adversarial loss: 0.599122\n",
      "epoch 80; iter: 0; batch classifier loss: 0.297922; batch adversarial loss: 0.600392\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415601; batch adversarial loss: 0.592326\n",
      "epoch 82; iter: 0; batch classifier loss: 0.368807; batch adversarial loss: 0.524593\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413661; batch adversarial loss: 0.614187\n",
      "epoch 84; iter: 0; batch classifier loss: 0.393728; batch adversarial loss: 0.601044\n",
      "epoch 85; iter: 0; batch classifier loss: 0.282536; batch adversarial loss: 0.600196\n",
      "epoch 86; iter: 0; batch classifier loss: 0.320517; batch adversarial loss: 0.614020\n",
      "epoch 87; iter: 0; batch classifier loss: 0.397416; batch adversarial loss: 0.590407\n",
      "epoch 88; iter: 0; batch classifier loss: 0.434785; batch adversarial loss: 0.484128\n",
      "epoch 89; iter: 0; batch classifier loss: 0.366433; batch adversarial loss: 0.539255\n",
      "epoch 90; iter: 0; batch classifier loss: 0.358152; batch adversarial loss: 0.536133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91; iter: 0; batch classifier loss: 0.365702; batch adversarial loss: 0.601796\n",
      "epoch 92; iter: 0; batch classifier loss: 0.348512; batch adversarial loss: 0.620762\n",
      "epoch 93; iter: 0; batch classifier loss: 0.491775; batch adversarial loss: 0.548703\n",
      "epoch 94; iter: 0; batch classifier loss: 0.399135; batch adversarial loss: 0.496502\n",
      "epoch 95; iter: 0; batch classifier loss: 0.429722; batch adversarial loss: 0.569954\n",
      "epoch 96; iter: 0; batch classifier loss: 0.366123; batch adversarial loss: 0.573329\n",
      "epoch 97; iter: 0; batch classifier loss: 0.412921; batch adversarial loss: 0.633086\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378547; batch adversarial loss: 0.511013\n",
      "epoch 99; iter: 0; batch classifier loss: 0.392707; batch adversarial loss: 0.541010\n",
      "Probas: [[0.9970735  0.0029265 ]\n",
      " [0.71485618 0.28514382]\n",
      " [0.28650093 0.71349907]\n",
      " [0.87707391 0.12292609]\n",
      " [0.55443954 0.44556046]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.86792119 0.13207881]\n",
      " [0.71485618 0.28514382]\n",
      " [0.28650093 0.71349907]\n",
      " [0.87707391 0.12292609]\n",
      " [0.55443954 0.44556046]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.99749203 0.00250797]\n",
      " [0.71485618 0.28514382]\n",
      " [0.28650093 0.71349907]\n",
      " [0.87707391 0.12292609]\n",
      " [0.55443954 0.44556046]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.76990426 0.23009574]\n",
      " [0.71485618 0.28514382]\n",
      " [0.28650093 0.71349907]\n",
      " [0.87707391 0.12292609]\n",
      " [0.55443954 0.44556046]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.90238744 0.09761256]\n",
      " [0.71485618 0.28514382]\n",
      " [0.28650093 0.71349907]\n",
      " [0.87707391 0.12292609]\n",
      " [0.55443954 0.44556046]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.9532399  0.0467601 ]\n",
      " [0.71485618 0.28514382]\n",
      " [0.28650093 0.71349907]\n",
      " [0.87707391 0.12292609]\n",
      " [0.55443954 0.44556046]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.75020373 0.24979627]\n",
      " [0.71485618 0.28514382]\n",
      " [0.28650093 0.71349907]\n",
      " [0.87707391 0.12292609]\n",
      " [0.55443954 0.44556046]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.42094564 0.57905436]\n",
      " [0.71485618 0.28514382]\n",
      " [0.28650093 0.71349907]\n",
      " [0.87707391 0.12292609]\n",
      " [0.55443954 0.44556046]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.8500167  0.1499833 ]\n",
      " [0.71485618 0.28514382]\n",
      " [0.28650093 0.71349907]\n",
      " [0.87707391 0.12292609]\n",
      " [0.55443954 0.44556046]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.37494242 0.62505758]\n",
      " [0.71485618 0.28514382]\n",
      " [0.28650093 0.71349907]\n",
      " [0.87707391 0.12292609]\n",
      " [0.55443954 0.44556046]] Sums: [1. 1. 1. 1. 1.]\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698844; batch adversarial loss: 0.829340\n",
      "epoch 1; iter: 0; batch classifier loss: 0.896694; batch adversarial loss: 0.836574\n",
      "epoch 2; iter: 0; batch classifier loss: 0.768919; batch adversarial loss: 0.808633\n",
      "epoch 3; iter: 0; batch classifier loss: 0.671266; batch adversarial loss: 0.724610\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574156; batch adversarial loss: 0.705212\n",
      "epoch 5; iter: 0; batch classifier loss: 0.499313; batch adversarial loss: 0.668438\n",
      "epoch 6; iter: 0; batch classifier loss: 0.503915; batch adversarial loss: 0.665125\n",
      "epoch 7; iter: 0; batch classifier loss: 0.462402; batch adversarial loss: 0.636378\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546255; batch adversarial loss: 0.619983\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503543; batch adversarial loss: 0.596486\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572362; batch adversarial loss: 0.591817\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539656; batch adversarial loss: 0.594811\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557028; batch adversarial loss: 0.578278\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530859; batch adversarial loss: 0.553914\n",
      "epoch 14; iter: 0; batch classifier loss: 0.493326; batch adversarial loss: 0.548957\n",
      "epoch 15; iter: 0; batch classifier loss: 0.572307; batch adversarial loss: 0.581173\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529963; batch adversarial loss: 0.520596\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550110; batch adversarial loss: 0.524374\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513989; batch adversarial loss: 0.514437\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501792; batch adversarial loss: 0.530308\n",
      "epoch 20; iter: 0; batch classifier loss: 0.533079; batch adversarial loss: 0.448990\n",
      "epoch 21; iter: 0; batch classifier loss: 0.431217; batch adversarial loss: 0.478244\n",
      "epoch 22; iter: 0; batch classifier loss: 0.414766; batch adversarial loss: 0.491354\n",
      "epoch 23; iter: 0; batch classifier loss: 0.437290; batch adversarial loss: 0.489713\n",
      "epoch 24; iter: 0; batch classifier loss: 0.436348; batch adversarial loss: 0.442168\n",
      "epoch 25; iter: 0; batch classifier loss: 0.574243; batch adversarial loss: 0.526250\n",
      "epoch 26; iter: 0; batch classifier loss: 0.519174; batch adversarial loss: 0.500630\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484393; batch adversarial loss: 0.619592\n",
      "epoch 28; iter: 0; batch classifier loss: 0.422426; batch adversarial loss: 0.496383\n",
      "epoch 29; iter: 0; batch classifier loss: 0.502724; batch adversarial loss: 0.524940\n",
      "epoch 30; iter: 0; batch classifier loss: 0.375956; batch adversarial loss: 0.541564\n",
      "epoch 31; iter: 0; batch classifier loss: 0.437748; batch adversarial loss: 0.490387\n",
      "epoch 32; iter: 0; batch classifier loss: 0.507540; batch adversarial loss: 0.526513\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448976; batch adversarial loss: 0.529840\n",
      "epoch 34; iter: 0; batch classifier loss: 0.540519; batch adversarial loss: 0.577901\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457806; batch adversarial loss: 0.492977\n",
      "epoch 36; iter: 0; batch classifier loss: 0.481447; batch adversarial loss: 0.480435\n",
      "epoch 37; iter: 0; batch classifier loss: 0.540248; batch adversarial loss: 0.565419\n",
      "epoch 38; iter: 0; batch classifier loss: 0.491979; batch adversarial loss: 0.433054\n",
      "epoch 39; iter: 0; batch classifier loss: 0.559936; batch adversarial loss: 0.492540\n",
      "epoch 40; iter: 0; batch classifier loss: 0.534932; batch adversarial loss: 0.464228\n",
      "epoch 41; iter: 0; batch classifier loss: 0.656770; batch adversarial loss: 0.562974\n",
      "epoch 42; iter: 0; batch classifier loss: 0.475186; batch adversarial loss: 0.472240\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474563; batch adversarial loss: 0.475039\n",
      "epoch 44; iter: 0; batch classifier loss: 0.516486; batch adversarial loss: 0.423406\n",
      "epoch 45; iter: 0; batch classifier loss: 0.372829; batch adversarial loss: 0.451351\n",
      "epoch 46; iter: 0; batch classifier loss: 0.478006; batch adversarial loss: 0.547869\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462951; batch adversarial loss: 0.518630\n",
      "epoch 48; iter: 0; batch classifier loss: 0.552368; batch adversarial loss: 0.441299\n",
      "epoch 49; iter: 0; batch classifier loss: 0.511326; batch adversarial loss: 0.479685\n",
      "epoch 50; iter: 0; batch classifier loss: 0.623473; batch adversarial loss: 0.510634\n",
      "epoch 51; iter: 0; batch classifier loss: 0.371642; batch adversarial loss: 0.484428\n",
      "epoch 52; iter: 0; batch classifier loss: 0.382926; batch adversarial loss: 0.429441\n",
      "epoch 53; iter: 0; batch classifier loss: 0.359733; batch adversarial loss: 0.428567\n",
      "epoch 54; iter: 0; batch classifier loss: 0.424938; batch adversarial loss: 0.447131\n",
      "epoch 55; iter: 0; batch classifier loss: 0.377017; batch adversarial loss: 0.368868\n",
      "epoch 56; iter: 0; batch classifier loss: 0.341326; batch adversarial loss: 0.521834\n",
      "epoch 57; iter: 0; batch classifier loss: 0.358038; batch adversarial loss: 0.499006\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378183; batch adversarial loss: 0.452980\n",
      "epoch 59; iter: 0; batch classifier loss: 0.307875; batch adversarial loss: 0.465160\n",
      "epoch 60; iter: 0; batch classifier loss: 0.378493; batch adversarial loss: 0.596202\n",
      "epoch 61; iter: 0; batch classifier loss: 0.324836; batch adversarial loss: 0.536589\n",
      "epoch 62; iter: 0; batch classifier loss: 0.366531; batch adversarial loss: 0.472598\n",
      "epoch 63; iter: 0; batch classifier loss: 0.395159; batch adversarial loss: 0.455573\n",
      "epoch 64; iter: 0; batch classifier loss: 0.306271; batch adversarial loss: 0.440082\n",
      "epoch 65; iter: 0; batch classifier loss: 0.324612; batch adversarial loss: 0.503839\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411013; batch adversarial loss: 0.451366\n",
      "epoch 67; iter: 0; batch classifier loss: 0.358731; batch adversarial loss: 0.457628\n",
      "epoch 68; iter: 0; batch classifier loss: 0.346826; batch adversarial loss: 0.435860\n",
      "epoch 69; iter: 0; batch classifier loss: 0.337955; batch adversarial loss: 0.453498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.379226; batch adversarial loss: 0.470236\n",
      "epoch 71; iter: 0; batch classifier loss: 0.329562; batch adversarial loss: 0.425335\n",
      "epoch 72; iter: 0; batch classifier loss: 0.309229; batch adversarial loss: 0.528472\n",
      "epoch 73; iter: 0; batch classifier loss: 0.359054; batch adversarial loss: 0.533186\n",
      "epoch 74; iter: 0; batch classifier loss: 0.397457; batch adversarial loss: 0.447781\n",
      "epoch 75; iter: 0; batch classifier loss: 0.381190; batch adversarial loss: 0.484290\n",
      "epoch 76; iter: 0; batch classifier loss: 0.388898; batch adversarial loss: 0.532813\n",
      "epoch 77; iter: 0; batch classifier loss: 0.317710; batch adversarial loss: 0.443613\n",
      "epoch 78; iter: 0; batch classifier loss: 0.299925; batch adversarial loss: 0.530033\n",
      "epoch 79; iter: 0; batch classifier loss: 0.346453; batch adversarial loss: 0.418598\n",
      "epoch 80; iter: 0; batch classifier loss: 0.362317; batch adversarial loss: 0.451991\n",
      "epoch 81; iter: 0; batch classifier loss: 0.315414; batch adversarial loss: 0.485111\n",
      "epoch 82; iter: 0; batch classifier loss: 0.311135; batch adversarial loss: 0.438091\n",
      "epoch 83; iter: 0; batch classifier loss: 0.333917; batch adversarial loss: 0.448016\n",
      "epoch 84; iter: 0; batch classifier loss: 0.292491; batch adversarial loss: 0.459633\n",
      "epoch 85; iter: 0; batch classifier loss: 0.280798; batch adversarial loss: 0.485280\n",
      "epoch 86; iter: 0; batch classifier loss: 0.344427; batch adversarial loss: 0.469120\n",
      "epoch 87; iter: 0; batch classifier loss: 0.285177; batch adversarial loss: 0.523212\n",
      "epoch 88; iter: 0; batch classifier loss: 0.340966; batch adversarial loss: 0.427477\n",
      "epoch 89; iter: 0; batch classifier loss: 0.314906; batch adversarial loss: 0.457591\n",
      "epoch 90; iter: 0; batch classifier loss: 0.376559; batch adversarial loss: 0.457313\n",
      "epoch 91; iter: 0; batch classifier loss: 0.293927; batch adversarial loss: 0.494429\n",
      "epoch 92; iter: 0; batch classifier loss: 0.248649; batch adversarial loss: 0.604740\n",
      "epoch 93; iter: 0; batch classifier loss: 0.295843; batch adversarial loss: 0.613057\n",
      "epoch 94; iter: 0; batch classifier loss: 0.259365; batch adversarial loss: 0.499364\n",
      "epoch 95; iter: 0; batch classifier loss: 0.208749; batch adversarial loss: 0.488058\n",
      "epoch 96; iter: 0; batch classifier loss: 0.306453; batch adversarial loss: 0.519139\n",
      "epoch 97; iter: 0; batch classifier loss: 0.321900; batch adversarial loss: 0.359283\n",
      "epoch 98; iter: 0; batch classifier loss: 0.269623; batch adversarial loss: 0.484119\n",
      "epoch 99; iter: 0; batch classifier loss: 0.338590; batch adversarial loss: 0.508450\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.161805; batch adversarial loss: 0.860781\n",
      "epoch 2; iter: 0; batch classifier loss: 1.019137; batch adversarial loss: 0.833349\n",
      "epoch 3; iter: 0; batch classifier loss: 0.984283; batch adversarial loss: 0.744430\n",
      "epoch 4; iter: 0; batch classifier loss: 0.780517; batch adversarial loss: 0.733370\n",
      "epoch 5; iter: 0; batch classifier loss: 0.596519; batch adversarial loss: 0.689408\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519864; batch adversarial loss: 0.666675\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496548; batch adversarial loss: 0.630501\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561452; batch adversarial loss: 0.615050\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502809; batch adversarial loss: 0.594333\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564536; batch adversarial loss: 0.590845\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543634; batch adversarial loss: 0.596054\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557591; batch adversarial loss: 0.577877\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516128; batch adversarial loss: 0.551349\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464231; batch adversarial loss: 0.551022\n",
      "epoch 15; iter: 0; batch classifier loss: 0.573416; batch adversarial loss: 0.580473\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528438; batch adversarial loss: 0.532365\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521808; batch adversarial loss: 0.541061\n",
      "epoch 18; iter: 0; batch classifier loss: 0.528034; batch adversarial loss: 0.530702\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543228; batch adversarial loss: 0.556970\n",
      "epoch 20; iter: 0; batch classifier loss: 0.602796; batch adversarial loss: 0.481192\n",
      "epoch 21; iter: 0; batch classifier loss: 0.563857; batch adversarial loss: 0.529174\n",
      "epoch 22; iter: 0; batch classifier loss: 0.609678; batch adversarial loss: 0.542168\n",
      "epoch 23; iter: 0; batch classifier loss: 0.581951; batch adversarial loss: 0.558505\n",
      "epoch 24; iter: 0; batch classifier loss: 0.578565; batch adversarial loss: 0.511918\n",
      "epoch 25; iter: 0; batch classifier loss: 0.789625; batch adversarial loss: 0.589267\n",
      "epoch 26; iter: 0; batch classifier loss: 0.659351; batch adversarial loss: 0.530298\n",
      "epoch 27; iter: 0; batch classifier loss: 0.704438; batch adversarial loss: 0.652287\n",
      "epoch 28; iter: 0; batch classifier loss: 0.599404; batch adversarial loss: 0.529103\n",
      "epoch 29; iter: 0; batch classifier loss: 0.650103; batch adversarial loss: 0.541038\n",
      "epoch 30; iter: 0; batch classifier loss: 0.537267; batch adversarial loss: 0.546997\n",
      "epoch 31; iter: 0; batch classifier loss: 0.539494; batch adversarial loss: 0.491926\n",
      "epoch 32; iter: 0; batch classifier loss: 0.532659; batch adversarial loss: 0.511986\n",
      "epoch 33; iter: 0; batch classifier loss: 0.482736; batch adversarial loss: 0.520360\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482863; batch adversarial loss: 0.540506\n",
      "epoch 35; iter: 0; batch classifier loss: 0.480598; batch adversarial loss: 0.481867\n",
      "epoch 36; iter: 0; batch classifier loss: 0.504733; batch adversarial loss: 0.458852\n",
      "epoch 37; iter: 0; batch classifier loss: 0.537162; batch adversarial loss: 0.532149\n",
      "epoch 38; iter: 0; batch classifier loss: 0.539395; batch adversarial loss: 0.416874\n",
      "epoch 39; iter: 0; batch classifier loss: 0.565707; batch adversarial loss: 0.466231\n",
      "epoch 40; iter: 0; batch classifier loss: 0.587004; batch adversarial loss: 0.451580\n",
      "epoch 41; iter: 0; batch classifier loss: 0.634994; batch adversarial loss: 0.537119\n",
      "epoch 42; iter: 0; batch classifier loss: 0.507935; batch adversarial loss: 0.455910\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475895; batch adversarial loss: 0.462228\n",
      "epoch 44; iter: 0; batch classifier loss: 0.499505; batch adversarial loss: 0.411772\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426545; batch adversarial loss: 0.447083\n",
      "epoch 46; iter: 0; batch classifier loss: 0.502003; batch adversarial loss: 0.536283\n",
      "epoch 47; iter: 0; batch classifier loss: 0.519965; batch adversarial loss: 0.506171\n",
      "epoch 48; iter: 0; batch classifier loss: 0.591346; batch adversarial loss: 0.433604\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433897; batch adversarial loss: 0.471671\n",
      "epoch 50; iter: 0; batch classifier loss: 0.469609; batch adversarial loss: 0.504452\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468983; batch adversarial loss: 0.483302\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451061; batch adversarial loss: 0.426320\n",
      "epoch 53; iter: 0; batch classifier loss: 0.470147; batch adversarial loss: 0.426243\n",
      "epoch 54; iter: 0; batch classifier loss: 0.513840; batch adversarial loss: 0.446669\n",
      "epoch 55; iter: 0; batch classifier loss: 0.485406; batch adversarial loss: 0.365765\n",
      "epoch 56; iter: 0; batch classifier loss: 0.418593; batch adversarial loss: 0.523653\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400716; batch adversarial loss: 0.498680\n",
      "epoch 58; iter: 0; batch classifier loss: 0.459487; batch adversarial loss: 0.453310\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416062; batch adversarial loss: 0.466002\n",
      "epoch 60; iter: 0; batch classifier loss: 0.445055; batch adversarial loss: 0.596864\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420811; batch adversarial loss: 0.539446\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436597; batch adversarial loss: 0.470820\n",
      "epoch 63; iter: 0; batch classifier loss: 0.434059; batch adversarial loss: 0.449908\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386735; batch adversarial loss: 0.440034\n",
      "epoch 65; iter: 0; batch classifier loss: 0.391372; batch adversarial loss: 0.503903\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437397; batch adversarial loss: 0.450269\n",
      "epoch 67; iter: 0; batch classifier loss: 0.420054; batch adversarial loss: 0.456691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.410676; batch adversarial loss: 0.432271\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449648; batch adversarial loss: 0.453877\n",
      "epoch 70; iter: 0; batch classifier loss: 0.474856; batch adversarial loss: 0.469497\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414686; batch adversarial loss: 0.425822\n",
      "epoch 72; iter: 0; batch classifier loss: 0.474796; batch adversarial loss: 0.530218\n",
      "epoch 73; iter: 0; batch classifier loss: 0.440243; batch adversarial loss: 0.527900\n",
      "epoch 74; iter: 0; batch classifier loss: 0.486566; batch adversarial loss: 0.442771\n",
      "epoch 75; iter: 0; batch classifier loss: 0.498785; batch adversarial loss: 0.482499\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461103; batch adversarial loss: 0.529466\n",
      "epoch 77; iter: 0; batch classifier loss: 0.403276; batch adversarial loss: 0.440375\n",
      "epoch 78; iter: 0; batch classifier loss: 0.370055; batch adversarial loss: 0.526268\n",
      "epoch 79; iter: 0; batch classifier loss: 0.392835; batch adversarial loss: 0.414336\n",
      "epoch 80; iter: 0; batch classifier loss: 0.442235; batch adversarial loss: 0.452897\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393022; batch adversarial loss: 0.485734\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398327; batch adversarial loss: 0.436756\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412226; batch adversarial loss: 0.447380\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374086; batch adversarial loss: 0.462701\n",
      "epoch 85; iter: 0; batch classifier loss: 0.346159; batch adversarial loss: 0.481642\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430736; batch adversarial loss: 0.469115\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366730; batch adversarial loss: 0.522225\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420514; batch adversarial loss: 0.419842\n",
      "epoch 89; iter: 0; batch classifier loss: 0.399998; batch adversarial loss: 0.453447\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405139; batch adversarial loss: 0.453930\n",
      "epoch 91; iter: 0; batch classifier loss: 0.377602; batch adversarial loss: 0.494343\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408716; batch adversarial loss: 0.605959\n",
      "epoch 93; iter: 0; batch classifier loss: 0.469197; batch adversarial loss: 0.611826\n",
      "epoch 94; iter: 0; batch classifier loss: 0.298855; batch adversarial loss: 0.497164\n",
      "epoch 95; iter: 0; batch classifier loss: 0.284809; batch adversarial loss: 0.484812\n",
      "epoch 96; iter: 0; batch classifier loss: 0.332574; batch adversarial loss: 0.517186\n",
      "epoch 97; iter: 0; batch classifier loss: 0.470799; batch adversarial loss: 0.361363\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385003; batch adversarial loss: 0.482444\n",
      "epoch 99; iter: 0; batch classifier loss: 0.459394; batch adversarial loss: 0.506941\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698844; batch adversarial loss: 0.829340\n",
      "epoch 1; iter: 0; batch classifier loss: 1.083449; batch adversarial loss: 0.856210\n",
      "epoch 2; iter: 0; batch classifier loss: 1.007949; batch adversarial loss: 0.835697\n",
      "epoch 3; iter: 0; batch classifier loss: 0.983196; batch adversarial loss: 0.747536\n",
      "epoch 4; iter: 0; batch classifier loss: 0.804035; batch adversarial loss: 0.736951\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607582; batch adversarial loss: 0.692632\n",
      "epoch 6; iter: 0; batch classifier loss: 0.499442; batch adversarial loss: 0.668195\n",
      "epoch 7; iter: 0; batch classifier loss: 0.461123; batch adversarial loss: 0.635995\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531060; batch adversarial loss: 0.619659\n",
      "epoch 9; iter: 0; batch classifier loss: 0.498442; batch adversarial loss: 0.594876\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561789; batch adversarial loss: 0.592847\n",
      "epoch 11; iter: 0; batch classifier loss: 0.506944; batch adversarial loss: 0.599293\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527453; batch adversarial loss: 0.581023\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483799; batch adversarial loss: 0.556692\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466633; batch adversarial loss: 0.549588\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549038; batch adversarial loss: 0.581391\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484712; batch adversarial loss: 0.535986\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497275; batch adversarial loss: 0.537958\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523793; batch adversarial loss: 0.538169\n",
      "epoch 19; iter: 0; batch classifier loss: 0.592682; batch adversarial loss: 0.576851\n",
      "epoch 20; iter: 0; batch classifier loss: 0.630658; batch adversarial loss: 0.499653\n",
      "epoch 21; iter: 0; batch classifier loss: 0.567731; batch adversarial loss: 0.549224\n",
      "epoch 22; iter: 0; batch classifier loss: 0.626542; batch adversarial loss: 0.569719\n",
      "epoch 23; iter: 0; batch classifier loss: 0.574836; batch adversarial loss: 0.555234\n",
      "epoch 24; iter: 0; batch classifier loss: 0.572064; batch adversarial loss: 0.505522\n",
      "epoch 25; iter: 0; batch classifier loss: 0.748888; batch adversarial loss: 0.579322\n",
      "epoch 26; iter: 0; batch classifier loss: 0.626555; batch adversarial loss: 0.521935\n",
      "epoch 27; iter: 0; batch classifier loss: 0.623706; batch adversarial loss: 0.632701\n",
      "epoch 28; iter: 0; batch classifier loss: 0.507222; batch adversarial loss: 0.521279\n",
      "epoch 29; iter: 0; batch classifier loss: 0.564550; batch adversarial loss: 0.530620\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459877; batch adversarial loss: 0.541621\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447228; batch adversarial loss: 0.487676\n",
      "epoch 32; iter: 0; batch classifier loss: 0.479618; batch adversarial loss: 0.508014\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412396; batch adversarial loss: 0.512800\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477399; batch adversarial loss: 0.537455\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458225; batch adversarial loss: 0.481811\n",
      "epoch 36; iter: 0; batch classifier loss: 0.514902; batch adversarial loss: 0.464798\n",
      "epoch 37; iter: 0; batch classifier loss: 0.583253; batch adversarial loss: 0.540533\n",
      "epoch 38; iter: 0; batch classifier loss: 0.522117; batch adversarial loss: 0.421198\n",
      "epoch 39; iter: 0; batch classifier loss: 0.498975; batch adversarial loss: 0.463515\n",
      "epoch 40; iter: 0; batch classifier loss: 0.514508; batch adversarial loss: 0.447505\n",
      "epoch 41; iter: 0; batch classifier loss: 0.557397; batch adversarial loss: 0.528421\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417938; batch adversarial loss: 0.450448\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425996; batch adversarial loss: 0.459335\n",
      "epoch 44; iter: 0; batch classifier loss: 0.483560; batch adversarial loss: 0.410841\n",
      "epoch 45; iter: 0; batch classifier loss: 0.381569; batch adversarial loss: 0.447112\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500403; batch adversarial loss: 0.536197\n",
      "epoch 47; iter: 0; batch classifier loss: 0.381509; batch adversarial loss: 0.503457\n",
      "epoch 48; iter: 0; batch classifier loss: 0.457257; batch adversarial loss: 0.431054\n",
      "epoch 49; iter: 0; batch classifier loss: 0.375323; batch adversarial loss: 0.469467\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428178; batch adversarial loss: 0.505136\n",
      "epoch 51; iter: 0; batch classifier loss: 0.397608; batch adversarial loss: 0.482971\n",
      "epoch 52; iter: 0; batch classifier loss: 0.376106; batch adversarial loss: 0.425316\n",
      "epoch 53; iter: 0; batch classifier loss: 0.385588; batch adversarial loss: 0.425768\n",
      "epoch 54; iter: 0; batch classifier loss: 0.463910; batch adversarial loss: 0.445114\n",
      "epoch 55; iter: 0; batch classifier loss: 0.391251; batch adversarial loss: 0.364999\n",
      "epoch 56; iter: 0; batch classifier loss: 0.370498; batch adversarial loss: 0.522593\n",
      "epoch 57; iter: 0; batch classifier loss: 0.377430; batch adversarial loss: 0.499064\n",
      "epoch 58; iter: 0; batch classifier loss: 0.410789; batch adversarial loss: 0.452963\n",
      "epoch 59; iter: 0; batch classifier loss: 0.335317; batch adversarial loss: 0.464746\n",
      "epoch 60; iter: 0; batch classifier loss: 0.399773; batch adversarial loss: 0.596878\n",
      "epoch 61; iter: 0; batch classifier loss: 0.328330; batch adversarial loss: 0.537045\n",
      "epoch 62; iter: 0; batch classifier loss: 0.376030; batch adversarial loss: 0.471747\n",
      "epoch 63; iter: 0; batch classifier loss: 0.399339; batch adversarial loss: 0.453159\n",
      "epoch 64; iter: 0; batch classifier loss: 0.316780; batch adversarial loss: 0.440041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.343344; batch adversarial loss: 0.503890\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417828; batch adversarial loss: 0.449770\n",
      "epoch 67; iter: 0; batch classifier loss: 0.382177; batch adversarial loss: 0.457557\n",
      "epoch 68; iter: 0; batch classifier loss: 0.338843; batch adversarial loss: 0.435380\n",
      "epoch 69; iter: 0; batch classifier loss: 0.357009; batch adversarial loss: 0.453171\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368787; batch adversarial loss: 0.471425\n",
      "epoch 71; iter: 0; batch classifier loss: 0.362267; batch adversarial loss: 0.426710\n",
      "epoch 72; iter: 0; batch classifier loss: 0.330122; batch adversarial loss: 0.528727\n",
      "epoch 73; iter: 0; batch classifier loss: 0.389097; batch adversarial loss: 0.531626\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414193; batch adversarial loss: 0.447470\n",
      "epoch 75; iter: 0; batch classifier loss: 0.426846; batch adversarial loss: 0.483814\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369347; batch adversarial loss: 0.533004\n",
      "epoch 77; iter: 0; batch classifier loss: 0.337482; batch adversarial loss: 0.442015\n",
      "epoch 78; iter: 0; batch classifier loss: 0.308003; batch adversarial loss: 0.529068\n",
      "epoch 79; iter: 0; batch classifier loss: 0.342656; batch adversarial loss: 0.417946\n",
      "epoch 80; iter: 0; batch classifier loss: 0.355508; batch adversarial loss: 0.451549\n",
      "epoch 81; iter: 0; batch classifier loss: 0.341869; batch adversarial loss: 0.486066\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356213; batch adversarial loss: 0.440098\n",
      "epoch 83; iter: 0; batch classifier loss: 0.368554; batch adversarial loss: 0.449883\n",
      "epoch 84; iter: 0; batch classifier loss: 0.303859; batch adversarial loss: 0.460299\n",
      "epoch 85; iter: 0; batch classifier loss: 0.277523; batch adversarial loss: 0.484719\n",
      "epoch 86; iter: 0; batch classifier loss: 0.338602; batch adversarial loss: 0.469603\n",
      "epoch 87; iter: 0; batch classifier loss: 0.286920; batch adversarial loss: 0.524273\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351591; batch adversarial loss: 0.427431\n",
      "epoch 89; iter: 0; batch classifier loss: 0.326997; batch adversarial loss: 0.456988\n",
      "epoch 90; iter: 0; batch classifier loss: 0.369864; batch adversarial loss: 0.456609\n",
      "epoch 91; iter: 0; batch classifier loss: 0.345072; batch adversarial loss: 0.496276\n",
      "epoch 92; iter: 0; batch classifier loss: 0.267364; batch adversarial loss: 0.603169\n",
      "epoch 93; iter: 0; batch classifier loss: 0.328349; batch adversarial loss: 0.612718\n",
      "epoch 94; iter: 0; batch classifier loss: 0.292016; batch adversarial loss: 0.499167\n",
      "epoch 95; iter: 0; batch classifier loss: 0.262657; batch adversarial loss: 0.489992\n",
      "epoch 96; iter: 0; batch classifier loss: 0.328968; batch adversarial loss: 0.521671\n",
      "epoch 97; iter: 0; batch classifier loss: 0.354780; batch adversarial loss: 0.361082\n",
      "epoch 98; iter: 0; batch classifier loss: 0.307868; batch adversarial loss: 0.485705\n",
      "epoch 99; iter: 0; batch classifier loss: 0.365555; batch adversarial loss: 0.510350\n",
      "epoch 100; iter: 0; batch classifier loss: 0.286871; batch adversarial loss: 0.488113\n",
      "epoch 101; iter: 0; batch classifier loss: 0.329789; batch adversarial loss: 0.495454\n",
      "epoch 102; iter: 0; batch classifier loss: 0.316933; batch adversarial loss: 0.489997\n",
      "epoch 103; iter: 0; batch classifier loss: 0.337041; batch adversarial loss: 0.447644\n",
      "epoch 104; iter: 0; batch classifier loss: 0.432663; batch adversarial loss: 0.429759\n",
      "epoch 105; iter: 0; batch classifier loss: 0.257461; batch adversarial loss: 0.499903\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352899; batch adversarial loss: 0.490201\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379573; batch adversarial loss: 0.577061\n",
      "epoch 108; iter: 0; batch classifier loss: 0.271144; batch adversarial loss: 0.539598\n",
      "epoch 109; iter: 0; batch classifier loss: 0.338497; batch adversarial loss: 0.461910\n",
      "epoch 110; iter: 0; batch classifier loss: 0.290441; batch adversarial loss: 0.593424\n",
      "epoch 111; iter: 0; batch classifier loss: 0.302164; batch adversarial loss: 0.560400\n",
      "epoch 112; iter: 0; batch classifier loss: 0.410702; batch adversarial loss: 0.490257\n",
      "epoch 113; iter: 0; batch classifier loss: 0.347023; batch adversarial loss: 0.488105\n",
      "epoch 114; iter: 0; batch classifier loss: 0.421943; batch adversarial loss: 0.533279\n",
      "epoch 115; iter: 0; batch classifier loss: 0.508818; batch adversarial loss: 0.418345\n",
      "epoch 116; iter: 0; batch classifier loss: 0.438040; batch adversarial loss: 0.462831\n",
      "epoch 117; iter: 0; batch classifier loss: 0.436607; batch adversarial loss: 0.481897\n",
      "epoch 118; iter: 0; batch classifier loss: 0.347268; batch adversarial loss: 0.444168\n",
      "epoch 119; iter: 0; batch classifier loss: 0.412261; batch adversarial loss: 0.533399\n",
      "epoch 120; iter: 0; batch classifier loss: 0.366446; batch adversarial loss: 0.459441\n",
      "epoch 121; iter: 0; batch classifier loss: 0.475714; batch adversarial loss: 0.528612\n",
      "epoch 122; iter: 0; batch classifier loss: 0.428316; batch adversarial loss: 0.493500\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354733; batch adversarial loss: 0.468974\n",
      "epoch 124; iter: 0; batch classifier loss: 0.322820; batch adversarial loss: 0.488280\n",
      "epoch 125; iter: 0; batch classifier loss: 0.411789; batch adversarial loss: 0.473903\n",
      "epoch 126; iter: 0; batch classifier loss: 0.469554; batch adversarial loss: 0.436812\n",
      "epoch 127; iter: 0; batch classifier loss: 0.372788; batch adversarial loss: 0.447376\n",
      "epoch 128; iter: 0; batch classifier loss: 0.318067; batch adversarial loss: 0.544438\n",
      "epoch 129; iter: 0; batch classifier loss: 0.375852; batch adversarial loss: 0.436415\n",
      "epoch 130; iter: 0; batch classifier loss: 0.402421; batch adversarial loss: 0.459623\n",
      "epoch 131; iter: 0; batch classifier loss: 0.440046; batch adversarial loss: 0.441463\n",
      "epoch 132; iter: 0; batch classifier loss: 0.384953; batch adversarial loss: 0.465265\n",
      "epoch 133; iter: 0; batch classifier loss: 0.390575; batch adversarial loss: 0.459239\n",
      "epoch 134; iter: 0; batch classifier loss: 0.415574; batch adversarial loss: 0.566090\n",
      "epoch 135; iter: 0; batch classifier loss: 0.395333; batch adversarial loss: 0.425010\n",
      "epoch 136; iter: 0; batch classifier loss: 0.359986; batch adversarial loss: 0.505716\n",
      "epoch 137; iter: 0; batch classifier loss: 0.462559; batch adversarial loss: 0.417904\n",
      "epoch 138; iter: 0; batch classifier loss: 0.397312; batch adversarial loss: 0.504644\n",
      "epoch 139; iter: 0; batch classifier loss: 0.374054; batch adversarial loss: 0.496538\n",
      "epoch 140; iter: 0; batch classifier loss: 0.411457; batch adversarial loss: 0.459061\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343263; batch adversarial loss: 0.480118\n",
      "epoch 142; iter: 0; batch classifier loss: 0.395288; batch adversarial loss: 0.506770\n",
      "epoch 143; iter: 0; batch classifier loss: 0.489254; batch adversarial loss: 0.395052\n",
      "epoch 144; iter: 0; batch classifier loss: 0.409078; batch adversarial loss: 0.460196\n",
      "epoch 145; iter: 0; batch classifier loss: 0.425149; batch adversarial loss: 0.482486\n",
      "epoch 146; iter: 0; batch classifier loss: 0.395225; batch adversarial loss: 0.493568\n",
      "epoch 147; iter: 0; batch classifier loss: 0.352722; batch adversarial loss: 0.452180\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381832; batch adversarial loss: 0.459605\n",
      "epoch 149; iter: 0; batch classifier loss: 0.431135; batch adversarial loss: 0.434805\n",
      "epoch 150; iter: 0; batch classifier loss: 0.382463; batch adversarial loss: 0.394753\n",
      "epoch 151; iter: 0; batch classifier loss: 0.367465; batch adversarial loss: 0.436600\n",
      "epoch 152; iter: 0; batch classifier loss: 0.382607; batch adversarial loss: 0.470414\n",
      "epoch 153; iter: 0; batch classifier loss: 0.385394; batch adversarial loss: 0.517747\n",
      "epoch 154; iter: 0; batch classifier loss: 0.314011; batch adversarial loss: 0.540914\n",
      "epoch 155; iter: 0; batch classifier loss: 0.331314; batch adversarial loss: 0.494988\n",
      "epoch 156; iter: 0; batch classifier loss: 0.383264; batch adversarial loss: 0.446772\n",
      "epoch 157; iter: 0; batch classifier loss: 0.470251; batch adversarial loss: 0.470715\n",
      "epoch 158; iter: 0; batch classifier loss: 0.386898; batch adversarial loss: 0.493474\n",
      "epoch 159; iter: 0; batch classifier loss: 0.468266; batch adversarial loss: 0.437817\n",
      "epoch 160; iter: 0; batch classifier loss: 0.416438; batch adversarial loss: 0.460313\n",
      "epoch 161; iter: 0; batch classifier loss: 0.460028; batch adversarial loss: 0.495154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.422128; batch adversarial loss: 0.483619\n",
      "epoch 163; iter: 0; batch classifier loss: 0.350195; batch adversarial loss: 0.505713\n",
      "epoch 164; iter: 0; batch classifier loss: 0.407731; batch adversarial loss: 0.412937\n",
      "epoch 165; iter: 0; batch classifier loss: 0.357880; batch adversarial loss: 0.401492\n",
      "epoch 166; iter: 0; batch classifier loss: 0.351637; batch adversarial loss: 0.436716\n",
      "epoch 167; iter: 0; batch classifier loss: 0.359733; batch adversarial loss: 0.436878\n",
      "epoch 168; iter: 0; batch classifier loss: 0.337575; batch adversarial loss: 0.458840\n",
      "epoch 169; iter: 0; batch classifier loss: 0.425838; batch adversarial loss: 0.494733\n",
      "epoch 170; iter: 0; batch classifier loss: 0.334921; batch adversarial loss: 0.481617\n",
      "epoch 171; iter: 0; batch classifier loss: 0.417147; batch adversarial loss: 0.505565\n",
      "epoch 172; iter: 0; batch classifier loss: 0.364287; batch adversarial loss: 0.447007\n",
      "epoch 173; iter: 0; batch classifier loss: 0.361192; batch adversarial loss: 0.415136\n",
      "epoch 174; iter: 0; batch classifier loss: 0.384651; batch adversarial loss: 0.413257\n",
      "epoch 175; iter: 0; batch classifier loss: 0.260169; batch adversarial loss: 0.458399\n",
      "epoch 176; iter: 0; batch classifier loss: 0.343989; batch adversarial loss: 0.516899\n",
      "epoch 177; iter: 0; batch classifier loss: 0.470131; batch adversarial loss: 0.575329\n",
      "epoch 178; iter: 0; batch classifier loss: 0.343401; batch adversarial loss: 0.518253\n",
      "epoch 179; iter: 0; batch classifier loss: 0.453990; batch adversarial loss: 0.449869\n",
      "epoch 180; iter: 0; batch classifier loss: 0.336174; batch adversarial loss: 0.411663\n",
      "epoch 181; iter: 0; batch classifier loss: 0.322552; batch adversarial loss: 0.541611\n",
      "epoch 182; iter: 0; batch classifier loss: 0.542132; batch adversarial loss: 0.376520\n",
      "epoch 183; iter: 0; batch classifier loss: 0.372635; batch adversarial loss: 0.456763\n",
      "epoch 184; iter: 0; batch classifier loss: 0.446233; batch adversarial loss: 0.516618\n",
      "epoch 185; iter: 0; batch classifier loss: 0.353871; batch adversarial loss: 0.435800\n",
      "epoch 186; iter: 0; batch classifier loss: 0.397125; batch adversarial loss: 0.470063\n",
      "epoch 187; iter: 0; batch classifier loss: 0.259698; batch adversarial loss: 0.482966\n",
      "epoch 188; iter: 0; batch classifier loss: 0.379159; batch adversarial loss: 0.517805\n",
      "epoch 189; iter: 0; batch classifier loss: 0.320655; batch adversarial loss: 0.575859\n",
      "epoch 190; iter: 0; batch classifier loss: 0.375322; batch adversarial loss: 0.447335\n",
      "epoch 191; iter: 0; batch classifier loss: 0.391864; batch adversarial loss: 0.424851\n",
      "epoch 192; iter: 0; batch classifier loss: 0.282696; batch adversarial loss: 0.458985\n",
      "epoch 193; iter: 0; batch classifier loss: 0.345833; batch adversarial loss: 0.516620\n",
      "epoch 194; iter: 0; batch classifier loss: 0.384914; batch adversarial loss: 0.528721\n",
      "epoch 195; iter: 0; batch classifier loss: 0.393937; batch adversarial loss: 0.459667\n",
      "epoch 196; iter: 0; batch classifier loss: 0.351194; batch adversarial loss: 0.435322\n",
      "epoch 197; iter: 0; batch classifier loss: 0.268388; batch adversarial loss: 0.413799\n",
      "epoch 198; iter: 0; batch classifier loss: 0.414958; batch adversarial loss: 0.459180\n",
      "epoch 199; iter: 0; batch classifier loss: 0.276891; batch adversarial loss: 0.634182\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698844; batch adversarial loss: 0.829340\n",
      "epoch 1; iter: 0; batch classifier loss: 1.084540; batch adversarial loss: 0.856305\n",
      "epoch 2; iter: 0; batch classifier loss: 1.009452; batch adversarial loss: 0.835749\n",
      "epoch 3; iter: 0; batch classifier loss: 0.985987; batch adversarial loss: 0.747608\n",
      "epoch 4; iter: 0; batch classifier loss: 0.806201; batch adversarial loss: 0.737104\n",
      "epoch 5; iter: 0; batch classifier loss: 0.608820; batch adversarial loss: 0.692793\n",
      "epoch 6; iter: 0; batch classifier loss: 0.499908; batch adversarial loss: 0.668376\n",
      "epoch 7; iter: 0; batch classifier loss: 0.461315; batch adversarial loss: 0.636015\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530344; batch adversarial loss: 0.619804\n",
      "epoch 9; iter: 0; batch classifier loss: 0.497725; batch adversarial loss: 0.595036\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560426; batch adversarial loss: 0.592950\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505545; batch adversarial loss: 0.599454\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527593; batch adversarial loss: 0.580929\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484396; batch adversarial loss: 0.556539\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466033; batch adversarial loss: 0.549589\n",
      "epoch 15; iter: 0; batch classifier loss: 0.548414; batch adversarial loss: 0.581815\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482520; batch adversarial loss: 0.536255\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495443; batch adversarial loss: 0.537664\n",
      "epoch 18; iter: 0; batch classifier loss: 0.521531; batch adversarial loss: 0.537932\n",
      "epoch 19; iter: 0; batch classifier loss: 0.583007; batch adversarial loss: 0.575175\n",
      "epoch 20; iter: 0; batch classifier loss: 0.628303; batch adversarial loss: 0.499505\n",
      "epoch 21; iter: 0; batch classifier loss: 0.567016; batch adversarial loss: 0.549113\n",
      "epoch 22; iter: 0; batch classifier loss: 0.629451; batch adversarial loss: 0.570309\n",
      "epoch 23; iter: 0; batch classifier loss: 0.580884; batch adversarial loss: 0.556013\n",
      "epoch 24; iter: 0; batch classifier loss: 0.574656; batch adversarial loss: 0.506453\n",
      "epoch 25; iter: 0; batch classifier loss: 0.754399; batch adversarial loss: 0.579712\n",
      "epoch 26; iter: 0; batch classifier loss: 0.630268; batch adversarial loss: 0.522671\n",
      "epoch 27; iter: 0; batch classifier loss: 0.629785; batch adversarial loss: 0.633249\n",
      "epoch 28; iter: 0; batch classifier loss: 0.507576; batch adversarial loss: 0.521659\n",
      "epoch 29; iter: 0; batch classifier loss: 0.569715; batch adversarial loss: 0.530658\n",
      "epoch 30; iter: 0; batch classifier loss: 0.459569; batch adversarial loss: 0.541204\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445369; batch adversarial loss: 0.487616\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484490; batch adversarial loss: 0.508087\n",
      "epoch 33; iter: 0; batch classifier loss: 0.410106; batch adversarial loss: 0.512425\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477098; batch adversarial loss: 0.537760\n",
      "epoch 35; iter: 0; batch classifier loss: 0.456992; batch adversarial loss: 0.481637\n",
      "epoch 36; iter: 0; batch classifier loss: 0.518344; batch adversarial loss: 0.465188\n",
      "epoch 37; iter: 0; batch classifier loss: 0.583659; batch adversarial loss: 0.540341\n",
      "epoch 38; iter: 0; batch classifier loss: 0.519897; batch adversarial loss: 0.421047\n",
      "epoch 39; iter: 0; batch classifier loss: 0.498605; batch adversarial loss: 0.463322\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507730; batch adversarial loss: 0.447521\n",
      "epoch 41; iter: 0; batch classifier loss: 0.562609; batch adversarial loss: 0.528373\n",
      "epoch 42; iter: 0; batch classifier loss: 0.416976; batch adversarial loss: 0.450444\n",
      "epoch 43; iter: 0; batch classifier loss: 0.425829; batch adversarial loss: 0.459329\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481640; batch adversarial loss: 0.410816\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376114; batch adversarial loss: 0.446967\n",
      "epoch 46; iter: 0; batch classifier loss: 0.499448; batch adversarial loss: 0.536667\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386698; batch adversarial loss: 0.503593\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454466; batch adversarial loss: 0.431200\n",
      "epoch 49; iter: 0; batch classifier loss: 0.372291; batch adversarial loss: 0.469515\n",
      "epoch 50; iter: 0; batch classifier loss: 0.420603; batch adversarial loss: 0.505006\n",
      "epoch 51; iter: 0; batch classifier loss: 0.395740; batch adversarial loss: 0.482919\n",
      "epoch 52; iter: 0; batch classifier loss: 0.379086; batch adversarial loss: 0.425283\n",
      "epoch 53; iter: 0; batch classifier loss: 0.384787; batch adversarial loss: 0.425753\n",
      "epoch 54; iter: 0; batch classifier loss: 0.450954; batch adversarial loss: 0.444891\n",
      "epoch 55; iter: 0; batch classifier loss: 0.388741; batch adversarial loss: 0.365306\n",
      "epoch 56; iter: 0; batch classifier loss: 0.367633; batch adversarial loss: 0.523055\n",
      "epoch 57; iter: 0; batch classifier loss: 0.368146; batch adversarial loss: 0.498733\n",
      "epoch 58; iter: 0; batch classifier loss: 0.405189; batch adversarial loss: 0.452957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.328718; batch adversarial loss: 0.464696\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394993; batch adversarial loss: 0.597106\n",
      "epoch 61; iter: 0; batch classifier loss: 0.334081; batch adversarial loss: 0.537667\n",
      "epoch 62; iter: 0; batch classifier loss: 0.380720; batch adversarial loss: 0.471418\n",
      "epoch 63; iter: 0; batch classifier loss: 0.402578; batch adversarial loss: 0.453033\n",
      "epoch 64; iter: 0; batch classifier loss: 0.317126; batch adversarial loss: 0.440124\n",
      "epoch 65; iter: 0; batch classifier loss: 0.345096; batch adversarial loss: 0.503875\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411763; batch adversarial loss: 0.450031\n",
      "epoch 67; iter: 0; batch classifier loss: 0.377571; batch adversarial loss: 0.457879\n",
      "epoch 68; iter: 0; batch classifier loss: 0.333641; batch adversarial loss: 0.435057\n",
      "epoch 69; iter: 0; batch classifier loss: 0.361819; batch adversarial loss: 0.453070\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368886; batch adversarial loss: 0.471597\n",
      "epoch 71; iter: 0; batch classifier loss: 0.354669; batch adversarial loss: 0.427141\n",
      "epoch 72; iter: 0; batch classifier loss: 0.323303; batch adversarial loss: 0.528973\n",
      "epoch 73; iter: 0; batch classifier loss: 0.403970; batch adversarial loss: 0.531733\n",
      "epoch 74; iter: 0; batch classifier loss: 0.409180; batch adversarial loss: 0.447898\n",
      "epoch 75; iter: 0; batch classifier loss: 0.432269; batch adversarial loss: 0.484194\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371779; batch adversarial loss: 0.533144\n",
      "epoch 77; iter: 0; batch classifier loss: 0.333300; batch adversarial loss: 0.442097\n",
      "epoch 78; iter: 0; batch classifier loss: 0.316471; batch adversarial loss: 0.529222\n",
      "epoch 79; iter: 0; batch classifier loss: 0.345984; batch adversarial loss: 0.417895\n",
      "epoch 80; iter: 0; batch classifier loss: 0.350173; batch adversarial loss: 0.451697\n",
      "epoch 81; iter: 0; batch classifier loss: 0.340545; batch adversarial loss: 0.486353\n",
      "epoch 82; iter: 0; batch classifier loss: 0.358558; batch adversarial loss: 0.440322\n",
      "epoch 83; iter: 0; batch classifier loss: 0.365654; batch adversarial loss: 0.450186\n",
      "epoch 84; iter: 0; batch classifier loss: 0.296597; batch adversarial loss: 0.459963\n",
      "epoch 85; iter: 0; batch classifier loss: 0.266914; batch adversarial loss: 0.484248\n",
      "epoch 86; iter: 0; batch classifier loss: 0.344059; batch adversarial loss: 0.470150\n",
      "epoch 87; iter: 0; batch classifier loss: 0.283257; batch adversarial loss: 0.524799\n",
      "epoch 88; iter: 0; batch classifier loss: 0.349688; batch adversarial loss: 0.427806\n",
      "epoch 89; iter: 0; batch classifier loss: 0.328165; batch adversarial loss: 0.456987\n",
      "epoch 90; iter: 0; batch classifier loss: 0.377383; batch adversarial loss: 0.457928\n",
      "epoch 91; iter: 0; batch classifier loss: 0.332056; batch adversarial loss: 0.495820\n",
      "epoch 92; iter: 0; batch classifier loss: 0.275472; batch adversarial loss: 0.603315\n",
      "epoch 93; iter: 0; batch classifier loss: 0.330905; batch adversarial loss: 0.612589\n",
      "epoch 94; iter: 0; batch classifier loss: 0.287950; batch adversarial loss: 0.498927\n",
      "epoch 95; iter: 0; batch classifier loss: 0.258179; batch adversarial loss: 0.489979\n",
      "epoch 96; iter: 0; batch classifier loss: 0.326986; batch adversarial loss: 0.521835\n",
      "epoch 97; iter: 0; batch classifier loss: 0.356539; batch adversarial loss: 0.361154\n",
      "epoch 98; iter: 0; batch classifier loss: 0.315417; batch adversarial loss: 0.486297\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361404; batch adversarial loss: 0.510243\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698844; batch adversarial loss: 0.829340\n",
      "epoch 1; iter: 0; batch classifier loss: 1.033662; batch adversarial loss: 0.852584\n",
      "epoch 2; iter: 0; batch classifier loss: 0.932124; batch adversarial loss: 0.830645\n",
      "epoch 3; iter: 0; batch classifier loss: 0.881919; batch adversarial loss: 0.744227\n",
      "epoch 4; iter: 0; batch classifier loss: 0.723456; batch adversarial loss: 0.731215\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534892; batch adversarial loss: 0.682077\n",
      "epoch 6; iter: 0; batch classifier loss: 0.491994; batch adversarial loss: 0.667409\n",
      "epoch 7; iter: 0; batch classifier loss: 0.453401; batch adversarial loss: 0.637255\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535272; batch adversarial loss: 0.620208\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495049; batch adversarial loss: 0.597173\n",
      "epoch 10; iter: 0; batch classifier loss: 0.554102; batch adversarial loss: 0.596292\n",
      "epoch 11; iter: 0; batch classifier loss: 0.509147; batch adversarial loss: 0.600306\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531772; batch adversarial loss: 0.581743\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483993; batch adversarial loss: 0.557620\n",
      "epoch 14; iter: 0; batch classifier loss: 0.467440; batch adversarial loss: 0.548382\n",
      "epoch 15; iter: 0; batch classifier loss: 0.560528; batch adversarial loss: 0.578113\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489293; batch adversarial loss: 0.528416\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508459; batch adversarial loss: 0.533043\n",
      "epoch 18; iter: 0; batch classifier loss: 0.512196; batch adversarial loss: 0.525754\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507236; batch adversarial loss: 0.544296\n",
      "epoch 20; iter: 0; batch classifier loss: 0.555842; batch adversarial loss: 0.471588\n",
      "epoch 21; iter: 0; batch classifier loss: 0.480090; batch adversarial loss: 0.520040\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503456; batch adversarial loss: 0.537722\n",
      "epoch 23; iter: 0; batch classifier loss: 0.487088; batch adversarial loss: 0.538727\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483367; batch adversarial loss: 0.486634\n",
      "epoch 25; iter: 0; batch classifier loss: 0.662997; batch adversarial loss: 0.574929\n",
      "epoch 26; iter: 0; batch classifier loss: 0.566478; batch adversarial loss: 0.520653\n",
      "epoch 27; iter: 0; batch classifier loss: 0.605667; batch adversarial loss: 0.650799\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491661; batch adversarial loss: 0.524417\n",
      "epoch 29; iter: 0; batch classifier loss: 0.616469; batch adversarial loss: 0.544729\n",
      "epoch 30; iter: 0; batch classifier loss: 0.492602; batch adversarial loss: 0.559427\n",
      "epoch 31; iter: 0; batch classifier loss: 0.488953; batch adversarial loss: 0.502015\n",
      "epoch 32; iter: 0; batch classifier loss: 0.541088; batch adversarial loss: 0.525525\n",
      "epoch 33; iter: 0; batch classifier loss: 0.520232; batch adversarial loss: 0.537738\n",
      "epoch 34; iter: 0; batch classifier loss: 0.584945; batch adversarial loss: 0.561587\n",
      "epoch 35; iter: 0; batch classifier loss: 0.480866; batch adversarial loss: 0.490545\n",
      "epoch 36; iter: 0; batch classifier loss: 0.490925; batch adversarial loss: 0.465035\n",
      "epoch 37; iter: 0; batch classifier loss: 0.510669; batch adversarial loss: 0.536244\n",
      "epoch 38; iter: 0; batch classifier loss: 0.462675; batch adversarial loss: 0.419723\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459569; batch adversarial loss: 0.462698\n",
      "epoch 40; iter: 0; batch classifier loss: 0.475009; batch adversarial loss: 0.447617\n",
      "epoch 41; iter: 0; batch classifier loss: 0.557915; batch adversarial loss: 0.531556\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422784; batch adversarial loss: 0.452473\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435023; batch adversarial loss: 0.461471\n",
      "epoch 44; iter: 0; batch classifier loss: 0.476976; batch adversarial loss: 0.413221\n",
      "epoch 45; iter: 0; batch classifier loss: 0.377843; batch adversarial loss: 0.448192\n",
      "epoch 46; iter: 0; batch classifier loss: 0.491578; batch adversarial loss: 0.539931\n",
      "epoch 47; iter: 0; batch classifier loss: 0.530691; batch adversarial loss: 0.506893\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447220; batch adversarial loss: 0.432485\n",
      "epoch 49; iter: 0; batch classifier loss: 0.369136; batch adversarial loss: 0.470249\n",
      "epoch 50; iter: 0; batch classifier loss: 0.415863; batch adversarial loss: 0.504879\n",
      "epoch 51; iter: 0; batch classifier loss: 0.388306; batch adversarial loss: 0.483015\n",
      "epoch 52; iter: 0; batch classifier loss: 0.363701; batch adversarial loss: 0.425334\n",
      "epoch 53; iter: 0; batch classifier loss: 0.377846; batch adversarial loss: 0.425779\n",
      "epoch 54; iter: 0; batch classifier loss: 0.445694; batch adversarial loss: 0.445093\n",
      "epoch 55; iter: 0; batch classifier loss: 0.391976; batch adversarial loss: 0.366017\n",
      "epoch 56; iter: 0; batch classifier loss: 0.356617; batch adversarial loss: 0.522269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.368170; batch adversarial loss: 0.499235\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395011; batch adversarial loss: 0.452397\n",
      "epoch 59; iter: 0; batch classifier loss: 0.313272; batch adversarial loss: 0.464188\n",
      "epoch 60; iter: 0; batch classifier loss: 0.393441; batch adversarial loss: 0.596961\n",
      "epoch 61; iter: 0; batch classifier loss: 0.332119; batch adversarial loss: 0.536793\n",
      "epoch 62; iter: 0; batch classifier loss: 0.387222; batch adversarial loss: 0.472062\n",
      "epoch 63; iter: 0; batch classifier loss: 0.414998; batch adversarial loss: 0.454422\n",
      "epoch 64; iter: 0; batch classifier loss: 0.304543; batch adversarial loss: 0.439475\n",
      "epoch 65; iter: 0; batch classifier loss: 0.330471; batch adversarial loss: 0.503899\n",
      "epoch 66; iter: 0; batch classifier loss: 0.412565; batch adversarial loss: 0.449507\n",
      "epoch 67; iter: 0; batch classifier loss: 0.376984; batch adversarial loss: 0.458100\n",
      "epoch 68; iter: 0; batch classifier loss: 0.329008; batch adversarial loss: 0.434936\n",
      "epoch 69; iter: 0; batch classifier loss: 0.357129; batch adversarial loss: 0.453450\n",
      "epoch 70; iter: 0; batch classifier loss: 0.392235; batch adversarial loss: 0.470877\n",
      "epoch 71; iter: 0; batch classifier loss: 0.332963; batch adversarial loss: 0.425893\n",
      "epoch 72; iter: 0; batch classifier loss: 0.327330; batch adversarial loss: 0.528492\n",
      "epoch 73; iter: 0; batch classifier loss: 0.393098; batch adversarial loss: 0.533289\n",
      "epoch 74; iter: 0; batch classifier loss: 0.402659; batch adversarial loss: 0.446399\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385832; batch adversarial loss: 0.483723\n",
      "epoch 76; iter: 0; batch classifier loss: 0.385668; batch adversarial loss: 0.533341\n",
      "epoch 77; iter: 0; batch classifier loss: 0.325955; batch adversarial loss: 0.442470\n",
      "epoch 78; iter: 0; batch classifier loss: 0.295402; batch adversarial loss: 0.528924\n",
      "epoch 79; iter: 0; batch classifier loss: 0.348016; batch adversarial loss: 0.417755\n",
      "epoch 80; iter: 0; batch classifier loss: 0.331668; batch adversarial loss: 0.450469\n",
      "epoch 81; iter: 0; batch classifier loss: 0.319180; batch adversarial loss: 0.485309\n",
      "epoch 82; iter: 0; batch classifier loss: 0.329697; batch adversarial loss: 0.438571\n",
      "epoch 83; iter: 0; batch classifier loss: 0.359915; batch adversarial loss: 0.449059\n",
      "epoch 84; iter: 0; batch classifier loss: 0.299019; batch adversarial loss: 0.459722\n",
      "epoch 85; iter: 0; batch classifier loss: 0.257179; batch adversarial loss: 0.483514\n",
      "epoch 86; iter: 0; batch classifier loss: 0.313935; batch adversarial loss: 0.468320\n",
      "epoch 87; iter: 0; batch classifier loss: 0.270339; batch adversarial loss: 0.523490\n",
      "epoch 88; iter: 0; batch classifier loss: 0.340118; batch adversarial loss: 0.427636\n",
      "epoch 89; iter: 0; batch classifier loss: 0.299611; batch adversarial loss: 0.456566\n",
      "epoch 90; iter: 0; batch classifier loss: 0.368872; batch adversarial loss: 0.456905\n",
      "epoch 91; iter: 0; batch classifier loss: 0.318521; batch adversarial loss: 0.495243\n",
      "epoch 92; iter: 0; batch classifier loss: 0.268666; batch adversarial loss: 0.602711\n",
      "epoch 93; iter: 0; batch classifier loss: 0.310020; batch adversarial loss: 0.613266\n",
      "epoch 94; iter: 0; batch classifier loss: 0.257866; batch adversarial loss: 0.498624\n",
      "epoch 95; iter: 0; batch classifier loss: 0.246092; batch adversarial loss: 0.488738\n",
      "epoch 96; iter: 0; batch classifier loss: 0.291327; batch adversarial loss: 0.521076\n",
      "epoch 97; iter: 0; batch classifier loss: 0.314533; batch adversarial loss: 0.359190\n",
      "epoch 98; iter: 0; batch classifier loss: 0.285711; batch adversarial loss: 0.485022\n",
      "epoch 99; iter: 0; batch classifier loss: 0.342833; batch adversarial loss: 0.508149\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698844; batch adversarial loss: 0.829340\n",
      "epoch 1; iter: 0; batch classifier loss: 1.087128; batch adversarial loss: 0.856464\n",
      "epoch 2; iter: 0; batch classifier loss: 1.013191; batch adversarial loss: 0.835936\n",
      "epoch 3; iter: 0; batch classifier loss: 0.991490; batch adversarial loss: 0.747688\n",
      "epoch 4; iter: 0; batch classifier loss: 0.810170; batch adversarial loss: 0.737197\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614663; batch adversarial loss: 0.693282\n",
      "epoch 6; iter: 0; batch classifier loss: 0.499889; batch adversarial loss: 0.668377\n",
      "epoch 7; iter: 0; batch classifier loss: 0.460455; batch adversarial loss: 0.636190\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530313; batch adversarial loss: 0.619723\n",
      "epoch 9; iter: 0; batch classifier loss: 0.498065; batch adversarial loss: 0.594836\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561749; batch adversarial loss: 0.592680\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507556; batch adversarial loss: 0.599157\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528197; batch adversarial loss: 0.580707\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484249; batch adversarial loss: 0.556560\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466871; batch adversarial loss: 0.549629\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549198; batch adversarial loss: 0.582081\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483429; batch adversarial loss: 0.536725\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497845; batch adversarial loss: 0.538038\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532793; batch adversarial loss: 0.541803\n",
      "epoch 19; iter: 0; batch classifier loss: 0.603359; batch adversarial loss: 0.580020\n",
      "epoch 20; iter: 0; batch classifier loss: 0.639087; batch adversarial loss: 0.501163\n",
      "epoch 21; iter: 0; batch classifier loss: 0.579594; batch adversarial loss: 0.552545\n",
      "epoch 22; iter: 0; batch classifier loss: 0.640931; batch adversarial loss: 0.570569\n",
      "epoch 23; iter: 0; batch classifier loss: 0.576071; batch adversarial loss: 0.553938\n",
      "epoch 24; iter: 0; batch classifier loss: 0.574005; batch adversarial loss: 0.505698\n",
      "epoch 25; iter: 0; batch classifier loss: 0.745168; batch adversarial loss: 0.577232\n",
      "epoch 26; iter: 0; batch classifier loss: 0.624177; batch adversarial loss: 0.521235\n",
      "epoch 27; iter: 0; batch classifier loss: 0.623757; batch adversarial loss: 0.631216\n",
      "epoch 28; iter: 0; batch classifier loss: 0.503382; batch adversarial loss: 0.520379\n",
      "epoch 29; iter: 0; batch classifier loss: 0.565374; batch adversarial loss: 0.530110\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458001; batch adversarial loss: 0.540303\n",
      "epoch 31; iter: 0; batch classifier loss: 0.444239; batch adversarial loss: 0.487134\n",
      "epoch 32; iter: 0; batch classifier loss: 0.486863; batch adversarial loss: 0.507930\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414321; batch adversarial loss: 0.512491\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477695; batch adversarial loss: 0.537479\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459313; batch adversarial loss: 0.482160\n",
      "epoch 36; iter: 0; batch classifier loss: 0.512427; batch adversarial loss: 0.465184\n",
      "epoch 37; iter: 0; batch classifier loss: 0.585412; batch adversarial loss: 0.539893\n",
      "epoch 38; iter: 0; batch classifier loss: 0.517255; batch adversarial loss: 0.420674\n",
      "epoch 39; iter: 0; batch classifier loss: 0.499544; batch adversarial loss: 0.462881\n",
      "epoch 40; iter: 0; batch classifier loss: 0.505357; batch adversarial loss: 0.447128\n",
      "epoch 41; iter: 0; batch classifier loss: 0.556072; batch adversarial loss: 0.528135\n",
      "epoch 42; iter: 0; batch classifier loss: 0.413428; batch adversarial loss: 0.450310\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434433; batch adversarial loss: 0.459309\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484400; batch adversarial loss: 0.410832\n",
      "epoch 45; iter: 0; batch classifier loss: 0.386673; batch adversarial loss: 0.447090\n",
      "epoch 46; iter: 0; batch classifier loss: 0.505986; batch adversarial loss: 0.536406\n",
      "epoch 47; iter: 0; batch classifier loss: 0.384759; batch adversarial loss: 0.503433\n",
      "epoch 48; iter: 0; batch classifier loss: 0.457959; batch adversarial loss: 0.431181\n",
      "epoch 49; iter: 0; batch classifier loss: 0.373244; batch adversarial loss: 0.469542\n",
      "epoch 50; iter: 0; batch classifier loss: 0.429985; batch adversarial loss: 0.505215\n",
      "epoch 51; iter: 0; batch classifier loss: 0.399084; batch adversarial loss: 0.482686\n",
      "epoch 52; iter: 0; batch classifier loss: 0.380718; batch adversarial loss: 0.425158\n",
      "epoch 53; iter: 0; batch classifier loss: 0.386036; batch adversarial loss: 0.425909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54; iter: 0; batch classifier loss: 0.455949; batch adversarial loss: 0.444678\n",
      "epoch 55; iter: 0; batch classifier loss: 0.390757; batch adversarial loss: 0.365066\n",
      "epoch 56; iter: 0; batch classifier loss: 0.372081; batch adversarial loss: 0.522953\n",
      "epoch 57; iter: 0; batch classifier loss: 0.369758; batch adversarial loss: 0.498706\n",
      "epoch 58; iter: 0; batch classifier loss: 0.398385; batch adversarial loss: 0.452798\n",
      "epoch 59; iter: 0; batch classifier loss: 0.325291; batch adversarial loss: 0.464965\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394829; batch adversarial loss: 0.597085\n",
      "epoch 61; iter: 0; batch classifier loss: 0.335837; batch adversarial loss: 0.537326\n",
      "epoch 62; iter: 0; batch classifier loss: 0.378648; batch adversarial loss: 0.471314\n",
      "epoch 63; iter: 0; batch classifier loss: 0.411828; batch adversarial loss: 0.453305\n",
      "epoch 64; iter: 0; batch classifier loss: 0.320969; batch adversarial loss: 0.440152\n",
      "epoch 65; iter: 0; batch classifier loss: 0.337666; batch adversarial loss: 0.503926\n",
      "epoch 66; iter: 0; batch classifier loss: 0.413842; batch adversarial loss: 0.450019\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381962; batch adversarial loss: 0.457665\n",
      "epoch 68; iter: 0; batch classifier loss: 0.328296; batch adversarial loss: 0.435487\n",
      "epoch 69; iter: 0; batch classifier loss: 0.358132; batch adversarial loss: 0.452764\n",
      "epoch 70; iter: 0; batch classifier loss: 0.372127; batch adversarial loss: 0.470646\n",
      "epoch 71; iter: 0; batch classifier loss: 0.344050; batch adversarial loss: 0.426982\n",
      "epoch 72; iter: 0; batch classifier loss: 0.337119; batch adversarial loss: 0.529067\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392743; batch adversarial loss: 0.531456\n",
      "epoch 74; iter: 0; batch classifier loss: 0.414394; batch adversarial loss: 0.448726\n",
      "epoch 75; iter: 0; batch classifier loss: 0.422350; batch adversarial loss: 0.483967\n",
      "epoch 76; iter: 0; batch classifier loss: 0.379756; batch adversarial loss: 0.533356\n",
      "epoch 77; iter: 0; batch classifier loss: 0.331457; batch adversarial loss: 0.442101\n",
      "epoch 78; iter: 0; batch classifier loss: 0.309261; batch adversarial loss: 0.529203\n",
      "epoch 79; iter: 0; batch classifier loss: 0.349996; batch adversarial loss: 0.417686\n",
      "epoch 80; iter: 0; batch classifier loss: 0.347741; batch adversarial loss: 0.451725\n",
      "epoch 81; iter: 0; batch classifier loss: 0.337754; batch adversarial loss: 0.486470\n",
      "epoch 82; iter: 0; batch classifier loss: 0.361875; batch adversarial loss: 0.440221\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374163; batch adversarial loss: 0.450276\n",
      "epoch 84; iter: 0; batch classifier loss: 0.311870; batch adversarial loss: 0.460126\n",
      "epoch 85; iter: 0; batch classifier loss: 0.279917; batch adversarial loss: 0.484846\n",
      "epoch 86; iter: 0; batch classifier loss: 0.335095; batch adversarial loss: 0.469673\n",
      "epoch 87; iter: 0; batch classifier loss: 0.284146; batch adversarial loss: 0.524821\n",
      "epoch 88; iter: 0; batch classifier loss: 0.351501; batch adversarial loss: 0.427777\n",
      "epoch 89; iter: 0; batch classifier loss: 0.321209; batch adversarial loss: 0.456486\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384942; batch adversarial loss: 0.458084\n",
      "epoch 91; iter: 0; batch classifier loss: 0.345390; batch adversarial loss: 0.496152\n",
      "epoch 92; iter: 0; batch classifier loss: 0.286720; batch adversarial loss: 0.603522\n",
      "epoch 93; iter: 0; batch classifier loss: 0.325748; batch adversarial loss: 0.613383\n",
      "epoch 94; iter: 0; batch classifier loss: 0.296885; batch adversarial loss: 0.499428\n",
      "epoch 95; iter: 0; batch classifier loss: 0.261792; batch adversarial loss: 0.489914\n",
      "epoch 96; iter: 0; batch classifier loss: 0.321710; batch adversarial loss: 0.520916\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362984; batch adversarial loss: 0.361414\n",
      "epoch 98; iter: 0; batch classifier loss: 0.317631; batch adversarial loss: 0.486748\n",
      "epoch 99; iter: 0; batch classifier loss: 0.376582; batch adversarial loss: 0.510842\n",
      "epoch 100; iter: 0; batch classifier loss: 0.287303; batch adversarial loss: 0.488521\n",
      "epoch 101; iter: 0; batch classifier loss: 0.342436; batch adversarial loss: 0.496444\n",
      "epoch 102; iter: 0; batch classifier loss: 0.323028; batch adversarial loss: 0.490675\n",
      "epoch 103; iter: 0; batch classifier loss: 0.350090; batch adversarial loss: 0.447809\n",
      "epoch 104; iter: 0; batch classifier loss: 0.439290; batch adversarial loss: 0.428919\n",
      "epoch 105; iter: 0; batch classifier loss: 0.254742; batch adversarial loss: 0.499478\n",
      "epoch 106; iter: 0; batch classifier loss: 0.352754; batch adversarial loss: 0.490214\n",
      "epoch 107; iter: 0; batch classifier loss: 0.379875; batch adversarial loss: 0.577738\n",
      "epoch 108; iter: 0; batch classifier loss: 0.288714; batch adversarial loss: 0.540286\n",
      "epoch 109; iter: 0; batch classifier loss: 0.351438; batch adversarial loss: 0.461767\n",
      "epoch 110; iter: 0; batch classifier loss: 0.294532; batch adversarial loss: 0.592424\n",
      "epoch 111; iter: 0; batch classifier loss: 0.294460; batch adversarial loss: 0.560293\n",
      "epoch 112; iter: 0; batch classifier loss: 0.402449; batch adversarial loss: 0.489870\n",
      "epoch 113; iter: 0; batch classifier loss: 0.358167; batch adversarial loss: 0.488742\n",
      "epoch 114; iter: 0; batch classifier loss: 0.431309; batch adversarial loss: 0.533376\n",
      "epoch 115; iter: 0; batch classifier loss: 0.506506; batch adversarial loss: 0.418459\n",
      "epoch 116; iter: 0; batch classifier loss: 0.410329; batch adversarial loss: 0.461903\n",
      "epoch 117; iter: 0; batch classifier loss: 0.462736; batch adversarial loss: 0.482508\n",
      "epoch 118; iter: 0; batch classifier loss: 0.331969; batch adversarial loss: 0.444126\n",
      "epoch 119; iter: 0; batch classifier loss: 0.415150; batch adversarial loss: 0.533349\n",
      "epoch 120; iter: 0; batch classifier loss: 0.378192; batch adversarial loss: 0.460588\n",
      "epoch 121; iter: 0; batch classifier loss: 0.476334; batch adversarial loss: 0.528646\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388474; batch adversarial loss: 0.493524\n",
      "epoch 123; iter: 0; batch classifier loss: 0.364801; batch adversarial loss: 0.469533\n",
      "epoch 124; iter: 0; batch classifier loss: 0.323246; batch adversarial loss: 0.488906\n",
      "epoch 125; iter: 0; batch classifier loss: 0.394331; batch adversarial loss: 0.473717\n",
      "epoch 126; iter: 0; batch classifier loss: 0.482298; batch adversarial loss: 0.436579\n",
      "epoch 127; iter: 0; batch classifier loss: 0.359659; batch adversarial loss: 0.447011\n",
      "epoch 128; iter: 0; batch classifier loss: 0.314303; batch adversarial loss: 0.544497\n",
      "epoch 129; iter: 0; batch classifier loss: 0.389864; batch adversarial loss: 0.436964\n",
      "epoch 130; iter: 0; batch classifier loss: 0.382341; batch adversarial loss: 0.459104\n",
      "epoch 131; iter: 0; batch classifier loss: 0.463592; batch adversarial loss: 0.442147\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364698; batch adversarial loss: 0.464910\n",
      "epoch 133; iter: 0; batch classifier loss: 0.379885; batch adversarial loss: 0.458616\n",
      "epoch 134; iter: 0; batch classifier loss: 0.412247; batch adversarial loss: 0.566166\n",
      "epoch 135; iter: 0; batch classifier loss: 0.402536; batch adversarial loss: 0.424970\n",
      "epoch 136; iter: 0; batch classifier loss: 0.341995; batch adversarial loss: 0.505554\n",
      "epoch 137; iter: 0; batch classifier loss: 0.479433; batch adversarial loss: 0.417891\n",
      "epoch 138; iter: 0; batch classifier loss: 0.406692; batch adversarial loss: 0.504954\n",
      "epoch 139; iter: 0; batch classifier loss: 0.376471; batch adversarial loss: 0.496345\n",
      "epoch 140; iter: 0; batch classifier loss: 0.440586; batch adversarial loss: 0.459195\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357277; batch adversarial loss: 0.480374\n",
      "epoch 142; iter: 0; batch classifier loss: 0.403398; batch adversarial loss: 0.506587\n",
      "epoch 143; iter: 0; batch classifier loss: 0.503023; batch adversarial loss: 0.394926\n",
      "epoch 144; iter: 0; batch classifier loss: 0.390283; batch adversarial loss: 0.459881\n",
      "epoch 145; iter: 0; batch classifier loss: 0.420380; batch adversarial loss: 0.482547\n",
      "epoch 146; iter: 0; batch classifier loss: 0.420261; batch adversarial loss: 0.493929\n",
      "epoch 147; iter: 0; batch classifier loss: 0.350967; batch adversarial loss: 0.451781\n",
      "epoch 148; iter: 0; batch classifier loss: 0.381774; batch adversarial loss: 0.459551\n",
      "epoch 149; iter: 0; batch classifier loss: 0.439217; batch adversarial loss: 0.435150\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384383; batch adversarial loss: 0.394285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 151; iter: 0; batch classifier loss: 0.403115; batch adversarial loss: 0.436965\n",
      "epoch 152; iter: 0; batch classifier loss: 0.384846; batch adversarial loss: 0.470486\n",
      "epoch 153; iter: 0; batch classifier loss: 0.374479; batch adversarial loss: 0.517458\n",
      "epoch 154; iter: 0; batch classifier loss: 0.348137; batch adversarial loss: 0.540863\n",
      "epoch 155; iter: 0; batch classifier loss: 0.320798; batch adversarial loss: 0.494648\n",
      "epoch 156; iter: 0; batch classifier loss: 0.434080; batch adversarial loss: 0.447274\n",
      "epoch 157; iter: 0; batch classifier loss: 0.407545; batch adversarial loss: 0.470446\n",
      "epoch 158; iter: 0; batch classifier loss: 0.411823; batch adversarial loss: 0.493731\n",
      "epoch 159; iter: 0; batch classifier loss: 0.407543; batch adversarial loss: 0.437233\n",
      "epoch 160; iter: 0; batch classifier loss: 0.468787; batch adversarial loss: 0.460782\n",
      "epoch 161; iter: 0; batch classifier loss: 0.378243; batch adversarial loss: 0.494664\n",
      "epoch 162; iter: 0; batch classifier loss: 0.450060; batch adversarial loss: 0.484326\n",
      "epoch 163; iter: 0; batch classifier loss: 0.373633; batch adversarial loss: 0.505751\n",
      "epoch 164; iter: 0; batch classifier loss: 0.377645; batch adversarial loss: 0.412199\n",
      "epoch 165; iter: 0; batch classifier loss: 0.447368; batch adversarial loss: 0.401609\n",
      "epoch 166; iter: 0; batch classifier loss: 0.334184; batch adversarial loss: 0.436417\n",
      "epoch 167; iter: 0; batch classifier loss: 0.404101; batch adversarial loss: 0.437188\n",
      "epoch 168; iter: 0; batch classifier loss: 0.400020; batch adversarial loss: 0.459428\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357277; batch adversarial loss: 0.494347\n",
      "epoch 170; iter: 0; batch classifier loss: 0.383054; batch adversarial loss: 0.482233\n",
      "epoch 171; iter: 0; batch classifier loss: 0.377871; batch adversarial loss: 0.505178\n",
      "epoch 172; iter: 0; batch classifier loss: 0.456855; batch adversarial loss: 0.447641\n",
      "epoch 173; iter: 0; batch classifier loss: 0.345387; batch adversarial loss: 0.414546\n",
      "epoch 174; iter: 0; batch classifier loss: 0.369752; batch adversarial loss: 0.413187\n",
      "epoch 175; iter: 0; batch classifier loss: 0.268800; batch adversarial loss: 0.458605\n",
      "epoch 176; iter: 0; batch classifier loss: 0.331568; batch adversarial loss: 0.516912\n",
      "epoch 177; iter: 0; batch classifier loss: 0.375935; batch adversarial loss: 0.574507\n",
      "epoch 178; iter: 0; batch classifier loss: 0.347998; batch adversarial loss: 0.518547\n",
      "epoch 179; iter: 0; batch classifier loss: 0.448211; batch adversarial loss: 0.449393\n",
      "epoch 180; iter: 0; batch classifier loss: 0.364342; batch adversarial loss: 0.411397\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347682; batch adversarial loss: 0.541687\n",
      "epoch 182; iter: 0; batch classifier loss: 0.465470; batch adversarial loss: 0.375870\n",
      "epoch 183; iter: 0; batch classifier loss: 0.408626; batch adversarial loss: 0.456803\n",
      "epoch 184; iter: 0; batch classifier loss: 0.376449; batch adversarial loss: 0.516208\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392342; batch adversarial loss: 0.435708\n",
      "epoch 186; iter: 0; batch classifier loss: 0.430353; batch adversarial loss: 0.470190\n",
      "epoch 187; iter: 0; batch classifier loss: 0.225355; batch adversarial loss: 0.482655\n",
      "epoch 188; iter: 0; batch classifier loss: 0.396517; batch adversarial loss: 0.518242\n",
      "epoch 189; iter: 0; batch classifier loss: 0.273682; batch adversarial loss: 0.575878\n",
      "epoch 190; iter: 0; batch classifier loss: 0.384042; batch adversarial loss: 0.447090\n",
      "epoch 191; iter: 0; batch classifier loss: 0.378877; batch adversarial loss: 0.424731\n",
      "epoch 192; iter: 0; batch classifier loss: 0.291195; batch adversarial loss: 0.458960\n",
      "epoch 193; iter: 0; batch classifier loss: 0.331000; batch adversarial loss: 0.516415\n",
      "epoch 194; iter: 0; batch classifier loss: 0.405400; batch adversarial loss: 0.528782\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359032; batch adversarial loss: 0.459434\n",
      "epoch 196; iter: 0; batch classifier loss: 0.408452; batch adversarial loss: 0.435299\n",
      "epoch 197; iter: 0; batch classifier loss: 0.240716; batch adversarial loss: 0.413780\n",
      "epoch 198; iter: 0; batch classifier loss: 0.437140; batch adversarial loss: 0.459086\n",
      "epoch 199; iter: 0; batch classifier loss: 0.283451; batch adversarial loss: 0.633945\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 0.673611; batch adversarial loss: 0.771297\n",
      "epoch 2; iter: 0; batch classifier loss: 0.614697; batch adversarial loss: 0.751706\n",
      "epoch 3; iter: 0; batch classifier loss: 0.551798; batch adversarial loss: 0.681021\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566736; batch adversarial loss: 0.672530\n",
      "epoch 5; iter: 0; batch classifier loss: 0.522436; batch adversarial loss: 0.656645\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555094; batch adversarial loss: 0.647058\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517828; batch adversarial loss: 0.622907\n",
      "epoch 8; iter: 0; batch classifier loss: 0.591780; batch adversarial loss: 0.608629\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524472; batch adversarial loss: 0.591489\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594079; batch adversarial loss: 0.583413\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575286; batch adversarial loss: 0.589357\n",
      "epoch 12; iter: 0; batch classifier loss: 0.581881; batch adversarial loss: 0.575773\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556679; batch adversarial loss: 0.548668\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500027; batch adversarial loss: 0.549751\n",
      "epoch 15; iter: 0; batch classifier loss: 0.579219; batch adversarial loss: 0.578855\n",
      "epoch 16; iter: 0; batch classifier loss: 0.569874; batch adversarial loss: 0.509748\n",
      "epoch 17; iter: 0; batch classifier loss: 0.585891; batch adversarial loss: 0.505315\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524108; batch adversarial loss: 0.488201\n",
      "epoch 19; iter: 0; batch classifier loss: 0.534043; batch adversarial loss: 0.497231\n",
      "epoch 20; iter: 0; batch classifier loss: 0.541127; batch adversarial loss: 0.419946\n",
      "epoch 21; iter: 0; batch classifier loss: 0.479157; batch adversarial loss: 0.447570\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465948; batch adversarial loss: 0.463282\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462870; batch adversarial loss: 0.464883\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445831; batch adversarial loss: 0.429286\n",
      "epoch 25; iter: 0; batch classifier loss: 0.552120; batch adversarial loss: 0.495895\n",
      "epoch 26; iter: 0; batch classifier loss: 0.525473; batch adversarial loss: 0.475662\n",
      "epoch 27; iter: 0; batch classifier loss: 0.444020; batch adversarial loss: 0.563297\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465153; batch adversarial loss: 0.471901\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447633; batch adversarial loss: 0.470422\n",
      "epoch 30; iter: 0; batch classifier loss: 0.368999; batch adversarial loss: 0.491727\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471855; batch adversarial loss: 0.465910\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481067; batch adversarial loss: 0.492392\n",
      "epoch 33; iter: 0; batch classifier loss: 0.409171; batch adversarial loss: 0.498223\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477299; batch adversarial loss: 0.560070\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458949; batch adversarial loss: 0.480673\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474107; batch adversarial loss: 0.482048\n",
      "epoch 37; iter: 0; batch classifier loss: 0.533174; batch adversarial loss: 0.567389\n",
      "epoch 38; iter: 0; batch classifier loss: 0.499019; batch adversarial loss: 0.414857\n",
      "epoch 39; iter: 0; batch classifier loss: 0.560290; batch adversarial loss: 0.494023\n",
      "epoch 40; iter: 0; batch classifier loss: 0.539998; batch adversarial loss: 0.465188\n",
      "epoch 41; iter: 0; batch classifier loss: 0.595186; batch adversarial loss: 0.585933\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459253; batch adversarial loss: 0.475472\n",
      "epoch 43; iter: 0; batch classifier loss: 0.492005; batch adversarial loss: 0.492780\n",
      "epoch 44; iter: 0; batch classifier loss: 0.530200; batch adversarial loss: 0.439886\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418825; batch adversarial loss: 0.458837\n",
      "epoch 46; iter: 0; batch classifier loss: 0.488347; batch adversarial loss: 0.572784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.506109; batch adversarial loss: 0.538968\n",
      "epoch 48; iter: 0; batch classifier loss: 0.535105; batch adversarial loss: 0.446306\n",
      "epoch 49; iter: 0; batch classifier loss: 0.491878; batch adversarial loss: 0.497573\n",
      "epoch 50; iter: 0; batch classifier loss: 0.514043; batch adversarial loss: 0.537350\n",
      "epoch 51; iter: 0; batch classifier loss: 0.546332; batch adversarial loss: 0.513765\n",
      "epoch 52; iter: 0; batch classifier loss: 0.525203; batch adversarial loss: 0.447992\n",
      "epoch 53; iter: 0; batch classifier loss: 0.541230; batch adversarial loss: 0.445101\n",
      "epoch 54; iter: 0; batch classifier loss: 0.698204; batch adversarial loss: 0.464327\n",
      "epoch 55; iter: 0; batch classifier loss: 0.556504; batch adversarial loss: 0.385568\n",
      "epoch 56; iter: 0; batch classifier loss: 0.426364; batch adversarial loss: 0.523260\n",
      "epoch 57; iter: 0; batch classifier loss: 0.410699; batch adversarial loss: 0.498848\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448152; batch adversarial loss: 0.454237\n",
      "epoch 59; iter: 0; batch classifier loss: 0.381818; batch adversarial loss: 0.465075\n",
      "epoch 60; iter: 0; batch classifier loss: 0.405608; batch adversarial loss: 0.588973\n",
      "epoch 61; iter: 0; batch classifier loss: 0.374161; batch adversarial loss: 0.533158\n",
      "epoch 62; iter: 0; batch classifier loss: 0.427782; batch adversarial loss: 0.472020\n",
      "epoch 63; iter: 0; batch classifier loss: 0.383737; batch adversarial loss: 0.448836\n",
      "epoch 64; iter: 0; batch classifier loss: 0.372128; batch adversarial loss: 0.438003\n",
      "epoch 65; iter: 0; batch classifier loss: 0.363615; batch adversarial loss: 0.503351\n",
      "epoch 66; iter: 0; batch classifier loss: 0.395157; batch adversarial loss: 0.447947\n",
      "epoch 67; iter: 0; batch classifier loss: 0.361590; batch adversarial loss: 0.456509\n",
      "epoch 68; iter: 0; batch classifier loss: 0.363500; batch adversarial loss: 0.434465\n",
      "epoch 69; iter: 0; batch classifier loss: 0.381938; batch adversarial loss: 0.449418\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427626; batch adversarial loss: 0.472913\n",
      "epoch 71; iter: 0; batch classifier loss: 0.381802; batch adversarial loss: 0.421297\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412612; batch adversarial loss: 0.526547\n",
      "epoch 73; iter: 0; batch classifier loss: 0.406604; batch adversarial loss: 0.531727\n",
      "epoch 74; iter: 0; batch classifier loss: 0.440404; batch adversarial loss: 0.445703\n",
      "epoch 75; iter: 0; batch classifier loss: 0.444540; batch adversarial loss: 0.479468\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400989; batch adversarial loss: 0.527793\n",
      "epoch 77; iter: 0; batch classifier loss: 0.386797; batch adversarial loss: 0.437010\n",
      "epoch 78; iter: 0; batch classifier loss: 0.339045; batch adversarial loss: 0.527086\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373691; batch adversarial loss: 0.420065\n",
      "epoch 80; iter: 0; batch classifier loss: 0.439292; batch adversarial loss: 0.452626\n",
      "epoch 81; iter: 0; batch classifier loss: 0.375911; batch adversarial loss: 0.481174\n",
      "epoch 82; iter: 0; batch classifier loss: 0.336781; batch adversarial loss: 0.433026\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402772; batch adversarial loss: 0.445816\n",
      "epoch 84; iter: 0; batch classifier loss: 0.344819; batch adversarial loss: 0.459713\n",
      "epoch 85; iter: 0; batch classifier loss: 0.322562; batch adversarial loss: 0.481988\n",
      "epoch 86; iter: 0; batch classifier loss: 0.405832; batch adversarial loss: 0.466618\n",
      "epoch 87; iter: 0; batch classifier loss: 0.350706; batch adversarial loss: 0.521144\n",
      "epoch 88; iter: 0; batch classifier loss: 0.408113; batch adversarial loss: 0.420614\n",
      "epoch 89; iter: 0; batch classifier loss: 0.341618; batch adversarial loss: 0.455199\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394780; batch adversarial loss: 0.452240\n",
      "epoch 91; iter: 0; batch classifier loss: 0.352947; batch adversarial loss: 0.493183\n",
      "epoch 92; iter: 0; batch classifier loss: 0.364439; batch adversarial loss: 0.605622\n",
      "epoch 93; iter: 0; batch classifier loss: 0.436315; batch adversarial loss: 0.613386\n",
      "epoch 94; iter: 0; batch classifier loss: 0.267319; batch adversarial loss: 0.493460\n",
      "epoch 95; iter: 0; batch classifier loss: 0.286673; batch adversarial loss: 0.483918\n",
      "epoch 96; iter: 0; batch classifier loss: 0.305145; batch adversarial loss: 0.515614\n",
      "epoch 97; iter: 0; batch classifier loss: 0.399524; batch adversarial loss: 0.359843\n",
      "epoch 98; iter: 0; batch classifier loss: 0.347979; batch adversarial loss: 0.481073\n",
      "epoch 99; iter: 0; batch classifier loss: 0.410413; batch adversarial loss: 0.503597\n",
      "epoch 100; iter: 0; batch classifier loss: 0.385811; batch adversarial loss: 0.493533\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415276; batch adversarial loss: 0.493246\n",
      "epoch 102; iter: 0; batch classifier loss: 0.334804; batch adversarial loss: 0.483757\n",
      "epoch 103; iter: 0; batch classifier loss: 0.344157; batch adversarial loss: 0.441247\n",
      "epoch 104; iter: 0; batch classifier loss: 0.364092; batch adversarial loss: 0.420970\n",
      "epoch 105; iter: 0; batch classifier loss: 0.334546; batch adversarial loss: 0.500120\n",
      "epoch 106; iter: 0; batch classifier loss: 0.344516; batch adversarial loss: 0.489233\n",
      "epoch 107; iter: 0; batch classifier loss: 0.300226; batch adversarial loss: 0.576180\n",
      "epoch 108; iter: 0; batch classifier loss: 0.348077; batch adversarial loss: 0.538124\n",
      "epoch 109; iter: 0; batch classifier loss: 0.309502; batch adversarial loss: 0.458855\n",
      "epoch 110; iter: 0; batch classifier loss: 0.310754; batch adversarial loss: 0.592706\n",
      "epoch 111; iter: 0; batch classifier loss: 0.304227; batch adversarial loss: 0.551442\n",
      "epoch 112; iter: 0; batch classifier loss: 0.359208; batch adversarial loss: 0.479294\n",
      "epoch 113; iter: 0; batch classifier loss: 0.369213; batch adversarial loss: 0.483278\n",
      "epoch 114; iter: 0; batch classifier loss: 0.294904; batch adversarial loss: 0.517271\n",
      "epoch 115; iter: 0; batch classifier loss: 0.413203; batch adversarial loss: 0.414597\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355496; batch adversarial loss: 0.450693\n",
      "epoch 117; iter: 0; batch classifier loss: 0.355894; batch adversarial loss: 0.481419\n",
      "epoch 118; iter: 0; batch classifier loss: 0.336835; batch adversarial loss: 0.436249\n",
      "epoch 119; iter: 0; batch classifier loss: 0.292694; batch adversarial loss: 0.523906\n",
      "epoch 120; iter: 0; batch classifier loss: 0.291435; batch adversarial loss: 0.454612\n",
      "epoch 121; iter: 0; batch classifier loss: 0.316480; batch adversarial loss: 0.515099\n",
      "epoch 122; iter: 0; batch classifier loss: 0.349326; batch adversarial loss: 0.490246\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353203; batch adversarial loss: 0.465759\n",
      "epoch 124; iter: 0; batch classifier loss: 0.332736; batch adversarial loss: 0.479455\n",
      "epoch 125; iter: 0; batch classifier loss: 0.398885; batch adversarial loss: 0.462830\n",
      "epoch 126; iter: 0; batch classifier loss: 0.451982; batch adversarial loss: 0.435503\n",
      "epoch 127; iter: 0; batch classifier loss: 0.325935; batch adversarial loss: 0.439156\n",
      "epoch 128; iter: 0; batch classifier loss: 0.273921; batch adversarial loss: 0.532035\n",
      "epoch 129; iter: 0; batch classifier loss: 0.387817; batch adversarial loss: 0.435803\n",
      "epoch 130; iter: 0; batch classifier loss: 0.341837; batch adversarial loss: 0.454876\n",
      "epoch 131; iter: 0; batch classifier loss: 0.318917; batch adversarial loss: 0.439987\n",
      "epoch 132; iter: 0; batch classifier loss: 0.342588; batch adversarial loss: 0.452965\n",
      "epoch 133; iter: 0; batch classifier loss: 0.324116; batch adversarial loss: 0.451090\n",
      "epoch 134; iter: 0; batch classifier loss: 0.364475; batch adversarial loss: 0.564020\n",
      "epoch 135; iter: 0; batch classifier loss: 0.337302; batch adversarial loss: 0.421189\n",
      "epoch 136; iter: 0; batch classifier loss: 0.279065; batch adversarial loss: 0.499962\n",
      "epoch 137; iter: 0; batch classifier loss: 0.448035; batch adversarial loss: 0.420539\n",
      "epoch 138; iter: 0; batch classifier loss: 0.319641; batch adversarial loss: 0.497927\n",
      "epoch 139; iter: 0; batch classifier loss: 0.319955; batch adversarial loss: 0.496662\n",
      "epoch 140; iter: 0; batch classifier loss: 0.445033; batch adversarial loss: 0.457642\n",
      "epoch 141; iter: 0; batch classifier loss: 0.328222; batch adversarial loss: 0.470274\n",
      "epoch 142; iter: 0; batch classifier loss: 0.438354; batch adversarial loss: 0.501582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.384849; batch adversarial loss: 0.402419\n",
      "epoch 144; iter: 0; batch classifier loss: 0.362985; batch adversarial loss: 0.457488\n",
      "epoch 145; iter: 0; batch classifier loss: 0.334909; batch adversarial loss: 0.477730\n",
      "epoch 146; iter: 0; batch classifier loss: 0.344842; batch adversarial loss: 0.488870\n",
      "epoch 147; iter: 0; batch classifier loss: 0.334546; batch adversarial loss: 0.459357\n",
      "epoch 148; iter: 0; batch classifier loss: 0.267633; batch adversarial loss: 0.453567\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377449; batch adversarial loss: 0.422264\n",
      "epoch 150; iter: 0; batch classifier loss: 0.269415; batch adversarial loss: 0.407069\n",
      "epoch 151; iter: 0; batch classifier loss: 0.360355; batch adversarial loss: 0.435994\n",
      "epoch 152; iter: 0; batch classifier loss: 0.372531; batch adversarial loss: 0.460905\n",
      "epoch 153; iter: 0; batch classifier loss: 0.306305; batch adversarial loss: 0.513669\n",
      "epoch 154; iter: 0; batch classifier loss: 0.236497; batch adversarial loss: 0.532337\n",
      "epoch 155; iter: 0; batch classifier loss: 0.274829; batch adversarial loss: 0.496294\n",
      "epoch 156; iter: 0; batch classifier loss: 0.301231; batch adversarial loss: 0.433621\n",
      "epoch 157; iter: 0; batch classifier loss: 0.335318; batch adversarial loss: 0.461194\n",
      "epoch 158; iter: 0; batch classifier loss: 0.387759; batch adversarial loss: 0.484667\n",
      "epoch 159; iter: 0; batch classifier loss: 0.296596; batch adversarial loss: 0.439910\n",
      "epoch 160; iter: 0; batch classifier loss: 0.390182; batch adversarial loss: 0.466270\n",
      "epoch 161; iter: 0; batch classifier loss: 0.305735; batch adversarial loss: 0.496817\n",
      "epoch 162; iter: 0; batch classifier loss: 0.327965; batch adversarial loss: 0.484918\n",
      "epoch 163; iter: 0; batch classifier loss: 0.323192; batch adversarial loss: 0.499645\n",
      "epoch 164; iter: 0; batch classifier loss: 0.360283; batch adversarial loss: 0.408335\n",
      "epoch 165; iter: 0; batch classifier loss: 0.387472; batch adversarial loss: 0.400572\n",
      "epoch 166; iter: 0; batch classifier loss: 0.407978; batch adversarial loss: 0.437631\n",
      "epoch 167; iter: 0; batch classifier loss: 0.310265; batch adversarial loss: 0.438388\n",
      "epoch 168; iter: 0; batch classifier loss: 0.308407; batch adversarial loss: 0.455008\n",
      "epoch 169; iter: 0; batch classifier loss: 0.311331; batch adversarial loss: 0.489605\n",
      "epoch 170; iter: 0; batch classifier loss: 0.333531; batch adversarial loss: 0.478068\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409892; batch adversarial loss: 0.499948\n",
      "epoch 172; iter: 0; batch classifier loss: 0.447325; batch adversarial loss: 0.443388\n",
      "epoch 173; iter: 0; batch classifier loss: 0.461851; batch adversarial loss: 0.428324\n",
      "epoch 174; iter: 0; batch classifier loss: 0.320491; batch adversarial loss: 0.408165\n",
      "epoch 175; iter: 0; batch classifier loss: 0.272192; batch adversarial loss: 0.452144\n",
      "epoch 176; iter: 0; batch classifier loss: 0.268705; batch adversarial loss: 0.509946\n",
      "epoch 177; iter: 0; batch classifier loss: 0.430981; batch adversarial loss: 0.572098\n",
      "epoch 178; iter: 0; batch classifier loss: 0.296741; batch adversarial loss: 0.521090\n",
      "epoch 179; iter: 0; batch classifier loss: 0.419625; batch adversarial loss: 0.454741\n",
      "epoch 180; iter: 0; batch classifier loss: 0.427303; batch adversarial loss: 0.404328\n",
      "epoch 181; iter: 0; batch classifier loss: 0.312059; batch adversarial loss: 0.537527\n",
      "epoch 182; iter: 0; batch classifier loss: 0.368533; batch adversarial loss: 0.353672\n",
      "epoch 183; iter: 0; batch classifier loss: 0.363005; batch adversarial loss: 0.436667\n",
      "epoch 184; iter: 0; batch classifier loss: 0.392371; batch adversarial loss: 0.505349\n",
      "epoch 185; iter: 0; batch classifier loss: 0.311973; batch adversarial loss: 0.425680\n",
      "epoch 186; iter: 0; batch classifier loss: 0.377530; batch adversarial loss: 0.460853\n",
      "epoch 187; iter: 0; batch classifier loss: 0.254528; batch adversarial loss: 0.484605\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386448; batch adversarial loss: 0.514951\n",
      "epoch 189; iter: 0; batch classifier loss: 0.265814; batch adversarial loss: 0.582763\n",
      "epoch 190; iter: 0; batch classifier loss: 0.313555; batch adversarial loss: 0.439447\n",
      "epoch 191; iter: 0; batch classifier loss: 0.305072; batch adversarial loss: 0.420774\n",
      "epoch 192; iter: 0; batch classifier loss: 0.285456; batch adversarial loss: 0.456453\n",
      "epoch 193; iter: 0; batch classifier loss: 0.335680; batch adversarial loss: 0.508435\n",
      "epoch 194; iter: 0; batch classifier loss: 0.316968; batch adversarial loss: 0.519673\n",
      "epoch 195; iter: 0; batch classifier loss: 0.359830; batch adversarial loss: 0.460159\n",
      "epoch 196; iter: 0; batch classifier loss: 0.342313; batch adversarial loss: 0.421526\n",
      "epoch 197; iter: 0; batch classifier loss: 0.214915; batch adversarial loss: 0.417541\n",
      "epoch 198; iter: 0; batch classifier loss: 0.335537; batch adversarial loss: 0.450194\n",
      "epoch 199; iter: 0; batch classifier loss: 0.349853; batch adversarial loss: 0.647049\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.207035; batch adversarial loss: 0.862760\n",
      "epoch 2; iter: 0; batch classifier loss: 1.059833; batch adversarial loss: 0.835343\n",
      "epoch 3; iter: 0; batch classifier loss: 1.041650; batch adversarial loss: 0.746392\n",
      "epoch 4; iter: 0; batch classifier loss: 0.832398; batch adversarial loss: 0.736712\n",
      "epoch 5; iter: 0; batch classifier loss: 0.652307; batch adversarial loss: 0.692842\n",
      "epoch 6; iter: 0; batch classifier loss: 0.540793; batch adversarial loss: 0.670203\n",
      "epoch 7; iter: 0; batch classifier loss: 0.505952; batch adversarial loss: 0.630362\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561877; batch adversarial loss: 0.614316\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506356; batch adversarial loss: 0.593078\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564736; batch adversarial loss: 0.590230\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541053; batch adversarial loss: 0.596020\n",
      "epoch 12; iter: 0; batch classifier loss: 0.554457; batch adversarial loss: 0.577597\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514812; batch adversarial loss: 0.551436\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462026; batch adversarial loss: 0.552469\n",
      "epoch 15; iter: 0; batch classifier loss: 0.569180; batch adversarial loss: 0.583336\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529885; batch adversarial loss: 0.537255\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519924; batch adversarial loss: 0.545048\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539830; batch adversarial loss: 0.537178\n",
      "epoch 19; iter: 0; batch classifier loss: 0.590211; batch adversarial loss: 0.574005\n",
      "epoch 20; iter: 0; batch classifier loss: 0.642424; batch adversarial loss: 0.495163\n",
      "epoch 21; iter: 0; batch classifier loss: 0.618508; batch adversarial loss: 0.546339\n",
      "epoch 22; iter: 0; batch classifier loss: 0.691146; batch adversarial loss: 0.566025\n",
      "epoch 23; iter: 0; batch classifier loss: 0.619651; batch adversarial loss: 0.558896\n",
      "epoch 24; iter: 0; batch classifier loss: 0.599878; batch adversarial loss: 0.510515\n",
      "epoch 25; iter: 0; batch classifier loss: 0.780066; batch adversarial loss: 0.579929\n",
      "epoch 26; iter: 0; batch classifier loss: 0.648669; batch adversarial loss: 0.523318\n",
      "epoch 27; iter: 0; batch classifier loss: 0.669431; batch adversarial loss: 0.638957\n",
      "epoch 28; iter: 0; batch classifier loss: 0.582790; batch adversarial loss: 0.523635\n",
      "epoch 29; iter: 0; batch classifier loss: 0.622076; batch adversarial loss: 0.534307\n",
      "epoch 30; iter: 0; batch classifier loss: 0.519468; batch adversarial loss: 0.540967\n",
      "epoch 31; iter: 0; batch classifier loss: 0.532069; batch adversarial loss: 0.489471\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525049; batch adversarial loss: 0.510031\n",
      "epoch 33; iter: 0; batch classifier loss: 0.465639; batch adversarial loss: 0.517235\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475573; batch adversarial loss: 0.538051\n",
      "epoch 35; iter: 0; batch classifier loss: 0.482937; batch adversarial loss: 0.480533\n",
      "epoch 36; iter: 0; batch classifier loss: 0.507600; batch adversarial loss: 0.458600\n",
      "epoch 37; iter: 0; batch classifier loss: 0.546254; batch adversarial loss: 0.532625\n",
      "epoch 38; iter: 0; batch classifier loss: 0.562470; batch adversarial loss: 0.417746\n",
      "epoch 39; iter: 0; batch classifier loss: 0.589479; batch adversarial loss: 0.466471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.589225; batch adversarial loss: 0.450902\n",
      "epoch 41; iter: 0; batch classifier loss: 0.635668; batch adversarial loss: 0.534958\n",
      "epoch 42; iter: 0; batch classifier loss: 0.505785; batch adversarial loss: 0.454604\n",
      "epoch 43; iter: 0; batch classifier loss: 0.467835; batch adversarial loss: 0.460943\n",
      "epoch 44; iter: 0; batch classifier loss: 0.493523; batch adversarial loss: 0.410809\n",
      "epoch 45; iter: 0; batch classifier loss: 0.423688; batch adversarial loss: 0.446340\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500651; batch adversarial loss: 0.535981\n",
      "epoch 47; iter: 0; batch classifier loss: 0.523477; batch adversarial loss: 0.506030\n",
      "epoch 48; iter: 0; batch classifier loss: 0.598950; batch adversarial loss: 0.433299\n",
      "epoch 49; iter: 0; batch classifier loss: 0.441221; batch adversarial loss: 0.471494\n",
      "epoch 50; iter: 0; batch classifier loss: 0.471279; batch adversarial loss: 0.504442\n",
      "epoch 51; iter: 0; batch classifier loss: 0.478906; batch adversarial loss: 0.483214\n",
      "epoch 52; iter: 0; batch classifier loss: 0.457430; batch adversarial loss: 0.426252\n",
      "epoch 53; iter: 0; batch classifier loss: 0.472626; batch adversarial loss: 0.426436\n",
      "epoch 54; iter: 0; batch classifier loss: 0.513730; batch adversarial loss: 0.446409\n",
      "epoch 55; iter: 0; batch classifier loss: 0.480974; batch adversarial loss: 0.365220\n",
      "epoch 56; iter: 0; batch classifier loss: 0.425759; batch adversarial loss: 0.523856\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403394; batch adversarial loss: 0.498841\n",
      "epoch 58; iter: 0; batch classifier loss: 0.460774; batch adversarial loss: 0.453310\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417175; batch adversarial loss: 0.465917\n",
      "epoch 60; iter: 0; batch classifier loss: 0.450529; batch adversarial loss: 0.596854\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425560; batch adversarial loss: 0.539690\n",
      "epoch 62; iter: 0; batch classifier loss: 0.448644; batch adversarial loss: 0.470582\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435926; batch adversarial loss: 0.449766\n",
      "epoch 64; iter: 0; batch classifier loss: 0.380457; batch adversarial loss: 0.440074\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389333; batch adversarial loss: 0.503291\n",
      "epoch 66; iter: 0; batch classifier loss: 0.441459; batch adversarial loss: 0.450305\n",
      "epoch 67; iter: 0; batch classifier loss: 0.413882; batch adversarial loss: 0.456278\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410085; batch adversarial loss: 0.432526\n",
      "epoch 69; iter: 0; batch classifier loss: 0.449253; batch adversarial loss: 0.454532\n",
      "epoch 70; iter: 0; batch classifier loss: 0.473661; batch adversarial loss: 0.469920\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411203; batch adversarial loss: 0.426323\n",
      "epoch 72; iter: 0; batch classifier loss: 0.471616; batch adversarial loss: 0.529867\n",
      "epoch 73; iter: 0; batch classifier loss: 0.450188; batch adversarial loss: 0.527887\n",
      "epoch 74; iter: 0; batch classifier loss: 0.486692; batch adversarial loss: 0.443553\n",
      "epoch 75; iter: 0; batch classifier loss: 0.510723; batch adversarial loss: 0.482156\n",
      "epoch 76; iter: 0; batch classifier loss: 0.462640; batch adversarial loss: 0.528613\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398433; batch adversarial loss: 0.439830\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368550; batch adversarial loss: 0.526363\n",
      "epoch 79; iter: 0; batch classifier loss: 0.412578; batch adversarial loss: 0.413199\n",
      "epoch 80; iter: 0; batch classifier loss: 0.449375; batch adversarial loss: 0.452715\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389272; batch adversarial loss: 0.485614\n",
      "epoch 82; iter: 0; batch classifier loss: 0.401235; batch adversarial loss: 0.437127\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416232; batch adversarial loss: 0.447628\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374882; batch adversarial loss: 0.461496\n",
      "epoch 85; iter: 0; batch classifier loss: 0.337164; batch adversarial loss: 0.481113\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425423; batch adversarial loss: 0.469269\n",
      "epoch 87; iter: 0; batch classifier loss: 0.362940; batch adversarial loss: 0.520945\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423060; batch adversarial loss: 0.419331\n",
      "epoch 89; iter: 0; batch classifier loss: 0.400330; batch adversarial loss: 0.452195\n",
      "epoch 90; iter: 0; batch classifier loss: 0.430437; batch adversarial loss: 0.455125\n",
      "epoch 91; iter: 0; batch classifier loss: 0.380719; batch adversarial loss: 0.495049\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408257; batch adversarial loss: 0.604072\n",
      "epoch 93; iter: 0; batch classifier loss: 0.496861; batch adversarial loss: 0.613643\n",
      "epoch 94; iter: 0; batch classifier loss: 0.303963; batch adversarial loss: 0.498286\n",
      "epoch 95; iter: 0; batch classifier loss: 0.276148; batch adversarial loss: 0.487897\n",
      "epoch 96; iter: 0; batch classifier loss: 0.326627; batch adversarial loss: 0.515843\n",
      "epoch 97; iter: 0; batch classifier loss: 0.480317; batch adversarial loss: 0.362038\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385603; batch adversarial loss: 0.481808\n",
      "epoch 99; iter: 0; batch classifier loss: 0.483191; batch adversarial loss: 0.506441\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 0.963277; batch adversarial loss: 0.845000\n",
      "epoch 2; iter: 0; batch classifier loss: 0.838257; batch adversarial loss: 0.816653\n",
      "epoch 3; iter: 0; batch classifier loss: 0.740964; batch adversarial loss: 0.727435\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614645; batch adversarial loss: 0.712839\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495654; batch adversarial loss: 0.674237\n",
      "epoch 6; iter: 0; batch classifier loss: 0.514242; batch adversarial loss: 0.663610\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490340; batch adversarial loss: 0.632025\n",
      "epoch 8; iter: 0; batch classifier loss: 0.565456; batch adversarial loss: 0.615971\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502591; batch adversarial loss: 0.595948\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578910; batch adversarial loss: 0.588330\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564475; batch adversarial loss: 0.592988\n",
      "epoch 12; iter: 0; batch classifier loss: 0.573536; batch adversarial loss: 0.577479\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548042; batch adversarial loss: 0.548536\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497218; batch adversarial loss: 0.548520\n",
      "epoch 15; iter: 0; batch classifier loss: 0.595570; batch adversarial loss: 0.576766\n",
      "epoch 16; iter: 0; batch classifier loss: 0.568700; batch adversarial loss: 0.514422\n",
      "epoch 17; iter: 0; batch classifier loss: 0.567786; batch adversarial loss: 0.524395\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523953; batch adversarial loss: 0.515341\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523850; batch adversarial loss: 0.532269\n",
      "epoch 20; iter: 0; batch classifier loss: 0.558325; batch adversarial loss: 0.452638\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477755; batch adversarial loss: 0.484365\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486591; batch adversarial loss: 0.494180\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464426; batch adversarial loss: 0.493217\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455355; batch adversarial loss: 0.455924\n",
      "epoch 25; iter: 0; batch classifier loss: 0.587091; batch adversarial loss: 0.531451\n",
      "epoch 26; iter: 0; batch classifier loss: 0.536043; batch adversarial loss: 0.507024\n",
      "epoch 27; iter: 0; batch classifier loss: 0.531422; batch adversarial loss: 0.639166\n",
      "epoch 28; iter: 0; batch classifier loss: 0.504971; batch adversarial loss: 0.510312\n",
      "epoch 29; iter: 0; batch classifier loss: 0.555377; batch adversarial loss: 0.542907\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462225; batch adversarial loss: 0.550638\n",
      "epoch 31; iter: 0; batch classifier loss: 0.526461; batch adversarial loss: 0.500318\n",
      "epoch 32; iter: 0; batch classifier loss: 0.568183; batch adversarial loss: 0.534996\n",
      "epoch 33; iter: 0; batch classifier loss: 0.538593; batch adversarial loss: 0.551050\n",
      "epoch 34; iter: 0; batch classifier loss: 0.602378; batch adversarial loss: 0.585773\n",
      "epoch 35; iter: 0; batch classifier loss: 0.534331; batch adversarial loss: 0.507291\n",
      "epoch 36; iter: 0; batch classifier loss: 0.546967; batch adversarial loss: 0.479128\n",
      "epoch 37; iter: 0; batch classifier loss: 0.668411; batch adversarial loss: 0.570733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.597826; batch adversarial loss: 0.434604\n",
      "epoch 39; iter: 0; batch classifier loss: 0.622826; batch adversarial loss: 0.483427\n",
      "epoch 40; iter: 0; batch classifier loss: 0.609732; batch adversarial loss: 0.462176\n",
      "epoch 41; iter: 0; batch classifier loss: 0.644582; batch adversarial loss: 0.547133\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501238; batch adversarial loss: 0.463307\n",
      "epoch 43; iter: 0; batch classifier loss: 0.484479; batch adversarial loss: 0.468244\n",
      "epoch 44; iter: 0; batch classifier loss: 0.509150; batch adversarial loss: 0.416992\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424502; batch adversarial loss: 0.449355\n",
      "epoch 46; iter: 0; batch classifier loss: 0.491372; batch adversarial loss: 0.539514\n",
      "epoch 47; iter: 0; batch classifier loss: 0.482356; batch adversarial loss: 0.508909\n",
      "epoch 48; iter: 0; batch classifier loss: 0.542124; batch adversarial loss: 0.436234\n",
      "epoch 49; iter: 0; batch classifier loss: 0.497953; batch adversarial loss: 0.475869\n",
      "epoch 50; iter: 0; batch classifier loss: 0.535274; batch adversarial loss: 0.507425\n",
      "epoch 51; iter: 0; batch classifier loss: 0.460111; batch adversarial loss: 0.484508\n",
      "epoch 52; iter: 0; batch classifier loss: 0.430460; batch adversarial loss: 0.428152\n",
      "epoch 53; iter: 0; batch classifier loss: 0.446548; batch adversarial loss: 0.427739\n",
      "epoch 54; iter: 0; batch classifier loss: 0.488198; batch adversarial loss: 0.446880\n",
      "epoch 55; iter: 0; batch classifier loss: 0.480242; batch adversarial loss: 0.367766\n",
      "epoch 56; iter: 0; batch classifier loss: 0.395947; batch adversarial loss: 0.523141\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400307; batch adversarial loss: 0.498232\n",
      "epoch 58; iter: 0; batch classifier loss: 0.436970; batch adversarial loss: 0.452551\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398534; batch adversarial loss: 0.464834\n",
      "epoch 60; iter: 0; batch classifier loss: 0.425594; batch adversarial loss: 0.596156\n",
      "epoch 61; iter: 0; batch classifier loss: 0.399572; batch adversarial loss: 0.537958\n",
      "epoch 62; iter: 0; batch classifier loss: 0.430198; batch adversarial loss: 0.470555\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425645; batch adversarial loss: 0.449520\n",
      "epoch 64; iter: 0; batch classifier loss: 0.371337; batch adversarial loss: 0.439602\n",
      "epoch 65; iter: 0; batch classifier loss: 0.372241; batch adversarial loss: 0.504164\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416021; batch adversarial loss: 0.449419\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384133; batch adversarial loss: 0.456806\n",
      "epoch 68; iter: 0; batch classifier loss: 0.382748; batch adversarial loss: 0.433048\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406517; batch adversarial loss: 0.451339\n",
      "epoch 70; iter: 0; batch classifier loss: 0.453506; batch adversarial loss: 0.470924\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403439; batch adversarial loss: 0.423769\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455716; batch adversarial loss: 0.529226\n",
      "epoch 73; iter: 0; batch classifier loss: 0.402504; batch adversarial loss: 0.530186\n",
      "epoch 74; iter: 0; batch classifier loss: 0.447939; batch adversarial loss: 0.446266\n",
      "epoch 75; iter: 0; batch classifier loss: 0.478284; batch adversarial loss: 0.481453\n",
      "epoch 76; iter: 0; batch classifier loss: 0.429138; batch adversarial loss: 0.529422\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389007; batch adversarial loss: 0.440787\n",
      "epoch 78; iter: 0; batch classifier loss: 0.357853; batch adversarial loss: 0.527492\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381414; batch adversarial loss: 0.416167\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436527; batch adversarial loss: 0.452540\n",
      "epoch 81; iter: 0; batch classifier loss: 0.404446; batch adversarial loss: 0.484366\n",
      "epoch 82; iter: 0; batch classifier loss: 0.353304; batch adversarial loss: 0.434467\n",
      "epoch 83; iter: 0; batch classifier loss: 0.417501; batch adversarial loss: 0.446628\n",
      "epoch 84; iter: 0; batch classifier loss: 0.325644; batch adversarial loss: 0.460043\n",
      "epoch 85; iter: 0; batch classifier loss: 0.331460; batch adversarial loss: 0.483970\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420521; batch adversarial loss: 0.467873\n",
      "epoch 87; iter: 0; batch classifier loss: 0.355719; batch adversarial loss: 0.520855\n",
      "epoch 88; iter: 0; batch classifier loss: 0.412582; batch adversarial loss: 0.418030\n",
      "epoch 89; iter: 0; batch classifier loss: 0.366000; batch adversarial loss: 0.452871\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374458; batch adversarial loss: 0.453181\n",
      "epoch 91; iter: 0; batch classifier loss: 0.369497; batch adversarial loss: 0.494139\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397751; batch adversarial loss: 0.603493\n",
      "epoch 93; iter: 0; batch classifier loss: 0.441051; batch adversarial loss: 0.612209\n",
      "epoch 94; iter: 0; batch classifier loss: 0.303913; batch adversarial loss: 0.494311\n",
      "epoch 95; iter: 0; batch classifier loss: 0.275132; batch adversarial loss: 0.483999\n",
      "epoch 96; iter: 0; batch classifier loss: 0.320311; batch adversarial loss: 0.515688\n",
      "epoch 97; iter: 0; batch classifier loss: 0.407860; batch adversarial loss: 0.358637\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369549; batch adversarial loss: 0.483566\n",
      "epoch 99; iter: 0; batch classifier loss: 0.455235; batch adversarial loss: 0.504293\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698844; batch adversarial loss: 0.829340\n",
      "epoch 1; iter: 0; batch classifier loss: 0.809030; batch adversarial loss: 0.819455\n",
      "epoch 2; iter: 0; batch classifier loss: 0.698297; batch adversarial loss: 0.791103\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588628; batch adversarial loss: 0.705584\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548899; batch adversarial loss: 0.690640\n",
      "epoch 5; iter: 0; batch classifier loss: 0.503837; batch adversarial loss: 0.666607\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512932; batch adversarial loss: 0.662784\n",
      "epoch 7; iter: 0; batch classifier loss: 0.473863; batch adversarial loss: 0.633206\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553902; batch adversarial loss: 0.617188\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514939; batch adversarial loss: 0.592961\n",
      "epoch 10; iter: 0; batch classifier loss: 0.582806; batch adversarial loss: 0.587653\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539560; batch adversarial loss: 0.593812\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555999; batch adversarial loss: 0.577863\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534058; batch adversarial loss: 0.553723\n",
      "epoch 14; iter: 0; batch classifier loss: 0.494669; batch adversarial loss: 0.549222\n",
      "epoch 15; iter: 0; batch classifier loss: 0.564648; batch adversarial loss: 0.581360\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523746; batch adversarial loss: 0.520870\n",
      "epoch 17; iter: 0; batch classifier loss: 0.552151; batch adversarial loss: 0.521585\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514196; batch adversarial loss: 0.508237\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504479; batch adversarial loss: 0.522342\n",
      "epoch 20; iter: 0; batch classifier loss: 0.531682; batch adversarial loss: 0.439298\n",
      "epoch 21; iter: 0; batch classifier loss: 0.431574; batch adversarial loss: 0.468956\n",
      "epoch 22; iter: 0; batch classifier loss: 0.412651; batch adversarial loss: 0.481209\n",
      "epoch 23; iter: 0; batch classifier loss: 0.436802; batch adversarial loss: 0.481035\n",
      "epoch 24; iter: 0; batch classifier loss: 0.436943; batch adversarial loss: 0.431987\n",
      "epoch 25; iter: 0; batch classifier loss: 0.561905; batch adversarial loss: 0.514681\n",
      "epoch 26; iter: 0; batch classifier loss: 0.511069; batch adversarial loss: 0.491684\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445953; batch adversarial loss: 0.594581\n",
      "epoch 28; iter: 0; batch classifier loss: 0.407492; batch adversarial loss: 0.483365\n",
      "epoch 29; iter: 0; batch classifier loss: 0.463638; batch adversarial loss: 0.501444\n",
      "epoch 30; iter: 0; batch classifier loss: 0.356903; batch adversarial loss: 0.528885\n",
      "epoch 31; iter: 0; batch classifier loss: 0.425657; batch adversarial loss: 0.479569\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487270; batch adversarial loss: 0.522080\n",
      "epoch 33; iter: 0; batch classifier loss: 0.420747; batch adversarial loss: 0.518096\n",
      "epoch 34; iter: 0; batch classifier loss: 0.507237; batch adversarial loss: 0.573719\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435326; batch adversarial loss: 0.486152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.475065; batch adversarial loss: 0.482683\n",
      "epoch 37; iter: 0; batch classifier loss: 0.525216; batch adversarial loss: 0.567476\n",
      "epoch 38; iter: 0; batch classifier loss: 0.471120; batch adversarial loss: 0.430057\n",
      "epoch 39; iter: 0; batch classifier loss: 0.514332; batch adversarial loss: 0.489969\n",
      "epoch 40; iter: 0; batch classifier loss: 0.498272; batch adversarial loss: 0.463533\n",
      "epoch 41; iter: 0; batch classifier loss: 0.625187; batch adversarial loss: 0.569265\n",
      "epoch 42; iter: 0; batch classifier loss: 0.452003; batch adversarial loss: 0.477130\n",
      "epoch 43; iter: 0; batch classifier loss: 0.468608; batch adversarial loss: 0.481792\n",
      "epoch 44; iter: 0; batch classifier loss: 0.518145; batch adversarial loss: 0.431021\n",
      "epoch 45; iter: 0; batch classifier loss: 0.365039; batch adversarial loss: 0.453728\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495358; batch adversarial loss: 0.561899\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464899; batch adversarial loss: 0.529632\n",
      "epoch 48; iter: 0; batch classifier loss: 0.555603; batch adversarial loss: 0.448169\n",
      "epoch 49; iter: 0; batch classifier loss: 0.481972; batch adversarial loss: 0.486443\n",
      "epoch 50; iter: 0; batch classifier loss: 0.592934; batch adversarial loss: 0.522247\n",
      "epoch 51; iter: 0; batch classifier loss: 0.554156; batch adversarial loss: 0.493850\n",
      "epoch 52; iter: 0; batch classifier loss: 0.439743; batch adversarial loss: 0.432228\n",
      "epoch 53; iter: 0; batch classifier loss: 0.368310; batch adversarial loss: 0.430639\n",
      "epoch 54; iter: 0; batch classifier loss: 0.423610; batch adversarial loss: 0.447663\n",
      "epoch 55; iter: 0; batch classifier loss: 0.367000; batch adversarial loss: 0.371197\n",
      "epoch 56; iter: 0; batch classifier loss: 0.339387; batch adversarial loss: 0.521326\n",
      "epoch 57; iter: 0; batch classifier loss: 0.348459; batch adversarial loss: 0.498221\n",
      "epoch 58; iter: 0; batch classifier loss: 0.360260; batch adversarial loss: 0.452992\n",
      "epoch 59; iter: 0; batch classifier loss: 0.304002; batch adversarial loss: 0.464757\n",
      "epoch 60; iter: 0; batch classifier loss: 0.362101; batch adversarial loss: 0.593896\n",
      "epoch 61; iter: 0; batch classifier loss: 0.312484; batch adversarial loss: 0.534587\n",
      "epoch 62; iter: 0; batch classifier loss: 0.352052; batch adversarial loss: 0.472953\n",
      "epoch 63; iter: 0; batch classifier loss: 0.378177; batch adversarial loss: 0.456769\n",
      "epoch 64; iter: 0; batch classifier loss: 0.318770; batch adversarial loss: 0.439741\n",
      "epoch 65; iter: 0; batch classifier loss: 0.299409; batch adversarial loss: 0.503876\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407396; batch adversarial loss: 0.450969\n",
      "epoch 67; iter: 0; batch classifier loss: 0.346135; batch adversarial loss: 0.457422\n",
      "epoch 68; iter: 0; batch classifier loss: 0.328916; batch adversarial loss: 0.436772\n",
      "epoch 69; iter: 0; batch classifier loss: 0.329832; batch adversarial loss: 0.453079\n",
      "epoch 70; iter: 0; batch classifier loss: 0.352665; batch adversarial loss: 0.471083\n",
      "epoch 71; iter: 0; batch classifier loss: 0.342619; batch adversarial loss: 0.425441\n",
      "epoch 72; iter: 0; batch classifier loss: 0.311033; batch adversarial loss: 0.527322\n",
      "epoch 73; iter: 0; batch classifier loss: 0.346072; batch adversarial loss: 0.533748\n",
      "epoch 74; iter: 0; batch classifier loss: 0.371204; batch adversarial loss: 0.447582\n",
      "epoch 75; iter: 0; batch classifier loss: 0.384935; batch adversarial loss: 0.484575\n",
      "epoch 76; iter: 0; batch classifier loss: 0.380445; batch adversarial loss: 0.531530\n",
      "epoch 77; iter: 0; batch classifier loss: 0.311826; batch adversarial loss: 0.443341\n",
      "epoch 78; iter: 0; batch classifier loss: 0.291067; batch adversarial loss: 0.529390\n",
      "epoch 79; iter: 0; batch classifier loss: 0.334947; batch adversarial loss: 0.418939\n",
      "epoch 80; iter: 0; batch classifier loss: 0.356283; batch adversarial loss: 0.451250\n",
      "epoch 81; iter: 0; batch classifier loss: 0.313143; batch adversarial loss: 0.484277\n",
      "epoch 82; iter: 0; batch classifier loss: 0.312599; batch adversarial loss: 0.438216\n",
      "epoch 83; iter: 0; batch classifier loss: 0.326918; batch adversarial loss: 0.447702\n",
      "epoch 84; iter: 0; batch classifier loss: 0.301789; batch adversarial loss: 0.460272\n",
      "epoch 85; iter: 0; batch classifier loss: 0.269010; batch adversarial loss: 0.485067\n",
      "epoch 86; iter: 0; batch classifier loss: 0.310055; batch adversarial loss: 0.467486\n",
      "epoch 87; iter: 0; batch classifier loss: 0.278346; batch adversarial loss: 0.523405\n",
      "epoch 88; iter: 0; batch classifier loss: 0.339505; batch adversarial loss: 0.427768\n",
      "epoch 89; iter: 0; batch classifier loss: 0.296917; batch adversarial loss: 0.456955\n",
      "epoch 90; iter: 0; batch classifier loss: 0.355895; batch adversarial loss: 0.456393\n",
      "epoch 91; iter: 0; batch classifier loss: 0.269633; batch adversarial loss: 0.493161\n",
      "epoch 92; iter: 0; batch classifier loss: 0.253310; batch adversarial loss: 0.604549\n",
      "epoch 93; iter: 0; batch classifier loss: 0.278789; batch adversarial loss: 0.613124\n",
      "epoch 94; iter: 0; batch classifier loss: 0.243731; batch adversarial loss: 0.498805\n",
      "epoch 95; iter: 0; batch classifier loss: 0.213492; batch adversarial loss: 0.487813\n",
      "epoch 96; iter: 0; batch classifier loss: 0.278228; batch adversarial loss: 0.519074\n",
      "epoch 97; iter: 0; batch classifier loss: 0.312459; batch adversarial loss: 0.358028\n",
      "epoch 98; iter: 0; batch classifier loss: 0.265493; batch adversarial loss: 0.484152\n",
      "epoch 99; iter: 0; batch classifier loss: 0.315108; batch adversarial loss: 0.507743\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698844; batch adversarial loss: 0.829340\n",
      "epoch 1; iter: 0; batch classifier loss: 1.026757; batch adversarial loss: 0.852069\n",
      "epoch 2; iter: 0; batch classifier loss: 0.923672; batch adversarial loss: 0.829963\n",
      "epoch 3; iter: 0; batch classifier loss: 0.868357; batch adversarial loss: 0.743654\n",
      "epoch 4; iter: 0; batch classifier loss: 0.713428; batch adversarial loss: 0.730229\n",
      "epoch 5; iter: 0; batch classifier loss: 0.530624; batch adversarial loss: 0.681112\n",
      "epoch 6; iter: 0; batch classifier loss: 0.491324; batch adversarial loss: 0.667362\n",
      "epoch 7; iter: 0; batch classifier loss: 0.453359; batch adversarial loss: 0.637276\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534574; batch adversarial loss: 0.620628\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495503; batch adversarial loss: 0.597274\n",
      "epoch 10; iter: 0; batch classifier loss: 0.551007; batch adversarial loss: 0.596835\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508601; batch adversarial loss: 0.600563\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531936; batch adversarial loss: 0.581832\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485380; batch adversarial loss: 0.557669\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469491; batch adversarial loss: 0.548201\n",
      "epoch 15; iter: 0; batch classifier loss: 0.561285; batch adversarial loss: 0.577526\n",
      "epoch 16; iter: 0; batch classifier loss: 0.490421; batch adversarial loss: 0.527675\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507413; batch adversarial loss: 0.532769\n",
      "epoch 18; iter: 0; batch classifier loss: 0.510265; batch adversarial loss: 0.525104\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507056; batch adversarial loss: 0.543589\n",
      "epoch 20; iter: 0; batch classifier loss: 0.551690; batch adversarial loss: 0.469328\n",
      "epoch 21; iter: 0; batch classifier loss: 0.467673; batch adversarial loss: 0.513665\n",
      "epoch 22; iter: 0; batch classifier loss: 0.495435; batch adversarial loss: 0.533671\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474991; batch adversarial loss: 0.535154\n",
      "epoch 24; iter: 0; batch classifier loss: 0.480355; batch adversarial loss: 0.485647\n",
      "epoch 25; iter: 0; batch classifier loss: 0.651438; batch adversarial loss: 0.572908\n",
      "epoch 26; iter: 0; batch classifier loss: 0.559442; batch adversarial loss: 0.519211\n",
      "epoch 27; iter: 0; batch classifier loss: 0.596563; batch adversarial loss: 0.650801\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478430; batch adversarial loss: 0.521445\n",
      "epoch 29; iter: 0; batch classifier loss: 0.591396; batch adversarial loss: 0.542378\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462558; batch adversarial loss: 0.554354\n",
      "epoch 31; iter: 0; batch classifier loss: 0.477802; batch adversarial loss: 0.500739\n",
      "epoch 32; iter: 0; batch classifier loss: 0.539204; batch adversarial loss: 0.525892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.508996; batch adversarial loss: 0.537988\n",
      "epoch 34; iter: 0; batch classifier loss: 0.592967; batch adversarial loss: 0.568041\n",
      "epoch 35; iter: 0; batch classifier loss: 0.492339; batch adversarial loss: 0.493040\n",
      "epoch 36; iter: 0; batch classifier loss: 0.510359; batch adversarial loss: 0.468645\n",
      "epoch 37; iter: 0; batch classifier loss: 0.526139; batch adversarial loss: 0.541075\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480175; batch adversarial loss: 0.422031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.474628; batch adversarial loss: 0.464706\n",
      "epoch 40; iter: 0; batch classifier loss: 0.496427; batch adversarial loss: 0.449084\n",
      "epoch 41; iter: 0; batch classifier loss: 0.558956; batch adversarial loss: 0.531983\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414050; batch adversarial loss: 0.452311\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421574; batch adversarial loss: 0.461235\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466432; batch adversarial loss: 0.413199\n",
      "epoch 45; iter: 0; batch classifier loss: 0.368596; batch adversarial loss: 0.447290\n",
      "epoch 46; iter: 0; batch classifier loss: 0.483892; batch adversarial loss: 0.540845\n",
      "epoch 47; iter: 0; batch classifier loss: 0.512759; batch adversarial loss: 0.509613\n",
      "epoch 48; iter: 0; batch classifier loss: 0.621697; batch adversarial loss: 0.434191\n",
      "epoch 49; iter: 0; batch classifier loss: 0.372881; batch adversarial loss: 0.470920\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422569; batch adversarial loss: 0.504839\n",
      "epoch 51; iter: 0; batch classifier loss: 0.383188; batch adversarial loss: 0.483239\n",
      "epoch 52; iter: 0; batch classifier loss: 0.364741; batch adversarial loss: 0.425775\n",
      "epoch 53; iter: 0; batch classifier loss: 0.388370; batch adversarial loss: 0.426465\n",
      "epoch 54; iter: 0; batch classifier loss: 0.448477; batch adversarial loss: 0.445183\n",
      "epoch 55; iter: 0; batch classifier loss: 0.382465; batch adversarial loss: 0.365924\n",
      "epoch 56; iter: 0; batch classifier loss: 0.366428; batch adversarial loss: 0.522268\n",
      "epoch 57; iter: 0; batch classifier loss: 0.369328; batch adversarial loss: 0.498845\n",
      "epoch 58; iter: 0; batch classifier loss: 0.394988; batch adversarial loss: 0.453038\n",
      "epoch 59; iter: 0; batch classifier loss: 0.315984; batch adversarial loss: 0.464648\n",
      "epoch 60; iter: 0; batch classifier loss: 0.399180; batch adversarial loss: 0.597123\n",
      "epoch 61; iter: 0; batch classifier loss: 0.336282; batch adversarial loss: 0.537206\n",
      "epoch 62; iter: 0; batch classifier loss: 0.375566; batch adversarial loss: 0.472141\n",
      "epoch 63; iter: 0; batch classifier loss: 0.401299; batch adversarial loss: 0.453798\n",
      "epoch 64; iter: 0; batch classifier loss: 0.305352; batch adversarial loss: 0.439627\n",
      "epoch 65; iter: 0; batch classifier loss: 0.331752; batch adversarial loss: 0.503674\n",
      "epoch 66; iter: 0; batch classifier loss: 0.408304; batch adversarial loss: 0.450224\n",
      "epoch 67; iter: 0; batch classifier loss: 0.370447; batch adversarial loss: 0.458102\n",
      "epoch 68; iter: 0; batch classifier loss: 0.344082; batch adversarial loss: 0.435021\n",
      "epoch 69; iter: 0; batch classifier loss: 0.352569; batch adversarial loss: 0.453456\n",
      "epoch 70; iter: 0; batch classifier loss: 0.386491; batch adversarial loss: 0.471363\n",
      "epoch 71; iter: 0; batch classifier loss: 0.335362; batch adversarial loss: 0.425956\n",
      "epoch 72; iter: 0; batch classifier loss: 0.339675; batch adversarial loss: 0.528933\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373401; batch adversarial loss: 0.532614\n",
      "epoch 74; iter: 0; batch classifier loss: 0.399326; batch adversarial loss: 0.447302\n",
      "epoch 75; iter: 0; batch classifier loss: 0.387849; batch adversarial loss: 0.483429\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370776; batch adversarial loss: 0.532136\n",
      "epoch 77; iter: 0; batch classifier loss: 0.327305; batch adversarial loss: 0.442356\n",
      "epoch 78; iter: 0; batch classifier loss: 0.299046; batch adversarial loss: 0.528746\n",
      "epoch 79; iter: 0; batch classifier loss: 0.343010; batch adversarial loss: 0.416992\n",
      "epoch 80; iter: 0; batch classifier loss: 0.350409; batch adversarial loss: 0.451010\n",
      "epoch 81; iter: 0; batch classifier loss: 0.315957; batch adversarial loss: 0.484837\n",
      "epoch 82; iter: 0; batch classifier loss: 0.346404; batch adversarial loss: 0.439010\n",
      "epoch 83; iter: 0; batch classifier loss: 0.362795; batch adversarial loss: 0.449045\n",
      "epoch 84; iter: 0; batch classifier loss: 0.285057; batch adversarial loss: 0.460276\n",
      "epoch 85; iter: 0; batch classifier loss: 0.259019; batch adversarial loss: 0.483989\n",
      "epoch 86; iter: 0; batch classifier loss: 0.329400; batch adversarial loss: 0.468565\n",
      "epoch 87; iter: 0; batch classifier loss: 0.263199; batch adversarial loss: 0.523743\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345514; batch adversarial loss: 0.427070\n",
      "epoch 89; iter: 0; batch classifier loss: 0.312967; batch adversarial loss: 0.456501\n",
      "epoch 90; iter: 0; batch classifier loss: 0.368371; batch adversarial loss: 0.457063\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334102; batch adversarial loss: 0.495513\n",
      "epoch 92; iter: 0; batch classifier loss: 0.269327; batch adversarial loss: 0.602793\n",
      "epoch 93; iter: 0; batch classifier loss: 0.316524; batch adversarial loss: 0.612375\n",
      "epoch 94; iter: 0; batch classifier loss: 0.258084; batch adversarial loss: 0.497798\n",
      "epoch 95; iter: 0; batch classifier loss: 0.236679; batch adversarial loss: 0.488103\n",
      "epoch 96; iter: 0; batch classifier loss: 0.296776; batch adversarial loss: 0.520749\n",
      "epoch 97; iter: 0; batch classifier loss: 0.315965; batch adversarial loss: 0.359248\n",
      "epoch 98; iter: 0; batch classifier loss: 0.297858; batch adversarial loss: 0.484793\n",
      "epoch 99; iter: 0; batch classifier loss: 0.342401; batch adversarial loss: 0.508135\n",
      "epoch 100; iter: 0; batch classifier loss: 0.303080; batch adversarial loss: 0.489463\n",
      "epoch 101; iter: 0; batch classifier loss: 0.280512; batch adversarial loss: 0.493630\n",
      "epoch 102; iter: 0; batch classifier loss: 0.311215; batch adversarial loss: 0.488311\n",
      "epoch 103; iter: 0; batch classifier loss: 0.313349; batch adversarial loss: 0.445604\n",
      "epoch 104; iter: 0; batch classifier loss: 0.391667; batch adversarial loss: 0.428334\n",
      "epoch 105; iter: 0; batch classifier loss: 0.240203; batch adversarial loss: 0.499677\n",
      "epoch 106; iter: 0; batch classifier loss: 0.319767; batch adversarial loss: 0.489667\n",
      "epoch 107; iter: 0; batch classifier loss: 0.343958; batch adversarial loss: 0.577366\n",
      "epoch 108; iter: 0; batch classifier loss: 0.255899; batch adversarial loss: 0.538363\n",
      "epoch 109; iter: 0; batch classifier loss: 0.299335; batch adversarial loss: 0.459753\n",
      "epoch 110; iter: 0; batch classifier loss: 0.251772; batch adversarial loss: 0.593083\n",
      "epoch 111; iter: 0; batch classifier loss: 0.257372; batch adversarial loss: 0.557851\n",
      "epoch 112; iter: 0; batch classifier loss: 0.330295; batch adversarial loss: 0.486357\n",
      "epoch 113; iter: 0; batch classifier loss: 0.332352; batch adversarial loss: 0.485212\n",
      "epoch 114; iter: 0; batch classifier loss: 0.397971; batch adversarial loss: 0.530681\n",
      "epoch 115; iter: 0; batch classifier loss: 0.428495; batch adversarial loss: 0.416535\n",
      "epoch 116; iter: 0; batch classifier loss: 0.358046; batch adversarial loss: 0.460961\n",
      "epoch 117; iter: 0; batch classifier loss: 0.411541; batch adversarial loss: 0.482713\n",
      "epoch 118; iter: 0; batch classifier loss: 0.311653; batch adversarial loss: 0.441968\n",
      "epoch 119; iter: 0; batch classifier loss: 0.366119; batch adversarial loss: 0.532104\n",
      "epoch 120; iter: 0; batch classifier loss: 0.346916; batch adversarial loss: 0.459806\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378818; batch adversarial loss: 0.524379\n",
      "epoch 122; iter: 0; batch classifier loss: 0.392602; batch adversarial loss: 0.493438\n",
      "epoch 123; iter: 0; batch classifier loss: 0.305340; batch adversarial loss: 0.466172\n",
      "epoch 124; iter: 0; batch classifier loss: 0.316119; batch adversarial loss: 0.486850\n",
      "epoch 125; iter: 0; batch classifier loss: 0.371397; batch adversarial loss: 0.469546\n",
      "epoch 126; iter: 0; batch classifier loss: 0.458996; batch adversarial loss: 0.440255\n",
      "epoch 127; iter: 0; batch classifier loss: 0.291353; batch adversarial loss: 0.443852\n",
      "epoch 128; iter: 0; batch classifier loss: 0.287540; batch adversarial loss: 0.540411\n",
      "epoch 129; iter: 0; batch classifier loss: 0.360242; batch adversarial loss: 0.435886\n",
      "epoch 130; iter: 0; batch classifier loss: 0.398956; batch adversarial loss: 0.459962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.408764; batch adversarial loss: 0.444343\n",
      "epoch 132; iter: 0; batch classifier loss: 0.341032; batch adversarial loss: 0.461194\n",
      "epoch 133; iter: 0; batch classifier loss: 0.324296; batch adversarial loss: 0.456698\n",
      "epoch 134; iter: 0; batch classifier loss: 0.434736; batch adversarial loss: 0.567624\n",
      "epoch 135; iter: 0; batch classifier loss: 0.401342; batch adversarial loss: 0.425054\n",
      "epoch 136; iter: 0; batch classifier loss: 0.301648; batch adversarial loss: 0.503935\n",
      "epoch 137; iter: 0; batch classifier loss: 0.476521; batch adversarial loss: 0.420260\n",
      "epoch 138; iter: 0; batch classifier loss: 0.387611; batch adversarial loss: 0.504031\n",
      "epoch 139; iter: 0; batch classifier loss: 0.373008; batch adversarial loss: 0.497498\n",
      "epoch 140; iter: 0; batch classifier loss: 0.401025; batch adversarial loss: 0.458511\n",
      "epoch 141; iter: 0; batch classifier loss: 0.314027; batch adversarial loss: 0.478231\n",
      "epoch 142; iter: 0; batch classifier loss: 0.394192; batch adversarial loss: 0.507389\n",
      "epoch 143; iter: 0; batch classifier loss: 0.464426; batch adversarial loss: 0.397621\n",
      "epoch 144; iter: 0; batch classifier loss: 0.361431; batch adversarial loss: 0.458276\n",
      "epoch 145; iter: 0; batch classifier loss: 0.408217; batch adversarial loss: 0.482203\n",
      "epoch 146; iter: 0; batch classifier loss: 0.331691; batch adversarial loss: 0.492057\n",
      "epoch 147; iter: 0; batch classifier loss: 0.372808; batch adversarial loss: 0.456211\n",
      "epoch 148; iter: 0; batch classifier loss: 0.370392; batch adversarial loss: 0.459434\n",
      "epoch 149; iter: 0; batch classifier loss: 0.418639; batch adversarial loss: 0.432829\n",
      "epoch 150; iter: 0; batch classifier loss: 0.370238; batch adversarial loss: 0.399231\n",
      "epoch 151; iter: 0; batch classifier loss: 0.333010; batch adversarial loss: 0.436314\n",
      "epoch 152; iter: 0; batch classifier loss: 0.363701; batch adversarial loss: 0.468920\n",
      "epoch 153; iter: 0; batch classifier loss: 0.428853; batch adversarial loss: 0.518784\n",
      "epoch 154; iter: 0; batch classifier loss: 0.289283; batch adversarial loss: 0.541308\n",
      "epoch 155; iter: 0; batch classifier loss: 0.356067; batch adversarial loss: 0.496936\n",
      "epoch 156; iter: 0; batch classifier loss: 0.401908; batch adversarial loss: 0.445647\n",
      "epoch 157; iter: 0; batch classifier loss: 0.458639; batch adversarial loss: 0.470552\n",
      "epoch 158; iter: 0; batch classifier loss: 0.400890; batch adversarial loss: 0.492692\n",
      "epoch 159; iter: 0; batch classifier loss: 0.447853; batch adversarial loss: 0.439677\n",
      "epoch 160; iter: 0; batch classifier loss: 0.432372; batch adversarial loss: 0.461877\n",
      "epoch 161; iter: 0; batch classifier loss: 0.488916; batch adversarial loss: 0.497253\n",
      "epoch 162; iter: 0; batch classifier loss: 0.480294; batch adversarial loss: 0.485730\n",
      "epoch 163; iter: 0; batch classifier loss: 0.380237; batch adversarial loss: 0.506166\n",
      "epoch 164; iter: 0; batch classifier loss: 0.407135; batch adversarial loss: 0.413154\n",
      "epoch 165; iter: 0; batch classifier loss: 0.434150; batch adversarial loss: 0.401797\n",
      "epoch 166; iter: 0; batch classifier loss: 0.339465; batch adversarial loss: 0.436863\n",
      "epoch 167; iter: 0; batch classifier loss: 0.389098; batch adversarial loss: 0.437751\n",
      "epoch 168; iter: 0; batch classifier loss: 0.393496; batch adversarial loss: 0.459374\n",
      "epoch 169; iter: 0; batch classifier loss: 0.431424; batch adversarial loss: 0.494931\n",
      "epoch 170; iter: 0; batch classifier loss: 0.412069; batch adversarial loss: 0.482168\n",
      "epoch 171; iter: 0; batch classifier loss: 0.402990; batch adversarial loss: 0.505108\n",
      "epoch 172; iter: 0; batch classifier loss: 0.428950; batch adversarial loss: 0.447536\n",
      "epoch 173; iter: 0; batch classifier loss: 0.386566; batch adversarial loss: 0.415753\n",
      "epoch 174; iter: 0; batch classifier loss: 0.365006; batch adversarial loss: 0.413352\n",
      "epoch 175; iter: 0; batch classifier loss: 0.336573; batch adversarial loss: 0.459116\n",
      "epoch 176; iter: 0; batch classifier loss: 0.345396; batch adversarial loss: 0.516775\n",
      "epoch 177; iter: 0; batch classifier loss: 0.430232; batch adversarial loss: 0.574738\n",
      "epoch 178; iter: 0; batch classifier loss: 0.350556; batch adversarial loss: 0.518111\n",
      "epoch 179; iter: 0; batch classifier loss: 0.464511; batch adversarial loss: 0.449664\n",
      "epoch 180; iter: 0; batch classifier loss: 0.334690; batch adversarial loss: 0.411473\n",
      "epoch 181; iter: 0; batch classifier loss: 0.314440; batch adversarial loss: 0.541719\n",
      "epoch 182; iter: 0; batch classifier loss: 0.439699; batch adversarial loss: 0.375952\n",
      "epoch 183; iter: 0; batch classifier loss: 0.395747; batch adversarial loss: 0.456587\n",
      "epoch 184; iter: 0; batch classifier loss: 0.407728; batch adversarial loss: 0.516299\n",
      "epoch 185; iter: 0; batch classifier loss: 0.389811; batch adversarial loss: 0.435858\n",
      "epoch 186; iter: 0; batch classifier loss: 0.400982; batch adversarial loss: 0.470078\n",
      "epoch 187; iter: 0; batch classifier loss: 0.233448; batch adversarial loss: 0.482808\n",
      "epoch 188; iter: 0; batch classifier loss: 0.404418; batch adversarial loss: 0.518295\n",
      "epoch 189; iter: 0; batch classifier loss: 0.300086; batch adversarial loss: 0.576181\n",
      "epoch 190; iter: 0; batch classifier loss: 0.340164; batch adversarial loss: 0.446669\n",
      "epoch 191; iter: 0; batch classifier loss: 0.339153; batch adversarial loss: 0.424295\n",
      "epoch 192; iter: 0; batch classifier loss: 0.303324; batch adversarial loss: 0.459017\n",
      "epoch 193; iter: 0; batch classifier loss: 0.295153; batch adversarial loss: 0.515838\n",
      "epoch 194; iter: 0; batch classifier loss: 0.435759; batch adversarial loss: 0.528871\n",
      "epoch 195; iter: 0; batch classifier loss: 0.361349; batch adversarial loss: 0.459469\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372216; batch adversarial loss: 0.434496\n",
      "epoch 197; iter: 0; batch classifier loss: 0.273813; batch adversarial loss: 0.414199\n",
      "epoch 198; iter: 0; batch classifier loss: 0.420656; batch adversarial loss: 0.458847\n",
      "epoch 199; iter: 0; batch classifier loss: 0.305506; batch adversarial loss: 0.634955\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.055996; batch adversarial loss: 0.853950\n",
      "epoch 2; iter: 0; batch classifier loss: 0.912392; batch adversarial loss: 0.825478\n",
      "epoch 3; iter: 0; batch classifier loss: 0.839760; batch adversarial loss: 0.736733\n",
      "epoch 4; iter: 0; batch classifier loss: 0.675278; batch adversarial loss: 0.723501\n",
      "epoch 5; iter: 0; batch classifier loss: 0.517078; batch adversarial loss: 0.681092\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509864; batch adversarial loss: 0.664471\n",
      "epoch 7; iter: 0; batch classifier loss: 0.488400; batch adversarial loss: 0.631920\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562591; batch adversarial loss: 0.616049\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502123; batch adversarial loss: 0.596127\n",
      "epoch 10; iter: 0; batch classifier loss: 0.567965; batch adversarial loss: 0.591365\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552575; batch adversarial loss: 0.595726\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564357; batch adversarial loss: 0.578413\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535884; batch adversarial loss: 0.549749\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483945; batch adversarial loss: 0.548970\n",
      "epoch 15; iter: 0; batch classifier loss: 0.591766; batch adversarial loss: 0.575952\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554381; batch adversarial loss: 0.517794\n",
      "epoch 17; iter: 0; batch classifier loss: 0.543046; batch adversarial loss: 0.531195\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523393; batch adversarial loss: 0.522524\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525236; batch adversarial loss: 0.539883\n",
      "epoch 20; iter: 0; batch classifier loss: 0.564916; batch adversarial loss: 0.459315\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486629; batch adversarial loss: 0.496440\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513236; batch adversarial loss: 0.509337\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475694; batch adversarial loss: 0.515649\n",
      "epoch 24; iter: 0; batch classifier loss: 0.481571; batch adversarial loss: 0.477746\n",
      "epoch 25; iter: 0; batch classifier loss: 0.625458; batch adversarial loss: 0.562235\n",
      "epoch 26; iter: 0; batch classifier loss: 0.566599; batch adversarial loss: 0.523538\n",
      "epoch 27; iter: 0; batch classifier loss: 0.625642; batch adversarial loss: 0.667136\n",
      "epoch 28; iter: 0; batch classifier loss: 0.562752; batch adversarial loss: 0.530826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.669881; batch adversarial loss: 0.562001\n",
      "epoch 30; iter: 0; batch classifier loss: 0.591730; batch adversarial loss: 0.575804\n",
      "epoch 31; iter: 0; batch classifier loss: 0.595983; batch adversarial loss: 0.512226\n",
      "epoch 32; iter: 0; batch classifier loss: 0.615554; batch adversarial loss: 0.534330\n",
      "epoch 33; iter: 0; batch classifier loss: 0.614853; batch adversarial loss: 0.551966\n",
      "epoch 34; iter: 0; batch classifier loss: 0.605467; batch adversarial loss: 0.567643\n",
      "epoch 35; iter: 0; batch classifier loss: 0.522106; batch adversarial loss: 0.494995\n",
      "epoch 36; iter: 0; batch classifier loss: 0.517124; batch adversarial loss: 0.466486\n",
      "epoch 37; iter: 0; batch classifier loss: 0.574208; batch adversarial loss: 0.539609\n",
      "epoch 38; iter: 0; batch classifier loss: 0.533451; batch adversarial loss: 0.420336\n",
      "epoch 39; iter: 0; batch classifier loss: 0.542452; batch adversarial loss: 0.464623\n",
      "epoch 40; iter: 0; batch classifier loss: 0.541263; batch adversarial loss: 0.449081\n",
      "epoch 41; iter: 0; batch classifier loss: 0.558362; batch adversarial loss: 0.532486\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453373; batch adversarial loss: 0.452947\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458529; batch adversarial loss: 0.462291\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481292; batch adversarial loss: 0.412128\n",
      "epoch 45; iter: 0; batch classifier loss: 0.418896; batch adversarial loss: 0.445873\n",
      "epoch 46; iter: 0; batch classifier loss: 0.479665; batch adversarial loss: 0.540263\n",
      "epoch 47; iter: 0; batch classifier loss: 0.481565; batch adversarial loss: 0.509903\n",
      "epoch 48; iter: 0; batch classifier loss: 0.560889; batch adversarial loss: 0.435685\n",
      "epoch 49; iter: 0; batch classifier loss: 0.515618; batch adversarial loss: 0.476262\n",
      "epoch 50; iter: 0; batch classifier loss: 0.553082; batch adversarial loss: 0.507813\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462848; batch adversarial loss: 0.483988\n",
      "epoch 52; iter: 0; batch classifier loss: 0.441670; batch adversarial loss: 0.427298\n",
      "epoch 53; iter: 0; batch classifier loss: 0.455372; batch adversarial loss: 0.427152\n",
      "epoch 54; iter: 0; batch classifier loss: 0.500341; batch adversarial loss: 0.446495\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483234; batch adversarial loss: 0.366634\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409792; batch adversarial loss: 0.523087\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398464; batch adversarial loss: 0.498046\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447984; batch adversarial loss: 0.452833\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406253; batch adversarial loss: 0.465248\n",
      "epoch 60; iter: 0; batch classifier loss: 0.429190; batch adversarial loss: 0.596227\n",
      "epoch 61; iter: 0; batch classifier loss: 0.405328; batch adversarial loss: 0.538031\n",
      "epoch 62; iter: 0; batch classifier loss: 0.435814; batch adversarial loss: 0.470703\n",
      "epoch 63; iter: 0; batch classifier loss: 0.427882; batch adversarial loss: 0.449664\n",
      "epoch 64; iter: 0; batch classifier loss: 0.371150; batch adversarial loss: 0.439453\n",
      "epoch 65; iter: 0; batch classifier loss: 0.360477; batch adversarial loss: 0.504012\n",
      "epoch 66; iter: 0; batch classifier loss: 0.415406; batch adversarial loss: 0.449817\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401731; batch adversarial loss: 0.456898\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390210; batch adversarial loss: 0.432624\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419064; batch adversarial loss: 0.453079\n",
      "epoch 70; iter: 0; batch classifier loss: 0.452805; batch adversarial loss: 0.469543\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407946; batch adversarial loss: 0.424704\n",
      "epoch 72; iter: 0; batch classifier loss: 0.467989; batch adversarial loss: 0.530290\n",
      "epoch 73; iter: 0; batch classifier loss: 0.428150; batch adversarial loss: 0.529788\n",
      "epoch 74; iter: 0; batch classifier loss: 0.460982; batch adversarial loss: 0.444294\n",
      "epoch 75; iter: 0; batch classifier loss: 0.485524; batch adversarial loss: 0.481426\n",
      "epoch 76; iter: 0; batch classifier loss: 0.441856; batch adversarial loss: 0.527977\n",
      "epoch 77; iter: 0; batch classifier loss: 0.394507; batch adversarial loss: 0.440647\n",
      "epoch 78; iter: 0; batch classifier loss: 0.369101; batch adversarial loss: 0.526424\n",
      "epoch 79; iter: 0; batch classifier loss: 0.394977; batch adversarial loss: 0.414474\n",
      "epoch 80; iter: 0; batch classifier loss: 0.439831; batch adversarial loss: 0.452331\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402103; batch adversarial loss: 0.484456\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363798; batch adversarial loss: 0.435270\n",
      "epoch 83; iter: 0; batch classifier loss: 0.412304; batch adversarial loss: 0.446400\n",
      "epoch 84; iter: 0; batch classifier loss: 0.366437; batch adversarial loss: 0.461792\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343543; batch adversarial loss: 0.484045\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427477; batch adversarial loss: 0.468378\n",
      "epoch 87; iter: 0; batch classifier loss: 0.358924; batch adversarial loss: 0.521119\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414646; batch adversarial loss: 0.418765\n",
      "epoch 89; iter: 0; batch classifier loss: 0.380614; batch adversarial loss: 0.453152\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387820; batch adversarial loss: 0.451817\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393255; batch adversarial loss: 0.495106\n",
      "epoch 92; iter: 0; batch classifier loss: 0.394414; batch adversarial loss: 0.603593\n",
      "epoch 93; iter: 0; batch classifier loss: 0.443833; batch adversarial loss: 0.614526\n",
      "epoch 94; iter: 0; batch classifier loss: 0.312561; batch adversarial loss: 0.494781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.284822; batch adversarial loss: 0.483625\n",
      "epoch 96; iter: 0; batch classifier loss: 0.340236; batch adversarial loss: 0.514209\n",
      "epoch 97; iter: 0; batch classifier loss: 0.438564; batch adversarial loss: 0.360495\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376987; batch adversarial loss: 0.482123\n",
      "epoch 99; iter: 0; batch classifier loss: 0.441624; batch adversarial loss: 0.504446\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.082477; batch adversarial loss: 0.855919\n",
      "epoch 2; iter: 0; batch classifier loss: 0.935668; batch adversarial loss: 0.827608\n",
      "epoch 3; iter: 0; batch classifier loss: 0.872331; batch adversarial loss: 0.738885\n",
      "epoch 4; iter: 0; batch classifier loss: 0.696546; batch adversarial loss: 0.726120\n",
      "epoch 5; iter: 0; batch classifier loss: 0.530348; batch adversarial loss: 0.682881\n",
      "epoch 6; iter: 0; batch classifier loss: 0.510052; batch adversarial loss: 0.664828\n",
      "epoch 7; iter: 0; batch classifier loss: 0.488903; batch adversarial loss: 0.631785\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561968; batch adversarial loss: 0.615933\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501689; batch adversarial loss: 0.595900\n",
      "epoch 10; iter: 0; batch classifier loss: 0.567997; batch adversarial loss: 0.591383\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549907; batch adversarial loss: 0.596134\n",
      "epoch 12; iter: 0; batch classifier loss: 0.561890; batch adversarial loss: 0.578536\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528519; batch adversarial loss: 0.550771\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477800; batch adversarial loss: 0.549351\n",
      "epoch 15; iter: 0; batch classifier loss: 0.587071; batch adversarial loss: 0.576247\n",
      "epoch 16; iter: 0; batch classifier loss: 0.543396; batch adversarial loss: 0.521360\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536543; batch adversarial loss: 0.533832\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524105; batch adversarial loss: 0.524381\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525997; batch adversarial loss: 0.542359\n",
      "epoch 20; iter: 0; batch classifier loss: 0.568630; batch adversarial loss: 0.462346\n",
      "epoch 21; iter: 0; batch classifier loss: 0.496408; batch adversarial loss: 0.503091\n",
      "epoch 22; iter: 0; batch classifier loss: 0.529659; batch adversarial loss: 0.516669\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486435; batch adversarial loss: 0.525343\n",
      "epoch 24; iter: 0; batch classifier loss: 0.496436; batch adversarial loss: 0.485333\n",
      "epoch 25; iter: 0; batch classifier loss: 0.648318; batch adversarial loss: 0.571274\n",
      "epoch 26; iter: 0; batch classifier loss: 0.586568; batch adversarial loss: 0.528174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.664116; batch adversarial loss: 0.672677\n",
      "epoch 28; iter: 0; batch classifier loss: 0.592866; batch adversarial loss: 0.536986\n",
      "epoch 29; iter: 0; batch classifier loss: 0.699175; batch adversarial loss: 0.561662\n",
      "epoch 30; iter: 0; batch classifier loss: 0.600262; batch adversarial loss: 0.570813\n",
      "epoch 31; iter: 0; batch classifier loss: 0.584014; batch adversarial loss: 0.506651\n",
      "epoch 32; iter: 0; batch classifier loss: 0.596335; batch adversarial loss: 0.527559\n",
      "epoch 33; iter: 0; batch classifier loss: 0.582897; batch adversarial loss: 0.542630\n",
      "epoch 34; iter: 0; batch classifier loss: 0.570325; batch adversarial loss: 0.559206\n",
      "epoch 35; iter: 0; batch classifier loss: 0.507872; batch adversarial loss: 0.491008\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508472; batch adversarial loss: 0.464147\n",
      "epoch 37; iter: 0; batch classifier loss: 0.552193; batch adversarial loss: 0.535351\n",
      "epoch 38; iter: 0; batch classifier loss: 0.520814; batch adversarial loss: 0.418157\n",
      "epoch 39; iter: 0; batch classifier loss: 0.532739; batch adversarial loss: 0.462698\n",
      "epoch 40; iter: 0; batch classifier loss: 0.538323; batch adversarial loss: 0.447751\n",
      "epoch 41; iter: 0; batch classifier loss: 0.557513; batch adversarial loss: 0.532517\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460115; batch adversarial loss: 0.453218\n",
      "epoch 43; iter: 0; batch classifier loss: 0.462899; batch adversarial loss: 0.462732\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484904; batch adversarial loss: 0.412444\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422395; batch adversarial loss: 0.446909\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496773; batch adversarial loss: 0.540841\n",
      "epoch 47; iter: 0; batch classifier loss: 0.505446; batch adversarial loss: 0.510032\n",
      "epoch 48; iter: 0; batch classifier loss: 0.580820; batch adversarial loss: 0.435753\n",
      "epoch 49; iter: 0; batch classifier loss: 0.529478; batch adversarial loss: 0.474203\n",
      "epoch 50; iter: 0; batch classifier loss: 0.477993; batch adversarial loss: 0.504813\n",
      "epoch 51; iter: 0; batch classifier loss: 0.465107; batch adversarial loss: 0.483615\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438959; batch adversarial loss: 0.426656\n",
      "epoch 53; iter: 0; batch classifier loss: 0.462555; batch adversarial loss: 0.426783\n",
      "epoch 54; iter: 0; batch classifier loss: 0.503471; batch adversarial loss: 0.446397\n",
      "epoch 55; iter: 0; batch classifier loss: 0.485803; batch adversarial loss: 0.366362\n",
      "epoch 56; iter: 0; batch classifier loss: 0.413758; batch adversarial loss: 0.523317\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398750; batch adversarial loss: 0.498307\n",
      "epoch 58; iter: 0; batch classifier loss: 0.444645; batch adversarial loss: 0.452925\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407710; batch adversarial loss: 0.465300\n",
      "epoch 60; iter: 0; batch classifier loss: 0.436017; batch adversarial loss: 0.596253\n",
      "epoch 61; iter: 0; batch classifier loss: 0.406809; batch adversarial loss: 0.538313\n",
      "epoch 62; iter: 0; batch classifier loss: 0.440490; batch adversarial loss: 0.470794\n",
      "epoch 63; iter: 0; batch classifier loss: 0.430405; batch adversarial loss: 0.449387\n",
      "epoch 64; iter: 0; batch classifier loss: 0.372196; batch adversarial loss: 0.439589\n",
      "epoch 65; iter: 0; batch classifier loss: 0.374565; batch adversarial loss: 0.504103\n",
      "epoch 66; iter: 0; batch classifier loss: 0.411881; batch adversarial loss: 0.449703\n",
      "epoch 67; iter: 0; batch classifier loss: 0.401187; batch adversarial loss: 0.456395\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397491; batch adversarial loss: 0.432966\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424712; batch adversarial loss: 0.453204\n",
      "epoch 70; iter: 0; batch classifier loss: 0.466622; batch adversarial loss: 0.469563\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404568; batch adversarial loss: 0.424634\n",
      "epoch 72; iter: 0; batch classifier loss: 0.476851; batch adversarial loss: 0.530665\n",
      "epoch 73; iter: 0; batch classifier loss: 0.423898; batch adversarial loss: 0.529495\n",
      "epoch 74; iter: 0; batch classifier loss: 0.465293; batch adversarial loss: 0.444939\n",
      "epoch 75; iter: 0; batch classifier loss: 0.483679; batch adversarial loss: 0.481616\n",
      "epoch 76; iter: 0; batch classifier loss: 0.451032; batch adversarial loss: 0.528022\n",
      "epoch 77; iter: 0; batch classifier loss: 0.391393; batch adversarial loss: 0.440745\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368439; batch adversarial loss: 0.526636\n",
      "epoch 79; iter: 0; batch classifier loss: 0.390341; batch adversarial loss: 0.415138\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436522; batch adversarial loss: 0.452678\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403971; batch adversarial loss: 0.484698\n",
      "epoch 82; iter: 0; batch classifier loss: 0.371009; batch adversarial loss: 0.436041\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398271; batch adversarial loss: 0.446869\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370010; batch adversarial loss: 0.462324\n",
      "epoch 85; iter: 0; batch classifier loss: 0.339985; batch adversarial loss: 0.483488\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424379; batch adversarial loss: 0.468650\n",
      "epoch 87; iter: 0; batch classifier loss: 0.370449; batch adversarial loss: 0.521542\n",
      "epoch 88; iter: 0; batch classifier loss: 0.412706; batch adversarial loss: 0.418802\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387720; batch adversarial loss: 0.452573\n",
      "epoch 90; iter: 0; batch classifier loss: 0.397608; batch adversarial loss: 0.453008\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390238; batch adversarial loss: 0.494890\n",
      "epoch 92; iter: 0; batch classifier loss: 0.400939; batch adversarial loss: 0.604336\n",
      "epoch 93; iter: 0; batch classifier loss: 0.440387; batch adversarial loss: 0.613378\n",
      "epoch 94; iter: 0; batch classifier loss: 0.299111; batch adversarial loss: 0.495691\n",
      "epoch 95; iter: 0; batch classifier loss: 0.281638; batch adversarial loss: 0.485046\n",
      "epoch 96; iter: 0; batch classifier loss: 0.341604; batch adversarial loss: 0.514972\n",
      "epoch 97; iter: 0; batch classifier loss: 0.445867; batch adversarial loss: 0.360682\n",
      "epoch 98; iter: 0; batch classifier loss: 0.370977; batch adversarial loss: 0.482359\n",
      "epoch 99; iter: 0; batch classifier loss: 0.448744; batch adversarial loss: 0.504702\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.117585; batch adversarial loss: 0.858258\n",
      "epoch 2; iter: 0; batch classifier loss: 0.973329; batch adversarial loss: 0.830484\n",
      "epoch 3; iter: 0; batch classifier loss: 0.923622; batch adversarial loss: 0.741772\n",
      "epoch 4; iter: 0; batch classifier loss: 0.732237; batch adversarial loss: 0.729590\n",
      "epoch 5; iter: 0; batch classifier loss: 0.554868; batch adversarial loss: 0.686208\n",
      "epoch 6; iter: 0; batch classifier loss: 0.511523; batch adversarial loss: 0.665367\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490210; batch adversarial loss: 0.631335\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561636; batch adversarial loss: 0.615736\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502148; batch adversarial loss: 0.595387\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564837; batch adversarial loss: 0.591371\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546933; batch adversarial loss: 0.596114\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559336; batch adversarial loss: 0.578241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519636; batch adversarial loss: 0.551551\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469690; batch adversarial loss: 0.549866\n",
      "epoch 15; iter: 0; batch classifier loss: 0.579664; batch adversarial loss: 0.578000\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533465; batch adversarial loss: 0.526983\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528811; batch adversarial loss: 0.537610\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526227; batch adversarial loss: 0.527195\n",
      "epoch 19; iter: 0; batch classifier loss: 0.529270; batch adversarial loss: 0.546761\n",
      "epoch 20; iter: 0; batch classifier loss: 0.580052; batch adversarial loss: 0.469105\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523788; batch adversarial loss: 0.515522\n",
      "epoch 22; iter: 0; batch classifier loss: 0.568265; batch adversarial loss: 0.529685\n",
      "epoch 23; iter: 0; batch classifier loss: 0.515148; batch adversarial loss: 0.540401\n",
      "epoch 24; iter: 0; batch classifier loss: 0.519319; batch adversarial loss: 0.496091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25; iter: 0; batch classifier loss: 0.713187; batch adversarial loss: 0.585706\n",
      "epoch 26; iter: 0; batch classifier loss: 0.639900; batch adversarial loss: 0.536997\n",
      "epoch 27; iter: 0; batch classifier loss: 0.714489; batch adversarial loss: 0.669672\n",
      "epoch 28; iter: 0; batch classifier loss: 0.609350; batch adversarial loss: 0.535089\n",
      "epoch 29; iter: 0; batch classifier loss: 0.692264; batch adversarial loss: 0.552288\n",
      "epoch 30; iter: 0; batch classifier loss: 0.573419; batch adversarial loss: 0.557834\n",
      "epoch 31; iter: 0; batch classifier loss: 0.566197; batch adversarial loss: 0.498541\n",
      "epoch 32; iter: 0; batch classifier loss: 0.555403; batch adversarial loss: 0.518465\n",
      "epoch 33; iter: 0; batch classifier loss: 0.527532; batch adversarial loss: 0.529610\n",
      "epoch 34; iter: 0; batch classifier loss: 0.514293; batch adversarial loss: 0.548145\n",
      "epoch 35; iter: 0; batch classifier loss: 0.491137; batch adversarial loss: 0.485832\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502673; batch adversarial loss: 0.461042\n",
      "epoch 37; iter: 0; batch classifier loss: 0.536960; batch adversarial loss: 0.532793\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523425; batch adversarial loss: 0.416472\n",
      "epoch 39; iter: 0; batch classifier loss: 0.535897; batch adversarial loss: 0.463046\n",
      "epoch 40; iter: 0; batch classifier loss: 0.545484; batch adversarial loss: 0.448743\n",
      "epoch 41; iter: 0; batch classifier loss: 0.588268; batch adversarial loss: 0.535828\n",
      "epoch 42; iter: 0; batch classifier loss: 0.488108; batch adversarial loss: 0.455800\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483686; batch adversarial loss: 0.463810\n",
      "epoch 44; iter: 0; batch classifier loss: 0.505584; batch adversarial loss: 0.413198\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430062; batch adversarial loss: 0.447922\n",
      "epoch 46; iter: 0; batch classifier loss: 0.512089; batch adversarial loss: 0.538519\n",
      "epoch 47; iter: 0; batch classifier loss: 0.526254; batch adversarial loss: 0.507364\n",
      "epoch 48; iter: 0; batch classifier loss: 0.595645; batch adversarial loss: 0.434239\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447914; batch adversarial loss: 0.472109\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458467; batch adversarial loss: 0.504600\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466791; batch adversarial loss: 0.483256\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438679; batch adversarial loss: 0.426113\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465927; batch adversarial loss: 0.426269\n",
      "epoch 54; iter: 0; batch classifier loss: 0.505384; batch adversarial loss: 0.446299\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487744; batch adversarial loss: 0.365819\n",
      "epoch 56; iter: 0; batch classifier loss: 0.424218; batch adversarial loss: 0.523810\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399976; batch adversarial loss: 0.498719\n",
      "epoch 58; iter: 0; batch classifier loss: 0.450449; batch adversarial loss: 0.453006\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407354; batch adversarial loss: 0.465361\n",
      "epoch 60; iter: 0; batch classifier loss: 0.445167; batch adversarial loss: 0.596431\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417752; batch adversarial loss: 0.538941\n",
      "epoch 62; iter: 0; batch classifier loss: 0.435197; batch adversarial loss: 0.471007\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431585; batch adversarial loss: 0.449620\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375816; batch adversarial loss: 0.439871\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382050; batch adversarial loss: 0.503889\n",
      "epoch 66; iter: 0; batch classifier loss: 0.433245; batch adversarial loss: 0.450188\n",
      "epoch 67; iter: 0; batch classifier loss: 0.400892; batch adversarial loss: 0.456047\n",
      "epoch 68; iter: 0; batch classifier loss: 0.399183; batch adversarial loss: 0.432875\n",
      "epoch 69; iter: 0; batch classifier loss: 0.437844; batch adversarial loss: 0.453533\n",
      "epoch 70; iter: 0; batch classifier loss: 0.461219; batch adversarial loss: 0.470138\n",
      "epoch 71; iter: 0; batch classifier loss: 0.400596; batch adversarial loss: 0.424917\n",
      "epoch 72; iter: 0; batch classifier loss: 0.487925; batch adversarial loss: 0.531134\n",
      "epoch 73; iter: 0; batch classifier loss: 0.427397; batch adversarial loss: 0.529651\n",
      "epoch 74; iter: 0; batch classifier loss: 0.465930; batch adversarial loss: 0.445633\n",
      "epoch 75; iter: 0; batch classifier loss: 0.504631; batch adversarial loss: 0.482590\n",
      "epoch 76; iter: 0; batch classifier loss: 0.448639; batch adversarial loss: 0.528010\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404813; batch adversarial loss: 0.440670\n",
      "epoch 78; iter: 0; batch classifier loss: 0.371466; batch adversarial loss: 0.527095\n",
      "epoch 79; iter: 0; batch classifier loss: 0.414809; batch adversarial loss: 0.414443\n",
      "epoch 80; iter: 0; batch classifier loss: 0.430581; batch adversarial loss: 0.452274\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394874; batch adversarial loss: 0.485197\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383228; batch adversarial loss: 0.436430\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405676; batch adversarial loss: 0.447314\n",
      "epoch 84; iter: 0; batch classifier loss: 0.366365; batch adversarial loss: 0.461782\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343880; batch adversarial loss: 0.483584\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421263; batch adversarial loss: 0.469026\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367182; batch adversarial loss: 0.522384\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427352; batch adversarial loss: 0.420555\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395247; batch adversarial loss: 0.452765\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399532; batch adversarial loss: 0.453999\n",
      "epoch 91; iter: 0; batch classifier loss: 0.377338; batch adversarial loss: 0.495402\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398589; batch adversarial loss: 0.603888\n",
      "epoch 93; iter: 0; batch classifier loss: 0.436397; batch adversarial loss: 0.613651\n",
      "epoch 94; iter: 0; batch classifier loss: 0.304427; batch adversarial loss: 0.496752\n",
      "epoch 95; iter: 0; batch classifier loss: 0.278392; batch adversarial loss: 0.487250\n",
      "epoch 96; iter: 0; batch classifier loss: 0.324196; batch adversarial loss: 0.515804\n",
      "epoch 97; iter: 0; batch classifier loss: 0.457379; batch adversarial loss: 0.361176\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372090; batch adversarial loss: 0.481589\n",
      "epoch 99; iter: 0; batch classifier loss: 0.460366; batch adversarial loss: 0.506239\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.138506; batch adversarial loss: 0.859498\n",
      "epoch 2; iter: 0; batch classifier loss: 0.996070; batch adversarial loss: 0.831924\n",
      "epoch 3; iter: 0; batch classifier loss: 0.953622; batch adversarial loss: 0.743212\n",
      "epoch 4; iter: 0; batch classifier loss: 0.755722; batch adversarial loss: 0.731354\n",
      "epoch 5; iter: 0; batch classifier loss: 0.574250; batch adversarial loss: 0.687862\n",
      "epoch 6; iter: 0; batch classifier loss: 0.514459; batch adversarial loss: 0.665779\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492657; batch adversarial loss: 0.631041\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561267; batch adversarial loss: 0.615455\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502387; batch adversarial loss: 0.594928\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565155; batch adversarial loss: 0.591087\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545812; batch adversarial loss: 0.596068\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557909; batch adversarial loss: 0.578127\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517323; batch adversarial loss: 0.551374\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466087; batch adversarial loss: 0.550364\n",
      "epoch 15; iter: 0; batch classifier loss: 0.576164; batch adversarial loss: 0.579365\n",
      "epoch 16; iter: 0; batch classifier loss: 0.530312; batch adversarial loss: 0.529794\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524167; batch adversarial loss: 0.539433\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526159; batch adversarial loss: 0.528732\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535285; batch adversarial loss: 0.550908\n",
      "epoch 20; iter: 0; batch classifier loss: 0.588306; batch adversarial loss: 0.474817\n",
      "epoch 21; iter: 0; batch classifier loss: 0.544833; batch adversarial loss: 0.523706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.587176; batch adversarial loss: 0.535401\n",
      "epoch 23; iter: 0; batch classifier loss: 0.540234; batch adversarial loss: 0.548620\n",
      "epoch 24; iter: 0; batch classifier loss: 0.549613; batch adversarial loss: 0.505413\n",
      "epoch 25; iter: 0; batch classifier loss: 0.770547; batch adversarial loss: 0.591877\n",
      "epoch 26; iter: 0; batch classifier loss: 0.660058; batch adversarial loss: 0.534659\n",
      "epoch 27; iter: 0; batch classifier loss: 0.716900; batch adversarial loss: 0.660719\n",
      "epoch 28; iter: 0; batch classifier loss: 0.608766; batch adversarial loss: 0.532334\n",
      "epoch 29; iter: 0; batch classifier loss: 0.676013; batch adversarial loss: 0.545787\n",
      "epoch 30; iter: 0; batch classifier loss: 0.553441; batch adversarial loss: 0.551183\n",
      "epoch 31; iter: 0; batch classifier loss: 0.550111; batch adversarial loss: 0.494456\n",
      "epoch 32; iter: 0; batch classifier loss: 0.545800; batch adversarial loss: 0.515141\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498751; batch adversarial loss: 0.523927\n",
      "epoch 34; iter: 0; batch classifier loss: 0.490382; batch adversarial loss: 0.543299\n",
      "epoch 35; iter: 0; batch classifier loss: 0.482325; batch adversarial loss: 0.482973\n",
      "epoch 36; iter: 0; batch classifier loss: 0.507960; batch adversarial loss: 0.459531\n",
      "epoch 37; iter: 0; batch classifier loss: 0.530079; batch adversarial loss: 0.532141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.532333; batch adversarial loss: 0.416151\n",
      "epoch 39; iter: 0; batch classifier loss: 0.549472; batch adversarial loss: 0.464704\n",
      "epoch 40; iter: 0; batch classifier loss: 0.567879; batch adversarial loss: 0.450563\n",
      "epoch 41; iter: 0; batch classifier loss: 0.616006; batch adversarial loss: 0.537344\n",
      "epoch 42; iter: 0; batch classifier loss: 0.504595; batch adversarial loss: 0.456516\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483676; batch adversarial loss: 0.463369\n",
      "epoch 44; iter: 0; batch classifier loss: 0.505221; batch adversarial loss: 0.412535\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433247; batch adversarial loss: 0.447673\n",
      "epoch 46; iter: 0; batch classifier loss: 0.504878; batch adversarial loss: 0.536981\n",
      "epoch 47; iter: 0; batch classifier loss: 0.523640; batch adversarial loss: 0.506255\n",
      "epoch 48; iter: 0; batch classifier loss: 0.571165; batch adversarial loss: 0.433650\n",
      "epoch 49; iter: 0; batch classifier loss: 0.436700; batch adversarial loss: 0.471777\n",
      "epoch 50; iter: 0; batch classifier loss: 0.468970; batch adversarial loss: 0.504686\n",
      "epoch 51; iter: 0; batch classifier loss: 0.465680; batch adversarial loss: 0.483180\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444948; batch adversarial loss: 0.426046\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466810; batch adversarial loss: 0.426180\n",
      "epoch 54; iter: 0; batch classifier loss: 0.502710; batch adversarial loss: 0.446268\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487794; batch adversarial loss: 0.365727\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417115; batch adversarial loss: 0.523556\n",
      "epoch 57; iter: 0; batch classifier loss: 0.397166; batch adversarial loss: 0.498556\n",
      "epoch 58; iter: 0; batch classifier loss: 0.455269; batch adversarial loss: 0.453293\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409024; batch adversarial loss: 0.465516\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437264; batch adversarial loss: 0.596748\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422914; batch adversarial loss: 0.539089\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441070; batch adversarial loss: 0.470966\n",
      "epoch 63; iter: 0; batch classifier loss: 0.428344; batch adversarial loss: 0.449587\n",
      "epoch 64; iter: 0; batch classifier loss: 0.383425; batch adversarial loss: 0.440029\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389729; batch adversarial loss: 0.503587\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439601; batch adversarial loss: 0.450397\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411019; batch adversarial loss: 0.455983\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412792; batch adversarial loss: 0.432056\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444933; batch adversarial loss: 0.454082\n",
      "epoch 70; iter: 0; batch classifier loss: 0.455526; batch adversarial loss: 0.469035\n",
      "epoch 71; iter: 0; batch classifier loss: 0.417936; batch adversarial loss: 0.425324\n",
      "epoch 72; iter: 0; batch classifier loss: 0.468244; batch adversarial loss: 0.530598\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438114; batch adversarial loss: 0.528664\n",
      "epoch 74; iter: 0; batch classifier loss: 0.470213; batch adversarial loss: 0.445235\n",
      "epoch 75; iter: 0; batch classifier loss: 0.491860; batch adversarial loss: 0.481418\n",
      "epoch 76; iter: 0; batch classifier loss: 0.465024; batch adversarial loss: 0.528598\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413924; batch adversarial loss: 0.440877\n",
      "epoch 78; iter: 0; batch classifier loss: 0.366839; batch adversarial loss: 0.526097\n",
      "epoch 79; iter: 0; batch classifier loss: 0.407107; batch adversarial loss: 0.413924\n",
      "epoch 80; iter: 0; batch classifier loss: 0.446640; batch adversarial loss: 0.452974\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391583; batch adversarial loss: 0.485356\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386101; batch adversarial loss: 0.436704\n",
      "epoch 83; iter: 0; batch classifier loss: 0.408009; batch adversarial loss: 0.447527\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374831; batch adversarial loss: 0.462152\n",
      "epoch 85; iter: 0; batch classifier loss: 0.351271; batch adversarial loss: 0.483171\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424392; batch adversarial loss: 0.469209\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369241; batch adversarial loss: 0.522273\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421454; batch adversarial loss: 0.419715\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398786; batch adversarial loss: 0.453295\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399474; batch adversarial loss: 0.454083\n",
      "epoch 91; iter: 0; batch classifier loss: 0.379376; batch adversarial loss: 0.494810\n",
      "epoch 92; iter: 0; batch classifier loss: 0.413308; batch adversarial loss: 0.604789\n",
      "epoch 93; iter: 0; batch classifier loss: 0.447881; batch adversarial loss: 0.614425\n",
      "epoch 94; iter: 0; batch classifier loss: 0.292235; batch adversarial loss: 0.497415\n",
      "epoch 95; iter: 0; batch classifier loss: 0.291459; batch adversarial loss: 0.484905\n",
      "epoch 96; iter: 0; batch classifier loss: 0.327004; batch adversarial loss: 0.515839\n",
      "epoch 97; iter: 0; batch classifier loss: 0.468623; batch adversarial loss: 0.360822\n",
      "epoch 98; iter: 0; batch classifier loss: 0.377408; batch adversarial loss: 0.482964\n",
      "epoch 99; iter: 0; batch classifier loss: 0.473270; batch adversarial loss: 0.506347\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.046453; batch adversarial loss: 0.853156\n",
      "epoch 2; iter: 0; batch classifier loss: 0.903150; batch adversarial loss: 0.824524\n",
      "epoch 3; iter: 0; batch classifier loss: 0.827185; batch adversarial loss: 0.735896\n",
      "epoch 4; iter: 0; batch classifier loss: 0.668269; batch adversarial loss: 0.722391\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512706; batch adversarial loss: 0.680166\n",
      "epoch 6; iter: 0; batch classifier loss: 0.510402; batch adversarial loss: 0.664333\n",
      "epoch 7; iter: 0; batch classifier loss: 0.487925; batch adversarial loss: 0.631993\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561826; batch adversarial loss: 0.616311\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500967; batch adversarial loss: 0.596374\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568338; batch adversarial loss: 0.591365\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553656; batch adversarial loss: 0.595439\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565735; batch adversarial loss: 0.578323\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537795; batch adversarial loss: 0.549484\n",
      "epoch 14; iter: 0; batch classifier loss: 0.486685; batch adversarial loss: 0.548793\n",
      "epoch 15; iter: 0; batch classifier loss: 0.594093; batch adversarial loss: 0.575798\n",
      "epoch 16; iter: 0; batch classifier loss: 0.557502; batch adversarial loss: 0.516827\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546412; batch adversarial loss: 0.530167\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523413; batch adversarial loss: 0.521884\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525385; batch adversarial loss: 0.539109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.562634; batch adversarial loss: 0.458646\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487108; batch adversarial loss: 0.494596\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509819; batch adversarial loss: 0.507046\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471559; batch adversarial loss: 0.512973\n",
      "epoch 24; iter: 0; batch classifier loss: 0.479341; batch adversarial loss: 0.475096\n",
      "epoch 25; iter: 0; batch classifier loss: 0.621265; batch adversarial loss: 0.558733\n",
      "epoch 26; iter: 0; batch classifier loss: 0.562660; batch adversarial loss: 0.521595\n",
      "epoch 27; iter: 0; batch classifier loss: 0.614499; batch adversarial loss: 0.665487\n",
      "epoch 28; iter: 0; batch classifier loss: 0.550795; batch adversarial loss: 0.528223\n",
      "epoch 29; iter: 0; batch classifier loss: 0.648560; batch adversarial loss: 0.559958\n",
      "epoch 30; iter: 0; batch classifier loss: 0.576894; batch adversarial loss: 0.574841\n",
      "epoch 31; iter: 0; batch classifier loss: 0.595896; batch adversarial loss: 0.513501\n",
      "epoch 32; iter: 0; batch classifier loss: 0.620452; batch adversarial loss: 0.536608\n",
      "epoch 33; iter: 0; batch classifier loss: 0.622595; batch adversarial loss: 0.555347\n",
      "epoch 34; iter: 0; batch classifier loss: 0.611166; batch adversarial loss: 0.570926\n",
      "epoch 35; iter: 0; batch classifier loss: 0.526728; batch adversarial loss: 0.496684\n",
      "epoch 36; iter: 0; batch classifier loss: 0.527429; batch adversarial loss: 0.467668\n",
      "epoch 37; iter: 0; batch classifier loss: 0.594052; batch adversarial loss: 0.542517\n",
      "epoch 38; iter: 0; batch classifier loss: 0.543077; batch adversarial loss: 0.421565\n",
      "epoch 39; iter: 0; batch classifier loss: 0.551377; batch adversarial loss: 0.465796\n",
      "epoch 40; iter: 0; batch classifier loss: 0.543892; batch adversarial loss: 0.449955\n",
      "epoch 41; iter: 0; batch classifier loss: 0.559301; batch adversarial loss: 0.533220\n",
      "epoch 42; iter: 0; batch classifier loss: 0.454341; batch adversarial loss: 0.453534\n",
      "epoch 43; iter: 0; batch classifier loss: 0.453067; batch adversarial loss: 0.462190\n",
      "epoch 44; iter: 0; batch classifier loss: 0.478973; batch adversarial loss: 0.411817\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414664; batch adversarial loss: 0.445436\n",
      "epoch 46; iter: 0; batch classifier loss: 0.477536; batch adversarial loss: 0.539402\n",
      "epoch 47; iter: 0; batch classifier loss: 0.479496; batch adversarial loss: 0.509301\n",
      "epoch 48; iter: 0; batch classifier loss: 0.551616; batch adversarial loss: 0.435209\n",
      "epoch 49; iter: 0; batch classifier loss: 0.501652; batch adversarial loss: 0.476809\n",
      "epoch 50; iter: 0; batch classifier loss: 0.559342; batch adversarial loss: 0.509195\n",
      "epoch 51; iter: 0; batch classifier loss: 0.479867; batch adversarial loss: 0.484577\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445798; batch adversarial loss: 0.427588\n",
      "epoch 53; iter: 0; batch classifier loss: 0.448068; batch adversarial loss: 0.427315\n",
      "epoch 54; iter: 0; batch classifier loss: 0.495512; batch adversarial loss: 0.446688\n",
      "epoch 55; iter: 0; batch classifier loss: 0.490710; batch adversarial loss: 0.366915\n",
      "epoch 56; iter: 0; batch classifier loss: 0.404280; batch adversarial loss: 0.523227\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401140; batch adversarial loss: 0.498181\n",
      "epoch 58; iter: 0; batch classifier loss: 0.444680; batch adversarial loss: 0.452847\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408914; batch adversarial loss: 0.465326\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434004; batch adversarial loss: 0.596340\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403529; batch adversarial loss: 0.538012\n",
      "epoch 62; iter: 0; batch classifier loss: 0.437653; batch adversarial loss: 0.470404\n",
      "epoch 63; iter: 0; batch classifier loss: 0.427176; batch adversarial loss: 0.449746\n",
      "epoch 64; iter: 0; batch classifier loss: 0.373304; batch adversarial loss: 0.439604\n",
      "epoch 65; iter: 0; batch classifier loss: 0.362362; batch adversarial loss: 0.504589\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414455; batch adversarial loss: 0.449512\n",
      "epoch 67; iter: 0; batch classifier loss: 0.402249; batch adversarial loss: 0.456770\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394222; batch adversarial loss: 0.433080\n",
      "epoch 69; iter: 0; batch classifier loss: 0.429862; batch adversarial loss: 0.453383\n",
      "epoch 70; iter: 0; batch classifier loss: 0.462923; batch adversarial loss: 0.470007\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405480; batch adversarial loss: 0.424535\n",
      "epoch 72; iter: 0; batch classifier loss: 0.455634; batch adversarial loss: 0.529766\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419299; batch adversarial loss: 0.529443\n",
      "epoch 74; iter: 0; batch classifier loss: 0.464841; batch adversarial loss: 0.445035\n",
      "epoch 75; iter: 0; batch classifier loss: 0.473543; batch adversarial loss: 0.482138\n",
      "epoch 76; iter: 0; batch classifier loss: 0.437499; batch adversarial loss: 0.528285\n",
      "epoch 77; iter: 0; batch classifier loss: 0.398199; batch adversarial loss: 0.441294\n",
      "epoch 78; iter: 0; batch classifier loss: 0.366161; batch adversarial loss: 0.526570\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387430; batch adversarial loss: 0.415032\n",
      "epoch 80; iter: 0; batch classifier loss: 0.433900; batch adversarial loss: 0.452444\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408577; batch adversarial loss: 0.484698\n",
      "epoch 82; iter: 0; batch classifier loss: 0.363676; batch adversarial loss: 0.435390\n",
      "epoch 83; iter: 0; batch classifier loss: 0.406516; batch adversarial loss: 0.446204\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365772; batch adversarial loss: 0.461806\n",
      "epoch 85; iter: 0; batch classifier loss: 0.336924; batch adversarial loss: 0.484299\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416602; batch adversarial loss: 0.468119\n",
      "epoch 87; iter: 0; batch classifier loss: 0.357907; batch adversarial loss: 0.521734\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415624; batch adversarial loss: 0.418533\n",
      "epoch 89; iter: 0; batch classifier loss: 0.367521; batch adversarial loss: 0.453433\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394426; batch adversarial loss: 0.453030\n",
      "epoch 91; iter: 0; batch classifier loss: 0.377308; batch adversarial loss: 0.494761\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399632; batch adversarial loss: 0.604278\n",
      "epoch 93; iter: 0; batch classifier loss: 0.431765; batch adversarial loss: 0.613202\n",
      "epoch 94; iter: 0; batch classifier loss: 0.310356; batch adversarial loss: 0.495386\n",
      "epoch 95; iter: 0; batch classifier loss: 0.287526; batch adversarial loss: 0.484022\n",
      "epoch 96; iter: 0; batch classifier loss: 0.341455; batch adversarial loss: 0.514220\n",
      "epoch 97; iter: 0; batch classifier loss: 0.433841; batch adversarial loss: 0.359443\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378431; batch adversarial loss: 0.482759\n",
      "epoch 99; iter: 0; batch classifier loss: 0.441091; batch adversarial loss: 0.504936\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.056169; batch adversarial loss: 0.853964\n",
      "epoch 2; iter: 0; batch classifier loss: 0.912442; batch adversarial loss: 0.825485\n",
      "epoch 3; iter: 0; batch classifier loss: 0.839930; batch adversarial loss: 0.736746\n",
      "epoch 4; iter: 0; batch classifier loss: 0.675452; batch adversarial loss: 0.723395\n",
      "epoch 5; iter: 0; batch classifier loss: 0.516848; batch adversarial loss: 0.681062\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509939; batch adversarial loss: 0.664440\n",
      "epoch 7; iter: 0; batch classifier loss: 0.488224; batch adversarial loss: 0.631932\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562699; batch adversarial loss: 0.615999\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501474; batch adversarial loss: 0.596197\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568540; batch adversarial loss: 0.591327\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552961; batch adversarial loss: 0.595572\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564323; batch adversarial loss: 0.578469\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535743; batch adversarial loss: 0.549788\n",
      "epoch 14; iter: 0; batch classifier loss: 0.484150; batch adversarial loss: 0.549015\n",
      "epoch 15; iter: 0; batch classifier loss: 0.592194; batch adversarial loss: 0.575976\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554241; batch adversarial loss: 0.517804\n",
      "epoch 17; iter: 0; batch classifier loss: 0.543332; batch adversarial loss: 0.531261\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522368; batch adversarial loss: 0.522476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19; iter: 0; batch classifier loss: 0.525639; batch adversarial loss: 0.539889\n",
      "epoch 20; iter: 0; batch classifier loss: 0.564933; batch adversarial loss: 0.459362\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487356; batch adversarial loss: 0.496403\n",
      "epoch 22; iter: 0; batch classifier loss: 0.514332; batch adversarial loss: 0.509318\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477866; batch adversarial loss: 0.516612\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483617; batch adversarial loss: 0.478606\n",
      "epoch 25; iter: 0; batch classifier loss: 0.626495; batch adversarial loss: 0.562478\n",
      "epoch 26; iter: 0; batch classifier loss: 0.568383; batch adversarial loss: 0.523803\n",
      "epoch 27; iter: 0; batch classifier loss: 0.627158; batch adversarial loss: 0.667197\n",
      "epoch 28; iter: 0; batch classifier loss: 0.563399; batch adversarial loss: 0.530801\n",
      "epoch 29; iter: 0; batch classifier loss: 0.665725; batch adversarial loss: 0.561619\n",
      "epoch 30; iter: 0; batch classifier loss: 0.588081; batch adversarial loss: 0.574790\n",
      "epoch 31; iter: 0; batch classifier loss: 0.593956; batch adversarial loss: 0.512413\n",
      "epoch 32; iter: 0; batch classifier loss: 0.613907; batch adversarial loss: 0.534120\n",
      "epoch 33; iter: 0; batch classifier loss: 0.613109; batch adversarial loss: 0.551673\n",
      "epoch 34; iter: 0; batch classifier loss: 0.600129; batch adversarial loss: 0.567232\n",
      "epoch 35; iter: 0; batch classifier loss: 0.521775; batch adversarial loss: 0.495011\n",
      "epoch 36; iter: 0; batch classifier loss: 0.518572; batch adversarial loss: 0.466404\n",
      "epoch 37; iter: 0; batch classifier loss: 0.576591; batch adversarial loss: 0.540096\n",
      "epoch 38; iter: 0; batch classifier loss: 0.536128; batch adversarial loss: 0.420497\n",
      "epoch 39; iter: 0; batch classifier loss: 0.546207; batch adversarial loss: 0.465130\n",
      "epoch 40; iter: 0; batch classifier loss: 0.536326; batch adversarial loss: 0.449299\n",
      "epoch 41; iter: 0; batch classifier loss: 0.557502; batch adversarial loss: 0.532587\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451136; batch adversarial loss: 0.452966\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459270; batch adversarial loss: 0.462228\n",
      "epoch 44; iter: 0; batch classifier loss: 0.478530; batch adversarial loss: 0.411975\n",
      "epoch 45; iter: 0; batch classifier loss: 0.415830; batch adversarial loss: 0.445920\n",
      "epoch 46; iter: 0; batch classifier loss: 0.480734; batch adversarial loss: 0.540042\n",
      "epoch 47; iter: 0; batch classifier loss: 0.481040; batch adversarial loss: 0.509832\n",
      "epoch 48; iter: 0; batch classifier loss: 0.554112; batch adversarial loss: 0.435498\n",
      "epoch 49; iter: 0; batch classifier loss: 0.517638; batch adversarial loss: 0.476296\n",
      "epoch 50; iter: 0; batch classifier loss: 0.554486; batch adversarial loss: 0.507827\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462980; batch adversarial loss: 0.483964\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442330; batch adversarial loss: 0.427334\n",
      "epoch 53; iter: 0; batch classifier loss: 0.456404; batch adversarial loss: 0.427161\n",
      "epoch 54; iter: 0; batch classifier loss: 0.501305; batch adversarial loss: 0.446476\n",
      "epoch 55; iter: 0; batch classifier loss: 0.481364; batch adversarial loss: 0.366531\n",
      "epoch 56; iter: 0; batch classifier loss: 0.413782; batch adversarial loss: 0.523277\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399209; batch adversarial loss: 0.498003\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448224; batch adversarial loss: 0.452702\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407301; batch adversarial loss: 0.465302\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427809; batch adversarial loss: 0.596065\n",
      "epoch 61; iter: 0; batch classifier loss: 0.407494; batch adversarial loss: 0.538069\n",
      "epoch 62; iter: 0; batch classifier loss: 0.435457; batch adversarial loss: 0.470778\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432854; batch adversarial loss: 0.449149\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375963; batch adversarial loss: 0.439451\n",
      "epoch 65; iter: 0; batch classifier loss: 0.366826; batch adversarial loss: 0.504265\n",
      "epoch 66; iter: 0; batch classifier loss: 0.417629; batch adversarial loss: 0.449660\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408762; batch adversarial loss: 0.457095\n",
      "epoch 68; iter: 0; batch classifier loss: 0.388793; batch adversarial loss: 0.432667\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420690; batch adversarial loss: 0.452994\n",
      "epoch 70; iter: 0; batch classifier loss: 0.461140; batch adversarial loss: 0.469327\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411198; batch adversarial loss: 0.424854\n",
      "epoch 72; iter: 0; batch classifier loss: 0.471997; batch adversarial loss: 0.530534\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425475; batch adversarial loss: 0.528909\n",
      "epoch 74; iter: 0; batch classifier loss: 0.465967; batch adversarial loss: 0.444440\n",
      "epoch 75; iter: 0; batch classifier loss: 0.481096; batch adversarial loss: 0.481569\n",
      "epoch 76; iter: 0; batch classifier loss: 0.444575; batch adversarial loss: 0.527808\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389723; batch adversarial loss: 0.440439\n",
      "epoch 78; iter: 0; batch classifier loss: 0.364486; batch adversarial loss: 0.526152\n",
      "epoch 79; iter: 0; batch classifier loss: 0.391672; batch adversarial loss: 0.414788\n",
      "epoch 80; iter: 0; batch classifier loss: 0.432976; batch adversarial loss: 0.452138\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402563; batch adversarial loss: 0.484173\n",
      "epoch 82; iter: 0; batch classifier loss: 0.364697; batch adversarial loss: 0.435623\n",
      "epoch 83; iter: 0; batch classifier loss: 0.407261; batch adversarial loss: 0.446613\n",
      "epoch 84; iter: 0; batch classifier loss: 0.363092; batch adversarial loss: 0.461824\n",
      "epoch 85; iter: 0; batch classifier loss: 0.346098; batch adversarial loss: 0.484357\n",
      "epoch 86; iter: 0; batch classifier loss: 0.433707; batch adversarial loss: 0.468686\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366818; batch adversarial loss: 0.521450\n",
      "epoch 88; iter: 0; batch classifier loss: 0.418721; batch adversarial loss: 0.419069\n",
      "epoch 89; iter: 0; batch classifier loss: 0.372955; batch adversarial loss: 0.452802\n",
      "epoch 90; iter: 0; batch classifier loss: 0.389632; batch adversarial loss: 0.452999\n",
      "epoch 91; iter: 0; batch classifier loss: 0.379966; batch adversarial loss: 0.494828\n",
      "epoch 92; iter: 0; batch classifier loss: 0.398960; batch adversarial loss: 0.603018\n",
      "epoch 93; iter: 0; batch classifier loss: 0.447580; batch adversarial loss: 0.614739\n",
      "epoch 94; iter: 0; batch classifier loss: 0.304275; batch adversarial loss: 0.494667\n",
      "epoch 95; iter: 0; batch classifier loss: 0.287991; batch adversarial loss: 0.484242\n",
      "epoch 96; iter: 0; batch classifier loss: 0.332107; batch adversarial loss: 0.512973\n",
      "epoch 97; iter: 0; batch classifier loss: 0.434079; batch adversarial loss: 0.359988\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384984; batch adversarial loss: 0.481772\n",
      "epoch 99; iter: 0; batch classifier loss: 0.434966; batch adversarial loss: 0.504022\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.146029; batch adversarial loss: 0.859959\n",
      "epoch 2; iter: 0; batch classifier loss: 1.003760; batch adversarial loss: 0.832403\n",
      "epoch 3; iter: 0; batch classifier loss: 0.964276; batch adversarial loss: 0.743607\n",
      "epoch 4; iter: 0; batch classifier loss: 0.763695; batch adversarial loss: 0.732018\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582088; batch adversarial loss: 0.688285\n",
      "epoch 6; iter: 0; batch classifier loss: 0.516675; batch adversarial loss: 0.666011\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494398; batch adversarial loss: 0.630835\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561517; batch adversarial loss: 0.615219\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501885; batch adversarial loss: 0.594866\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565627; batch adversarial loss: 0.590985\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543829; batch adversarial loss: 0.596169\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557965; batch adversarial loss: 0.577992\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516136; batch adversarial loss: 0.551405\n",
      "epoch 14; iter: 0; batch classifier loss: 0.465644; batch adversarial loss: 0.550549\n",
      "epoch 15; iter: 0; batch classifier loss: 0.574931; batch adversarial loss: 0.579579\n",
      "epoch 16; iter: 0; batch classifier loss: 0.530424; batch adversarial loss: 0.530558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.523522; batch adversarial loss: 0.539845\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526832; batch adversarial loss: 0.529362\n",
      "epoch 19; iter: 0; batch classifier loss: 0.534739; batch adversarial loss: 0.551736\n",
      "epoch 20; iter: 0; batch classifier loss: 0.595195; batch adversarial loss: 0.476427\n",
      "epoch 21; iter: 0; batch classifier loss: 0.550225; batch adversarial loss: 0.524900\n",
      "epoch 22; iter: 0; batch classifier loss: 0.593330; batch adversarial loss: 0.537597\n",
      "epoch 23; iter: 0; batch classifier loss: 0.550647; batch adversarial loss: 0.551163\n",
      "epoch 24; iter: 0; batch classifier loss: 0.562346; batch adversarial loss: 0.508272\n",
      "epoch 25; iter: 0; batch classifier loss: 0.779948; batch adversarial loss: 0.591635\n",
      "epoch 26; iter: 0; batch classifier loss: 0.659382; batch adversarial loss: 0.533629\n",
      "epoch 27; iter: 0; batch classifier loss: 0.710986; batch adversarial loss: 0.657788\n",
      "epoch 28; iter: 0; batch classifier loss: 0.598502; batch adversarial loss: 0.530626\n",
      "epoch 29; iter: 0; batch classifier loss: 0.663381; batch adversarial loss: 0.544252\n",
      "epoch 30; iter: 0; batch classifier loss: 0.545202; batch adversarial loss: 0.549523\n",
      "epoch 31; iter: 0; batch classifier loss: 0.547055; batch adversarial loss: 0.493905\n",
      "epoch 32; iter: 0; batch classifier loss: 0.535720; batch adversarial loss: 0.513296\n",
      "epoch 33; iter: 0; batch classifier loss: 0.488706; batch adversarial loss: 0.522862\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488823; batch adversarial loss: 0.542284\n",
      "epoch 35; iter: 0; batch classifier loss: 0.482259; batch adversarial loss: 0.483076\n",
      "epoch 36; iter: 0; batch classifier loss: 0.504405; batch adversarial loss: 0.459177\n",
      "epoch 37; iter: 0; batch classifier loss: 0.529425; batch adversarial loss: 0.531728\n",
      "epoch 38; iter: 0; batch classifier loss: 0.527160; batch adversarial loss: 0.416066\n",
      "epoch 39; iter: 0; batch classifier loss: 0.559142; batch adversarial loss: 0.464999\n",
      "epoch 40; iter: 0; batch classifier loss: 0.572310; batch adversarial loss: 0.450835\n",
      "epoch 41; iter: 0; batch classifier loss: 0.621953; batch adversarial loss: 0.537471\n",
      "epoch 42; iter: 0; batch classifier loss: 0.502936; batch adversarial loss: 0.456510\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483903; batch adversarial loss: 0.463296\n",
      "epoch 44; iter: 0; batch classifier loss: 0.505161; batch adversarial loss: 0.412486\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432524; batch adversarial loss: 0.447617\n",
      "epoch 46; iter: 0; batch classifier loss: 0.508256; batch adversarial loss: 0.536543\n",
      "epoch 47; iter: 0; batch classifier loss: 0.521603; batch adversarial loss: 0.505968\n",
      "epoch 48; iter: 0; batch classifier loss: 0.548738; batch adversarial loss: 0.433501\n",
      "epoch 49; iter: 0; batch classifier loss: 0.431204; batch adversarial loss: 0.471692\n",
      "epoch 50; iter: 0; batch classifier loss: 0.469122; batch adversarial loss: 0.504670\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470427; batch adversarial loss: 0.483208\n",
      "epoch 52; iter: 0; batch classifier loss: 0.444924; batch adversarial loss: 0.426163\n",
      "epoch 53; iter: 0; batch classifier loss: 0.472610; batch adversarial loss: 0.426438\n",
      "epoch 54; iter: 0; batch classifier loss: 0.504128; batch adversarial loss: 0.446490\n",
      "epoch 55; iter: 0; batch classifier loss: 0.484949; batch adversarial loss: 0.365702\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417224; batch adversarial loss: 0.523520\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400044; batch adversarial loss: 0.498693\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452085; batch adversarial loss: 0.453186\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414762; batch adversarial loss: 0.465672\n",
      "epoch 60; iter: 0; batch classifier loss: 0.440142; batch adversarial loss: 0.596955\n",
      "epoch 61; iter: 0; batch classifier loss: 0.421354; batch adversarial loss: 0.539349\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438819; batch adversarial loss: 0.470775\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426877; batch adversarial loss: 0.450017\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375917; batch adversarial loss: 0.439870\n",
      "epoch 65; iter: 0; batch classifier loss: 0.381737; batch adversarial loss: 0.503566\n",
      "epoch 66; iter: 0; batch classifier loss: 0.431487; batch adversarial loss: 0.450510\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403877; batch adversarial loss: 0.456685\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401891; batch adversarial loss: 0.433351\n",
      "epoch 69; iter: 0; batch classifier loss: 0.448429; batch adversarial loss: 0.453885\n",
      "epoch 70; iter: 0; batch classifier loss: 0.467696; batch adversarial loss: 0.469608\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407442; batch adversarial loss: 0.425434\n",
      "epoch 72; iter: 0; batch classifier loss: 0.482896; batch adversarial loss: 0.530824\n",
      "epoch 73; iter: 0; batch classifier loss: 0.434394; batch adversarial loss: 0.527809\n",
      "epoch 74; iter: 0; batch classifier loss: 0.471810; batch adversarial loss: 0.444520\n",
      "epoch 75; iter: 0; batch classifier loss: 0.505820; batch adversarial loss: 0.482072\n",
      "epoch 76; iter: 0; batch classifier loss: 0.459715; batch adversarial loss: 0.528023\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407456; batch adversarial loss: 0.440059\n",
      "epoch 78; iter: 0; batch classifier loss: 0.369597; batch adversarial loss: 0.526631\n",
      "epoch 79; iter: 0; batch classifier loss: 0.406559; batch adversarial loss: 0.414310\n",
      "epoch 80; iter: 0; batch classifier loss: 0.438408; batch adversarial loss: 0.452659\n",
      "epoch 81; iter: 0; batch classifier loss: 0.403322; batch adversarial loss: 0.485436\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390384; batch adversarial loss: 0.436465\n",
      "epoch 83; iter: 0; batch classifier loss: 0.407334; batch adversarial loss: 0.446859\n",
      "epoch 84; iter: 0; batch classifier loss: 0.377001; batch adversarial loss: 0.462152\n",
      "epoch 85; iter: 0; batch classifier loss: 0.342352; batch adversarial loss: 0.480982\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420185; batch adversarial loss: 0.469188\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371855; batch adversarial loss: 0.522854\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421218; batch adversarial loss: 0.420488\n",
      "epoch 89; iter: 0; batch classifier loss: 0.408925; batch adversarial loss: 0.453268\n",
      "epoch 90; iter: 0; batch classifier loss: 0.398341; batch adversarial loss: 0.453353\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391523; batch adversarial loss: 0.494521\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404119; batch adversarial loss: 0.605202\n",
      "epoch 93; iter: 0; batch classifier loss: 0.465613; batch adversarial loss: 0.614202\n",
      "epoch 94; iter: 0; batch classifier loss: 0.298292; batch adversarial loss: 0.497269\n",
      "epoch 95; iter: 0; batch classifier loss: 0.276698; batch adversarial loss: 0.484561\n",
      "epoch 96; iter: 0; batch classifier loss: 0.336494; batch adversarial loss: 0.516530\n",
      "epoch 97; iter: 0; batch classifier loss: 0.467815; batch adversarial loss: 0.361173\n",
      "epoch 98; iter: 0; batch classifier loss: 0.364028; batch adversarial loss: 0.481997\n",
      "epoch 99; iter: 0; batch classifier loss: 0.464860; batch adversarial loss: 0.507182\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.160716; batch adversarial loss: 0.860731\n",
      "epoch 2; iter: 0; batch classifier loss: 1.017910; batch adversarial loss: 0.833268\n",
      "epoch 3; iter: 0; batch classifier loss: 0.982521; batch adversarial loss: 0.744407\n",
      "epoch 4; iter: 0; batch classifier loss: 0.779667; batch adversarial loss: 0.733387\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595788; batch adversarial loss: 0.689293\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519399; batch adversarial loss: 0.666602\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495962; batch adversarial loss: 0.630608\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561672; batch adversarial loss: 0.615065\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502406; batch adversarial loss: 0.594488\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565170; batch adversarial loss: 0.590769\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543214; batch adversarial loss: 0.596074\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556603; batch adversarial loss: 0.577974\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514733; batch adversarial loss: 0.551507\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464246; batch adversarial loss: 0.550966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.572895; batch adversarial loss: 0.580531\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528483; batch adversarial loss: 0.532360\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521088; batch adversarial loss: 0.540910\n",
      "epoch 18; iter: 0; batch classifier loss: 0.528923; batch adversarial loss: 0.530693\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543278; batch adversarial loss: 0.556936\n",
      "epoch 20; iter: 0; batch classifier loss: 0.605997; batch adversarial loss: 0.481434\n",
      "epoch 21; iter: 0; batch classifier loss: 0.566562; batch adversarial loss: 0.529497\n",
      "epoch 22; iter: 0; batch classifier loss: 0.611769; batch adversarial loss: 0.543327\n",
      "epoch 23; iter: 0; batch classifier loss: 0.583873; batch adversarial loss: 0.558826\n",
      "epoch 24; iter: 0; batch classifier loss: 0.578574; batch adversarial loss: 0.511913\n",
      "epoch 25; iter: 0; batch classifier loss: 0.790846; batch adversarial loss: 0.588892\n",
      "epoch 26; iter: 0; batch classifier loss: 0.654303; batch adversarial loss: 0.530019\n",
      "epoch 27; iter: 0; batch classifier loss: 0.695945; batch adversarial loss: 0.651198\n",
      "epoch 28; iter: 0; batch classifier loss: 0.596588; batch adversarial loss: 0.529053\n",
      "epoch 29; iter: 0; batch classifier loss: 0.649131; batch adversarial loss: 0.540835\n",
      "epoch 30; iter: 0; batch classifier loss: 0.540479; batch adversarial loss: 0.546882\n",
      "epoch 31; iter: 0; batch classifier loss: 0.538589; batch adversarial loss: 0.491943\n",
      "epoch 32; iter: 0; batch classifier loss: 0.530764; batch adversarial loss: 0.512044\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481675; batch adversarial loss: 0.520398\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482467; batch adversarial loss: 0.540399\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483257; batch adversarial loss: 0.482106\n",
      "epoch 36; iter: 0; batch classifier loss: 0.504396; batch adversarial loss: 0.458796\n",
      "epoch 37; iter: 0; batch classifier loss: 0.537456; batch adversarial loss: 0.532230\n",
      "epoch 38; iter: 0; batch classifier loss: 0.534302; batch adversarial loss: 0.417016\n",
      "epoch 39; iter: 0; batch classifier loss: 0.575905; batch adversarial loss: 0.466037\n",
      "epoch 40; iter: 0; batch classifier loss: 0.578303; batch adversarial loss: 0.451165\n",
      "epoch 41; iter: 0; batch classifier loss: 0.634820; batch adversarial loss: 0.536925\n",
      "epoch 42; iter: 0; batch classifier loss: 0.506057; batch adversarial loss: 0.456031\n",
      "epoch 43; iter: 0; batch classifier loss: 0.476102; batch adversarial loss: 0.462223\n",
      "epoch 44; iter: 0; batch classifier loss: 0.502052; batch adversarial loss: 0.411801\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427314; batch adversarial loss: 0.447104\n",
      "epoch 46; iter: 0; batch classifier loss: 0.502302; batch adversarial loss: 0.536243\n",
      "epoch 47; iter: 0; batch classifier loss: 0.521334; batch adversarial loss: 0.505961\n",
      "epoch 48; iter: 0; batch classifier loss: 0.564232; batch adversarial loss: 0.433378\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429574; batch adversarial loss: 0.471603\n",
      "epoch 50; iter: 0; batch classifier loss: 0.468410; batch adversarial loss: 0.504549\n",
      "epoch 51; iter: 0; batch classifier loss: 0.476829; batch adversarial loss: 0.483137\n",
      "epoch 52; iter: 0; batch classifier loss: 0.452996; batch adversarial loss: 0.426185\n",
      "epoch 53; iter: 0; batch classifier loss: 0.472874; batch adversarial loss: 0.426279\n",
      "epoch 54; iter: 0; batch classifier loss: 0.516443; batch adversarial loss: 0.446677\n",
      "epoch 55; iter: 0; batch classifier loss: 0.485384; batch adversarial loss: 0.365454\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417322; batch adversarial loss: 0.523679\n",
      "epoch 57; iter: 0; batch classifier loss: 0.397717; batch adversarial loss: 0.498821\n",
      "epoch 58; iter: 0; batch classifier loss: 0.455426; batch adversarial loss: 0.453013\n",
      "epoch 59; iter: 0; batch classifier loss: 0.411821; batch adversarial loss: 0.465651\n",
      "epoch 60; iter: 0; batch classifier loss: 0.449524; batch adversarial loss: 0.597136\n",
      "epoch 61; iter: 0; batch classifier loss: 0.426875; batch adversarial loss: 0.539431\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434554; batch adversarial loss: 0.470736\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431386; batch adversarial loss: 0.449992\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376605; batch adversarial loss: 0.439961\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386157; batch adversarial loss: 0.503506\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432346; batch adversarial loss: 0.450316\n",
      "epoch 67; iter: 0; batch classifier loss: 0.415921; batch adversarial loss: 0.456261\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406252; batch adversarial loss: 0.432684\n",
      "epoch 69; iter: 0; batch classifier loss: 0.445352; batch adversarial loss: 0.453878\n",
      "epoch 70; iter: 0; batch classifier loss: 0.463402; batch adversarial loss: 0.469602\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404352; batch adversarial loss: 0.425566\n",
      "epoch 72; iter: 0; batch classifier loss: 0.473635; batch adversarial loss: 0.529998\n",
      "epoch 73; iter: 0; batch classifier loss: 0.448921; batch adversarial loss: 0.527738\n",
      "epoch 74; iter: 0; batch classifier loss: 0.472346; batch adversarial loss: 0.444336\n",
      "epoch 75; iter: 0; batch classifier loss: 0.498295; batch adversarial loss: 0.482392\n",
      "epoch 76; iter: 0; batch classifier loss: 0.471838; batch adversarial loss: 0.528144\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400360; batch adversarial loss: 0.440300\n",
      "epoch 78; iter: 0; batch classifier loss: 0.361868; batch adversarial loss: 0.525979\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404185; batch adversarial loss: 0.413324\n",
      "epoch 80; iter: 0; batch classifier loss: 0.438017; batch adversarial loss: 0.452455\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393428; batch adversarial loss: 0.485227\n",
      "epoch 82; iter: 0; batch classifier loss: 0.389103; batch adversarial loss: 0.436655\n",
      "epoch 83; iter: 0; batch classifier loss: 0.415073; batch adversarial loss: 0.447161\n",
      "epoch 84; iter: 0; batch classifier loss: 0.375017; batch adversarial loss: 0.462182\n",
      "epoch 85; iter: 0; batch classifier loss: 0.340386; batch adversarial loss: 0.482094\n",
      "epoch 86; iter: 0; batch classifier loss: 0.419040; batch adversarial loss: 0.469056\n",
      "epoch 87; iter: 0; batch classifier loss: 0.361787; batch adversarial loss: 0.522332\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423596; batch adversarial loss: 0.419135\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407151; batch adversarial loss: 0.452620\n",
      "epoch 90; iter: 0; batch classifier loss: 0.392840; batch adversarial loss: 0.453348\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386818; batch adversarial loss: 0.494767\n",
      "epoch 92; iter: 0; batch classifier loss: 0.408465; batch adversarial loss: 0.604998\n",
      "epoch 93; iter: 0; batch classifier loss: 0.458680; batch adversarial loss: 0.613246\n",
      "epoch 94; iter: 0; batch classifier loss: 0.291078; batch adversarial loss: 0.497052\n",
      "epoch 95; iter: 0; batch classifier loss: 0.277846; batch adversarial loss: 0.484336\n",
      "epoch 96; iter: 0; batch classifier loss: 0.333404; batch adversarial loss: 0.515961\n",
      "epoch 97; iter: 0; batch classifier loss: 0.468648; batch adversarial loss: 0.361272\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376877; batch adversarial loss: 0.482297\n",
      "epoch 99; iter: 0; batch classifier loss: 0.471501; batch adversarial loss: 0.506439\n",
      "epoch 100; iter: 0; batch classifier loss: 0.367453; batch adversarial loss: 0.488937\n",
      "epoch 101; iter: 0; batch classifier loss: 0.415871; batch adversarial loss: 0.493967\n",
      "epoch 102; iter: 0; batch classifier loss: 0.385266; batch adversarial loss: 0.487115\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358523; batch adversarial loss: 0.443860\n",
      "epoch 104; iter: 0; batch classifier loss: 0.418026; batch adversarial loss: 0.424873\n",
      "epoch 105; iter: 0; batch classifier loss: 0.311906; batch adversarial loss: 0.498468\n",
      "epoch 106; iter: 0; batch classifier loss: 0.395643; batch adversarial loss: 0.488952\n",
      "epoch 107; iter: 0; batch classifier loss: 0.345003; batch adversarial loss: 0.578878\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370629; batch adversarial loss: 0.541693\n",
      "epoch 109; iter: 0; batch classifier loss: 0.323028; batch adversarial loss: 0.456262\n",
      "epoch 110; iter: 0; batch classifier loss: 0.344134; batch adversarial loss: 0.594014\n",
      "epoch 111; iter: 0; batch classifier loss: 0.341879; batch adversarial loss: 0.552343\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378273; batch adversarial loss: 0.480929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.324434; batch adversarial loss: 0.481953\n",
      "epoch 114; iter: 0; batch classifier loss: 0.356642; batch adversarial loss: 0.523733\n",
      "epoch 115; iter: 0; batch classifier loss: 0.432464; batch adversarial loss: 0.413229\n",
      "epoch 116; iter: 0; batch classifier loss: 0.357788; batch adversarial loss: 0.453597\n",
      "epoch 117; iter: 0; batch classifier loss: 0.406060; batch adversarial loss: 0.481729\n",
      "epoch 118; iter: 0; batch classifier loss: 0.337139; batch adversarial loss: 0.438219\n",
      "epoch 119; iter: 0; batch classifier loss: 0.345403; batch adversarial loss: 0.528008\n",
      "epoch 120; iter: 0; batch classifier loss: 0.338960; batch adversarial loss: 0.455361\n",
      "epoch 121; iter: 0; batch classifier loss: 0.400315; batch adversarial loss: 0.517310\n",
      "epoch 122; iter: 0; batch classifier loss: 0.383895; batch adversarial loss: 0.491836\n",
      "epoch 123; iter: 0; batch classifier loss: 0.398439; batch adversarial loss: 0.467826\n",
      "epoch 124; iter: 0; batch classifier loss: 0.339245; batch adversarial loss: 0.481481\n",
      "epoch 125; iter: 0; batch classifier loss: 0.384095; batch adversarial loss: 0.464172\n",
      "epoch 126; iter: 0; batch classifier loss: 0.447414; batch adversarial loss: 0.439500\n",
      "epoch 127; iter: 0; batch classifier loss: 0.366012; batch adversarial loss: 0.443988\n",
      "epoch 128; iter: 0; batch classifier loss: 0.294954; batch adversarial loss: 0.536426\n",
      "epoch 129; iter: 0; batch classifier loss: 0.431868; batch adversarial loss: 0.435605\n",
      "epoch 130; iter: 0; batch classifier loss: 0.386311; batch adversarial loss: 0.455716\n",
      "epoch 131; iter: 0; batch classifier loss: 0.359955; batch adversarial loss: 0.443309\n",
      "epoch 132; iter: 0; batch classifier loss: 0.364807; batch adversarial loss: 0.455915\n",
      "epoch 133; iter: 0; batch classifier loss: 0.338595; batch adversarial loss: 0.452825\n",
      "epoch 134; iter: 0; batch classifier loss: 0.361568; batch adversarial loss: 0.560486\n",
      "epoch 135; iter: 0; batch classifier loss: 0.408411; batch adversarial loss: 0.421715\n",
      "epoch 136; iter: 0; batch classifier loss: 0.322217; batch adversarial loss: 0.502776\n",
      "epoch 137; iter: 0; batch classifier loss: 0.506464; batch adversarial loss: 0.421863\n",
      "epoch 138; iter: 0; batch classifier loss: 0.319041; batch adversarial loss: 0.498421\n",
      "epoch 139; iter: 0; batch classifier loss: 0.354084; batch adversarial loss: 0.496848\n",
      "epoch 140; iter: 0; batch classifier loss: 0.477441; batch adversarial loss: 0.458397\n",
      "epoch 141; iter: 0; batch classifier loss: 0.347895; batch adversarial loss: 0.474477\n",
      "epoch 142; iter: 0; batch classifier loss: 0.420621; batch adversarial loss: 0.506002\n",
      "epoch 143; iter: 0; batch classifier loss: 0.439912; batch adversarial loss: 0.399829\n",
      "epoch 144; iter: 0; batch classifier loss: 0.427246; batch adversarial loss: 0.458689\n",
      "epoch 145; iter: 0; batch classifier loss: 0.397349; batch adversarial loss: 0.481485\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373092; batch adversarial loss: 0.489528\n",
      "epoch 147; iter: 0; batch classifier loss: 0.407607; batch adversarial loss: 0.459375\n",
      "epoch 148; iter: 0; batch classifier loss: 0.326714; batch adversarial loss: 0.453175\n",
      "epoch 149; iter: 0; batch classifier loss: 0.365238; batch adversarial loss: 0.425661\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350544; batch adversarial loss: 0.406880\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356621; batch adversarial loss: 0.435761\n",
      "epoch 152; iter: 0; batch classifier loss: 0.400287; batch adversarial loss: 0.466547\n",
      "epoch 153; iter: 0; batch classifier loss: 0.350869; batch adversarial loss: 0.514729\n",
      "epoch 154; iter: 0; batch classifier loss: 0.261016; batch adversarial loss: 0.536386\n",
      "epoch 155; iter: 0; batch classifier loss: 0.281577; batch adversarial loss: 0.496837\n",
      "epoch 156; iter: 0; batch classifier loss: 0.309824; batch adversarial loss: 0.436956\n",
      "epoch 157; iter: 0; batch classifier loss: 0.425550; batch adversarial loss: 0.464802\n",
      "epoch 158; iter: 0; batch classifier loss: 0.355260; batch adversarial loss: 0.486745\n",
      "epoch 159; iter: 0; batch classifier loss: 0.325676; batch adversarial loss: 0.440266\n",
      "epoch 160; iter: 0; batch classifier loss: 0.457702; batch adversarial loss: 0.466015\n",
      "epoch 161; iter: 0; batch classifier loss: 0.333238; batch adversarial loss: 0.497732\n",
      "epoch 162; iter: 0; batch classifier loss: 0.389984; batch adversarial loss: 0.488368\n",
      "epoch 163; iter: 0; batch classifier loss: 0.295071; batch adversarial loss: 0.497986\n",
      "epoch 164; iter: 0; batch classifier loss: 0.423158; batch adversarial loss: 0.412988\n",
      "epoch 165; iter: 0; batch classifier loss: 0.411782; batch adversarial loss: 0.401437\n",
      "epoch 166; iter: 0; batch classifier loss: 0.408842; batch adversarial loss: 0.437390\n",
      "epoch 167; iter: 0; batch classifier loss: 0.343897; batch adversarial loss: 0.438358\n",
      "epoch 168; iter: 0; batch classifier loss: 0.342055; batch adversarial loss: 0.455198\n",
      "epoch 169; iter: 0; batch classifier loss: 0.353832; batch adversarial loss: 0.493424\n",
      "epoch 170; iter: 0; batch classifier loss: 0.410418; batch adversarial loss: 0.481194\n",
      "epoch 171; iter: 0; batch classifier loss: 0.476369; batch adversarial loss: 0.503243\n",
      "epoch 172; iter: 0; batch classifier loss: 0.488428; batch adversarial loss: 0.446770\n",
      "epoch 173; iter: 0; batch classifier loss: 0.427676; batch adversarial loss: 0.423063\n",
      "epoch 174; iter: 0; batch classifier loss: 0.361692; batch adversarial loss: 0.410574\n",
      "epoch 175; iter: 0; batch classifier loss: 0.316258; batch adversarial loss: 0.455746\n",
      "epoch 176; iter: 0; batch classifier loss: 0.306568; batch adversarial loss: 0.514027\n",
      "epoch 177; iter: 0; batch classifier loss: 0.497087; batch adversarial loss: 0.574926\n",
      "epoch 178; iter: 0; batch classifier loss: 0.382771; batch adversarial loss: 0.521514\n",
      "epoch 179; iter: 0; batch classifier loss: 0.438389; batch adversarial loss: 0.455845\n",
      "epoch 180; iter: 0; batch classifier loss: 0.481988; batch adversarial loss: 0.408186\n",
      "epoch 181; iter: 0; batch classifier loss: 0.347788; batch adversarial loss: 0.540170\n",
      "epoch 182; iter: 0; batch classifier loss: 0.484527; batch adversarial loss: 0.363843\n",
      "epoch 183; iter: 0; batch classifier loss: 0.384082; batch adversarial loss: 0.445610\n",
      "epoch 184; iter: 0; batch classifier loss: 0.414765; batch adversarial loss: 0.509544\n",
      "epoch 185; iter: 0; batch classifier loss: 0.367352; batch adversarial loss: 0.431711\n",
      "epoch 186; iter: 0; batch classifier loss: 0.414214; batch adversarial loss: 0.465257\n",
      "epoch 187; iter: 0; batch classifier loss: 0.332230; batch adversarial loss: 0.485391\n",
      "epoch 188; iter: 0; batch classifier loss: 0.381202; batch adversarial loss: 0.516375\n",
      "epoch 189; iter: 0; batch classifier loss: 0.265147; batch adversarial loss: 0.581423\n",
      "epoch 190; iter: 0; batch classifier loss: 0.376662; batch adversarial loss: 0.443358\n",
      "epoch 191; iter: 0; batch classifier loss: 0.342708; batch adversarial loss: 0.421765\n",
      "epoch 192; iter: 0; batch classifier loss: 0.319720; batch adversarial loss: 0.458213\n",
      "epoch 193; iter: 0; batch classifier loss: 0.403366; batch adversarial loss: 0.514372\n",
      "epoch 194; iter: 0; batch classifier loss: 0.343212; batch adversarial loss: 0.524369\n",
      "epoch 195; iter: 0; batch classifier loss: 0.471166; batch adversarial loss: 0.462022\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372150; batch adversarial loss: 0.427814\n",
      "epoch 197; iter: 0; batch classifier loss: 0.297836; batch adversarial loss: 0.418562\n",
      "epoch 198; iter: 0; batch classifier loss: 0.382880; batch adversarial loss: 0.454457\n",
      "epoch 199; iter: 0; batch classifier loss: 0.380337; batch adversarial loss: 0.641790\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.131054; batch adversarial loss: 0.859049\n",
      "epoch 2; iter: 0; batch classifier loss: 0.987459; batch adversarial loss: 0.831447\n",
      "epoch 3; iter: 0; batch classifier loss: 0.943393; batch adversarial loss: 0.742661\n",
      "epoch 4; iter: 0; batch classifier loss: 0.746778; batch adversarial loss: 0.730698\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567446; batch adversarial loss: 0.687221\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513299; batch adversarial loss: 0.665600\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491813; batch adversarial loss: 0.631185\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560898; batch adversarial loss: 0.615656\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500821; batch adversarial loss: 0.595291\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564799; batch adversarial loss: 0.591251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.545627; batch adversarial loss: 0.596103\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558848; batch adversarial loss: 0.578179\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518034; batch adversarial loss: 0.551477\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466406; batch adversarial loss: 0.550296\n",
      "epoch 15; iter: 0; batch classifier loss: 0.576698; batch adversarial loss: 0.578979\n",
      "epoch 16; iter: 0; batch classifier loss: 0.530567; batch adversarial loss: 0.528970\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525195; batch adversarial loss: 0.538706\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526820; batch adversarial loss: 0.528134\n",
      "epoch 19; iter: 0; batch classifier loss: 0.533206; batch adversarial loss: 0.549525\n",
      "epoch 20; iter: 0; batch classifier loss: 0.586644; batch adversarial loss: 0.472860\n",
      "epoch 21; iter: 0; batch classifier loss: 0.538114; batch adversarial loss: 0.521229\n",
      "epoch 22; iter: 0; batch classifier loss: 0.582134; batch adversarial loss: 0.533595\n",
      "epoch 23; iter: 0; batch classifier loss: 0.532422; batch adversarial loss: 0.546589\n",
      "epoch 24; iter: 0; batch classifier loss: 0.541093; batch adversarial loss: 0.502611\n",
      "epoch 25; iter: 0; batch classifier loss: 0.758376; batch adversarial loss: 0.591205\n",
      "epoch 26; iter: 0; batch classifier loss: 0.656889; batch adversarial loss: 0.535886\n",
      "epoch 27; iter: 0; batch classifier loss: 0.721123; batch adversarial loss: 0.663196\n",
      "epoch 28; iter: 0; batch classifier loss: 0.610895; batch adversarial loss: 0.533497\n",
      "epoch 29; iter: 0; batch classifier loss: 0.675436; batch adversarial loss: 0.547338\n",
      "epoch 30; iter: 0; batch classifier loss: 0.558151; batch adversarial loss: 0.552662\n",
      "epoch 31; iter: 0; batch classifier loss: 0.553317; batch adversarial loss: 0.495125\n",
      "epoch 32; iter: 0; batch classifier loss: 0.545893; batch adversarial loss: 0.515926\n",
      "epoch 33; iter: 0; batch classifier loss: 0.504815; batch adversarial loss: 0.525052\n",
      "epoch 34; iter: 0; batch classifier loss: 0.498397; batch adversarial loss: 0.544577\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484219; batch adversarial loss: 0.483582\n",
      "epoch 36; iter: 0; batch classifier loss: 0.507108; batch adversarial loss: 0.459609\n",
      "epoch 37; iter: 0; batch classifier loss: 0.529960; batch adversarial loss: 0.531734\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523964; batch adversarial loss: 0.415794\n",
      "epoch 39; iter: 0; batch classifier loss: 0.547202; batch adversarial loss: 0.464019\n",
      "epoch 40; iter: 0; batch classifier loss: 0.559954; batch adversarial loss: 0.449938\n",
      "epoch 41; iter: 0; batch classifier loss: 0.611547; batch adversarial loss: 0.537269\n",
      "epoch 42; iter: 0; batch classifier loss: 0.500056; batch adversarial loss: 0.456747\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486015; batch adversarial loss: 0.463979\n",
      "epoch 44; iter: 0; batch classifier loss: 0.509335; batch adversarial loss: 0.413029\n",
      "epoch 45; iter: 0; batch classifier loss: 0.436929; batch adversarial loss: 0.448016\n",
      "epoch 46; iter: 0; batch classifier loss: 0.511554; batch adversarial loss: 0.537355\n",
      "epoch 47; iter: 0; batch classifier loss: 0.523840; batch adversarial loss: 0.506397\n",
      "epoch 48; iter: 0; batch classifier loss: 0.563257; batch adversarial loss: 0.433763\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437660; batch adversarial loss: 0.471888\n",
      "epoch 50; iter: 0; batch classifier loss: 0.467255; batch adversarial loss: 0.504764\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469587; batch adversarial loss: 0.483176\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445499; batch adversarial loss: 0.426209\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466989; batch adversarial loss: 0.426348\n",
      "epoch 54; iter: 0; batch classifier loss: 0.505686; batch adversarial loss: 0.446309\n",
      "epoch 55; iter: 0; batch classifier loss: 0.482475; batch adversarial loss: 0.365797\n",
      "epoch 56; iter: 0; batch classifier loss: 0.418568; batch adversarial loss: 0.523855\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404481; batch adversarial loss: 0.498724\n",
      "epoch 58; iter: 0; batch classifier loss: 0.457900; batch adversarial loss: 0.453277\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408728; batch adversarial loss: 0.465578\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444314; batch adversarial loss: 0.596718\n",
      "epoch 61; iter: 0; batch classifier loss: 0.418897; batch adversarial loss: 0.539038\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439939; batch adversarial loss: 0.471006\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429998; batch adversarial loss: 0.449234\n",
      "epoch 64; iter: 0; batch classifier loss: 0.386058; batch adversarial loss: 0.440112\n",
      "epoch 65; iter: 0; batch classifier loss: 0.383986; batch adversarial loss: 0.503760\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432597; batch adversarial loss: 0.450292\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411313; batch adversarial loss: 0.456114\n",
      "epoch 68; iter: 0; batch classifier loss: 0.409280; batch adversarial loss: 0.432355\n",
      "epoch 69; iter: 0; batch classifier loss: 0.440954; batch adversarial loss: 0.453674\n",
      "epoch 70; iter: 0; batch classifier loss: 0.465197; batch adversarial loss: 0.469284\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411321; batch adversarial loss: 0.425024\n",
      "epoch 72; iter: 0; batch classifier loss: 0.478808; batch adversarial loss: 0.530869\n",
      "epoch 73; iter: 0; batch classifier loss: 0.433066; batch adversarial loss: 0.528645\n",
      "epoch 74; iter: 0; batch classifier loss: 0.468365; batch adversarial loss: 0.445443\n",
      "epoch 75; iter: 0; batch classifier loss: 0.504835; batch adversarial loss: 0.481704\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461455; batch adversarial loss: 0.528470\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406552; batch adversarial loss: 0.441204\n",
      "epoch 78; iter: 0; batch classifier loss: 0.366265; batch adversarial loss: 0.526428\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400558; batch adversarial loss: 0.413843\n",
      "epoch 80; iter: 0; batch classifier loss: 0.429033; batch adversarial loss: 0.452448\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391535; batch adversarial loss: 0.485353\n",
      "epoch 82; iter: 0; batch classifier loss: 0.374091; batch adversarial loss: 0.436633\n",
      "epoch 83; iter: 0; batch classifier loss: 0.410182; batch adversarial loss: 0.447451\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365706; batch adversarial loss: 0.461997\n",
      "epoch 85; iter: 0; batch classifier loss: 0.353595; batch adversarial loss: 0.483452\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424901; batch adversarial loss: 0.469117\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367248; batch adversarial loss: 0.522135\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423662; batch adversarial loss: 0.420770\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394945; batch adversarial loss: 0.454361\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407222; batch adversarial loss: 0.454380\n",
      "epoch 91; iter: 0; batch classifier loss: 0.398932; batch adversarial loss: 0.495976\n",
      "epoch 92; iter: 0; batch classifier loss: 0.412010; batch adversarial loss: 0.604483\n",
      "epoch 93; iter: 0; batch classifier loss: 0.449813; batch adversarial loss: 0.613580\n",
      "epoch 94; iter: 0; batch classifier loss: 0.305334; batch adversarial loss: 0.495615\n",
      "epoch 95; iter: 0; batch classifier loss: 0.279421; batch adversarial loss: 0.485781\n",
      "epoch 96; iter: 0; batch classifier loss: 0.328300; batch adversarial loss: 0.514917\n",
      "epoch 97; iter: 0; batch classifier loss: 0.464926; batch adversarial loss: 0.361072\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385421; batch adversarial loss: 0.482257\n",
      "epoch 99; iter: 0; batch classifier loss: 0.455867; batch adversarial loss: 0.506485\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.172548; batch adversarial loss: 0.861287\n",
      "epoch 2; iter: 0; batch classifier loss: 1.029074; batch adversarial loss: 0.833923\n",
      "epoch 3; iter: 0; batch classifier loss: 0.997386; batch adversarial loss: 0.744838\n",
      "epoch 4; iter: 0; batch classifier loss: 0.790882; batch adversarial loss: 0.734159\n",
      "epoch 5; iter: 0; batch classifier loss: 0.606807; batch adversarial loss: 0.690208\n",
      "epoch 6; iter: 0; batch classifier loss: 0.523580; batch adversarial loss: 0.667031\n",
      "epoch 7; iter: 0; batch classifier loss: 0.497435; batch adversarial loss: 0.630444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.561811; batch adversarial loss: 0.614799\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503647; batch adversarial loss: 0.594023\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565348; batch adversarial loss: 0.590518\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542551; batch adversarial loss: 0.596087\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556274; batch adversarial loss: 0.577781\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514158; batch adversarial loss: 0.551578\n",
      "epoch 14; iter: 0; batch classifier loss: 0.463287; batch adversarial loss: 0.551206\n",
      "epoch 15; iter: 0; batch classifier loss: 0.572988; batch adversarial loss: 0.581318\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526901; batch adversarial loss: 0.533201\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520642; batch adversarial loss: 0.541735\n",
      "epoch 18; iter: 0; batch classifier loss: 0.530771; batch adversarial loss: 0.531641\n",
      "epoch 19; iter: 0; batch classifier loss: 0.548747; batch adversarial loss: 0.559991\n",
      "epoch 20; iter: 0; batch classifier loss: 0.610079; batch adversarial loss: 0.483908\n",
      "epoch 21; iter: 0; batch classifier loss: 0.569439; batch adversarial loss: 0.531456\n",
      "epoch 22; iter: 0; batch classifier loss: 0.617758; batch adversarial loss: 0.545805\n",
      "epoch 23; iter: 0; batch classifier loss: 0.594472; batch adversarial loss: 0.559623\n",
      "epoch 24; iter: 0; batch classifier loss: 0.582475; batch adversarial loss: 0.511551\n",
      "epoch 25; iter: 0; batch classifier loss: 0.786163; batch adversarial loss: 0.586590\n",
      "epoch 26; iter: 0; batch classifier loss: 0.656093; batch adversarial loss: 0.528165\n",
      "epoch 27; iter: 0; batch classifier loss: 0.690967; batch adversarial loss: 0.649092\n",
      "epoch 28; iter: 0; batch classifier loss: 0.593792; batch adversarial loss: 0.527971\n",
      "epoch 29; iter: 0; batch classifier loss: 0.642509; batch adversarial loss: 0.539829\n",
      "epoch 30; iter: 0; batch classifier loss: 0.531429; batch adversarial loss: 0.545514\n",
      "epoch 31; iter: 0; batch classifier loss: 0.535107; batch adversarial loss: 0.490986\n",
      "epoch 32; iter: 0; batch classifier loss: 0.528882; batch adversarial loss: 0.511138\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477177; batch adversarial loss: 0.519567\n",
      "epoch 34; iter: 0; batch classifier loss: 0.478577; batch adversarial loss: 0.540089\n",
      "epoch 35; iter: 0; batch classifier loss: 0.487505; batch adversarial loss: 0.481893\n",
      "epoch 36; iter: 0; batch classifier loss: 0.511101; batch adversarial loss: 0.458978\n",
      "epoch 37; iter: 0; batch classifier loss: 0.547078; batch adversarial loss: 0.533080\n",
      "epoch 38; iter: 0; batch classifier loss: 0.549727; batch adversarial loss: 0.417543\n",
      "epoch 39; iter: 0; batch classifier loss: 0.577598; batch adversarial loss: 0.466583\n",
      "epoch 40; iter: 0; batch classifier loss: 0.587192; batch adversarial loss: 0.451299\n",
      "epoch 41; iter: 0; batch classifier loss: 0.630599; batch adversarial loss: 0.536366\n",
      "epoch 42; iter: 0; batch classifier loss: 0.504389; batch adversarial loss: 0.455448\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474251; batch adversarial loss: 0.461828\n",
      "epoch 44; iter: 0; batch classifier loss: 0.491194; batch adversarial loss: 0.411416\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430025; batch adversarial loss: 0.446857\n",
      "epoch 46; iter: 0; batch classifier loss: 0.493910; batch adversarial loss: 0.536199\n",
      "epoch 47; iter: 0; batch classifier loss: 0.521736; batch adversarial loss: 0.506158\n",
      "epoch 48; iter: 0; batch classifier loss: 0.603854; batch adversarial loss: 0.433631\n",
      "epoch 49; iter: 0; batch classifier loss: 0.441045; batch adversarial loss: 0.471704\n",
      "epoch 50; iter: 0; batch classifier loss: 0.470746; batch adversarial loss: 0.504524\n",
      "epoch 51; iter: 0; batch classifier loss: 0.474543; batch adversarial loss: 0.483247\n",
      "epoch 52; iter: 0; batch classifier loss: 0.456331; batch adversarial loss: 0.426135\n",
      "epoch 53; iter: 0; batch classifier loss: 0.473306; batch adversarial loss: 0.426432\n",
      "epoch 54; iter: 0; batch classifier loss: 0.519687; batch adversarial loss: 0.446664\n",
      "epoch 55; iter: 0; batch classifier loss: 0.478615; batch adversarial loss: 0.365587\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416337; batch adversarial loss: 0.523778\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395890; batch adversarial loss: 0.498774\n",
      "epoch 58; iter: 0; batch classifier loss: 0.460296; batch adversarial loss: 0.453399\n",
      "epoch 59; iter: 0; batch classifier loss: 0.413949; batch adversarial loss: 0.465913\n",
      "epoch 60; iter: 0; batch classifier loss: 0.447210; batch adversarial loss: 0.596617\n",
      "epoch 61; iter: 0; batch classifier loss: 0.419402; batch adversarial loss: 0.539525\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445159; batch adversarial loss: 0.470849\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426508; batch adversarial loss: 0.449457\n",
      "epoch 64; iter: 0; batch classifier loss: 0.388676; batch adversarial loss: 0.440145\n",
      "epoch 65; iter: 0; batch classifier loss: 0.382804; batch adversarial loss: 0.503825\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432695; batch adversarial loss: 0.450459\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408551; batch adversarial loss: 0.456352\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408983; batch adversarial loss: 0.432877\n",
      "epoch 69; iter: 0; batch classifier loss: 0.452400; batch adversarial loss: 0.454175\n",
      "epoch 70; iter: 0; batch classifier loss: 0.478713; batch adversarial loss: 0.469664\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407372; batch adversarial loss: 0.425740\n",
      "epoch 72; iter: 0; batch classifier loss: 0.472328; batch adversarial loss: 0.530120\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441899; batch adversarial loss: 0.527611\n",
      "epoch 74; iter: 0; batch classifier loss: 0.486456; batch adversarial loss: 0.443765\n",
      "epoch 75; iter: 0; batch classifier loss: 0.513114; batch adversarial loss: 0.482378\n",
      "epoch 76; iter: 0; batch classifier loss: 0.476129; batch adversarial loss: 0.527499\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404913; batch adversarial loss: 0.439756\n",
      "epoch 78; iter: 0; batch classifier loss: 0.379243; batch adversarial loss: 0.526641\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403540; batch adversarial loss: 0.412392\n",
      "epoch 80; iter: 0; batch classifier loss: 0.452213; batch adversarial loss: 0.452515\n",
      "epoch 81; iter: 0; batch classifier loss: 0.386358; batch adversarial loss: 0.485502\n",
      "epoch 82; iter: 0; batch classifier loss: 0.401799; batch adversarial loss: 0.436612\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405971; batch adversarial loss: 0.447457\n",
      "epoch 84; iter: 0; batch classifier loss: 0.379449; batch adversarial loss: 0.462237\n",
      "epoch 85; iter: 0; batch classifier loss: 0.341060; batch adversarial loss: 0.482254\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416075; batch adversarial loss: 0.468970\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367464; batch adversarial loss: 0.521226\n",
      "epoch 88; iter: 0; batch classifier loss: 0.428672; batch adversarial loss: 0.418749\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406065; batch adversarial loss: 0.452277\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407104; batch adversarial loss: 0.454650\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385626; batch adversarial loss: 0.495105\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411656; batch adversarial loss: 0.604076\n",
      "epoch 93; iter: 0; batch classifier loss: 0.490800; batch adversarial loss: 0.613277\n",
      "epoch 94; iter: 0; batch classifier loss: 0.316696; batch adversarial loss: 0.496864\n",
      "epoch 95; iter: 0; batch classifier loss: 0.283097; batch adversarial loss: 0.486418\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335122; batch adversarial loss: 0.515599\n",
      "epoch 97; iter: 0; batch classifier loss: 0.458735; batch adversarial loss: 0.361280\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373842; batch adversarial loss: 0.481363\n",
      "epoch 99; iter: 0; batch classifier loss: 0.474980; batch adversarial loss: 0.507085\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.130143; batch adversarial loss: 0.858998\n",
      "epoch 2; iter: 0; batch classifier loss: 0.986391; batch adversarial loss: 0.831385\n",
      "epoch 3; iter: 0; batch classifier loss: 0.941853; batch adversarial loss: 0.742646\n",
      "epoch 4; iter: 0; batch classifier loss: 0.746258; batch adversarial loss: 0.730588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.566662; batch adversarial loss: 0.687199\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513268; batch adversarial loss: 0.665557\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491297; batch adversarial loss: 0.631256\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561010; batch adversarial loss: 0.615650\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501570; batch adversarial loss: 0.595208\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565150; batch adversarial loss: 0.591229\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545729; batch adversarial loss: 0.596125\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558776; batch adversarial loss: 0.578174\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518515; batch adversarial loss: 0.551425\n",
      "epoch 14; iter: 0; batch classifier loss: 0.467174; batch adversarial loss: 0.550082\n",
      "epoch 15; iter: 0; batch classifier loss: 0.576554; batch adversarial loss: 0.578912\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531617; batch adversarial loss: 0.528757\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524747; batch adversarial loss: 0.538722\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526717; batch adversarial loss: 0.528112\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531445; batch adversarial loss: 0.548940\n",
      "epoch 20; iter: 0; batch classifier loss: 0.586452; batch adversarial loss: 0.471996\n",
      "epoch 21; iter: 0; batch classifier loss: 0.535108; batch adversarial loss: 0.520293\n",
      "epoch 22; iter: 0; batch classifier loss: 0.578297; batch adversarial loss: 0.532853\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528600; batch adversarial loss: 0.545078\n",
      "epoch 24; iter: 0; batch classifier loss: 0.537223; batch adversarial loss: 0.501005\n",
      "epoch 25; iter: 0; batch classifier loss: 0.750667; batch adversarial loss: 0.590339\n",
      "epoch 26; iter: 0; batch classifier loss: 0.650078; batch adversarial loss: 0.536617\n",
      "epoch 27; iter: 0; batch classifier loss: 0.720179; batch adversarial loss: 0.664760\n",
      "epoch 28; iter: 0; batch classifier loss: 0.608830; batch adversarial loss: 0.533615\n",
      "epoch 29; iter: 0; batch classifier loss: 0.676939; batch adversarial loss: 0.548137\n",
      "epoch 30; iter: 0; batch classifier loss: 0.562556; batch adversarial loss: 0.553742\n",
      "epoch 31; iter: 0; batch classifier loss: 0.557356; batch adversarial loss: 0.495979\n",
      "epoch 32; iter: 0; batch classifier loss: 0.545928; batch adversarial loss: 0.516188\n",
      "epoch 33; iter: 0; batch classifier loss: 0.506542; batch adversarial loss: 0.525954\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501575; batch adversarial loss: 0.545293\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484942; batch adversarial loss: 0.483941\n",
      "epoch 36; iter: 0; batch classifier loss: 0.504179; batch adversarial loss: 0.460008\n",
      "epoch 37; iter: 0; batch classifier loss: 0.524725; batch adversarial loss: 0.531771\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523676; batch adversarial loss: 0.416021\n",
      "epoch 39; iter: 0; batch classifier loss: 0.546587; batch adversarial loss: 0.463924\n",
      "epoch 40; iter: 0; batch classifier loss: 0.556603; batch adversarial loss: 0.449938\n",
      "epoch 41; iter: 0; batch classifier loss: 0.607321; batch adversarial loss: 0.537154\n",
      "epoch 42; iter: 0; batch classifier loss: 0.494162; batch adversarial loss: 0.456479\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486374; batch adversarial loss: 0.463944\n",
      "epoch 44; iter: 0; batch classifier loss: 0.509452; batch adversarial loss: 0.413041\n",
      "epoch 45; iter: 0; batch classifier loss: 0.431573; batch adversarial loss: 0.448003\n",
      "epoch 46; iter: 0; batch classifier loss: 0.511674; batch adversarial loss: 0.537549\n",
      "epoch 47; iter: 0; batch classifier loss: 0.523656; batch adversarial loss: 0.506550\n",
      "epoch 48; iter: 0; batch classifier loss: 0.565423; batch adversarial loss: 0.433800\n",
      "epoch 49; iter: 0; batch classifier loss: 0.441333; batch adversarial loss: 0.471954\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465702; batch adversarial loss: 0.504653\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468889; batch adversarial loss: 0.483165\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440644; batch adversarial loss: 0.426234\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464825; batch adversarial loss: 0.426327\n",
      "epoch 54; iter: 0; batch classifier loss: 0.506644; batch adversarial loss: 0.446389\n",
      "epoch 55; iter: 0; batch classifier loss: 0.479463; batch adversarial loss: 0.365874\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414870; batch adversarial loss: 0.523619\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399653; batch adversarial loss: 0.498793\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452979; batch adversarial loss: 0.453064\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406997; batch adversarial loss: 0.465580\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443897; batch adversarial loss: 0.596486\n",
      "epoch 61; iter: 0; batch classifier loss: 0.423148; batch adversarial loss: 0.539085\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434198; batch adversarial loss: 0.470925\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429804; batch adversarial loss: 0.449944\n",
      "epoch 64; iter: 0; batch classifier loss: 0.379583; batch adversarial loss: 0.440149\n",
      "epoch 65; iter: 0; batch classifier loss: 0.383779; batch adversarial loss: 0.503731\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427375; batch adversarial loss: 0.450202\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411576; batch adversarial loss: 0.456202\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402658; batch adversarial loss: 0.432404\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444677; batch adversarial loss: 0.454053\n",
      "epoch 70; iter: 0; batch classifier loss: 0.466346; batch adversarial loss: 0.469747\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409510; batch adversarial loss: 0.424934\n",
      "epoch 72; iter: 0; batch classifier loss: 0.476261; batch adversarial loss: 0.530716\n",
      "epoch 73; iter: 0; batch classifier loss: 0.437223; batch adversarial loss: 0.528774\n",
      "epoch 74; iter: 0; batch classifier loss: 0.470614; batch adversarial loss: 0.445905\n",
      "epoch 75; iter: 0; batch classifier loss: 0.493898; batch adversarial loss: 0.481512\n",
      "epoch 76; iter: 0; batch classifier loss: 0.466355; batch adversarial loss: 0.528241\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409106; batch adversarial loss: 0.440995\n",
      "epoch 78; iter: 0; batch classifier loss: 0.370610; batch adversarial loss: 0.526661\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405402; batch adversarial loss: 0.414081\n",
      "epoch 80; iter: 0; batch classifier loss: 0.441666; batch adversarial loss: 0.452858\n",
      "epoch 81; iter: 0; batch classifier loss: 0.390095; batch adversarial loss: 0.485107\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377487; batch adversarial loss: 0.436561\n",
      "epoch 83; iter: 0; batch classifier loss: 0.415597; batch adversarial loss: 0.447269\n",
      "epoch 84; iter: 0; batch classifier loss: 0.373904; batch adversarial loss: 0.462163\n",
      "epoch 85; iter: 0; batch classifier loss: 0.337183; batch adversarial loss: 0.483071\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421719; batch adversarial loss: 0.469155\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373382; batch adversarial loss: 0.522598\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417872; batch adversarial loss: 0.420325\n",
      "epoch 89; iter: 0; batch classifier loss: 0.404317; batch adversarial loss: 0.453202\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387225; batch adversarial loss: 0.453959\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386362; batch adversarial loss: 0.495537\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399936; batch adversarial loss: 0.604775\n",
      "epoch 93; iter: 0; batch classifier loss: 0.453709; batch adversarial loss: 0.614593\n",
      "epoch 94; iter: 0; batch classifier loss: 0.297768; batch adversarial loss: 0.496304\n",
      "epoch 95; iter: 0; batch classifier loss: 0.286071; batch adversarial loss: 0.486033\n",
      "epoch 96; iter: 0; batch classifier loss: 0.330099; batch adversarial loss: 0.514232\n",
      "epoch 97; iter: 0; batch classifier loss: 0.469247; batch adversarial loss: 0.361364\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369643; batch adversarial loss: 0.482417\n",
      "epoch 99; iter: 0; batch classifier loss: 0.465329; batch adversarial loss: 0.505858\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.131405; batch adversarial loss: 0.859071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.987698; batch adversarial loss: 0.831457\n",
      "epoch 3; iter: 0; batch classifier loss: 0.943628; batch adversarial loss: 0.742663\n",
      "epoch 4; iter: 0; batch classifier loss: 0.746996; batch adversarial loss: 0.730734\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567461; batch adversarial loss: 0.687294\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513583; batch adversarial loss: 0.665576\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491673; batch adversarial loss: 0.631175\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560762; batch adversarial loss: 0.615686\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500776; batch adversarial loss: 0.595297\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564852; batch adversarial loss: 0.591230\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545675; batch adversarial loss: 0.596107\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558760; batch adversarial loss: 0.578203\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517951; batch adversarial loss: 0.551496\n",
      "epoch 14; iter: 0; batch classifier loss: 0.467181; batch adversarial loss: 0.550172\n",
      "epoch 15; iter: 0; batch classifier loss: 0.576600; batch adversarial loss: 0.579002\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531443; batch adversarial loss: 0.529003\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524915; batch adversarial loss: 0.538696\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526236; batch adversarial loss: 0.527994\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531930; batch adversarial loss: 0.549267\n",
      "epoch 20; iter: 0; batch classifier loss: 0.585163; batch adversarial loss: 0.472345\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537925; batch adversarial loss: 0.521133\n",
      "epoch 22; iter: 0; batch classifier loss: 0.580715; batch adversarial loss: 0.533054\n",
      "epoch 23; iter: 0; batch classifier loss: 0.530829; batch adversarial loss: 0.545974\n",
      "epoch 24; iter: 0; batch classifier loss: 0.539838; batch adversarial loss: 0.502368\n",
      "epoch 25; iter: 0; batch classifier loss: 0.757067; batch adversarial loss: 0.591084\n",
      "epoch 26; iter: 0; batch classifier loss: 0.654899; batch adversarial loss: 0.536119\n",
      "epoch 27; iter: 0; batch classifier loss: 0.716921; batch adversarial loss: 0.663139\n",
      "epoch 28; iter: 0; batch classifier loss: 0.610105; batch adversarial loss: 0.533389\n",
      "epoch 29; iter: 0; batch classifier loss: 0.678089; batch adversarial loss: 0.547804\n",
      "epoch 30; iter: 0; batch classifier loss: 0.560251; batch adversarial loss: 0.553168\n",
      "epoch 31; iter: 0; batch classifier loss: 0.552929; batch adversarial loss: 0.495462\n",
      "epoch 32; iter: 0; batch classifier loss: 0.547451; batch adversarial loss: 0.516172\n",
      "epoch 33; iter: 0; batch classifier loss: 0.506528; batch adversarial loss: 0.525383\n",
      "epoch 34; iter: 0; batch classifier loss: 0.499529; batch adversarial loss: 0.544804\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483534; batch adversarial loss: 0.483446\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503608; batch adversarial loss: 0.459782\n",
      "epoch 37; iter: 0; batch classifier loss: 0.527965; batch adversarial loss: 0.531525\n",
      "epoch 38; iter: 0; batch classifier loss: 0.525173; batch adversarial loss: 0.415920\n",
      "epoch 39; iter: 0; batch classifier loss: 0.543896; batch adversarial loss: 0.463907\n",
      "epoch 40; iter: 0; batch classifier loss: 0.554032; batch adversarial loss: 0.449979\n",
      "epoch 41; iter: 0; batch classifier loss: 0.609607; batch adversarial loss: 0.537343\n",
      "epoch 42; iter: 0; batch classifier loss: 0.495802; batch adversarial loss: 0.456751\n",
      "epoch 43; iter: 0; batch classifier loss: 0.489961; batch adversarial loss: 0.464149\n",
      "epoch 44; iter: 0; batch classifier loss: 0.511604; batch adversarial loss: 0.413044\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433695; batch adversarial loss: 0.448059\n",
      "epoch 46; iter: 0; batch classifier loss: 0.507776; batch adversarial loss: 0.537356\n",
      "epoch 47; iter: 0; batch classifier loss: 0.523690; batch adversarial loss: 0.506404\n",
      "epoch 48; iter: 0; batch classifier loss: 0.564036; batch adversarial loss: 0.433777\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438392; batch adversarial loss: 0.471894\n",
      "epoch 50; iter: 0; batch classifier loss: 0.468124; batch adversarial loss: 0.504648\n",
      "epoch 51; iter: 0; batch classifier loss: 0.467214; batch adversarial loss: 0.483260\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442225; batch adversarial loss: 0.426255\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466068; batch adversarial loss: 0.426312\n",
      "epoch 54; iter: 0; batch classifier loss: 0.510366; batch adversarial loss: 0.446440\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483276; batch adversarial loss: 0.365920\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417192; batch adversarial loss: 0.523823\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400257; batch adversarial loss: 0.498572\n",
      "epoch 58; iter: 0; batch classifier loss: 0.449799; batch adversarial loss: 0.453043\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408244; batch adversarial loss: 0.465581\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439872; batch adversarial loss: 0.596727\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424205; batch adversarial loss: 0.539109\n",
      "epoch 62; iter: 0; batch classifier loss: 0.439887; batch adversarial loss: 0.471163\n",
      "epoch 63; iter: 0; batch classifier loss: 0.423804; batch adversarial loss: 0.449390\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387797; batch adversarial loss: 0.440028\n",
      "epoch 65; iter: 0; batch classifier loss: 0.383341; batch adversarial loss: 0.503656\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426891; batch adversarial loss: 0.450136\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410529; batch adversarial loss: 0.456323\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407773; batch adversarial loss: 0.432137\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442188; batch adversarial loss: 0.454101\n",
      "epoch 70; iter: 0; batch classifier loss: 0.466190; batch adversarial loss: 0.469075\n",
      "epoch 71; iter: 0; batch classifier loss: 0.413320; batch adversarial loss: 0.425248\n",
      "epoch 72; iter: 0; batch classifier loss: 0.475368; batch adversarial loss: 0.530898\n",
      "epoch 73; iter: 0; batch classifier loss: 0.432905; batch adversarial loss: 0.529233\n",
      "epoch 74; iter: 0; batch classifier loss: 0.469015; batch adversarial loss: 0.445583\n",
      "epoch 75; iter: 0; batch classifier loss: 0.493767; batch adversarial loss: 0.482097\n",
      "epoch 76; iter: 0; batch classifier loss: 0.459373; batch adversarial loss: 0.528826\n",
      "epoch 77; iter: 0; batch classifier loss: 0.405018; batch adversarial loss: 0.441410\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368630; batch adversarial loss: 0.526092\n",
      "epoch 79; iter: 0; batch classifier loss: 0.401615; batch adversarial loss: 0.413780\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431081; batch adversarial loss: 0.452791\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393912; batch adversarial loss: 0.485185\n",
      "epoch 82; iter: 0; batch classifier loss: 0.375658; batch adversarial loss: 0.436206\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413946; batch adversarial loss: 0.447612\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378201; batch adversarial loss: 0.462185\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347969; batch adversarial loss: 0.483614\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430494; batch adversarial loss: 0.469274\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363565; batch adversarial loss: 0.522986\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417618; batch adversarial loss: 0.419736\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393838; batch adversarial loss: 0.453101\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394602; batch adversarial loss: 0.454449\n",
      "epoch 91; iter: 0; batch classifier loss: 0.396232; batch adversarial loss: 0.495993\n",
      "epoch 92; iter: 0; batch classifier loss: 0.401930; batch adversarial loss: 0.604569\n",
      "epoch 93; iter: 0; batch classifier loss: 0.451766; batch adversarial loss: 0.613895\n",
      "epoch 94; iter: 0; batch classifier loss: 0.298331; batch adversarial loss: 0.496361\n",
      "epoch 95; iter: 0; batch classifier loss: 0.287518; batch adversarial loss: 0.485888\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335970; batch adversarial loss: 0.515661\n",
      "epoch 97; iter: 0; batch classifier loss: 0.462230; batch adversarial loss: 0.360549\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368426; batch adversarial loss: 0.482333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.454844; batch adversarial loss: 0.506382\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.176834; batch adversarial loss: 0.861480\n",
      "epoch 2; iter: 0; batch classifier loss: 1.032316; batch adversarial loss: 0.834083\n",
      "epoch 3; iter: 0; batch classifier loss: 1.004463; batch adversarial loss: 0.745107\n",
      "epoch 4; iter: 0; batch classifier loss: 0.795933; batch adversarial loss: 0.734594\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613005; batch adversarial loss: 0.690562\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524939; batch adversarial loss: 0.667326\n",
      "epoch 7; iter: 0; batch classifier loss: 0.497900; batch adversarial loss: 0.630424\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561835; batch adversarial loss: 0.614634\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502761; batch adversarial loss: 0.594111\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565207; batch adversarial loss: 0.590483\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542356; batch adversarial loss: 0.595909\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555917; batch adversarial loss: 0.577867\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513410; batch adversarial loss: 0.551659\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462573; batch adversarial loss: 0.551321\n",
      "epoch 15; iter: 0; batch classifier loss: 0.571978; batch adversarial loss: 0.581738\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526552; batch adversarial loss: 0.533779\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520314; batch adversarial loss: 0.542100\n",
      "epoch 18; iter: 0; batch classifier loss: 0.530424; batch adversarial loss: 0.532094\n",
      "epoch 19; iter: 0; batch classifier loss: 0.552305; batch adversarial loss: 0.561472\n",
      "epoch 20; iter: 0; batch classifier loss: 0.615095; batch adversarial loss: 0.485595\n",
      "epoch 21; iter: 0; batch classifier loss: 0.576166; batch adversarial loss: 0.533071\n",
      "epoch 22; iter: 0; batch classifier loss: 0.628674; batch adversarial loss: 0.548897\n",
      "epoch 23; iter: 0; batch classifier loss: 0.601497; batch adversarial loss: 0.561080\n",
      "epoch 24; iter: 0; batch classifier loss: 0.584460; batch adversarial loss: 0.511893\n",
      "epoch 25; iter: 0; batch classifier loss: 0.791963; batch adversarial loss: 0.586142\n",
      "epoch 26; iter: 0; batch classifier loss: 0.660683; batch adversarial loss: 0.527685\n",
      "epoch 27; iter: 0; batch classifier loss: 0.689627; batch adversarial loss: 0.647653\n",
      "epoch 28; iter: 0; batch classifier loss: 0.593151; batch adversarial loss: 0.527356\n",
      "epoch 29; iter: 0; batch classifier loss: 0.640821; batch adversarial loss: 0.538693\n",
      "epoch 30; iter: 0; batch classifier loss: 0.529516; batch adversarial loss: 0.544689\n",
      "epoch 31; iter: 0; batch classifier loss: 0.536791; batch adversarial loss: 0.490657\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525723; batch adversarial loss: 0.510979\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475002; batch adversarial loss: 0.519508\n",
      "epoch 34; iter: 0; batch classifier loss: 0.476343; batch adversarial loss: 0.539831\n",
      "epoch 35; iter: 0; batch classifier loss: 0.489571; batch adversarial loss: 0.481829\n",
      "epoch 36; iter: 0; batch classifier loss: 0.512633; batch adversarial loss: 0.459235\n",
      "epoch 37; iter: 0; batch classifier loss: 0.547643; batch adversarial loss: 0.533511\n",
      "epoch 38; iter: 0; batch classifier loss: 0.550105; batch adversarial loss: 0.417678\n",
      "epoch 39; iter: 0; batch classifier loss: 0.585622; batch adversarial loss: 0.466767\n",
      "epoch 40; iter: 0; batch classifier loss: 0.589589; batch adversarial loss: 0.451144\n",
      "epoch 41; iter: 0; batch classifier loss: 0.631287; batch adversarial loss: 0.535702\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501168; batch adversarial loss: 0.454924\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470444; batch adversarial loss: 0.461495\n",
      "epoch 44; iter: 0; batch classifier loss: 0.486239; batch adversarial loss: 0.411122\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425176; batch adversarial loss: 0.446631\n",
      "epoch 46; iter: 0; batch classifier loss: 0.493579; batch adversarial loss: 0.536094\n",
      "epoch 47; iter: 0; batch classifier loss: 0.521193; batch adversarial loss: 0.506313\n",
      "epoch 48; iter: 0; batch classifier loss: 0.596795; batch adversarial loss: 0.433543\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440924; batch adversarial loss: 0.471592\n",
      "epoch 50; iter: 0; batch classifier loss: 0.475864; batch adversarial loss: 0.504522\n",
      "epoch 51; iter: 0; batch classifier loss: 0.476511; batch adversarial loss: 0.483125\n",
      "epoch 52; iter: 0; batch classifier loss: 0.450431; batch adversarial loss: 0.426041\n",
      "epoch 53; iter: 0; batch classifier loss: 0.469688; batch adversarial loss: 0.426391\n",
      "epoch 54; iter: 0; batch classifier loss: 0.513625; batch adversarial loss: 0.446471\n",
      "epoch 55; iter: 0; batch classifier loss: 0.475352; batch adversarial loss: 0.365180\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417466; batch adversarial loss: 0.523797\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402143; batch adversarial loss: 0.498982\n",
      "epoch 58; iter: 0; batch classifier loss: 0.465534; batch adversarial loss: 0.452954\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416513; batch adversarial loss: 0.465948\n",
      "epoch 60; iter: 0; batch classifier loss: 0.446350; batch adversarial loss: 0.596907\n",
      "epoch 61; iter: 0; batch classifier loss: 0.417149; batch adversarial loss: 0.539207\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444876; batch adversarial loss: 0.470516\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431387; batch adversarial loss: 0.449362\n",
      "epoch 64; iter: 0; batch classifier loss: 0.390271; batch adversarial loss: 0.440183\n",
      "epoch 65; iter: 0; batch classifier loss: 0.388571; batch adversarial loss: 0.503477\n",
      "epoch 66; iter: 0; batch classifier loss: 0.447121; batch adversarial loss: 0.450599\n",
      "epoch 67; iter: 0; batch classifier loss: 0.417290; batch adversarial loss: 0.456456\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410331; batch adversarial loss: 0.432923\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447180; batch adversarial loss: 0.453768\n",
      "epoch 70; iter: 0; batch classifier loss: 0.477235; batch adversarial loss: 0.469302\n",
      "epoch 71; iter: 0; batch classifier loss: 0.399616; batch adversarial loss: 0.425522\n",
      "epoch 72; iter: 0; batch classifier loss: 0.472650; batch adversarial loss: 0.529859\n",
      "epoch 73; iter: 0; batch classifier loss: 0.435817; batch adversarial loss: 0.527833\n",
      "epoch 74; iter: 0; batch classifier loss: 0.473601; batch adversarial loss: 0.444124\n",
      "epoch 75; iter: 0; batch classifier loss: 0.503593; batch adversarial loss: 0.482682\n",
      "epoch 76; iter: 0; batch classifier loss: 0.472280; batch adversarial loss: 0.528137\n",
      "epoch 77; iter: 0; batch classifier loss: 0.404353; batch adversarial loss: 0.439364\n",
      "epoch 78; iter: 0; batch classifier loss: 0.381716; batch adversarial loss: 0.526824\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404855; batch adversarial loss: 0.413271\n",
      "epoch 80; iter: 0; batch classifier loss: 0.442389; batch adversarial loss: 0.452432\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391143; batch adversarial loss: 0.485857\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393535; batch adversarial loss: 0.436850\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403951; batch adversarial loss: 0.447390\n",
      "epoch 84; iter: 0; batch classifier loss: 0.378968; batch adversarial loss: 0.462360\n",
      "epoch 85; iter: 0; batch classifier loss: 0.348642; batch adversarial loss: 0.482376\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431087; batch adversarial loss: 0.469167\n",
      "epoch 87; iter: 0; batch classifier loss: 0.370390; batch adversarial loss: 0.521379\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423864; batch adversarial loss: 0.419149\n",
      "epoch 89; iter: 0; batch classifier loss: 0.406640; batch adversarial loss: 0.453406\n",
      "epoch 90; iter: 0; batch classifier loss: 0.423256; batch adversarial loss: 0.454993\n",
      "epoch 91; iter: 0; batch classifier loss: 0.389249; batch adversarial loss: 0.495520\n",
      "epoch 92; iter: 0; batch classifier loss: 0.403076; batch adversarial loss: 0.604905\n",
      "epoch 93; iter: 0; batch classifier loss: 0.489969; batch adversarial loss: 0.612767\n",
      "epoch 94; iter: 0; batch classifier loss: 0.297012; batch adversarial loss: 0.496920\n",
      "epoch 95; iter: 0; batch classifier loss: 0.287864; batch adversarial loss: 0.485965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.336566; batch adversarial loss: 0.515425\n",
      "epoch 97; iter: 0; batch classifier loss: 0.467248; batch adversarial loss: 0.361222\n",
      "epoch 98; iter: 0; batch classifier loss: 0.380624; batch adversarial loss: 0.481270\n",
      "epoch 99; iter: 0; batch classifier loss: 0.462553; batch adversarial loss: 0.507185\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.143675; batch adversarial loss: 0.859821\n",
      "epoch 2; iter: 0; batch classifier loss: 1.001531; batch adversarial loss: 0.832297\n",
      "epoch 3; iter: 0; batch classifier loss: 0.960645; batch adversarial loss: 0.743491\n",
      "epoch 4; iter: 0; batch classifier loss: 0.761381; batch adversarial loss: 0.731746\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578983; batch adversarial loss: 0.688221\n",
      "epoch 6; iter: 0; batch classifier loss: 0.515121; batch adversarial loss: 0.665963\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493396; batch adversarial loss: 0.630944\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561289; batch adversarial loss: 0.615310\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502458; batch adversarial loss: 0.594808\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564888; batch adversarial loss: 0.591045\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544367; batch adversarial loss: 0.596133\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557941; batch adversarial loss: 0.578008\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516154; batch adversarial loss: 0.551494\n",
      "epoch 14; iter: 0; batch classifier loss: 0.465557; batch adversarial loss: 0.550480\n",
      "epoch 15; iter: 0; batch classifier loss: 0.576667; batch adversarial loss: 0.579598\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529166; batch adversarial loss: 0.530111\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522758; batch adversarial loss: 0.539583\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526867; batch adversarial loss: 0.529199\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535048; batch adversarial loss: 0.551371\n",
      "epoch 20; iter: 0; batch classifier loss: 0.592461; batch adversarial loss: 0.476049\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545829; batch adversarial loss: 0.523728\n",
      "epoch 22; iter: 0; batch classifier loss: 0.588095; batch adversarial loss: 0.536258\n",
      "epoch 23; iter: 0; batch classifier loss: 0.552575; batch adversarial loss: 0.551814\n",
      "epoch 24; iter: 0; batch classifier loss: 0.554428; batch adversarial loss: 0.507616\n",
      "epoch 25; iter: 0; batch classifier loss: 0.776653; batch adversarial loss: 0.591005\n",
      "epoch 26; iter: 0; batch classifier loss: 0.656027; batch adversarial loss: 0.533340\n",
      "epoch 27; iter: 0; batch classifier loss: 0.708966; batch adversarial loss: 0.658189\n",
      "epoch 28; iter: 0; batch classifier loss: 0.606671; batch adversarial loss: 0.532105\n",
      "epoch 29; iter: 0; batch classifier loss: 0.665610; batch adversarial loss: 0.544879\n",
      "epoch 30; iter: 0; batch classifier loss: 0.548732; batch adversarial loss: 0.550011\n",
      "epoch 31; iter: 0; batch classifier loss: 0.548882; batch adversarial loss: 0.493864\n",
      "epoch 32; iter: 0; batch classifier loss: 0.541810; batch adversarial loss: 0.514570\n",
      "epoch 33; iter: 0; batch classifier loss: 0.496129; batch adversarial loss: 0.523216\n",
      "epoch 34; iter: 0; batch classifier loss: 0.491674; batch adversarial loss: 0.542895\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485310; batch adversarial loss: 0.483060\n",
      "epoch 36; iter: 0; batch classifier loss: 0.509741; batch adversarial loss: 0.459425\n",
      "epoch 37; iter: 0; batch classifier loss: 0.534334; batch adversarial loss: 0.532113\n",
      "epoch 38; iter: 0; batch classifier loss: 0.526589; batch adversarial loss: 0.416058\n",
      "epoch 39; iter: 0; batch classifier loss: 0.560464; batch adversarial loss: 0.464764\n",
      "epoch 40; iter: 0; batch classifier loss: 0.564422; batch adversarial loss: 0.450599\n",
      "epoch 41; iter: 0; batch classifier loss: 0.621366; batch adversarial loss: 0.537621\n",
      "epoch 42; iter: 0; batch classifier loss: 0.505083; batch adversarial loss: 0.456659\n",
      "epoch 43; iter: 0; batch classifier loss: 0.481337; batch adversarial loss: 0.463276\n",
      "epoch 44; iter: 0; batch classifier loss: 0.502995; batch adversarial loss: 0.412445\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432871; batch adversarial loss: 0.447693\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500639; batch adversarial loss: 0.536789\n",
      "epoch 47; iter: 0; batch classifier loss: 0.524184; batch adversarial loss: 0.505950\n",
      "epoch 48; iter: 0; batch classifier loss: 0.548951; batch adversarial loss: 0.433529\n",
      "epoch 49; iter: 0; batch classifier loss: 0.431160; batch adversarial loss: 0.471704\n",
      "epoch 50; iter: 0; batch classifier loss: 0.467772; batch adversarial loss: 0.504728\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469715; batch adversarial loss: 0.483259\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448953; batch adversarial loss: 0.426163\n",
      "epoch 53; iter: 0; batch classifier loss: 0.468700; batch adversarial loss: 0.426356\n",
      "epoch 54; iter: 0; batch classifier loss: 0.505498; batch adversarial loss: 0.446465\n",
      "epoch 55; iter: 0; batch classifier loss: 0.481838; batch adversarial loss: 0.365716\n",
      "epoch 56; iter: 0; batch classifier loss: 0.416402; batch adversarial loss: 0.523827\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404553; batch adversarial loss: 0.498915\n",
      "epoch 58; iter: 0; batch classifier loss: 0.457613; batch adversarial loss: 0.453006\n",
      "epoch 59; iter: 0; batch classifier loss: 0.408016; batch adversarial loss: 0.465706\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441483; batch adversarial loss: 0.596928\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425634; batch adversarial loss: 0.539282\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436440; batch adversarial loss: 0.470824\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426669; batch adversarial loss: 0.449068\n",
      "epoch 64; iter: 0; batch classifier loss: 0.389938; batch adversarial loss: 0.439921\n",
      "epoch 65; iter: 0; batch classifier loss: 0.375910; batch adversarial loss: 0.503306\n",
      "epoch 66; iter: 0; batch classifier loss: 0.434947; batch adversarial loss: 0.450459\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409378; batch adversarial loss: 0.455575\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406599; batch adversarial loss: 0.432333\n",
      "epoch 69; iter: 0; batch classifier loss: 0.438074; batch adversarial loss: 0.454059\n",
      "epoch 70; iter: 0; batch classifier loss: 0.467439; batch adversarial loss: 0.469216\n",
      "epoch 71; iter: 0; batch classifier loss: 0.412210; batch adversarial loss: 0.425279\n",
      "epoch 72; iter: 0; batch classifier loss: 0.469446; batch adversarial loss: 0.530794\n",
      "epoch 73; iter: 0; batch classifier loss: 0.434556; batch adversarial loss: 0.528366\n",
      "epoch 74; iter: 0; batch classifier loss: 0.472180; batch adversarial loss: 0.444625\n",
      "epoch 75; iter: 0; batch classifier loss: 0.500051; batch adversarial loss: 0.482427\n",
      "epoch 76; iter: 0; batch classifier loss: 0.464131; batch adversarial loss: 0.528995\n",
      "epoch 77; iter: 0; batch classifier loss: 0.400515; batch adversarial loss: 0.440602\n",
      "epoch 78; iter: 0; batch classifier loss: 0.369289; batch adversarial loss: 0.526183\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393205; batch adversarial loss: 0.414078\n",
      "epoch 80; iter: 0; batch classifier loss: 0.435717; batch adversarial loss: 0.452767\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397736; batch adversarial loss: 0.485709\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390691; batch adversarial loss: 0.436834\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404361; batch adversarial loss: 0.447089\n",
      "epoch 84; iter: 0; batch classifier loss: 0.366808; batch adversarial loss: 0.461786\n",
      "epoch 85; iter: 0; batch classifier loss: 0.357153; batch adversarial loss: 0.483934\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421333; batch adversarial loss: 0.469535\n",
      "epoch 87; iter: 0; batch classifier loss: 0.360716; batch adversarial loss: 0.521323\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420973; batch adversarial loss: 0.419269\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397417; batch adversarial loss: 0.454895\n",
      "epoch 90; iter: 0; batch classifier loss: 0.404787; batch adversarial loss: 0.454548\n",
      "epoch 91; iter: 0; batch classifier loss: 0.389587; batch adversarial loss: 0.495633\n",
      "epoch 92; iter: 0; batch classifier loss: 0.410189; batch adversarial loss: 0.605292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.458581; batch adversarial loss: 0.613635\n",
      "epoch 94; iter: 0; batch classifier loss: 0.295376; batch adversarial loss: 0.496697\n",
      "epoch 95; iter: 0; batch classifier loss: 0.277997; batch adversarial loss: 0.485048\n",
      "epoch 96; iter: 0; batch classifier loss: 0.334008; batch adversarial loss: 0.516064\n",
      "epoch 97; iter: 0; batch classifier loss: 0.468719; batch adversarial loss: 0.360832\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382796; batch adversarial loss: 0.481737\n",
      "epoch 99; iter: 0; batch classifier loss: 0.463146; batch adversarial loss: 0.507128\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.156005; batch adversarial loss: 0.860502\n",
      "epoch 2; iter: 0; batch classifier loss: 1.013508; batch adversarial loss: 0.833001\n",
      "epoch 3; iter: 0; batch classifier loss: 0.977010; batch adversarial loss: 0.744108\n",
      "epoch 4; iter: 0; batch classifier loss: 0.774907; batch adversarial loss: 0.732902\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592739; batch adversarial loss: 0.689074\n",
      "epoch 6; iter: 0; batch classifier loss: 0.518253; batch adversarial loss: 0.666412\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495783; batch adversarial loss: 0.630584\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561133; batch adversarial loss: 0.615065\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502618; batch adversarial loss: 0.594546\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565094; batch adversarial loss: 0.590801\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543564; batch adversarial loss: 0.596078\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557513; batch adversarial loss: 0.577998\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515022; batch adversarial loss: 0.551477\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464391; batch adversarial loss: 0.550776\n",
      "epoch 15; iter: 0; batch classifier loss: 0.574218; batch adversarial loss: 0.580319\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528025; batch adversarial loss: 0.531491\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523341; batch adversarial loss: 0.540483\n",
      "epoch 18; iter: 0; batch classifier loss: 0.528316; batch adversarial loss: 0.530165\n",
      "epoch 19; iter: 0; batch classifier loss: 0.538558; batch adversarial loss: 0.554704\n",
      "epoch 20; iter: 0; batch classifier loss: 0.599797; batch adversarial loss: 0.479275\n",
      "epoch 21; iter: 0; batch classifier loss: 0.556354; batch adversarial loss: 0.526942\n",
      "epoch 22; iter: 0; batch classifier loss: 0.600726; batch adversarial loss: 0.540102\n",
      "epoch 23; iter: 0; batch classifier loss: 0.573975; batch adversarial loss: 0.556858\n",
      "epoch 24; iter: 0; batch classifier loss: 0.569156; batch adversarial loss: 0.510672\n",
      "epoch 25; iter: 0; batch classifier loss: 0.789885; batch adversarial loss: 0.590178\n",
      "epoch 26; iter: 0; batch classifier loss: 0.657536; batch adversarial loss: 0.531059\n",
      "epoch 27; iter: 0; batch classifier loss: 0.700417; batch adversarial loss: 0.653298\n",
      "epoch 28; iter: 0; batch classifier loss: 0.601156; batch adversarial loss: 0.530199\n",
      "epoch 29; iter: 0; batch classifier loss: 0.651283; batch adversarial loss: 0.542124\n",
      "epoch 30; iter: 0; batch classifier loss: 0.541897; batch adversarial loss: 0.547898\n",
      "epoch 31; iter: 0; batch classifier loss: 0.543906; batch adversarial loss: 0.492320\n",
      "epoch 32; iter: 0; batch classifier loss: 0.534940; batch adversarial loss: 0.512886\n",
      "epoch 33; iter: 0; batch classifier loss: 0.482425; batch adversarial loss: 0.521307\n",
      "epoch 34; iter: 0; batch classifier loss: 0.485677; batch adversarial loss: 0.541419\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485348; batch adversarial loss: 0.482383\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508289; batch adversarial loss: 0.459045\n",
      "epoch 37; iter: 0; batch classifier loss: 0.531876; batch adversarial loss: 0.532103\n",
      "epoch 38; iter: 0; batch classifier loss: 0.531355; batch adversarial loss: 0.416740\n",
      "epoch 39; iter: 0; batch classifier loss: 0.564953; batch adversarial loss: 0.465554\n",
      "epoch 40; iter: 0; batch classifier loss: 0.575823; batch adversarial loss: 0.451038\n",
      "epoch 41; iter: 0; batch classifier loss: 0.630406; batch adversarial loss: 0.537536\n",
      "epoch 42; iter: 0; batch classifier loss: 0.510226; batch adversarial loss: 0.456448\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478508; batch adversarial loss: 0.462687\n",
      "epoch 44; iter: 0; batch classifier loss: 0.502353; batch adversarial loss: 0.412025\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434662; batch adversarial loss: 0.447429\n",
      "epoch 46; iter: 0; batch classifier loss: 0.503934; batch adversarial loss: 0.536347\n",
      "epoch 47; iter: 0; batch classifier loss: 0.524652; batch adversarial loss: 0.505882\n",
      "epoch 48; iter: 0; batch classifier loss: 0.558117; batch adversarial loss: 0.433443\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432693; batch adversarial loss: 0.471634\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465179; batch adversarial loss: 0.504648\n",
      "epoch 51; iter: 0; batch classifier loss: 0.477691; batch adversarial loss: 0.483186\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446000; batch adversarial loss: 0.426202\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466780; batch adversarial loss: 0.426421\n",
      "epoch 54; iter: 0; batch classifier loss: 0.510514; batch adversarial loss: 0.446575\n",
      "epoch 55; iter: 0; batch classifier loss: 0.484045; batch adversarial loss: 0.365863\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420525; batch adversarial loss: 0.523718\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402959; batch adversarial loss: 0.499039\n",
      "epoch 58; iter: 0; batch classifier loss: 0.453460; batch adversarial loss: 0.453311\n",
      "epoch 59; iter: 0; batch classifier loss: 0.415044; batch adversarial loss: 0.465931\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444408; batch adversarial loss: 0.597122\n",
      "epoch 61; iter: 0; batch classifier loss: 0.419914; batch adversarial loss: 0.539441\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441391; batch adversarial loss: 0.471207\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425561; batch adversarial loss: 0.449261\n",
      "epoch 64; iter: 0; batch classifier loss: 0.390114; batch adversarial loss: 0.439917\n",
      "epoch 65; iter: 0; batch classifier loss: 0.385651; batch adversarial loss: 0.503835\n",
      "epoch 66; iter: 0; batch classifier loss: 0.431466; batch adversarial loss: 0.450429\n",
      "epoch 67; iter: 0; batch classifier loss: 0.416163; batch adversarial loss: 0.455747\n",
      "epoch 68; iter: 0; batch classifier loss: 0.414825; batch adversarial loss: 0.432843\n",
      "epoch 69; iter: 0; batch classifier loss: 0.436944; batch adversarial loss: 0.453559\n",
      "epoch 70; iter: 0; batch classifier loss: 0.467555; batch adversarial loss: 0.469607\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411990; batch adversarial loss: 0.425509\n",
      "epoch 72; iter: 0; batch classifier loss: 0.463925; batch adversarial loss: 0.530514\n",
      "epoch 73; iter: 0; batch classifier loss: 0.441966; batch adversarial loss: 0.529011\n",
      "epoch 74; iter: 0; batch classifier loss: 0.478278; batch adversarial loss: 0.444819\n",
      "epoch 75; iter: 0; batch classifier loss: 0.493544; batch adversarial loss: 0.482316\n",
      "epoch 76; iter: 0; batch classifier loss: 0.464961; batch adversarial loss: 0.529033\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401356; batch adversarial loss: 0.440261\n",
      "epoch 78; iter: 0; batch classifier loss: 0.373101; batch adversarial loss: 0.526089\n",
      "epoch 79; iter: 0; batch classifier loss: 0.397382; batch adversarial loss: 0.414117\n",
      "epoch 80; iter: 0; batch classifier loss: 0.437505; batch adversarial loss: 0.452607\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399035; batch adversarial loss: 0.486061\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386464; batch adversarial loss: 0.437029\n",
      "epoch 83; iter: 0; batch classifier loss: 0.415631; batch adversarial loss: 0.447544\n",
      "epoch 84; iter: 0; batch classifier loss: 0.369583; batch adversarial loss: 0.462257\n",
      "epoch 85; iter: 0; batch classifier loss: 0.345709; batch adversarial loss: 0.483127\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421710; batch adversarial loss: 0.469478\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371244; batch adversarial loss: 0.522136\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425671; batch adversarial loss: 0.419601\n",
      "epoch 89; iter: 0; batch classifier loss: 0.411259; batch adversarial loss: 0.453724\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407917; batch adversarial loss: 0.454156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91; iter: 0; batch classifier loss: 0.397119; batch adversarial loss: 0.495998\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402164; batch adversarial loss: 0.604874\n",
      "epoch 93; iter: 0; batch classifier loss: 0.458839; batch adversarial loss: 0.614537\n",
      "epoch 94; iter: 0; batch classifier loss: 0.301647; batch adversarial loss: 0.496725\n",
      "epoch 95; iter: 0; batch classifier loss: 0.282938; batch adversarial loss: 0.485986\n",
      "epoch 96; iter: 0; batch classifier loss: 0.344258; batch adversarial loss: 0.514138\n",
      "epoch 97; iter: 0; batch classifier loss: 0.484051; batch adversarial loss: 0.361656\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383940; batch adversarial loss: 0.481925\n",
      "epoch 99; iter: 0; batch classifier loss: 0.475749; batch adversarial loss: 0.506873\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.125424; batch adversarial loss: 0.858739\n",
      "epoch 2; iter: 0; batch classifier loss: 0.981329; batch adversarial loss: 0.831028\n",
      "epoch 3; iter: 0; batch classifier loss: 0.934227; batch adversarial loss: 0.742237\n",
      "epoch 4; iter: 0; batch classifier loss: 0.740333; batch adversarial loss: 0.729979\n",
      "epoch 5; iter: 0; batch classifier loss: 0.562435; batch adversarial loss: 0.686818\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512371; batch adversarial loss: 0.665514\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491111; batch adversarial loss: 0.631253\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561039; batch adversarial loss: 0.615705\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501324; batch adversarial loss: 0.595323\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564757; batch adversarial loss: 0.591368\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545862; batch adversarial loss: 0.596122\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559386; batch adversarial loss: 0.578170\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518542; batch adversarial loss: 0.551498\n",
      "epoch 14; iter: 0; batch classifier loss: 0.467667; batch adversarial loss: 0.550037\n",
      "epoch 15; iter: 0; batch classifier loss: 0.577159; batch adversarial loss: 0.578650\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531774; batch adversarial loss: 0.527969\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527394; batch adversarial loss: 0.538093\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526827; batch adversarial loss: 0.527611\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530796; batch adversarial loss: 0.547696\n",
      "epoch 20; iter: 0; batch classifier loss: 0.583023; batch adversarial loss: 0.470733\n",
      "epoch 21; iter: 0; batch classifier loss: 0.528275; batch adversarial loss: 0.517956\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573469; batch adversarial loss: 0.531116\n",
      "epoch 23; iter: 0; batch classifier loss: 0.522533; batch adversarial loss: 0.543098\n",
      "epoch 24; iter: 0; batch classifier loss: 0.528449; batch adversarial loss: 0.498353\n",
      "epoch 25; iter: 0; batch classifier loss: 0.730193; batch adversarial loss: 0.588114\n",
      "epoch 26; iter: 0; batch classifier loss: 0.649013; batch adversarial loss: 0.537469\n",
      "epoch 27; iter: 0; batch classifier loss: 0.718504; batch adversarial loss: 0.667203\n",
      "epoch 28; iter: 0; batch classifier loss: 0.612509; batch adversarial loss: 0.534546\n",
      "epoch 29; iter: 0; batch classifier loss: 0.684686; batch adversarial loss: 0.550146\n",
      "epoch 30; iter: 0; batch classifier loss: 0.563741; batch adversarial loss: 0.555189\n",
      "epoch 31; iter: 0; batch classifier loss: 0.560681; batch adversarial loss: 0.497108\n",
      "epoch 32; iter: 0; batch classifier loss: 0.552747; batch adversarial loss: 0.517348\n",
      "epoch 33; iter: 0; batch classifier loss: 0.513751; batch adversarial loss: 0.527420\n",
      "epoch 34; iter: 0; batch classifier loss: 0.508854; batch adversarial loss: 0.546557\n",
      "epoch 35; iter: 0; batch classifier loss: 0.487244; batch adversarial loss: 0.484693\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502645; batch adversarial loss: 0.460325\n",
      "epoch 37; iter: 0; batch classifier loss: 0.531333; batch adversarial loss: 0.531812\n",
      "epoch 38; iter: 0; batch classifier loss: 0.525336; batch adversarial loss: 0.415944\n",
      "epoch 39; iter: 0; batch classifier loss: 0.544084; batch adversarial loss: 0.463790\n",
      "epoch 40; iter: 0; batch classifier loss: 0.548829; batch adversarial loss: 0.449485\n",
      "epoch 41; iter: 0; batch classifier loss: 0.604104; batch adversarial loss: 0.536830\n",
      "epoch 42; iter: 0; batch classifier loss: 0.491427; batch adversarial loss: 0.456231\n",
      "epoch 43; iter: 0; batch classifier loss: 0.485005; batch adversarial loss: 0.464020\n",
      "epoch 44; iter: 0; batch classifier loss: 0.506535; batch adversarial loss: 0.413058\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429859; batch adversarial loss: 0.447986\n",
      "epoch 46; iter: 0; batch classifier loss: 0.508943; batch adversarial loss: 0.537901\n",
      "epoch 47; iter: 0; batch classifier loss: 0.521898; batch adversarial loss: 0.506917\n",
      "epoch 48; iter: 0; batch classifier loss: 0.593742; batch adversarial loss: 0.434076\n",
      "epoch 49; iter: 0; batch classifier loss: 0.441817; batch adversarial loss: 0.472035\n",
      "epoch 50; iter: 0; batch classifier loss: 0.466083; batch adversarial loss: 0.504638\n",
      "epoch 51; iter: 0; batch classifier loss: 0.465276; batch adversarial loss: 0.483213\n",
      "epoch 52; iter: 0; batch classifier loss: 0.443042; batch adversarial loss: 0.426204\n",
      "epoch 53; iter: 0; batch classifier loss: 0.468029; batch adversarial loss: 0.426402\n",
      "epoch 54; iter: 0; batch classifier loss: 0.507554; batch adversarial loss: 0.446321\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487428; batch adversarial loss: 0.365902\n",
      "epoch 56; iter: 0; batch classifier loss: 0.418885; batch adversarial loss: 0.523652\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403874; batch adversarial loss: 0.498795\n",
      "epoch 58; iter: 0; batch classifier loss: 0.455216; batch adversarial loss: 0.453109\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407305; batch adversarial loss: 0.465334\n",
      "epoch 60; iter: 0; batch classifier loss: 0.437762; batch adversarial loss: 0.596297\n",
      "epoch 61; iter: 0; batch classifier loss: 0.425653; batch adversarial loss: 0.538862\n",
      "epoch 62; iter: 0; batch classifier loss: 0.437800; batch adversarial loss: 0.471139\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429519; batch adversarial loss: 0.449473\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387973; batch adversarial loss: 0.440139\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386552; batch adversarial loss: 0.503562\n",
      "epoch 66; iter: 0; batch classifier loss: 0.428929; batch adversarial loss: 0.450328\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399978; batch adversarial loss: 0.456247\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407147; batch adversarial loss: 0.431586\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442911; batch adversarial loss: 0.454129\n",
      "epoch 70; iter: 0; batch classifier loss: 0.463810; batch adversarial loss: 0.469471\n",
      "epoch 71; iter: 0; batch classifier loss: 0.411422; batch adversarial loss: 0.424908\n",
      "epoch 72; iter: 0; batch classifier loss: 0.476975; batch adversarial loss: 0.530740\n",
      "epoch 73; iter: 0; batch classifier loss: 0.429626; batch adversarial loss: 0.529023\n",
      "epoch 74; iter: 0; batch classifier loss: 0.462961; batch adversarial loss: 0.445830\n",
      "epoch 75; iter: 0; batch classifier loss: 0.502538; batch adversarial loss: 0.481716\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461435; batch adversarial loss: 0.528786\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409142; batch adversarial loss: 0.441384\n",
      "epoch 78; iter: 0; batch classifier loss: 0.375230; batch adversarial loss: 0.526108\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402712; batch adversarial loss: 0.413985\n",
      "epoch 80; iter: 0; batch classifier loss: 0.448172; batch adversarial loss: 0.452815\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395940; batch adversarial loss: 0.485143\n",
      "epoch 82; iter: 0; batch classifier loss: 0.383775; batch adversarial loss: 0.436624\n",
      "epoch 83; iter: 0; batch classifier loss: 0.416154; batch adversarial loss: 0.447494\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376261; batch adversarial loss: 0.462039\n",
      "epoch 85; iter: 0; batch classifier loss: 0.353068; batch adversarial loss: 0.483384\n",
      "epoch 86; iter: 0; batch classifier loss: 0.428770; batch adversarial loss: 0.469261\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365099; batch adversarial loss: 0.522117\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415132; batch adversarial loss: 0.420140\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397279; batch adversarial loss: 0.453865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.397935; batch adversarial loss: 0.454235\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384801; batch adversarial loss: 0.495205\n",
      "epoch 92; iter: 0; batch classifier loss: 0.405831; batch adversarial loss: 0.604246\n",
      "epoch 93; iter: 0; batch classifier loss: 0.440579; batch adversarial loss: 0.614383\n",
      "epoch 94; iter: 0; batch classifier loss: 0.294805; batch adversarial loss: 0.496221\n",
      "epoch 95; iter: 0; batch classifier loss: 0.280800; batch adversarial loss: 0.485977\n",
      "epoch 96; iter: 0; batch classifier loss: 0.327855; batch adversarial loss: 0.516429\n",
      "epoch 97; iter: 0; batch classifier loss: 0.465607; batch adversarial loss: 0.361443\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376664; batch adversarial loss: 0.482229\n",
      "epoch 99; iter: 0; batch classifier loss: 0.470284; batch adversarial loss: 0.505974\n",
      "epoch 100; iter: 0; batch classifier loss: 0.381853; batch adversarial loss: 0.489500\n",
      "epoch 101; iter: 0; batch classifier loss: 0.401041; batch adversarial loss: 0.492765\n",
      "epoch 102; iter: 0; batch classifier loss: 0.367738; batch adversarial loss: 0.486343\n",
      "epoch 103; iter: 0; batch classifier loss: 0.352757; batch adversarial loss: 0.443337\n",
      "epoch 104; iter: 0; batch classifier loss: 0.420469; batch adversarial loss: 0.424802\n",
      "epoch 105; iter: 0; batch classifier loss: 0.318742; batch adversarial loss: 0.500263\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397210; batch adversarial loss: 0.489048\n",
      "epoch 107; iter: 0; batch classifier loss: 0.349354; batch adversarial loss: 0.578883\n",
      "epoch 108; iter: 0; batch classifier loss: 0.369716; batch adversarial loss: 0.540625\n",
      "epoch 109; iter: 0; batch classifier loss: 0.335782; batch adversarial loss: 0.455930\n",
      "epoch 110; iter: 0; batch classifier loss: 0.334607; batch adversarial loss: 0.593254\n",
      "epoch 111; iter: 0; batch classifier loss: 0.323659; batch adversarial loss: 0.554022\n",
      "epoch 112; iter: 0; batch classifier loss: 0.364412; batch adversarial loss: 0.480775\n",
      "epoch 113; iter: 0; batch classifier loss: 0.333850; batch adversarial loss: 0.482885\n",
      "epoch 114; iter: 0; batch classifier loss: 0.359155; batch adversarial loss: 0.522253\n",
      "epoch 115; iter: 0; batch classifier loss: 0.418674; batch adversarial loss: 0.413517\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355721; batch adversarial loss: 0.453734\n",
      "epoch 117; iter: 0; batch classifier loss: 0.414952; batch adversarial loss: 0.482538\n",
      "epoch 118; iter: 0; batch classifier loss: 0.357661; batch adversarial loss: 0.438946\n",
      "epoch 119; iter: 0; batch classifier loss: 0.332032; batch adversarial loss: 0.526927\n",
      "epoch 120; iter: 0; batch classifier loss: 0.324197; batch adversarial loss: 0.456240\n",
      "epoch 121; iter: 0; batch classifier loss: 0.378278; batch adversarial loss: 0.518547\n",
      "epoch 122; iter: 0; batch classifier loss: 0.396740; batch adversarial loss: 0.492466\n",
      "epoch 123; iter: 0; batch classifier loss: 0.402913; batch adversarial loss: 0.466756\n",
      "epoch 124; iter: 0; batch classifier loss: 0.346834; batch adversarial loss: 0.481738\n",
      "epoch 125; iter: 0; batch classifier loss: 0.380296; batch adversarial loss: 0.464028\n",
      "epoch 126; iter: 0; batch classifier loss: 0.439825; batch adversarial loss: 0.437409\n",
      "epoch 127; iter: 0; batch classifier loss: 0.350183; batch adversarial loss: 0.442905\n",
      "epoch 128; iter: 0; batch classifier loss: 0.291197; batch adversarial loss: 0.536040\n",
      "epoch 129; iter: 0; batch classifier loss: 0.413145; batch adversarial loss: 0.434703\n",
      "epoch 130; iter: 0; batch classifier loss: 0.374730; batch adversarial loss: 0.455582\n",
      "epoch 131; iter: 0; batch classifier loss: 0.345189; batch adversarial loss: 0.442924\n",
      "epoch 132; iter: 0; batch classifier loss: 0.382178; batch adversarial loss: 0.456339\n",
      "epoch 133; iter: 0; batch classifier loss: 0.329842; batch adversarial loss: 0.451850\n",
      "epoch 134; iter: 0; batch classifier loss: 0.380944; batch adversarial loss: 0.558205\n",
      "epoch 135; iter: 0; batch classifier loss: 0.387300; batch adversarial loss: 0.421311\n",
      "epoch 136; iter: 0; batch classifier loss: 0.315557; batch adversarial loss: 0.502505\n",
      "epoch 137; iter: 0; batch classifier loss: 0.495574; batch adversarial loss: 0.422281\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318105; batch adversarial loss: 0.498216\n",
      "epoch 139; iter: 0; batch classifier loss: 0.339813; batch adversarial loss: 0.496272\n",
      "epoch 140; iter: 0; batch classifier loss: 0.462482; batch adversarial loss: 0.458684\n",
      "epoch 141; iter: 0; batch classifier loss: 0.345418; batch adversarial loss: 0.473642\n",
      "epoch 142; iter: 0; batch classifier loss: 0.430319; batch adversarial loss: 0.506861\n",
      "epoch 143; iter: 0; batch classifier loss: 0.431301; batch adversarial loss: 0.401186\n",
      "epoch 144; iter: 0; batch classifier loss: 0.416398; batch adversarial loss: 0.457511\n",
      "epoch 145; iter: 0; batch classifier loss: 0.398033; batch adversarial loss: 0.481532\n",
      "epoch 146; iter: 0; batch classifier loss: 0.362455; batch adversarial loss: 0.489617\n",
      "epoch 147; iter: 0; batch classifier loss: 0.363263; batch adversarial loss: 0.460090\n",
      "epoch 148; iter: 0; batch classifier loss: 0.319385; batch adversarial loss: 0.453221\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376692; batch adversarial loss: 0.425122\n",
      "epoch 150; iter: 0; batch classifier loss: 0.340890; batch adversarial loss: 0.406941\n",
      "epoch 151; iter: 0; batch classifier loss: 0.376927; batch adversarial loss: 0.436495\n",
      "epoch 152; iter: 0; batch classifier loss: 0.399036; batch adversarial loss: 0.465085\n",
      "epoch 153; iter: 0; batch classifier loss: 0.362786; batch adversarial loss: 0.515474\n",
      "epoch 154; iter: 0; batch classifier loss: 0.259882; batch adversarial loss: 0.536537\n",
      "epoch 155; iter: 0; batch classifier loss: 0.283192; batch adversarial loss: 0.496459\n",
      "epoch 156; iter: 0; batch classifier loss: 0.298759; batch adversarial loss: 0.436783\n",
      "epoch 157; iter: 0; batch classifier loss: 0.419510; batch adversarial loss: 0.464672\n",
      "epoch 158; iter: 0; batch classifier loss: 0.335977; batch adversarial loss: 0.486254\n",
      "epoch 159; iter: 0; batch classifier loss: 0.331616; batch adversarial loss: 0.440061\n",
      "epoch 160; iter: 0; batch classifier loss: 0.459145; batch adversarial loss: 0.465792\n",
      "epoch 161; iter: 0; batch classifier loss: 0.338708; batch adversarial loss: 0.494716\n",
      "epoch 162; iter: 0; batch classifier loss: 0.390510; batch adversarial loss: 0.489250\n",
      "epoch 163; iter: 0; batch classifier loss: 0.309763; batch adversarial loss: 0.499151\n",
      "epoch 164; iter: 0; batch classifier loss: 0.431685; batch adversarial loss: 0.412281\n",
      "epoch 165; iter: 0; batch classifier loss: 0.424288; batch adversarial loss: 0.401688\n",
      "epoch 166; iter: 0; batch classifier loss: 0.413206; batch adversarial loss: 0.437287\n",
      "epoch 167; iter: 0; batch classifier loss: 0.333343; batch adversarial loss: 0.437683\n",
      "epoch 168; iter: 0; batch classifier loss: 0.306079; batch adversarial loss: 0.454642\n",
      "epoch 169; iter: 0; batch classifier loss: 0.342161; batch adversarial loss: 0.492878\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398873; batch adversarial loss: 0.481055\n",
      "epoch 171; iter: 0; batch classifier loss: 0.437554; batch adversarial loss: 0.501098\n",
      "epoch 172; iter: 0; batch classifier loss: 0.481187; batch adversarial loss: 0.446059\n",
      "epoch 173; iter: 0; batch classifier loss: 0.456758; batch adversarial loss: 0.424314\n",
      "epoch 174; iter: 0; batch classifier loss: 0.340187; batch adversarial loss: 0.408564\n",
      "epoch 175; iter: 0; batch classifier loss: 0.314009; batch adversarial loss: 0.454116\n",
      "epoch 176; iter: 0; batch classifier loss: 0.304574; batch adversarial loss: 0.514096\n",
      "epoch 177; iter: 0; batch classifier loss: 0.491162; batch adversarial loss: 0.573596\n",
      "epoch 178; iter: 0; batch classifier loss: 0.335280; batch adversarial loss: 0.522100\n",
      "epoch 179; iter: 0; batch classifier loss: 0.430701; batch adversarial loss: 0.455135\n",
      "epoch 180; iter: 0; batch classifier loss: 0.468368; batch adversarial loss: 0.407416\n",
      "epoch 181; iter: 0; batch classifier loss: 0.368085; batch adversarial loss: 0.542527\n",
      "epoch 182; iter: 0; batch classifier loss: 0.460590; batch adversarial loss: 0.361441\n",
      "epoch 183; iter: 0; batch classifier loss: 0.386668; batch adversarial loss: 0.443585\n",
      "epoch 184; iter: 0; batch classifier loss: 0.399174; batch adversarial loss: 0.508444\n",
      "epoch 185; iter: 0; batch classifier loss: 0.371277; batch adversarial loss: 0.430906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.410498; batch adversarial loss: 0.464517\n",
      "epoch 187; iter: 0; batch classifier loss: 0.304205; batch adversarial loss: 0.485170\n",
      "epoch 188; iter: 0; batch classifier loss: 0.385373; batch adversarial loss: 0.516309\n",
      "epoch 189; iter: 0; batch classifier loss: 0.261404; batch adversarial loss: 0.580942\n",
      "epoch 190; iter: 0; batch classifier loss: 0.406916; batch adversarial loss: 0.443790\n",
      "epoch 191; iter: 0; batch classifier loss: 0.325467; batch adversarial loss: 0.420991\n",
      "epoch 192; iter: 0; batch classifier loss: 0.299046; batch adversarial loss: 0.457643\n",
      "epoch 193; iter: 0; batch classifier loss: 0.395880; batch adversarial loss: 0.513009\n",
      "epoch 194; iter: 0; batch classifier loss: 0.366889; batch adversarial loss: 0.524895\n",
      "epoch 195; iter: 0; batch classifier loss: 0.464668; batch adversarial loss: 0.461728\n",
      "epoch 196; iter: 0; batch classifier loss: 0.379743; batch adversarial loss: 0.427195\n",
      "epoch 197; iter: 0; batch classifier loss: 0.276508; batch adversarial loss: 0.418646\n",
      "epoch 198; iter: 0; batch classifier loss: 0.353563; batch adversarial loss: 0.453508\n",
      "epoch 199; iter: 0; batch classifier loss: 0.375596; batch adversarial loss: 0.642552\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.182094; batch adversarial loss: 0.861699\n",
      "epoch 2; iter: 0; batch classifier loss: 1.036524; batch adversarial loss: 0.834301\n",
      "epoch 3; iter: 0; batch classifier loss: 1.010488; batch adversarial loss: 0.745336\n",
      "epoch 4; iter: 0; batch classifier loss: 0.800988; batch adversarial loss: 0.734872\n",
      "epoch 5; iter: 0; batch classifier loss: 0.619195; batch adversarial loss: 0.690817\n",
      "epoch 6; iter: 0; batch classifier loss: 0.526470; batch adversarial loss: 0.667743\n",
      "epoch 7; iter: 0; batch classifier loss: 0.499001; batch adversarial loss: 0.630375\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562321; batch adversarial loss: 0.614469\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504364; batch adversarial loss: 0.593745\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565529; batch adversarial loss: 0.590325\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542733; batch adversarial loss: 0.595916\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555061; batch adversarial loss: 0.577820\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514233; batch adversarial loss: 0.551555\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462438; batch adversarial loss: 0.551499\n",
      "epoch 15; iter: 0; batch classifier loss: 0.572153; batch adversarial loss: 0.581938\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526882; batch adversarial loss: 0.534279\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519485; batch adversarial loss: 0.542688\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532085; batch adversarial loss: 0.532949\n",
      "epoch 19; iter: 0; batch classifier loss: 0.555947; batch adversarial loss: 0.563077\n",
      "epoch 20; iter: 0; batch classifier loss: 0.619695; batch adversarial loss: 0.486586\n",
      "epoch 21; iter: 0; batch classifier loss: 0.578845; batch adversarial loss: 0.533972\n",
      "epoch 22; iter: 0; batch classifier loss: 0.633329; batch adversarial loss: 0.550644\n",
      "epoch 23; iter: 0; batch classifier loss: 0.604540; batch adversarial loss: 0.560834\n",
      "epoch 24; iter: 0; batch classifier loss: 0.588595; batch adversarial loss: 0.511834\n",
      "epoch 25; iter: 0; batch classifier loss: 0.787770; batch adversarial loss: 0.584885\n",
      "epoch 26; iter: 0; batch classifier loss: 0.653732; batch adversarial loss: 0.526846\n",
      "epoch 27; iter: 0; batch classifier loss: 0.680105; batch adversarial loss: 0.645918\n",
      "epoch 28; iter: 0; batch classifier loss: 0.588044; batch adversarial loss: 0.526909\n",
      "epoch 29; iter: 0; batch classifier loss: 0.638443; batch adversarial loss: 0.538075\n",
      "epoch 30; iter: 0; batch classifier loss: 0.532539; batch adversarial loss: 0.544406\n",
      "epoch 31; iter: 0; batch classifier loss: 0.538541; batch adversarial loss: 0.490688\n",
      "epoch 32; iter: 0; batch classifier loss: 0.527136; batch adversarial loss: 0.510784\n",
      "epoch 33; iter: 0; batch classifier loss: 0.474213; batch adversarial loss: 0.519051\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477512; batch adversarial loss: 0.539570\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488707; batch adversarial loss: 0.481679\n",
      "epoch 36; iter: 0; batch classifier loss: 0.509994; batch adversarial loss: 0.459024\n",
      "epoch 37; iter: 0; batch classifier loss: 0.548237; batch adversarial loss: 0.532958\n",
      "epoch 38; iter: 0; batch classifier loss: 0.547423; batch adversarial loss: 0.417652\n",
      "epoch 39; iter: 0; batch classifier loss: 0.588287; batch adversarial loss: 0.466684\n",
      "epoch 40; iter: 0; batch classifier loss: 0.585400; batch adversarial loss: 0.451421\n",
      "epoch 41; iter: 0; batch classifier loss: 0.631809; batch adversarial loss: 0.535983\n",
      "epoch 42; iter: 0; batch classifier loss: 0.502605; batch adversarial loss: 0.455119\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475317; batch adversarial loss: 0.461484\n",
      "epoch 44; iter: 0; batch classifier loss: 0.489535; batch adversarial loss: 0.411158\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428612; batch adversarial loss: 0.446635\n",
      "epoch 46; iter: 0; batch classifier loss: 0.501927; batch adversarial loss: 0.536191\n",
      "epoch 47; iter: 0; batch classifier loss: 0.526402; batch adversarial loss: 0.506223\n",
      "epoch 48; iter: 0; batch classifier loss: 0.591244; batch adversarial loss: 0.433512\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439084; batch adversarial loss: 0.471651\n",
      "epoch 50; iter: 0; batch classifier loss: 0.472921; batch adversarial loss: 0.504531\n",
      "epoch 51; iter: 0; batch classifier loss: 0.480466; batch adversarial loss: 0.483271\n",
      "epoch 52; iter: 0; batch classifier loss: 0.453499; batch adversarial loss: 0.426112\n",
      "epoch 53; iter: 0; batch classifier loss: 0.470083; batch adversarial loss: 0.426485\n",
      "epoch 54; iter: 0; batch classifier loss: 0.520847; batch adversarial loss: 0.446588\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483456; batch adversarial loss: 0.365243\n",
      "epoch 56; iter: 0; batch classifier loss: 0.425538; batch adversarial loss: 0.523851\n",
      "epoch 57; iter: 0; batch classifier loss: 0.403221; batch adversarial loss: 0.499025\n",
      "epoch 58; iter: 0; batch classifier loss: 0.461986; batch adversarial loss: 0.452920\n",
      "epoch 59; iter: 0; batch classifier loss: 0.417795; batch adversarial loss: 0.465899\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455736; batch adversarial loss: 0.596983\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422371; batch adversarial loss: 0.539459\n",
      "epoch 62; iter: 0; batch classifier loss: 0.451190; batch adversarial loss: 0.470487\n",
      "epoch 63; iter: 0; batch classifier loss: 0.426073; batch adversarial loss: 0.449344\n",
      "epoch 64; iter: 0; batch classifier loss: 0.385113; batch adversarial loss: 0.440012\n",
      "epoch 65; iter: 0; batch classifier loss: 0.384028; batch adversarial loss: 0.503104\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439274; batch adversarial loss: 0.450379\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412147; batch adversarial loss: 0.456016\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410206; batch adversarial loss: 0.432838\n",
      "epoch 69; iter: 0; batch classifier loss: 0.447725; batch adversarial loss: 0.454346\n",
      "epoch 70; iter: 0; batch classifier loss: 0.474430; batch adversarial loss: 0.469682\n",
      "epoch 71; iter: 0; batch classifier loss: 0.405763; batch adversarial loss: 0.425891\n",
      "epoch 72; iter: 0; batch classifier loss: 0.472917; batch adversarial loss: 0.530386\n",
      "epoch 73; iter: 0; batch classifier loss: 0.447341; batch adversarial loss: 0.528358\n",
      "epoch 74; iter: 0; batch classifier loss: 0.481564; batch adversarial loss: 0.443603\n",
      "epoch 75; iter: 0; batch classifier loss: 0.498565; batch adversarial loss: 0.481767\n",
      "epoch 76; iter: 0; batch classifier loss: 0.471786; batch adversarial loss: 0.528350\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402056; batch adversarial loss: 0.440008\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382623; batch adversarial loss: 0.526395\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400511; batch adversarial loss: 0.413258\n",
      "epoch 80; iter: 0; batch classifier loss: 0.448177; batch adversarial loss: 0.452635\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395914; batch adversarial loss: 0.485520\n",
      "epoch 82; iter: 0; batch classifier loss: 0.397632; batch adversarial loss: 0.437333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.418280; batch adversarial loss: 0.447983\n",
      "epoch 84; iter: 0; batch classifier loss: 0.382218; batch adversarial loss: 0.462402\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347690; batch adversarial loss: 0.483035\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420516; batch adversarial loss: 0.469121\n",
      "epoch 87; iter: 0; batch classifier loss: 0.358523; batch adversarial loss: 0.521251\n",
      "epoch 88; iter: 0; batch classifier loss: 0.438905; batch adversarial loss: 0.420101\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397549; batch adversarial loss: 0.452857\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409452; batch adversarial loss: 0.454757\n",
      "epoch 91; iter: 0; batch classifier loss: 0.396900; batch adversarial loss: 0.495891\n",
      "epoch 92; iter: 0; batch classifier loss: 0.413305; batch adversarial loss: 0.603784\n",
      "epoch 93; iter: 0; batch classifier loss: 0.475582; batch adversarial loss: 0.612197\n",
      "epoch 94; iter: 0; batch classifier loss: 0.311368; batch adversarial loss: 0.497134\n",
      "epoch 95; iter: 0; batch classifier loss: 0.283347; batch adversarial loss: 0.486905\n",
      "epoch 96; iter: 0; batch classifier loss: 0.340523; batch adversarial loss: 0.514507\n",
      "epoch 97; iter: 0; batch classifier loss: 0.480681; batch adversarial loss: 0.361894\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376665; batch adversarial loss: 0.481314\n",
      "epoch 99; iter: 0; batch classifier loss: 0.479161; batch adversarial loss: 0.507167\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.141827; batch adversarial loss: 0.859715\n",
      "epoch 2; iter: 0; batch classifier loss: 0.999535; batch adversarial loss: 0.832161\n",
      "epoch 3; iter: 0; batch classifier loss: 0.958312; batch adversarial loss: 0.743384\n",
      "epoch 4; iter: 0; batch classifier loss: 0.758641; batch adversarial loss: 0.731667\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578190; batch adversarial loss: 0.688027\n",
      "epoch 6; iter: 0; batch classifier loss: 0.514975; batch adversarial loss: 0.665941\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493131; batch adversarial loss: 0.630958\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561022; batch adversarial loss: 0.615389\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502201; batch adversarial loss: 0.594903\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564260; batch adversarial loss: 0.591087\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544938; batch adversarial loss: 0.596090\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557870; batch adversarial loss: 0.578016\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516560; batch adversarial loss: 0.551441\n",
      "epoch 14; iter: 0; batch classifier loss: 0.465555; batch adversarial loss: 0.550502\n",
      "epoch 15; iter: 0; batch classifier loss: 0.576584; batch adversarial loss: 0.579483\n",
      "epoch 16; iter: 0; batch classifier loss: 0.530394; batch adversarial loss: 0.530116\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524934; batch adversarial loss: 0.539443\n",
      "epoch 18; iter: 0; batch classifier loss: 0.525907; batch adversarial loss: 0.528767\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535458; batch adversarial loss: 0.551720\n",
      "epoch 20; iter: 0; batch classifier loss: 0.592427; batch adversarial loss: 0.475621\n",
      "epoch 21; iter: 0; batch classifier loss: 0.548479; batch adversarial loss: 0.524839\n",
      "epoch 22; iter: 0; batch classifier loss: 0.590482; batch adversarial loss: 0.536507\n",
      "epoch 23; iter: 0; batch classifier loss: 0.548302; batch adversarial loss: 0.550834\n",
      "epoch 24; iter: 0; batch classifier loss: 0.556039; batch adversarial loss: 0.507423\n",
      "epoch 25; iter: 0; batch classifier loss: 0.776223; batch adversarial loss: 0.591562\n",
      "epoch 26; iter: 0; batch classifier loss: 0.660227; batch adversarial loss: 0.534063\n",
      "epoch 27; iter: 0; batch classifier loss: 0.717124; batch adversarial loss: 0.659373\n",
      "epoch 28; iter: 0; batch classifier loss: 0.606094; batch adversarial loss: 0.531872\n",
      "epoch 29; iter: 0; batch classifier loss: 0.667382; batch adversarial loss: 0.544958\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550614; batch adversarial loss: 0.550189\n",
      "epoch 31; iter: 0; batch classifier loss: 0.545873; batch adversarial loss: 0.493870\n",
      "epoch 32; iter: 0; batch classifier loss: 0.539477; batch adversarial loss: 0.514035\n",
      "epoch 33; iter: 0; batch classifier loss: 0.491108; batch adversarial loss: 0.522785\n",
      "epoch 34; iter: 0; batch classifier loss: 0.486360; batch adversarial loss: 0.542504\n",
      "epoch 35; iter: 0; batch classifier loss: 0.481259; batch adversarial loss: 0.482457\n",
      "epoch 36; iter: 0; batch classifier loss: 0.509525; batch adversarial loss: 0.459194\n",
      "epoch 37; iter: 0; batch classifier loss: 0.526193; batch adversarial loss: 0.531663\n",
      "epoch 38; iter: 0; batch classifier loss: 0.529651; batch adversarial loss: 0.416090\n",
      "epoch 39; iter: 0; batch classifier loss: 0.551694; batch adversarial loss: 0.464607\n",
      "epoch 40; iter: 0; batch classifier loss: 0.570474; batch adversarial loss: 0.450718\n",
      "epoch 41; iter: 0; batch classifier loss: 0.619764; batch adversarial loss: 0.537944\n",
      "epoch 42; iter: 0; batch classifier loss: 0.507754; batch adversarial loss: 0.456970\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486167; batch adversarial loss: 0.463652\n",
      "epoch 44; iter: 0; batch classifier loss: 0.508657; batch adversarial loss: 0.412612\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432922; batch adversarial loss: 0.447816\n",
      "epoch 46; iter: 0; batch classifier loss: 0.510323; batch adversarial loss: 0.536723\n",
      "epoch 47; iter: 0; batch classifier loss: 0.520585; batch adversarial loss: 0.505868\n",
      "epoch 48; iter: 0; batch classifier loss: 0.536883; batch adversarial loss: 0.433487\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429454; batch adversarial loss: 0.471678\n",
      "epoch 50; iter: 0; batch classifier loss: 0.470016; batch adversarial loss: 0.504683\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466169; batch adversarial loss: 0.483258\n",
      "epoch 52; iter: 0; batch classifier loss: 0.448635; batch adversarial loss: 0.426191\n",
      "epoch 53; iter: 0; batch classifier loss: 0.467606; batch adversarial loss: 0.426309\n",
      "epoch 54; iter: 0; batch classifier loss: 0.504678; batch adversarial loss: 0.446331\n",
      "epoch 55; iter: 0; batch classifier loss: 0.486363; batch adversarial loss: 0.365737\n",
      "epoch 56; iter: 0; batch classifier loss: 0.418731; batch adversarial loss: 0.523891\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404568; batch adversarial loss: 0.498852\n",
      "epoch 58; iter: 0; batch classifier loss: 0.455177; batch adversarial loss: 0.453112\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414398; batch adversarial loss: 0.465944\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444405; batch adversarial loss: 0.596720\n",
      "epoch 61; iter: 0; batch classifier loss: 0.428993; batch adversarial loss: 0.539397\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436978; batch adversarial loss: 0.470956\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432303; batch adversarial loss: 0.449883\n",
      "epoch 64; iter: 0; batch classifier loss: 0.383423; batch adversarial loss: 0.440112\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379230; batch adversarial loss: 0.503973\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435208; batch adversarial loss: 0.450207\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409474; batch adversarial loss: 0.455933\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410112; batch adversarial loss: 0.432571\n",
      "epoch 69; iter: 0; batch classifier loss: 0.437572; batch adversarial loss: 0.453856\n",
      "epoch 70; iter: 0; batch classifier loss: 0.464212; batch adversarial loss: 0.469142\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410130; batch adversarial loss: 0.425140\n",
      "epoch 72; iter: 0; batch classifier loss: 0.474756; batch adversarial loss: 0.530782\n",
      "epoch 73; iter: 0; batch classifier loss: 0.439530; batch adversarial loss: 0.529176\n",
      "epoch 74; iter: 0; batch classifier loss: 0.474442; batch adversarial loss: 0.445103\n",
      "epoch 75; iter: 0; batch classifier loss: 0.494718; batch adversarial loss: 0.481975\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461883; batch adversarial loss: 0.529241\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409165; batch adversarial loss: 0.440640\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358644; batch adversarial loss: 0.526547\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400138; batch adversarial loss: 0.414180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.442891; batch adversarial loss: 0.452807\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389981; batch adversarial loss: 0.485578\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386216; batch adversarial loss: 0.436650\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409400; batch adversarial loss: 0.447516\n",
      "epoch 84; iter: 0; batch classifier loss: 0.373697; batch adversarial loss: 0.462642\n",
      "epoch 85; iter: 0; batch classifier loss: 0.347762; batch adversarial loss: 0.483757\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418750; batch adversarial loss: 0.469283\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366546; batch adversarial loss: 0.522333\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422282; batch adversarial loss: 0.419666\n",
      "epoch 89; iter: 0; batch classifier loss: 0.394585; batch adversarial loss: 0.453502\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399472; batch adversarial loss: 0.454279\n",
      "epoch 91; iter: 0; batch classifier loss: 0.377407; batch adversarial loss: 0.495333\n",
      "epoch 92; iter: 0; batch classifier loss: 0.410491; batch adversarial loss: 0.604950\n",
      "epoch 93; iter: 0; batch classifier loss: 0.450214; batch adversarial loss: 0.613868\n",
      "epoch 94; iter: 0; batch classifier loss: 0.302355; batch adversarial loss: 0.497413\n",
      "epoch 95; iter: 0; batch classifier loss: 0.280367; batch adversarial loss: 0.485192\n",
      "epoch 96; iter: 0; batch classifier loss: 0.324433; batch adversarial loss: 0.515964\n",
      "epoch 97; iter: 0; batch classifier loss: 0.459085; batch adversarial loss: 0.360912\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383239; batch adversarial loss: 0.482619\n",
      "epoch 99; iter: 0; batch classifier loss: 0.467458; batch adversarial loss: 0.506482\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.089267; batch adversarial loss: 0.856428\n",
      "epoch 2; iter: 0; batch classifier loss: 0.942360; batch adversarial loss: 0.828161\n",
      "epoch 3; iter: 0; batch classifier loss: 0.883129; batch adversarial loss: 0.739480\n",
      "epoch 4; iter: 0; batch classifier loss: 0.703418; batch adversarial loss: 0.726673\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534428; batch adversarial loss: 0.683598\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509580; batch adversarial loss: 0.664930\n",
      "epoch 7; iter: 0; batch classifier loss: 0.489075; batch adversarial loss: 0.631706\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561649; batch adversarial loss: 0.615960\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501440; batch adversarial loss: 0.595866\n",
      "epoch 10; iter: 0; batch classifier loss: 0.567041; batch adversarial loss: 0.591448\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549019; batch adversarial loss: 0.596189\n",
      "epoch 12; iter: 0; batch classifier loss: 0.561600; batch adversarial loss: 0.578489\n",
      "epoch 13; iter: 0; batch classifier loss: 0.526962; batch adversarial loss: 0.550916\n",
      "epoch 14; iter: 0; batch classifier loss: 0.475500; batch adversarial loss: 0.549472\n",
      "epoch 15; iter: 0; batch classifier loss: 0.585102; batch adversarial loss: 0.576481\n",
      "epoch 16; iter: 0; batch classifier loss: 0.541777; batch adversarial loss: 0.522419\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533464; batch adversarial loss: 0.534771\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524776; batch adversarial loss: 0.525114\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526771; batch adversarial loss: 0.543280\n",
      "epoch 20; iter: 0; batch classifier loss: 0.570897; batch adversarial loss: 0.463764\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501174; batch adversarial loss: 0.505525\n",
      "epoch 22; iter: 0; batch classifier loss: 0.539694; batch adversarial loss: 0.519434\n",
      "epoch 23; iter: 0; batch classifier loss: 0.492061; batch adversarial loss: 0.529465\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498807; batch adversarial loss: 0.487357\n",
      "epoch 25; iter: 0; batch classifier loss: 0.657789; batch adversarial loss: 0.573633\n",
      "epoch 26; iter: 0; batch classifier loss: 0.592670; batch adversarial loss: 0.529464\n",
      "epoch 27; iter: 0; batch classifier loss: 0.677714; batch adversarial loss: 0.673115\n",
      "epoch 28; iter: 0; batch classifier loss: 0.600373; batch adversarial loss: 0.537520\n",
      "epoch 29; iter: 0; batch classifier loss: 0.703522; batch adversarial loss: 0.560071\n",
      "epoch 30; iter: 0; batch classifier loss: 0.598614; batch adversarial loss: 0.568424\n",
      "epoch 31; iter: 0; batch classifier loss: 0.581547; batch adversarial loss: 0.504450\n",
      "epoch 32; iter: 0; batch classifier loss: 0.585219; batch adversarial loss: 0.525233\n",
      "epoch 33; iter: 0; batch classifier loss: 0.570112; batch adversarial loss: 0.539971\n",
      "epoch 34; iter: 0; batch classifier loss: 0.559030; batch adversarial loss: 0.556807\n",
      "epoch 35; iter: 0; batch classifier loss: 0.502081; batch adversarial loss: 0.490222\n",
      "epoch 36; iter: 0; batch classifier loss: 0.509187; batch adversarial loss: 0.463565\n",
      "epoch 37; iter: 0; batch classifier loss: 0.548332; batch adversarial loss: 0.534566\n",
      "epoch 38; iter: 0; batch classifier loss: 0.519455; batch adversarial loss: 0.417648\n",
      "epoch 39; iter: 0; batch classifier loss: 0.529584; batch adversarial loss: 0.462310\n",
      "epoch 40; iter: 0; batch classifier loss: 0.534352; batch adversarial loss: 0.447704\n",
      "epoch 41; iter: 0; batch classifier loss: 0.562027; batch adversarial loss: 0.533083\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462784; batch adversarial loss: 0.453468\n",
      "epoch 43; iter: 0; batch classifier loss: 0.462955; batch adversarial loss: 0.462776\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490795; batch adversarial loss: 0.412610\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424295; batch adversarial loss: 0.447057\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500584; batch adversarial loss: 0.540909\n",
      "epoch 47; iter: 0; batch classifier loss: 0.510334; batch adversarial loss: 0.510011\n",
      "epoch 48; iter: 0; batch classifier loss: 0.587476; batch adversarial loss: 0.435641\n",
      "epoch 49; iter: 0; batch classifier loss: 0.525593; batch adversarial loss: 0.473377\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465781; batch adversarial loss: 0.504484\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466026; batch adversarial loss: 0.483513\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440908; batch adversarial loss: 0.426596\n",
      "epoch 53; iter: 0; batch classifier loss: 0.462163; batch adversarial loss: 0.426610\n",
      "epoch 54; iter: 0; batch classifier loss: 0.504852; batch adversarial loss: 0.446307\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487048; batch adversarial loss: 0.366255\n",
      "epoch 56; iter: 0; batch classifier loss: 0.412107; batch adversarial loss: 0.523207\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396982; batch adversarial loss: 0.498439\n",
      "epoch 58; iter: 0; batch classifier loss: 0.447660; batch adversarial loss: 0.452817\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410010; batch adversarial loss: 0.465268\n",
      "epoch 60; iter: 0; batch classifier loss: 0.435878; batch adversarial loss: 0.596524\n",
      "epoch 61; iter: 0; batch classifier loss: 0.402714; batch adversarial loss: 0.538312\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433904; batch adversarial loss: 0.470587\n",
      "epoch 63; iter: 0; batch classifier loss: 0.424887; batch adversarial loss: 0.449583\n",
      "epoch 64; iter: 0; batch classifier loss: 0.380664; batch adversarial loss: 0.439672\n",
      "epoch 65; iter: 0; batch classifier loss: 0.376400; batch adversarial loss: 0.504373\n",
      "epoch 66; iter: 0; batch classifier loss: 0.416584; batch adversarial loss: 0.449645\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405997; batch adversarial loss: 0.456683\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395425; batch adversarial loss: 0.432262\n",
      "epoch 69; iter: 0; batch classifier loss: 0.431551; batch adversarial loss: 0.453422\n",
      "epoch 70; iter: 0; batch classifier loss: 0.461695; batch adversarial loss: 0.469566\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406662; batch adversarial loss: 0.424960\n",
      "epoch 72; iter: 0; batch classifier loss: 0.464724; batch adversarial loss: 0.530476\n",
      "epoch 73; iter: 0; batch classifier loss: 0.419558; batch adversarial loss: 0.529589\n",
      "epoch 74; iter: 0; batch classifier loss: 0.460216; batch adversarial loss: 0.445388\n",
      "epoch 75; iter: 0; batch classifier loss: 0.485182; batch adversarial loss: 0.481624\n",
      "epoch 76; iter: 0; batch classifier loss: 0.444891; batch adversarial loss: 0.528252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.387146; batch adversarial loss: 0.440294\n",
      "epoch 78; iter: 0; batch classifier loss: 0.373106; batch adversarial loss: 0.526874\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400242; batch adversarial loss: 0.414259\n",
      "epoch 80; iter: 0; batch classifier loss: 0.445541; batch adversarial loss: 0.452702\n",
      "epoch 81; iter: 0; batch classifier loss: 0.390850; batch adversarial loss: 0.484261\n",
      "epoch 82; iter: 0; batch classifier loss: 0.369101; batch adversarial loss: 0.435851\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402658; batch adversarial loss: 0.446724\n",
      "epoch 84; iter: 0; batch classifier loss: 0.367434; batch adversarial loss: 0.462344\n",
      "epoch 85; iter: 0; batch classifier loss: 0.345674; batch adversarial loss: 0.483838\n",
      "epoch 86; iter: 0; batch classifier loss: 0.425250; batch adversarial loss: 0.468888\n",
      "epoch 87; iter: 0; batch classifier loss: 0.366999; batch adversarial loss: 0.521356\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420983; batch adversarial loss: 0.418503\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390304; batch adversarial loss: 0.453587\n",
      "epoch 90; iter: 0; batch classifier loss: 0.402488; batch adversarial loss: 0.453338\n",
      "epoch 91; iter: 0; batch classifier loss: 0.387813; batch adversarial loss: 0.494612\n",
      "epoch 92; iter: 0; batch classifier loss: 0.393821; batch adversarial loss: 0.604591\n",
      "epoch 93; iter: 0; batch classifier loss: 0.456886; batch adversarial loss: 0.614216\n",
      "epoch 94; iter: 0; batch classifier loss: 0.301354; batch adversarial loss: 0.496445\n",
      "epoch 95; iter: 0; batch classifier loss: 0.283663; batch adversarial loss: 0.484493\n",
      "epoch 96; iter: 0; batch classifier loss: 0.342490; batch adversarial loss: 0.515105\n",
      "epoch 97; iter: 0; batch classifier loss: 0.439796; batch adversarial loss: 0.360230\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368921; batch adversarial loss: 0.482736\n",
      "epoch 99; iter: 0; batch classifier loss: 0.442079; batch adversarial loss: 0.504776\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 0.997180; batch adversarial loss: 0.848625\n",
      "epoch 2; iter: 0; batch classifier loss: 0.862084; batch adversarial loss: 0.819853\n",
      "epoch 3; iter: 0; batch classifier loss: 0.772549; batch adversarial loss: 0.730728\n",
      "epoch 4; iter: 0; batch classifier loss: 0.634014; batch adversarial loss: 0.716954\n",
      "epoch 5; iter: 0; batch classifier loss: 0.499529; batch adversarial loss: 0.676535\n",
      "epoch 6; iter: 0; batch classifier loss: 0.511978; batch adversarial loss: 0.663928\n",
      "epoch 7; iter: 0; batch classifier loss: 0.489803; batch adversarial loss: 0.631981\n",
      "epoch 8; iter: 0; batch classifier loss: 0.563926; batch adversarial loss: 0.616079\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501624; batch adversarial loss: 0.596177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574217; batch adversarial loss: 0.589726\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560622; batch adversarial loss: 0.593901\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571455; batch adversarial loss: 0.577736\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546980; batch adversarial loss: 0.548227\n",
      "epoch 14; iter: 0; batch classifier loss: 0.495981; batch adversarial loss: 0.548115\n",
      "epoch 15; iter: 0; batch classifier loss: 0.596059; batch adversarial loss: 0.576275\n",
      "epoch 16; iter: 0; batch classifier loss: 0.567844; batch adversarial loss: 0.514544\n",
      "epoch 17; iter: 0; batch classifier loss: 0.561298; batch adversarial loss: 0.526276\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523485; batch adversarial loss: 0.517946\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525146; batch adversarial loss: 0.535137\n",
      "epoch 20; iter: 0; batch classifier loss: 0.561049; batch adversarial loss: 0.455218\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478879; batch adversarial loss: 0.488002\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490923; batch adversarial loss: 0.498067\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467880; batch adversarial loss: 0.499718\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458430; batch adversarial loss: 0.462051\n",
      "epoch 25; iter: 0; batch classifier loss: 0.593565; batch adversarial loss: 0.540404\n",
      "epoch 26; iter: 0; batch classifier loss: 0.540699; batch adversarial loss: 0.512441\n",
      "epoch 27; iter: 0; batch classifier loss: 0.559436; batch adversarial loss: 0.650654\n",
      "epoch 28; iter: 0; batch classifier loss: 0.519459; batch adversarial loss: 0.517257\n",
      "epoch 29; iter: 0; batch classifier loss: 0.576740; batch adversarial loss: 0.547834\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480459; batch adversarial loss: 0.554196\n",
      "epoch 31; iter: 0; batch classifier loss: 0.546472; batch adversarial loss: 0.504481\n",
      "epoch 32; iter: 0; batch classifier loss: 0.580417; batch adversarial loss: 0.536169\n",
      "epoch 33; iter: 0; batch classifier loss: 0.569644; batch adversarial loss: 0.556742\n",
      "epoch 34; iter: 0; batch classifier loss: 0.619685; batch adversarial loss: 0.586176\n",
      "epoch 35; iter: 0; batch classifier loss: 0.544169; batch adversarial loss: 0.507449\n",
      "epoch 36; iter: 0; batch classifier loss: 0.551859; batch adversarial loss: 0.476560\n",
      "epoch 37; iter: 0; batch classifier loss: 0.663975; batch adversarial loss: 0.562510\n",
      "epoch 38; iter: 0; batch classifier loss: 0.586611; batch adversarial loss: 0.430308\n",
      "epoch 39; iter: 0; batch classifier loss: 0.602746; batch adversarial loss: 0.477143\n",
      "epoch 40; iter: 0; batch classifier loss: 0.593805; batch adversarial loss: 0.457811\n",
      "epoch 41; iter: 0; batch classifier loss: 0.612698; batch adversarial loss: 0.540718\n",
      "epoch 42; iter: 0; batch classifier loss: 0.477842; batch adversarial loss: 0.459067\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469769; batch adversarial loss: 0.465427\n",
      "epoch 44; iter: 0; batch classifier loss: 0.493987; batch adversarial loss: 0.414660\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416207; batch adversarial loss: 0.447330\n",
      "epoch 46; iter: 0; batch classifier loss: 0.477775; batch adversarial loss: 0.538012\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468312; batch adversarial loss: 0.508033\n",
      "epoch 48; iter: 0; batch classifier loss: 0.535475; batch adversarial loss: 0.435004\n",
      "epoch 49; iter: 0; batch classifier loss: 0.480463; batch adversarial loss: 0.476110\n",
      "epoch 50; iter: 0; batch classifier loss: 0.535906; batch adversarial loss: 0.509030\n",
      "epoch 51; iter: 0; batch classifier loss: 0.500823; batch adversarial loss: 0.485348\n",
      "epoch 52; iter: 0; batch classifier loss: 0.441210; batch adversarial loss: 0.428166\n",
      "epoch 53; iter: 0; batch classifier loss: 0.456314; batch adversarial loss: 0.427854\n",
      "epoch 54; iter: 0; batch classifier loss: 0.492208; batch adversarial loss: 0.446930\n",
      "epoch 55; iter: 0; batch classifier loss: 0.477233; batch adversarial loss: 0.367228\n",
      "epoch 56; iter: 0; batch classifier loss: 0.399273; batch adversarial loss: 0.523416\n",
      "epoch 57; iter: 0; batch classifier loss: 0.391332; batch adversarial loss: 0.498245\n",
      "epoch 58; iter: 0; batch classifier loss: 0.442584; batch adversarial loss: 0.452795\n",
      "epoch 59; iter: 0; batch classifier loss: 0.399010; batch adversarial loss: 0.465184\n",
      "epoch 60; iter: 0; batch classifier loss: 0.427447; batch adversarial loss: 0.596169\n",
      "epoch 61; iter: 0; batch classifier loss: 0.400328; batch adversarial loss: 0.537793\n",
      "epoch 62; iter: 0; batch classifier loss: 0.429760; batch adversarial loss: 0.470632\n",
      "epoch 63; iter: 0; batch classifier loss: 0.428407; batch adversarial loss: 0.449528\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375063; batch adversarial loss: 0.439745\n",
      "epoch 65; iter: 0; batch classifier loss: 0.358233; batch adversarial loss: 0.504061\n",
      "epoch 66; iter: 0; batch classifier loss: 0.418618; batch adversarial loss: 0.449582\n",
      "epoch 67; iter: 0; batch classifier loss: 0.386931; batch adversarial loss: 0.456994\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394805; batch adversarial loss: 0.433358\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410010; batch adversarial loss: 0.452485\n",
      "epoch 70; iter: 0; batch classifier loss: 0.460491; batch adversarial loss: 0.470913\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402968; batch adversarial loss: 0.424070\n",
      "epoch 72; iter: 0; batch classifier loss: 0.458569; batch adversarial loss: 0.529881\n",
      "epoch 73; iter: 0; batch classifier loss: 0.417886; batch adversarial loss: 0.530483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.449500; batch adversarial loss: 0.446910\n",
      "epoch 75; iter: 0; batch classifier loss: 0.477843; batch adversarial loss: 0.481621\n",
      "epoch 76; iter: 0; batch classifier loss: 0.448670; batch adversarial loss: 0.528018\n",
      "epoch 77; iter: 0; batch classifier loss: 0.389763; batch adversarial loss: 0.440800\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358681; batch adversarial loss: 0.527092\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367920; batch adversarial loss: 0.415860\n",
      "epoch 80; iter: 0; batch classifier loss: 0.431310; batch adversarial loss: 0.452260\n",
      "epoch 81; iter: 0; batch classifier loss: 0.405001; batch adversarial loss: 0.484684\n",
      "epoch 82; iter: 0; batch classifier loss: 0.358400; batch adversarial loss: 0.434528\n",
      "epoch 83; iter: 0; batch classifier loss: 0.410680; batch adversarial loss: 0.446455\n",
      "epoch 84; iter: 0; batch classifier loss: 0.333969; batch adversarial loss: 0.460738\n",
      "epoch 85; iter: 0; batch classifier loss: 0.325810; batch adversarial loss: 0.483529\n",
      "epoch 86; iter: 0; batch classifier loss: 0.445457; batch adversarial loss: 0.468798\n",
      "epoch 87; iter: 0; batch classifier loss: 0.357672; batch adversarial loss: 0.522061\n",
      "epoch 88; iter: 0; batch classifier loss: 0.428837; batch adversarial loss: 0.418823\n",
      "epoch 89; iter: 0; batch classifier loss: 0.361857; batch adversarial loss: 0.452591\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370815; batch adversarial loss: 0.452512\n",
      "epoch 91; iter: 0; batch classifier loss: 0.375719; batch adversarial loss: 0.494162\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396223; batch adversarial loss: 0.604439\n",
      "epoch 93; iter: 0; batch classifier loss: 0.449617; batch adversarial loss: 0.612854\n",
      "epoch 94; iter: 0; batch classifier loss: 0.299138; batch adversarial loss: 0.494152\n",
      "epoch 95; iter: 0; batch classifier loss: 0.276028; batch adversarial loss: 0.484730\n",
      "epoch 96; iter: 0; batch classifier loss: 0.331752; batch adversarial loss: 0.515168\n",
      "epoch 97; iter: 0; batch classifier loss: 0.406264; batch adversarial loss: 0.358410\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382005; batch adversarial loss: 0.483065\n",
      "epoch 99; iter: 0; batch classifier loss: 0.453900; batch adversarial loss: 0.506279\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.097056; batch adversarial loss: 0.856961\n",
      "epoch 2; iter: 0; batch classifier loss: 0.950367; batch adversarial loss: 0.828766\n",
      "epoch 3; iter: 0; batch classifier loss: 0.892699; batch adversarial loss: 0.740186\n",
      "epoch 4; iter: 0; batch classifier loss: 0.710884; batch adversarial loss: 0.727545\n",
      "epoch 5; iter: 0; batch classifier loss: 0.539539; batch adversarial loss: 0.684297\n",
      "epoch 6; iter: 0; batch classifier loss: 0.510218; batch adversarial loss: 0.664923\n",
      "epoch 7; iter: 0; batch classifier loss: 0.489035; batch adversarial loss: 0.631680\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561793; batch adversarial loss: 0.615810\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501082; batch adversarial loss: 0.595783\n",
      "epoch 10; iter: 0; batch classifier loss: 0.567004; batch adversarial loss: 0.591380\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549133; batch adversarial loss: 0.596086\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560825; batch adversarial loss: 0.578459\n",
      "epoch 13; iter: 0; batch classifier loss: 0.523862; batch adversarial loss: 0.551291\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473312; batch adversarial loss: 0.549597\n",
      "epoch 15; iter: 0; batch classifier loss: 0.584188; batch adversarial loss: 0.576912\n",
      "epoch 16; iter: 0; batch classifier loss: 0.536951; batch adversarial loss: 0.524058\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532533; batch adversarial loss: 0.535555\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523234; batch adversarial loss: 0.525764\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526960; batch adversarial loss: 0.543985\n",
      "epoch 20; iter: 0; batch classifier loss: 0.572476; batch adversarial loss: 0.464894\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504386; batch adversarial loss: 0.507463\n",
      "epoch 22; iter: 0; batch classifier loss: 0.543802; batch adversarial loss: 0.521604\n",
      "epoch 23; iter: 0; batch classifier loss: 0.495844; batch adversarial loss: 0.531313\n",
      "epoch 24; iter: 0; batch classifier loss: 0.502691; batch adversarial loss: 0.488732\n",
      "epoch 25; iter: 0; batch classifier loss: 0.660569; batch adversarial loss: 0.574367\n",
      "epoch 26; iter: 0; batch classifier loss: 0.595259; batch adversarial loss: 0.530176\n",
      "epoch 27; iter: 0; batch classifier loss: 0.676235; batch adversarial loss: 0.671637\n",
      "epoch 28; iter: 0; batch classifier loss: 0.597555; batch adversarial loss: 0.536482\n",
      "epoch 29; iter: 0; batch classifier loss: 0.704244; batch adversarial loss: 0.559531\n",
      "epoch 30; iter: 0; batch classifier loss: 0.597667; batch adversarial loss: 0.567597\n",
      "epoch 31; iter: 0; batch classifier loss: 0.579505; batch adversarial loss: 0.503844\n",
      "epoch 32; iter: 0; batch classifier loss: 0.582425; batch adversarial loss: 0.524354\n",
      "epoch 33; iter: 0; batch classifier loss: 0.565405; batch adversarial loss: 0.538629\n",
      "epoch 34; iter: 0; batch classifier loss: 0.554023; batch adversarial loss: 0.555698\n",
      "epoch 35; iter: 0; batch classifier loss: 0.503559; batch adversarial loss: 0.489575\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508300; batch adversarial loss: 0.462997\n",
      "epoch 37; iter: 0; batch classifier loss: 0.546745; batch adversarial loss: 0.534200\n",
      "epoch 38; iter: 0; batch classifier loss: 0.521561; batch adversarial loss: 0.417393\n",
      "epoch 39; iter: 0; batch classifier loss: 0.531650; batch adversarial loss: 0.462173\n",
      "epoch 40; iter: 0; batch classifier loss: 0.536157; batch adversarial loss: 0.447696\n",
      "epoch 41; iter: 0; batch classifier loss: 0.562858; batch adversarial loss: 0.533024\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464048; batch adversarial loss: 0.453720\n",
      "epoch 43; iter: 0; batch classifier loss: 0.464659; batch adversarial loss: 0.463082\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490471; batch adversarial loss: 0.412834\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427816; batch adversarial loss: 0.447608\n",
      "epoch 46; iter: 0; batch classifier loss: 0.509711; batch adversarial loss: 0.540728\n",
      "epoch 47; iter: 0; batch classifier loss: 0.521083; batch adversarial loss: 0.509657\n",
      "epoch 48; iter: 0; batch classifier loss: 0.601639; batch adversarial loss: 0.435460\n",
      "epoch 49; iter: 0; batch classifier loss: 0.497554; batch adversarial loss: 0.472484\n",
      "epoch 50; iter: 0; batch classifier loss: 0.461705; batch adversarial loss: 0.504394\n",
      "epoch 51; iter: 0; batch classifier loss: 0.462489; batch adversarial loss: 0.483424\n",
      "epoch 52; iter: 0; batch classifier loss: 0.435580; batch adversarial loss: 0.426414\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465177; batch adversarial loss: 0.426584\n",
      "epoch 54; iter: 0; batch classifier loss: 0.496725; batch adversarial loss: 0.446182\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483793; batch adversarial loss: 0.366154\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414241; batch adversarial loss: 0.523475\n",
      "epoch 57; iter: 0; batch classifier loss: 0.397260; batch adversarial loss: 0.498457\n",
      "epoch 58; iter: 0; batch classifier loss: 0.445925; batch adversarial loss: 0.452878\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414287; batch adversarial loss: 0.465474\n",
      "epoch 60; iter: 0; batch classifier loss: 0.438804; batch adversarial loss: 0.596717\n",
      "epoch 61; iter: 0; batch classifier loss: 0.408394; batch adversarial loss: 0.538451\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434386; batch adversarial loss: 0.470865\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431240; batch adversarial loss: 0.449619\n",
      "epoch 64; iter: 0; batch classifier loss: 0.378204; batch adversarial loss: 0.439886\n",
      "epoch 65; iter: 0; batch classifier loss: 0.378383; batch adversarial loss: 0.504224\n",
      "epoch 66; iter: 0; batch classifier loss: 0.421724; batch adversarial loss: 0.449983\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399583; batch adversarial loss: 0.456226\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397450; batch adversarial loss: 0.432770\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428302; batch adversarial loss: 0.453412\n",
      "epoch 70; iter: 0; batch classifier loss: 0.467249; batch adversarial loss: 0.469807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.408383; batch adversarial loss: 0.424955\n",
      "epoch 72; iter: 0; batch classifier loss: 0.474711; batch adversarial loss: 0.530660\n",
      "epoch 73; iter: 0; batch classifier loss: 0.425055; batch adversarial loss: 0.529541\n",
      "epoch 74; iter: 0; batch classifier loss: 0.460203; batch adversarial loss: 0.445246\n",
      "epoch 75; iter: 0; batch classifier loss: 0.494875; batch adversarial loss: 0.481813\n",
      "epoch 76; iter: 0; batch classifier loss: 0.450862; batch adversarial loss: 0.527458\n",
      "epoch 77; iter: 0; batch classifier loss: 0.395558; batch adversarial loss: 0.440556\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378425; batch adversarial loss: 0.526837\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402334; batch adversarial loss: 0.413711\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436678; batch adversarial loss: 0.452746\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393840; batch adversarial loss: 0.484711\n",
      "epoch 82; iter: 0; batch classifier loss: 0.375792; batch adversarial loss: 0.436154\n",
      "epoch 83; iter: 0; batch classifier loss: 0.396686; batch adversarial loss: 0.447144\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376850; batch adversarial loss: 0.462366\n",
      "epoch 85; iter: 0; batch classifier loss: 0.351798; batch adversarial loss: 0.483805\n",
      "epoch 86; iter: 0; batch classifier loss: 0.426851; batch adversarial loss: 0.469195\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369048; batch adversarial loss: 0.521580\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420449; batch adversarial loss: 0.418622\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393961; batch adversarial loss: 0.453658\n",
      "epoch 90; iter: 0; batch classifier loss: 0.405661; batch adversarial loss: 0.453430\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386440; batch adversarial loss: 0.494595\n",
      "epoch 92; iter: 0; batch classifier loss: 0.391422; batch adversarial loss: 0.603940\n",
      "epoch 93; iter: 0; batch classifier loss: 0.455509; batch adversarial loss: 0.612567\n",
      "epoch 94; iter: 0; batch classifier loss: 0.293079; batch adversarial loss: 0.495731\n",
      "epoch 95; iter: 0; batch classifier loss: 0.276240; batch adversarial loss: 0.485482\n",
      "epoch 96; iter: 0; batch classifier loss: 0.349956; batch adversarial loss: 0.515475\n",
      "epoch 97; iter: 0; batch classifier loss: 0.450189; batch adversarial loss: 0.360313\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358417; batch adversarial loss: 0.481614\n",
      "epoch 99; iter: 0; batch classifier loss: 0.442760; batch adversarial loss: 0.505225\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.121659; batch adversarial loss: 0.858503\n",
      "epoch 2; iter: 0; batch classifier loss: 0.977070; batch adversarial loss: 0.830744\n",
      "epoch 3; iter: 0; batch classifier loss: 0.929270; batch adversarial loss: 0.742055\n",
      "epoch 4; iter: 0; batch classifier loss: 0.736352; batch adversarial loss: 0.729732\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558210; batch adversarial loss: 0.686436\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512186; batch adversarial loss: 0.665394\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490415; batch adversarial loss: 0.631376\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560934; batch adversarial loss: 0.615818\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500821; batch adversarial loss: 0.595492\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564328; batch adversarial loss: 0.591492\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546484; batch adversarial loss: 0.596169\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559340; batch adversarial loss: 0.578310\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518757; batch adversarial loss: 0.551559\n",
      "epoch 14; iter: 0; batch classifier loss: 0.467997; batch adversarial loss: 0.550117\n",
      "epoch 15; iter: 0; batch classifier loss: 0.578336; batch adversarial loss: 0.578293\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531705; batch adversarial loss: 0.527415\n",
      "epoch 17; iter: 0; batch classifier loss: 0.526793; batch adversarial loss: 0.537867\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526476; batch adversarial loss: 0.527400\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530740; batch adversarial loss: 0.547339\n",
      "epoch 20; iter: 0; batch classifier loss: 0.580101; batch adversarial loss: 0.470133\n",
      "epoch 21; iter: 0; batch classifier loss: 0.527345; batch adversarial loss: 0.517072\n",
      "epoch 22; iter: 0; batch classifier loss: 0.570884; batch adversarial loss: 0.530059\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518738; batch adversarial loss: 0.541914\n",
      "epoch 24; iter: 0; batch classifier loss: 0.520428; batch adversarial loss: 0.496555\n",
      "epoch 25; iter: 0; batch classifier loss: 0.722905; batch adversarial loss: 0.587323\n",
      "epoch 26; iter: 0; batch classifier loss: 0.643032; batch adversarial loss: 0.537222\n",
      "epoch 27; iter: 0; batch classifier loss: 0.716952; batch adversarial loss: 0.668068\n",
      "epoch 28; iter: 0; batch classifier loss: 0.617276; batch adversarial loss: 0.535543\n",
      "epoch 29; iter: 0; batch classifier loss: 0.690327; batch adversarial loss: 0.551250\n",
      "epoch 30; iter: 0; batch classifier loss: 0.572566; batch adversarial loss: 0.556690\n",
      "epoch 31; iter: 0; batch classifier loss: 0.561822; batch adversarial loss: 0.497600\n",
      "epoch 32; iter: 0; batch classifier loss: 0.557077; batch adversarial loss: 0.518445\n",
      "epoch 33; iter: 0; batch classifier loss: 0.523509; batch adversarial loss: 0.528464\n",
      "epoch 34; iter: 0; batch classifier loss: 0.507894; batch adversarial loss: 0.546835\n",
      "epoch 35; iter: 0; batch classifier loss: 0.489397; batch adversarial loss: 0.484981\n",
      "epoch 36; iter: 0; batch classifier loss: 0.507799; batch adversarial loss: 0.460601\n",
      "epoch 37; iter: 0; batch classifier loss: 0.530051; batch adversarial loss: 0.532001\n",
      "epoch 38; iter: 0; batch classifier loss: 0.521468; batch adversarial loss: 0.416149\n",
      "epoch 39; iter: 0; batch classifier loss: 0.541336; batch adversarial loss: 0.463184\n",
      "epoch 40; iter: 0; batch classifier loss: 0.548124; batch adversarial loss: 0.448937\n",
      "epoch 41; iter: 0; batch classifier loss: 0.595922; batch adversarial loss: 0.536468\n",
      "epoch 42; iter: 0; batch classifier loss: 0.490968; batch adversarial loss: 0.455848\n",
      "epoch 43; iter: 0; batch classifier loss: 0.479835; batch adversarial loss: 0.464073\n",
      "epoch 44; iter: 0; batch classifier loss: 0.505764; batch adversarial loss: 0.413112\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434797; batch adversarial loss: 0.448200\n",
      "epoch 46; iter: 0; batch classifier loss: 0.514779; batch adversarial loss: 0.538346\n",
      "epoch 47; iter: 0; batch classifier loss: 0.526075; batch adversarial loss: 0.506963\n",
      "epoch 48; iter: 0; batch classifier loss: 0.587458; batch adversarial loss: 0.434060\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440888; batch adversarial loss: 0.471974\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465068; batch adversarial loss: 0.504595\n",
      "epoch 51; iter: 0; batch classifier loss: 0.465047; batch adversarial loss: 0.483161\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442341; batch adversarial loss: 0.426246\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465549; batch adversarial loss: 0.426261\n",
      "epoch 54; iter: 0; batch classifier loss: 0.509012; batch adversarial loss: 0.446280\n",
      "epoch 55; iter: 0; batch classifier loss: 0.486109; batch adversarial loss: 0.365884\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420224; batch adversarial loss: 0.523705\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401748; batch adversarial loss: 0.498748\n",
      "epoch 58; iter: 0; batch classifier loss: 0.456257; batch adversarial loss: 0.452987\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409184; batch adversarial loss: 0.465509\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439328; batch adversarial loss: 0.596545\n",
      "epoch 61; iter: 0; batch classifier loss: 0.415477; batch adversarial loss: 0.538615\n",
      "epoch 62; iter: 0; batch classifier loss: 0.433096; batch adversarial loss: 0.471115\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425655; batch adversarial loss: 0.448913\n",
      "epoch 64; iter: 0; batch classifier loss: 0.385376; batch adversarial loss: 0.439952\n",
      "epoch 65; iter: 0; batch classifier loss: 0.384324; batch adversarial loss: 0.503736\n",
      "epoch 66; iter: 0; batch classifier loss: 0.434578; batch adversarial loss: 0.450397\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412770; batch adversarial loss: 0.456018\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410597; batch adversarial loss: 0.432239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.433346; batch adversarial loss: 0.454083\n",
      "epoch 70; iter: 0; batch classifier loss: 0.449837; batch adversarial loss: 0.469290\n",
      "epoch 71; iter: 0; batch classifier loss: 0.407849; batch adversarial loss: 0.425082\n",
      "epoch 72; iter: 0; batch classifier loss: 0.471190; batch adversarial loss: 0.530627\n",
      "epoch 73; iter: 0; batch classifier loss: 0.423956; batch adversarial loss: 0.528994\n",
      "epoch 74; iter: 0; batch classifier loss: 0.471130; batch adversarial loss: 0.445017\n",
      "epoch 75; iter: 0; batch classifier loss: 0.499689; batch adversarial loss: 0.481436\n",
      "epoch 76; iter: 0; batch classifier loss: 0.463912; batch adversarial loss: 0.528640\n",
      "epoch 77; iter: 0; batch classifier loss: 0.405318; batch adversarial loss: 0.441642\n",
      "epoch 78; iter: 0; batch classifier loss: 0.375829; batch adversarial loss: 0.526358\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402161; batch adversarial loss: 0.414247\n",
      "epoch 80; iter: 0; batch classifier loss: 0.441594; batch adversarial loss: 0.452409\n",
      "epoch 81; iter: 0; batch classifier loss: 0.389908; batch adversarial loss: 0.485026\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381102; batch adversarial loss: 0.436689\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404761; batch adversarial loss: 0.446898\n",
      "epoch 84; iter: 0; batch classifier loss: 0.365301; batch adversarial loss: 0.461893\n",
      "epoch 85; iter: 0; batch classifier loss: 0.351077; batch adversarial loss: 0.483274\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431186; batch adversarial loss: 0.468951\n",
      "epoch 87; iter: 0; batch classifier loss: 0.352472; batch adversarial loss: 0.521713\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421647; batch adversarial loss: 0.418766\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398582; batch adversarial loss: 0.453966\n",
      "epoch 90; iter: 0; batch classifier loss: 0.399527; batch adversarial loss: 0.453997\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383385; batch adversarial loss: 0.495222\n",
      "epoch 92; iter: 0; batch classifier loss: 0.397048; batch adversarial loss: 0.604049\n",
      "epoch 93; iter: 0; batch classifier loss: 0.459629; batch adversarial loss: 0.613430\n",
      "epoch 94; iter: 0; batch classifier loss: 0.291313; batch adversarial loss: 0.495672\n",
      "epoch 95; iter: 0; batch classifier loss: 0.289602; batch adversarial loss: 0.485788\n",
      "epoch 96; iter: 0; batch classifier loss: 0.327317; batch adversarial loss: 0.514662\n",
      "epoch 97; iter: 0; batch classifier loss: 0.456164; batch adversarial loss: 0.360569\n",
      "epoch 98; iter: 0; batch classifier loss: 0.375736; batch adversarial loss: 0.481556\n",
      "epoch 99; iter: 0; batch classifier loss: 0.458868; batch adversarial loss: 0.505367\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.157124; batch adversarial loss: 0.860556\n",
      "epoch 2; iter: 0; batch classifier loss: 1.014492; batch adversarial loss: 0.833058\n",
      "epoch 3; iter: 0; batch classifier loss: 0.978037; batch adversarial loss: 0.744194\n",
      "epoch 4; iter: 0; batch classifier loss: 0.775132; batch adversarial loss: 0.733007\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592279; batch adversarial loss: 0.689009\n",
      "epoch 6; iter: 0; batch classifier loss: 0.518403; batch adversarial loss: 0.666530\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495356; batch adversarial loss: 0.630651\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560872; batch adversarial loss: 0.615215\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502363; batch adversarial loss: 0.594554\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564695; batch adversarial loss: 0.590822\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543931; batch adversarial loss: 0.595971\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556944; batch adversarial loss: 0.577939\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515314; batch adversarial loss: 0.551471\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464082; batch adversarial loss: 0.550937\n",
      "epoch 15; iter: 0; batch classifier loss: 0.572929; batch adversarial loss: 0.580480\n",
      "epoch 16; iter: 0; batch classifier loss: 0.529540; batch adversarial loss: 0.531941\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524637; batch adversarial loss: 0.540713\n",
      "epoch 18; iter: 0; batch classifier loss: 0.527283; batch adversarial loss: 0.530154\n",
      "epoch 19; iter: 0; batch classifier loss: 0.540452; batch adversarial loss: 0.555208\n",
      "epoch 20; iter: 0; batch classifier loss: 0.601089; batch adversarial loss: 0.480098\n",
      "epoch 21; iter: 0; batch classifier loss: 0.563463; batch adversarial loss: 0.528312\n",
      "epoch 22; iter: 0; batch classifier loss: 0.604199; batch adversarial loss: 0.541072\n",
      "epoch 23; iter: 0; batch classifier loss: 0.574046; batch adversarial loss: 0.556672\n",
      "epoch 24; iter: 0; batch classifier loss: 0.573348; batch adversarial loss: 0.511099\n",
      "epoch 25; iter: 0; batch classifier loss: 0.788066; batch adversarial loss: 0.590005\n",
      "epoch 26; iter: 0; batch classifier loss: 0.662630; batch adversarial loss: 0.531221\n",
      "epoch 27; iter: 0; batch classifier loss: 0.705931; batch adversarial loss: 0.653967\n",
      "epoch 28; iter: 0; batch classifier loss: 0.599880; batch adversarial loss: 0.529942\n",
      "epoch 29; iter: 0; batch classifier loss: 0.656067; batch adversarial loss: 0.542099\n",
      "epoch 30; iter: 0; batch classifier loss: 0.540709; batch adversarial loss: 0.547457\n",
      "epoch 31; iter: 0; batch classifier loss: 0.541687; batch adversarial loss: 0.491953\n",
      "epoch 32; iter: 0; batch classifier loss: 0.529975; batch adversarial loss: 0.512047\n",
      "epoch 33; iter: 0; batch classifier loss: 0.480308; batch adversarial loss: 0.520371\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483255; batch adversarial loss: 0.540757\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485914; batch adversarial loss: 0.482117\n",
      "epoch 36; iter: 0; batch classifier loss: 0.505562; batch adversarial loss: 0.458975\n",
      "epoch 37; iter: 0; batch classifier loss: 0.539231; batch adversarial loss: 0.532571\n",
      "epoch 38; iter: 0; batch classifier loss: 0.535610; batch adversarial loss: 0.417080\n",
      "epoch 39; iter: 0; batch classifier loss: 0.567073; batch adversarial loss: 0.466114\n",
      "epoch 40; iter: 0; batch classifier loss: 0.583077; batch adversarial loss: 0.451415\n",
      "epoch 41; iter: 0; batch classifier loss: 0.629615; batch adversarial loss: 0.537244\n",
      "epoch 42; iter: 0; batch classifier loss: 0.507234; batch adversarial loss: 0.456017\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475863; batch adversarial loss: 0.462496\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500893; batch adversarial loss: 0.411884\n",
      "epoch 45; iter: 0; batch classifier loss: 0.431245; batch adversarial loss: 0.447237\n",
      "epoch 46; iter: 0; batch classifier loss: 0.506079; batch adversarial loss: 0.536384\n",
      "epoch 47; iter: 0; batch classifier loss: 0.522439; batch adversarial loss: 0.506134\n",
      "epoch 48; iter: 0; batch classifier loss: 0.574191; batch adversarial loss: 0.433556\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432784; batch adversarial loss: 0.471677\n",
      "epoch 50; iter: 0; batch classifier loss: 0.470837; batch adversarial loss: 0.504619\n",
      "epoch 51; iter: 0; batch classifier loss: 0.475819; batch adversarial loss: 0.483210\n",
      "epoch 52; iter: 0; batch classifier loss: 0.449991; batch adversarial loss: 0.426183\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465553; batch adversarial loss: 0.426294\n",
      "epoch 54; iter: 0; batch classifier loss: 0.509373; batch adversarial loss: 0.446526\n",
      "epoch 55; iter: 0; batch classifier loss: 0.485195; batch adversarial loss: 0.365575\n",
      "epoch 56; iter: 0; batch classifier loss: 0.418194; batch adversarial loss: 0.523801\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401187; batch adversarial loss: 0.498742\n",
      "epoch 58; iter: 0; batch classifier loss: 0.458856; batch adversarial loss: 0.453075\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410921; batch adversarial loss: 0.465828\n",
      "epoch 60; iter: 0; batch classifier loss: 0.449074; batch adversarial loss: 0.597080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.427644; batch adversarial loss: 0.539369\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438248; batch adversarial loss: 0.471157\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435109; batch adversarial loss: 0.449785\n",
      "epoch 64; iter: 0; batch classifier loss: 0.381988; batch adversarial loss: 0.440146\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389071; batch adversarial loss: 0.503721\n",
      "epoch 66; iter: 0; batch classifier loss: 0.436169; batch adversarial loss: 0.450338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67; iter: 0; batch classifier loss: 0.411325; batch adversarial loss: 0.456027\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412060; batch adversarial loss: 0.432129\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444730; batch adversarial loss: 0.453673\n",
      "epoch 70; iter: 0; batch classifier loss: 0.471896; batch adversarial loss: 0.469718\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406682; batch adversarial loss: 0.425658\n",
      "epoch 72; iter: 0; batch classifier loss: 0.466668; batch adversarial loss: 0.530026\n",
      "epoch 73; iter: 0; batch classifier loss: 0.445488; batch adversarial loss: 0.529100\n",
      "epoch 74; iter: 0; batch classifier loss: 0.478104; batch adversarial loss: 0.444401\n",
      "epoch 75; iter: 0; batch classifier loss: 0.498229; batch adversarial loss: 0.482838\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461979; batch adversarial loss: 0.529750\n",
      "epoch 77; iter: 0; batch classifier loss: 0.399364; batch adversarial loss: 0.440204\n",
      "epoch 78; iter: 0; batch classifier loss: 0.374036; batch adversarial loss: 0.526032\n",
      "epoch 79; iter: 0; batch classifier loss: 0.399925; batch adversarial loss: 0.413763\n",
      "epoch 80; iter: 0; batch classifier loss: 0.438315; batch adversarial loss: 0.452489\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395000; batch adversarial loss: 0.485559\n",
      "epoch 82; iter: 0; batch classifier loss: 0.393655; batch adversarial loss: 0.436681\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404088; batch adversarial loss: 0.447221\n",
      "epoch 84; iter: 0; batch classifier loss: 0.367679; batch adversarial loss: 0.462584\n",
      "epoch 85; iter: 0; batch classifier loss: 0.352475; batch adversarial loss: 0.482499\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420883; batch adversarial loss: 0.469092\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371201; batch adversarial loss: 0.522878\n",
      "epoch 88; iter: 0; batch classifier loss: 0.414601; batch adversarial loss: 0.419584\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401196; batch adversarial loss: 0.452483\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395299; batch adversarial loss: 0.454591\n",
      "epoch 91; iter: 0; batch classifier loss: 0.390688; batch adversarial loss: 0.495251\n",
      "epoch 92; iter: 0; batch classifier loss: 0.403062; batch adversarial loss: 0.604951\n",
      "epoch 93; iter: 0; batch classifier loss: 0.454228; batch adversarial loss: 0.612696\n",
      "epoch 94; iter: 0; batch classifier loss: 0.301104; batch adversarial loss: 0.497257\n",
      "epoch 95; iter: 0; batch classifier loss: 0.283783; batch adversarial loss: 0.485370\n",
      "epoch 96; iter: 0; batch classifier loss: 0.328163; batch adversarial loss: 0.516016\n",
      "epoch 97; iter: 0; batch classifier loss: 0.470907; batch adversarial loss: 0.361181\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378101; batch adversarial loss: 0.482246\n",
      "epoch 99; iter: 0; batch classifier loss: 0.482525; batch adversarial loss: 0.507296\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.116877; batch adversarial loss: 0.858226\n",
      "epoch 2; iter: 0; batch classifier loss: 0.973166; batch adversarial loss: 0.830481\n",
      "epoch 3; iter: 0; batch classifier loss: 0.922704; batch adversarial loss: 0.741695\n",
      "epoch 4; iter: 0; batch classifier loss: 0.731484; batch adversarial loss: 0.729335\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555116; batch adversarial loss: 0.686134\n",
      "epoch 6; iter: 0; batch classifier loss: 0.511650; batch adversarial loss: 0.665133\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490225; batch adversarial loss: 0.631397\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561535; batch adversarial loss: 0.615719\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501659; batch adversarial loss: 0.595442\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565149; batch adversarial loss: 0.591349\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546279; batch adversarial loss: 0.596177\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559775; batch adversarial loss: 0.578285\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520355; batch adversarial loss: 0.551459\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469301; batch adversarial loss: 0.549887\n",
      "epoch 15; iter: 0; batch classifier loss: 0.578714; batch adversarial loss: 0.578122\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533027; batch adversarial loss: 0.526656\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528363; batch adversarial loss: 0.537472\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526085; batch adversarial loss: 0.527092\n",
      "epoch 19; iter: 0; batch classifier loss: 0.528929; batch adversarial loss: 0.546431\n",
      "epoch 20; iter: 0; batch classifier loss: 0.579613; batch adversarial loss: 0.468620\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521750; batch adversarial loss: 0.514814\n",
      "epoch 22; iter: 0; batch classifier loss: 0.565306; batch adversarial loss: 0.529123\n",
      "epoch 23; iter: 0; batch classifier loss: 0.513502; batch adversarial loss: 0.539901\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518571; batch adversarial loss: 0.495462\n",
      "epoch 25; iter: 0; batch classifier loss: 0.706582; batch adversarial loss: 0.584643\n",
      "epoch 26; iter: 0; batch classifier loss: 0.635641; batch adversarial loss: 0.537210\n",
      "epoch 27; iter: 0; batch classifier loss: 0.711536; batch adversarial loss: 0.669914\n",
      "epoch 28; iter: 0; batch classifier loss: 0.613523; batch adversarial loss: 0.535750\n",
      "epoch 29; iter: 0; batch classifier loss: 0.692219; batch adversarial loss: 0.552816\n",
      "epoch 30; iter: 0; batch classifier loss: 0.571515; batch adversarial loss: 0.557990\n",
      "epoch 31; iter: 0; batch classifier loss: 0.565124; batch adversarial loss: 0.498728\n",
      "epoch 32; iter: 0; batch classifier loss: 0.558538; batch adversarial loss: 0.519041\n",
      "epoch 33; iter: 0; batch classifier loss: 0.525706; batch adversarial loss: 0.529950\n",
      "epoch 34; iter: 0; batch classifier loss: 0.515605; batch adversarial loss: 0.548526\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488614; batch adversarial loss: 0.485990\n",
      "epoch 36; iter: 0; batch classifier loss: 0.506731; batch adversarial loss: 0.461162\n",
      "epoch 37; iter: 0; batch classifier loss: 0.536375; batch adversarial loss: 0.532938\n",
      "epoch 38; iter: 0; batch classifier loss: 0.524404; batch adversarial loss: 0.416668\n",
      "epoch 39; iter: 0; batch classifier loss: 0.536894; batch adversarial loss: 0.463075\n",
      "epoch 40; iter: 0; batch classifier loss: 0.545680; batch adversarial loss: 0.448595\n",
      "epoch 41; iter: 0; batch classifier loss: 0.587353; batch adversarial loss: 0.535533\n",
      "epoch 42; iter: 0; batch classifier loss: 0.485648; batch adversarial loss: 0.455619\n",
      "epoch 43; iter: 0; batch classifier loss: 0.476537; batch adversarial loss: 0.463878\n",
      "epoch 44; iter: 0; batch classifier loss: 0.507838; batch adversarial loss: 0.413084\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430194; batch adversarial loss: 0.447912\n",
      "epoch 46; iter: 0; batch classifier loss: 0.512353; batch adversarial loss: 0.538845\n",
      "epoch 47; iter: 0; batch classifier loss: 0.525123; batch adversarial loss: 0.507656\n",
      "epoch 48; iter: 0; batch classifier loss: 0.604106; batch adversarial loss: 0.434399\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452514; batch adversarial loss: 0.472124\n",
      "epoch 50; iter: 0; batch classifier loss: 0.459054; batch adversarial loss: 0.504549\n",
      "epoch 51; iter: 0; batch classifier loss: 0.464809; batch adversarial loss: 0.483184\n",
      "epoch 52; iter: 0; batch classifier loss: 0.439360; batch adversarial loss: 0.426185\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465288; batch adversarial loss: 0.426446\n",
      "epoch 54; iter: 0; batch classifier loss: 0.501439; batch adversarial loss: 0.446243\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483401; batch adversarial loss: 0.365899\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420069; batch adversarial loss: 0.523709\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399661; batch adversarial loss: 0.498570\n",
      "epoch 58; iter: 0; batch classifier loss: 0.450312; batch adversarial loss: 0.452977\n",
      "epoch 59; iter: 0; batch classifier loss: 0.413029; batch adversarial loss: 0.465478\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444991; batch adversarial loss: 0.596607\n",
      "epoch 61; iter: 0; batch classifier loss: 0.418810; batch adversarial loss: 0.538646\n",
      "epoch 62; iter: 0; batch classifier loss: 0.435209; batch adversarial loss: 0.471031\n",
      "epoch 63; iter: 0; batch classifier loss: 0.430751; batch adversarial loss: 0.449261\n",
      "epoch 64; iter: 0; batch classifier loss: 0.378523; batch adversarial loss: 0.439798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.387375; batch adversarial loss: 0.503850\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423513; batch adversarial loss: 0.450159\n",
      "epoch 67; iter: 0; batch classifier loss: 0.404621; batch adversarial loss: 0.456223\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400880; batch adversarial loss: 0.432439\n",
      "epoch 69; iter: 0; batch classifier loss: 0.439126; batch adversarial loss: 0.453960\n",
      "epoch 70; iter: 0; batch classifier loss: 0.465174; batch adversarial loss: 0.470049\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408363; batch adversarial loss: 0.425028\n",
      "epoch 72; iter: 0; batch classifier loss: 0.489396; batch adversarial loss: 0.531070\n",
      "epoch 73; iter: 0; batch classifier loss: 0.431171; batch adversarial loss: 0.529338\n",
      "epoch 74; iter: 0; batch classifier loss: 0.461386; batch adversarial loss: 0.445196\n",
      "epoch 75; iter: 0; batch classifier loss: 0.498346; batch adversarial loss: 0.482301\n",
      "epoch 76; iter: 0; batch classifier loss: 0.461393; batch adversarial loss: 0.528007\n",
      "epoch 77; iter: 0; batch classifier loss: 0.405379; batch adversarial loss: 0.441363\n",
      "epoch 78; iter: 0; batch classifier loss: 0.372353; batch adversarial loss: 0.526322\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408170; batch adversarial loss: 0.415046\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436033; batch adversarial loss: 0.452419\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394163; batch adversarial loss: 0.484986\n",
      "epoch 82; iter: 0; batch classifier loss: 0.381896; batch adversarial loss: 0.436602\n",
      "epoch 83; iter: 0; batch classifier loss: 0.411937; batch adversarial loss: 0.447490\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376835; batch adversarial loss: 0.462015\n",
      "epoch 85; iter: 0; batch classifier loss: 0.352042; batch adversarial loss: 0.483201\n",
      "epoch 86; iter: 0; batch classifier loss: 0.423576; batch adversarial loss: 0.469235\n",
      "epoch 87; iter: 0; batch classifier loss: 0.370422; batch adversarial loss: 0.522070\n",
      "epoch 88; iter: 0; batch classifier loss: 0.429829; batch adversarial loss: 0.419160\n",
      "epoch 89; iter: 0; batch classifier loss: 0.397507; batch adversarial loss: 0.454293\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409391; batch adversarial loss: 0.453820\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388925; batch adversarial loss: 0.495120\n",
      "epoch 92; iter: 0; batch classifier loss: 0.396975; batch adversarial loss: 0.604230\n",
      "epoch 93; iter: 0; batch classifier loss: 0.443816; batch adversarial loss: 0.613482\n",
      "epoch 94; iter: 0; batch classifier loss: 0.301286; batch adversarial loss: 0.496125\n",
      "epoch 95; iter: 0; batch classifier loss: 0.283263; batch adversarial loss: 0.486228\n",
      "epoch 96; iter: 0; batch classifier loss: 0.320656; batch adversarial loss: 0.515132\n",
      "epoch 97; iter: 0; batch classifier loss: 0.456554; batch adversarial loss: 0.360505\n",
      "epoch 98; iter: 0; batch classifier loss: 0.374401; batch adversarial loss: 0.481243\n",
      "epoch 99; iter: 0; batch classifier loss: 0.448053; batch adversarial loss: 0.505263\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698844; batch adversarial loss: 0.829340\n",
      "epoch 1; iter: 0; batch classifier loss: 1.030814; batch adversarial loss: 0.852416\n",
      "epoch 2; iter: 0; batch classifier loss: 0.929415; batch adversarial loss: 0.830411\n",
      "epoch 3; iter: 0; batch classifier loss: 0.877511; batch adversarial loss: 0.744087\n",
      "epoch 4; iter: 0; batch classifier loss: 0.719232; batch adversarial loss: 0.730850\n",
      "epoch 5; iter: 0; batch classifier loss: 0.533802; batch adversarial loss: 0.681901\n",
      "epoch 6; iter: 0; batch classifier loss: 0.492003; batch adversarial loss: 0.667466\n",
      "epoch 7; iter: 0; batch classifier loss: 0.453484; batch adversarial loss: 0.637267\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534390; batch adversarial loss: 0.620524\n",
      "epoch 9; iter: 0; batch classifier loss: 0.494925; batch adversarial loss: 0.597434\n",
      "epoch 10; iter: 0; batch classifier loss: 0.554384; batch adversarial loss: 0.596287\n",
      "epoch 11; iter: 0; batch classifier loss: 0.509687; batch adversarial loss: 0.600286\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532658; batch adversarial loss: 0.581701\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483075; batch adversarial loss: 0.557876\n",
      "epoch 14; iter: 0; batch classifier loss: 0.468988; batch adversarial loss: 0.548181\n",
      "epoch 15; iter: 0; batch classifier loss: 0.561934; batch adversarial loss: 0.578029\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489312; batch adversarial loss: 0.527866\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506691; batch adversarial loss: 0.532928\n",
      "epoch 18; iter: 0; batch classifier loss: 0.509788; batch adversarial loss: 0.525560\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506137; batch adversarial loss: 0.543933\n",
      "epoch 20; iter: 0; batch classifier loss: 0.552830; batch adversarial loss: 0.470291\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476335; batch adversarial loss: 0.517334\n",
      "epoch 22; iter: 0; batch classifier loss: 0.506027; batch adversarial loss: 0.537171\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486725; batch adversarial loss: 0.537920\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483676; batch adversarial loss: 0.487711\n",
      "epoch 25; iter: 0; batch classifier loss: 0.664208; batch adversarial loss: 0.575053\n",
      "epoch 26; iter: 0; batch classifier loss: 0.566024; batch adversarial loss: 0.521070\n",
      "epoch 27; iter: 0; batch classifier loss: 0.604652; batch adversarial loss: 0.651754\n",
      "epoch 28; iter: 0; batch classifier loss: 0.488211; batch adversarial loss: 0.524669\n",
      "epoch 29; iter: 0; batch classifier loss: 0.614763; batch adversarial loss: 0.545091\n",
      "epoch 30; iter: 0; batch classifier loss: 0.494457; batch adversarial loss: 0.559831\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492170; batch adversarial loss: 0.503110\n",
      "epoch 32; iter: 0; batch classifier loss: 0.548762; batch adversarial loss: 0.525165\n",
      "epoch 33; iter: 0; batch classifier loss: 0.518383; batch adversarial loss: 0.537908\n",
      "epoch 34; iter: 0; batch classifier loss: 0.590754; batch adversarial loss: 0.562291\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476926; batch adversarial loss: 0.490001\n",
      "epoch 36; iter: 0; batch classifier loss: 0.494117; batch adversarial loss: 0.465008\n",
      "epoch 37; iter: 0; batch classifier loss: 0.503300; batch adversarial loss: 0.536076\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461062; batch adversarial loss: 0.419811\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453694; batch adversarial loss: 0.462450\n",
      "epoch 40; iter: 0; batch classifier loss: 0.475537; batch adversarial loss: 0.447585\n",
      "epoch 41; iter: 0; batch classifier loss: 0.557175; batch adversarial loss: 0.531003\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417040; batch adversarial loss: 0.452327\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420645; batch adversarial loss: 0.461320\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481084; batch adversarial loss: 0.413488\n",
      "epoch 45; iter: 0; batch classifier loss: 0.368098; batch adversarial loss: 0.447854\n",
      "epoch 46; iter: 0; batch classifier loss: 0.494368; batch adversarial loss: 0.540458\n",
      "epoch 47; iter: 0; batch classifier loss: 0.525495; batch adversarial loss: 0.507454\n",
      "epoch 48; iter: 0; batch classifier loss: 0.453493; batch adversarial loss: 0.432541\n",
      "epoch 49; iter: 0; batch classifier loss: 0.367432; batch adversarial loss: 0.470228\n",
      "epoch 50; iter: 0; batch classifier loss: 0.422609; batch adversarial loss: 0.504821\n",
      "epoch 51; iter: 0; batch classifier loss: 0.384182; batch adversarial loss: 0.483048\n",
      "epoch 52; iter: 0; batch classifier loss: 0.354541; batch adversarial loss: 0.425540\n",
      "epoch 53; iter: 0; batch classifier loss: 0.374203; batch adversarial loss: 0.425700\n",
      "epoch 54; iter: 0; batch classifier loss: 0.446364; batch adversarial loss: 0.445011\n",
      "epoch 55; iter: 0; batch classifier loss: 0.400818; batch adversarial loss: 0.366286\n",
      "epoch 56; iter: 0; batch classifier loss: 0.362407; batch adversarial loss: 0.522016\n",
      "epoch 57; iter: 0; batch classifier loss: 0.362294; batch adversarial loss: 0.499085\n",
      "epoch 58; iter: 0; batch classifier loss: 0.382245; batch adversarial loss: 0.452515\n",
      "epoch 59; iter: 0; batch classifier loss: 0.311422; batch adversarial loss: 0.464195\n",
      "epoch 60; iter: 0; batch classifier loss: 0.401665; batch adversarial loss: 0.596851\n",
      "epoch 61; iter: 0; batch classifier loss: 0.327971; batch adversarial loss: 0.537091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.390135; batch adversarial loss: 0.472258\n",
      "epoch 63; iter: 0; batch classifier loss: 0.407257; batch adversarial loss: 0.454582\n",
      "epoch 64; iter: 0; batch classifier loss: 0.314661; batch adversarial loss: 0.439537\n",
      "epoch 65; iter: 0; batch classifier loss: 0.332607; batch adversarial loss: 0.503513\n",
      "epoch 66; iter: 0; batch classifier loss: 0.405789; batch adversarial loss: 0.449267\n",
      "epoch 67; iter: 0; batch classifier loss: 0.379575; batch adversarial loss: 0.458250\n",
      "epoch 68; iter: 0; batch classifier loss: 0.319258; batch adversarial loss: 0.434637\n",
      "epoch 69; iter: 0; batch classifier loss: 0.350081; batch adversarial loss: 0.452957\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397495; batch adversarial loss: 0.470946\n",
      "epoch 71; iter: 0; batch classifier loss: 0.339899; batch adversarial loss: 0.426026\n",
      "epoch 72; iter: 0; batch classifier loss: 0.330171; batch adversarial loss: 0.528749\n",
      "epoch 73; iter: 0; batch classifier loss: 0.387081; batch adversarial loss: 0.532679\n",
      "epoch 74; iter: 0; batch classifier loss: 0.398785; batch adversarial loss: 0.446642\n",
      "epoch 75; iter: 0; batch classifier loss: 0.379280; batch adversarial loss: 0.483246\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364681; batch adversarial loss: 0.531595\n",
      "epoch 77; iter: 0; batch classifier loss: 0.325800; batch adversarial loss: 0.442846\n",
      "epoch 78; iter: 0; batch classifier loss: 0.287374; batch adversarial loss: 0.528181\n",
      "epoch 79; iter: 0; batch classifier loss: 0.342537; batch adversarial loss: 0.417130\n",
      "epoch 80; iter: 0; batch classifier loss: 0.330967; batch adversarial loss: 0.450497\n",
      "epoch 81; iter: 0; batch classifier loss: 0.317159; batch adversarial loss: 0.485192\n",
      "epoch 82; iter: 0; batch classifier loss: 0.323048; batch adversarial loss: 0.438614\n",
      "epoch 83; iter: 0; batch classifier loss: 0.358435; batch adversarial loss: 0.448710\n",
      "epoch 84; iter: 0; batch classifier loss: 0.281290; batch adversarial loss: 0.458861\n",
      "epoch 85; iter: 0; batch classifier loss: 0.257120; batch adversarial loss: 0.483660\n",
      "epoch 86; iter: 0; batch classifier loss: 0.305837; batch adversarial loss: 0.467530\n",
      "epoch 87; iter: 0; batch classifier loss: 0.269891; batch adversarial loss: 0.523495\n",
      "epoch 88; iter: 0; batch classifier loss: 0.339593; batch adversarial loss: 0.427241\n",
      "epoch 89; iter: 0; batch classifier loss: 0.299448; batch adversarial loss: 0.456499\n",
      "epoch 90; iter: 0; batch classifier loss: 0.359145; batch adversarial loss: 0.456523\n",
      "epoch 91; iter: 0; batch classifier loss: 0.318666; batch adversarial loss: 0.495126\n",
      "epoch 92; iter: 0; batch classifier loss: 0.260183; batch adversarial loss: 0.602577\n",
      "epoch 93; iter: 0; batch classifier loss: 0.301855; batch adversarial loss: 0.613001\n",
      "epoch 94; iter: 0; batch classifier loss: 0.261785; batch adversarial loss: 0.497426\n",
      "epoch 95; iter: 0; batch classifier loss: 0.251053; batch adversarial loss: 0.488521\n",
      "epoch 96; iter: 0; batch classifier loss: 0.303011; batch adversarial loss: 0.521003\n",
      "epoch 97; iter: 0; batch classifier loss: 0.313490; batch adversarial loss: 0.358730\n",
      "epoch 98; iter: 0; batch classifier loss: 0.282863; batch adversarial loss: 0.484263\n",
      "epoch 99; iter: 0; batch classifier loss: 0.338377; batch adversarial loss: 0.507598\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.185801; batch adversarial loss: 0.861862\n",
      "epoch 2; iter: 0; batch classifier loss: 1.039711; batch adversarial loss: 0.834419\n",
      "epoch 3; iter: 0; batch classifier loss: 1.015527; batch adversarial loss: 0.745571\n",
      "epoch 4; iter: 0; batch classifier loss: 0.807003; batch adversarial loss: 0.735225\n",
      "epoch 5; iter: 0; batch classifier loss: 0.623109; batch adversarial loss: 0.691089\n",
      "epoch 6; iter: 0; batch classifier loss: 0.528604; batch adversarial loss: 0.667851\n",
      "epoch 7; iter: 0; batch classifier loss: 0.499517; batch adversarial loss: 0.630306\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561863; batch adversarial loss: 0.614589\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504151; batch adversarial loss: 0.593726\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565108; batch adversarial loss: 0.590450\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542290; batch adversarial loss: 0.595926\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556043; batch adversarial loss: 0.577729\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514518; batch adversarial loss: 0.551490\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462617; batch adversarial loss: 0.551577\n",
      "epoch 15; iter: 0; batch classifier loss: 0.570274; batch adversarial loss: 0.582109\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527807; batch adversarial loss: 0.534650\n",
      "epoch 17; iter: 0; batch classifier loss: 0.520663; batch adversarial loss: 0.543030\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532343; batch adversarial loss: 0.533133\n",
      "epoch 19; iter: 0; batch classifier loss: 0.558476; batch adversarial loss: 0.563839\n",
      "epoch 20; iter: 0; batch classifier loss: 0.624346; batch adversarial loss: 0.488552\n",
      "epoch 21; iter: 0; batch classifier loss: 0.584969; batch adversarial loss: 0.536141\n",
      "epoch 22; iter: 0; batch classifier loss: 0.644649; batch adversarial loss: 0.554000\n",
      "epoch 23; iter: 0; batch classifier loss: 0.610260; batch adversarial loss: 0.561457\n",
      "epoch 24; iter: 0; batch classifier loss: 0.592287; batch adversarial loss: 0.512421\n",
      "epoch 25; iter: 0; batch classifier loss: 0.788103; batch adversarial loss: 0.584340\n",
      "epoch 26; iter: 0; batch classifier loss: 0.658196; batch adversarial loss: 0.526456\n",
      "epoch 27; iter: 0; batch classifier loss: 0.679449; batch adversarial loss: 0.644620\n",
      "epoch 28; iter: 0; batch classifier loss: 0.587739; batch adversarial loss: 0.526243\n",
      "epoch 29; iter: 0; batch classifier loss: 0.635249; batch adversarial loss: 0.537413\n",
      "epoch 30; iter: 0; batch classifier loss: 0.529764; batch adversarial loss: 0.543616\n",
      "epoch 31; iter: 0; batch classifier loss: 0.533605; batch adversarial loss: 0.490361\n",
      "epoch 32; iter: 0; batch classifier loss: 0.528243; batch adversarial loss: 0.510597\n",
      "epoch 33; iter: 0; batch classifier loss: 0.473882; batch adversarial loss: 0.518540\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477370; batch adversarial loss: 0.539436\n",
      "epoch 35; iter: 0; batch classifier loss: 0.486379; batch adversarial loss: 0.481635\n",
      "epoch 36; iter: 0; batch classifier loss: 0.510447; batch adversarial loss: 0.459114\n",
      "epoch 37; iter: 0; batch classifier loss: 0.550485; batch adversarial loss: 0.532750\n",
      "epoch 38; iter: 0; batch classifier loss: 0.553704; batch adversarial loss: 0.417672\n",
      "epoch 39; iter: 0; batch classifier loss: 0.590586; batch adversarial loss: 0.466748\n",
      "epoch 40; iter: 0; batch classifier loss: 0.585717; batch adversarial loss: 0.451220\n",
      "epoch 41; iter: 0; batch classifier loss: 0.629674; batch adversarial loss: 0.535658\n",
      "epoch 42; iter: 0; batch classifier loss: 0.505600; batch adversarial loss: 0.454912\n",
      "epoch 43; iter: 0; batch classifier loss: 0.472749; batch adversarial loss: 0.461283\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490419; batch adversarial loss: 0.411059\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422369; batch adversarial loss: 0.446445\n",
      "epoch 46; iter: 0; batch classifier loss: 0.494848; batch adversarial loss: 0.536046\n",
      "epoch 47; iter: 0; batch classifier loss: 0.521676; batch adversarial loss: 0.506267\n",
      "epoch 48; iter: 0; batch classifier loss: 0.597143; batch adversarial loss: 0.433450\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442739; batch adversarial loss: 0.471593\n",
      "epoch 50; iter: 0; batch classifier loss: 0.474160; batch adversarial loss: 0.504505\n",
      "epoch 51; iter: 0; batch classifier loss: 0.483797; batch adversarial loss: 0.483178\n",
      "epoch 52; iter: 0; batch classifier loss: 0.452509; batch adversarial loss: 0.426070\n",
      "epoch 53; iter: 0; batch classifier loss: 0.470611; batch adversarial loss: 0.426358\n",
      "epoch 54; iter: 0; batch classifier loss: 0.518958; batch adversarial loss: 0.446507\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487633; batch adversarial loss: 0.365218\n",
      "epoch 56; iter: 0; batch classifier loss: 0.424822; batch adversarial loss: 0.523636\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399691; batch adversarial loss: 0.498945\n",
      "epoch 58; iter: 0; batch classifier loss: 0.472288; batch adversarial loss: 0.453151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.415796; batch adversarial loss: 0.465676\n",
      "epoch 60; iter: 0; batch classifier loss: 0.452862; batch adversarial loss: 0.597113\n",
      "epoch 61; iter: 0; batch classifier loss: 0.420871; batch adversarial loss: 0.539241\n",
      "epoch 62; iter: 0; batch classifier loss: 0.445023; batch adversarial loss: 0.470837\n",
      "epoch 63; iter: 0; batch classifier loss: 0.431442; batch adversarial loss: 0.449601\n",
      "epoch 64; iter: 0; batch classifier loss: 0.384971; batch adversarial loss: 0.440011\n",
      "epoch 65; iter: 0; batch classifier loss: 0.396388; batch adversarial loss: 0.503130\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435852; batch adversarial loss: 0.450409\n",
      "epoch 67; iter: 0; batch classifier loss: 0.415796; batch adversarial loss: 0.456145\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400617; batch adversarial loss: 0.432583\n",
      "epoch 69; iter: 0; batch classifier loss: 0.446841; batch adversarial loss: 0.454311\n",
      "epoch 70; iter: 0; batch classifier loss: 0.474938; batch adversarial loss: 0.469971\n",
      "epoch 71; iter: 0; batch classifier loss: 0.402804; batch adversarial loss: 0.425752\n",
      "epoch 72; iter: 0; batch classifier loss: 0.469973; batch adversarial loss: 0.530200\n",
      "epoch 73; iter: 0; batch classifier loss: 0.446314; batch adversarial loss: 0.527787\n",
      "epoch 74; iter: 0; batch classifier loss: 0.484387; batch adversarial loss: 0.443195\n",
      "epoch 75; iter: 0; batch classifier loss: 0.500612; batch adversarial loss: 0.481875\n",
      "epoch 76; iter: 0; batch classifier loss: 0.466668; batch adversarial loss: 0.528256\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407609; batch adversarial loss: 0.439663\n",
      "epoch 78; iter: 0; batch classifier loss: 0.385902; batch adversarial loss: 0.526120\n",
      "epoch 79; iter: 0; batch classifier loss: 0.403842; batch adversarial loss: 0.413191\n",
      "epoch 80; iter: 0; batch classifier loss: 0.452633; batch adversarial loss: 0.452610\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402529; batch adversarial loss: 0.485844\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390017; batch adversarial loss: 0.436326\n",
      "epoch 83; iter: 0; batch classifier loss: 0.406772; batch adversarial loss: 0.447486\n",
      "epoch 84; iter: 0; batch classifier loss: 0.376064; batch adversarial loss: 0.462687\n",
      "epoch 85; iter: 0; batch classifier loss: 0.344392; batch adversarial loss: 0.482168\n",
      "epoch 86; iter: 0; batch classifier loss: 0.429594; batch adversarial loss: 0.469205\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365328; batch adversarial loss: 0.521473\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422332; batch adversarial loss: 0.419849\n",
      "epoch 89; iter: 0; batch classifier loss: 0.412599; batch adversarial loss: 0.452903\n",
      "epoch 90; iter: 0; batch classifier loss: 0.420632; batch adversarial loss: 0.454822\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388055; batch adversarial loss: 0.495058\n",
      "epoch 92; iter: 0; batch classifier loss: 0.411686; batch adversarial loss: 0.603972\n",
      "epoch 93; iter: 0; batch classifier loss: 0.475541; batch adversarial loss: 0.612810\n",
      "epoch 94; iter: 0; batch classifier loss: 0.299697; batch adversarial loss: 0.497868\n",
      "epoch 95; iter: 0; batch classifier loss: 0.280352; batch adversarial loss: 0.486259\n",
      "epoch 96; iter: 0; batch classifier loss: 0.330179; batch adversarial loss: 0.515253\n",
      "epoch 97; iter: 0; batch classifier loss: 0.465712; batch adversarial loss: 0.361480\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376958; batch adversarial loss: 0.482003\n",
      "epoch 99; iter: 0; batch classifier loss: 0.477915; batch adversarial loss: 0.506726\n",
      "epoch 100; iter: 0; batch classifier loss: 0.380913; batch adversarial loss: 0.489466\n",
      "epoch 101; iter: 0; batch classifier loss: 0.427001; batch adversarial loss: 0.493600\n",
      "epoch 102; iter: 0; batch classifier loss: 0.384453; batch adversarial loss: 0.487504\n",
      "epoch 103; iter: 0; batch classifier loss: 0.358595; batch adversarial loss: 0.444098\n",
      "epoch 104; iter: 0; batch classifier loss: 0.399809; batch adversarial loss: 0.424998\n",
      "epoch 105; iter: 0; batch classifier loss: 0.306189; batch adversarial loss: 0.499112\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397335; batch adversarial loss: 0.489774\n",
      "epoch 107; iter: 0; batch classifier loss: 0.338986; batch adversarial loss: 0.578556\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379951; batch adversarial loss: 0.541519\n",
      "epoch 109; iter: 0; batch classifier loss: 0.322790; batch adversarial loss: 0.456625\n",
      "epoch 110; iter: 0; batch classifier loss: 0.339666; batch adversarial loss: 0.593910\n",
      "epoch 111; iter: 0; batch classifier loss: 0.349882; batch adversarial loss: 0.554261\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379110; batch adversarial loss: 0.481186\n",
      "epoch 113; iter: 0; batch classifier loss: 0.340308; batch adversarial loss: 0.482337\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350404; batch adversarial loss: 0.525238\n",
      "epoch 115; iter: 0; batch classifier loss: 0.447272; batch adversarial loss: 0.413672\n",
      "epoch 116; iter: 0; batch classifier loss: 0.369796; batch adversarial loss: 0.454002\n",
      "epoch 117; iter: 0; batch classifier loss: 0.410035; batch adversarial loss: 0.480626\n",
      "epoch 118; iter: 0; batch classifier loss: 0.359951; batch adversarial loss: 0.439299\n",
      "epoch 119; iter: 0; batch classifier loss: 0.342168; batch adversarial loss: 0.527625\n",
      "epoch 120; iter: 0; batch classifier loss: 0.360877; batch adversarial loss: 0.456049\n",
      "epoch 121; iter: 0; batch classifier loss: 0.390575; batch adversarial loss: 0.519234\n",
      "epoch 122; iter: 0; batch classifier loss: 0.399239; batch adversarial loss: 0.491791\n",
      "epoch 123; iter: 0; batch classifier loss: 0.413603; batch adversarial loss: 0.468259\n",
      "epoch 124; iter: 0; batch classifier loss: 0.365042; batch adversarial loss: 0.482440\n",
      "epoch 125; iter: 0; batch classifier loss: 0.398892; batch adversarial loss: 0.465419\n",
      "epoch 126; iter: 0; batch classifier loss: 0.454511; batch adversarial loss: 0.439193\n",
      "epoch 127; iter: 0; batch classifier loss: 0.367214; batch adversarial loss: 0.443861\n",
      "epoch 128; iter: 0; batch classifier loss: 0.308493; batch adversarial loss: 0.537042\n",
      "epoch 129; iter: 0; batch classifier loss: 0.444379; batch adversarial loss: 0.435211\n",
      "epoch 130; iter: 0; batch classifier loss: 0.383458; batch adversarial loss: 0.454927\n",
      "epoch 131; iter: 0; batch classifier loss: 0.360539; batch adversarial loss: 0.442605\n",
      "epoch 132; iter: 0; batch classifier loss: 0.376024; batch adversarial loss: 0.456400\n",
      "epoch 133; iter: 0; batch classifier loss: 0.340412; batch adversarial loss: 0.452292\n",
      "epoch 134; iter: 0; batch classifier loss: 0.367912; batch adversarial loss: 0.561045\n",
      "epoch 135; iter: 0; batch classifier loss: 0.413147; batch adversarial loss: 0.421389\n",
      "epoch 136; iter: 0; batch classifier loss: 0.316639; batch adversarial loss: 0.502465\n",
      "epoch 137; iter: 0; batch classifier loss: 0.478713; batch adversarial loss: 0.420157\n",
      "epoch 138; iter: 0; batch classifier loss: 0.328696; batch adversarial loss: 0.498747\n",
      "epoch 139; iter: 0; batch classifier loss: 0.359655; batch adversarial loss: 0.497036\n",
      "epoch 140; iter: 0; batch classifier loss: 0.488431; batch adversarial loss: 0.458748\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357003; batch adversarial loss: 0.475232\n",
      "epoch 142; iter: 0; batch classifier loss: 0.429828; batch adversarial loss: 0.505977\n",
      "epoch 143; iter: 0; batch classifier loss: 0.461071; batch adversarial loss: 0.399444\n",
      "epoch 144; iter: 0; batch classifier loss: 0.422340; batch adversarial loss: 0.457774\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387285; batch adversarial loss: 0.481730\n",
      "epoch 146; iter: 0; batch classifier loss: 0.405652; batch adversarial loss: 0.490307\n",
      "epoch 147; iter: 0; batch classifier loss: 0.405891; batch adversarial loss: 0.458703\n",
      "epoch 148; iter: 0; batch classifier loss: 0.327467; batch adversarial loss: 0.453881\n",
      "epoch 149; iter: 0; batch classifier loss: 0.382981; batch adversarial loss: 0.426516\n",
      "epoch 150; iter: 0; batch classifier loss: 0.368950; batch adversarial loss: 0.407280\n",
      "epoch 151; iter: 0; batch classifier loss: 0.356111; batch adversarial loss: 0.435877\n",
      "epoch 152; iter: 0; batch classifier loss: 0.388203; batch adversarial loss: 0.466585\n",
      "epoch 153; iter: 0; batch classifier loss: 0.369209; batch adversarial loss: 0.514352\n",
      "epoch 154; iter: 0; batch classifier loss: 0.275184; batch adversarial loss: 0.538048\n",
      "epoch 155; iter: 0; batch classifier loss: 0.300755; batch adversarial loss: 0.497741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.299508; batch adversarial loss: 0.437247\n",
      "epoch 157; iter: 0; batch classifier loss: 0.444129; batch adversarial loss: 0.465768\n",
      "epoch 158; iter: 0; batch classifier loss: 0.390080; batch adversarial loss: 0.487663\n",
      "epoch 159; iter: 0; batch classifier loss: 0.333062; batch adversarial loss: 0.440891\n",
      "epoch 160; iter: 0; batch classifier loss: 0.482144; batch adversarial loss: 0.466829\n",
      "epoch 161; iter: 0; batch classifier loss: 0.359098; batch adversarial loss: 0.497987\n",
      "epoch 162; iter: 0; batch classifier loss: 0.426162; batch adversarial loss: 0.489576\n",
      "epoch 163; iter: 0; batch classifier loss: 0.314976; batch adversarial loss: 0.500260\n",
      "epoch 164; iter: 0; batch classifier loss: 0.460099; batch adversarial loss: 0.413926\n",
      "epoch 165; iter: 0; batch classifier loss: 0.405682; batch adversarial loss: 0.401436\n",
      "epoch 166; iter: 0; batch classifier loss: 0.419014; batch adversarial loss: 0.437477\n",
      "epoch 167; iter: 0; batch classifier loss: 0.370038; batch adversarial loss: 0.438736\n",
      "epoch 168; iter: 0; batch classifier loss: 0.358489; batch adversarial loss: 0.457019\n",
      "epoch 169; iter: 0; batch classifier loss: 0.371647; batch adversarial loss: 0.493571\n",
      "epoch 170; iter: 0; batch classifier loss: 0.410457; batch adversarial loss: 0.481776\n",
      "epoch 171; iter: 0; batch classifier loss: 0.471484; batch adversarial loss: 0.503779\n",
      "epoch 172; iter: 0; batch classifier loss: 0.522243; batch adversarial loss: 0.448095\n",
      "epoch 173; iter: 0; batch classifier loss: 0.433408; batch adversarial loss: 0.421933\n",
      "epoch 174; iter: 0; batch classifier loss: 0.355320; batch adversarial loss: 0.410321\n",
      "epoch 175; iter: 0; batch classifier loss: 0.317098; batch adversarial loss: 0.455878\n",
      "epoch 176; iter: 0; batch classifier loss: 0.335735; batch adversarial loss: 0.515550\n",
      "epoch 177; iter: 0; batch classifier loss: 0.510190; batch adversarial loss: 0.575610\n",
      "epoch 178; iter: 0; batch classifier loss: 0.405992; batch adversarial loss: 0.522125\n",
      "epoch 179; iter: 0; batch classifier loss: 0.455710; batch adversarial loss: 0.455108\n",
      "epoch 180; iter: 0; batch classifier loss: 0.487110; batch adversarial loss: 0.408734\n",
      "epoch 181; iter: 0; batch classifier loss: 0.344509; batch adversarial loss: 0.540798\n",
      "epoch 182; iter: 0; batch classifier loss: 0.517927; batch adversarial loss: 0.366281\n",
      "epoch 183; iter: 0; batch classifier loss: 0.415043; batch adversarial loss: 0.447516\n",
      "epoch 184; iter: 0; batch classifier loss: 0.461482; batch adversarial loss: 0.511145\n",
      "epoch 185; iter: 0; batch classifier loss: 0.408590; batch adversarial loss: 0.433320\n",
      "epoch 186; iter: 0; batch classifier loss: 0.426128; batch adversarial loss: 0.466478\n",
      "epoch 187; iter: 0; batch classifier loss: 0.348522; batch adversarial loss: 0.485830\n",
      "epoch 188; iter: 0; batch classifier loss: 0.386456; batch adversarial loss: 0.516354\n",
      "epoch 189; iter: 0; batch classifier loss: 0.270822; batch adversarial loss: 0.580619\n",
      "epoch 190; iter: 0; batch classifier loss: 0.380027; batch adversarial loss: 0.443536\n",
      "epoch 191; iter: 0; batch classifier loss: 0.345949; batch adversarial loss: 0.422301\n",
      "epoch 192; iter: 0; batch classifier loss: 0.298796; batch adversarial loss: 0.458115\n",
      "epoch 193; iter: 0; batch classifier loss: 0.392834; batch adversarial loss: 0.514739\n",
      "epoch 194; iter: 0; batch classifier loss: 0.370150; batch adversarial loss: 0.525021\n",
      "epoch 195; iter: 0; batch classifier loss: 0.484709; batch adversarial loss: 0.461542\n",
      "epoch 196; iter: 0; batch classifier loss: 0.372477; batch adversarial loss: 0.429258\n",
      "epoch 197; iter: 0; batch classifier loss: 0.317979; batch adversarial loss: 0.418014\n",
      "epoch 198; iter: 0; batch classifier loss: 0.393354; batch adversarial loss: 0.455908\n",
      "epoch 199; iter: 0; batch classifier loss: 0.393565; batch adversarial loss: 0.640458\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698844; batch adversarial loss: 0.829340\n",
      "epoch 1; iter: 0; batch classifier loss: 1.053871; batch adversarial loss: 0.854143\n",
      "epoch 2; iter: 0; batch classifier loss: 0.963194; batch adversarial loss: 0.832942\n",
      "epoch 3; iter: 0; batch classifier loss: 0.922913; batch adversarial loss: 0.745869\n",
      "epoch 4; iter: 0; batch classifier loss: 0.755127; batch adversarial loss: 0.733995\n",
      "epoch 5; iter: 0; batch classifier loss: 0.560446; batch adversarial loss: 0.686848\n",
      "epoch 6; iter: 0; batch classifier loss: 0.493256; batch adversarial loss: 0.667432\n",
      "epoch 7; iter: 0; batch classifier loss: 0.454855; batch adversarial loss: 0.636942\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534252; batch adversarial loss: 0.619947\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496751; batch adversarial loss: 0.596155\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557267; batch adversarial loss: 0.594792\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508333; batch adversarial loss: 0.599834\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530835; batch adversarial loss: 0.581343\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483207; batch adversarial loss: 0.557042\n",
      "epoch 14; iter: 0; batch classifier loss: 0.468140; batch adversarial loss: 0.548270\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556955; batch adversarial loss: 0.578826\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487156; batch adversarial loss: 0.531047\n",
      "epoch 17; iter: 0; batch classifier loss: 0.503790; batch adversarial loss: 0.534741\n",
      "epoch 18; iter: 0; batch classifier loss: 0.514301; batch adversarial loss: 0.527683\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511901; batch adversarial loss: 0.548397\n",
      "epoch 20; iter: 0; batch classifier loss: 0.578988; batch adversarial loss: 0.482689\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511383; batch adversarial loss: 0.532214\n",
      "epoch 22; iter: 0; batch classifier loss: 0.521580; batch adversarial loss: 0.543677\n",
      "epoch 23; iter: 0; batch classifier loss: 0.509871; batch adversarial loss: 0.544065\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512792; batch adversarial loss: 0.497313\n",
      "epoch 25; iter: 0; batch classifier loss: 0.747065; batch adversarial loss: 0.590226\n",
      "epoch 26; iter: 0; batch classifier loss: 0.646344; batch adversarial loss: 0.534036\n",
      "epoch 27; iter: 0; batch classifier loss: 0.685665; batch adversarial loss: 0.654865\n",
      "epoch 28; iter: 0; batch classifier loss: 0.526703; batch adversarial loss: 0.528534\n",
      "epoch 29; iter: 0; batch classifier loss: 0.618615; batch adversarial loss: 0.540855\n",
      "epoch 30; iter: 0; batch classifier loss: 0.484146; batch adversarial loss: 0.549120\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463224; batch adversarial loss: 0.491959\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493935; batch adversarial loss: 0.511505\n",
      "epoch 33; iter: 0; batch classifier loss: 0.428407; batch adversarial loss: 0.516594\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484790; batch adversarial loss: 0.542683\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449418; batch adversarial loss: 0.483101\n",
      "epoch 36; iter: 0; batch classifier loss: 0.489628; batch adversarial loss: 0.463805\n",
      "epoch 37; iter: 0; batch classifier loss: 0.535065; batch adversarial loss: 0.540670\n",
      "epoch 38; iter: 0; batch classifier loss: 0.499902; batch adversarial loss: 0.422417\n",
      "epoch 39; iter: 0; batch classifier loss: 0.510150; batch adversarial loss: 0.466493\n",
      "epoch 40; iter: 0; batch classifier loss: 0.509571; batch adversarial loss: 0.449532\n",
      "epoch 41; iter: 0; batch classifier loss: 0.566252; batch adversarial loss: 0.531016\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424752; batch adversarial loss: 0.452572\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427207; batch adversarial loss: 0.460620\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464247; batch adversarial loss: 0.411551\n",
      "epoch 45; iter: 0; batch classifier loss: 0.368842; batch adversarial loss: 0.447224\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496870; batch adversarial loss: 0.537418\n",
      "epoch 47; iter: 0; batch classifier loss: 0.427142; batch adversarial loss: 0.504253\n",
      "epoch 48; iter: 0; batch classifier loss: 0.454984; batch adversarial loss: 0.431877\n",
      "epoch 49; iter: 0; batch classifier loss: 0.373845; batch adversarial loss: 0.469985\n",
      "epoch 50; iter: 0; batch classifier loss: 0.423386; batch adversarial loss: 0.505088\n",
      "epoch 51; iter: 0; batch classifier loss: 0.383452; batch adversarial loss: 0.483155\n",
      "epoch 52; iter: 0; batch classifier loss: 0.369557; batch adversarial loss: 0.425363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.388862; batch adversarial loss: 0.425986\n",
      "epoch 54; iter: 0; batch classifier loss: 0.454126; batch adversarial loss: 0.445050\n",
      "epoch 55; iter: 0; batch classifier loss: 0.383104; batch adversarial loss: 0.365265\n",
      "epoch 56; iter: 0; batch classifier loss: 0.374671; batch adversarial loss: 0.522753\n",
      "epoch 57; iter: 0; batch classifier loss: 0.364956; batch adversarial loss: 0.499171\n",
      "epoch 58; iter: 0; batch classifier loss: 0.396507; batch adversarial loss: 0.452723\n",
      "epoch 59; iter: 0; batch classifier loss: 0.318320; batch adversarial loss: 0.464383\n",
      "epoch 60; iter: 0; batch classifier loss: 0.394142; batch adversarial loss: 0.596917\n",
      "epoch 61; iter: 0; batch classifier loss: 0.329010; batch adversarial loss: 0.537129\n",
      "epoch 62; iter: 0; batch classifier loss: 0.373074; batch adversarial loss: 0.471810\n",
      "epoch 63; iter: 0; batch classifier loss: 0.407987; batch adversarial loss: 0.453748\n",
      "epoch 64; iter: 0; batch classifier loss: 0.306055; batch adversarial loss: 0.439680\n",
      "epoch 65; iter: 0; batch classifier loss: 0.332041; batch adversarial loss: 0.503536\n",
      "epoch 66; iter: 0; batch classifier loss: 0.407668; batch adversarial loss: 0.449422\n",
      "epoch 67; iter: 0; batch classifier loss: 0.384336; batch adversarial loss: 0.457998\n",
      "epoch 68; iter: 0; batch classifier loss: 0.338046; batch adversarial loss: 0.435040\n",
      "epoch 69; iter: 0; batch classifier loss: 0.349567; batch adversarial loss: 0.453303\n",
      "epoch 70; iter: 0; batch classifier loss: 0.383529; batch adversarial loss: 0.470323\n",
      "epoch 71; iter: 0; batch classifier loss: 0.355193; batch adversarial loss: 0.426393\n",
      "epoch 72; iter: 0; batch classifier loss: 0.315696; batch adversarial loss: 0.528725\n",
      "epoch 73; iter: 0; batch classifier loss: 0.411256; batch adversarial loss: 0.533060\n",
      "epoch 74; iter: 0; batch classifier loss: 0.410454; batch adversarial loss: 0.447049\n",
      "epoch 75; iter: 0; batch classifier loss: 0.388349; batch adversarial loss: 0.483012\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376791; batch adversarial loss: 0.532907\n",
      "epoch 77; iter: 0; batch classifier loss: 0.332897; batch adversarial loss: 0.441847\n",
      "epoch 78; iter: 0; batch classifier loss: 0.301791; batch adversarial loss: 0.529109\n",
      "epoch 79; iter: 0; batch classifier loss: 0.338861; batch adversarial loss: 0.417052\n",
      "epoch 80; iter: 0; batch classifier loss: 0.340435; batch adversarial loss: 0.451009\n",
      "epoch 81; iter: 0; batch classifier loss: 0.309399; batch adversarial loss: 0.485382\n",
      "epoch 82; iter: 0; batch classifier loss: 0.337612; batch adversarial loss: 0.439128\n",
      "epoch 83; iter: 0; batch classifier loss: 0.367430; batch adversarial loss: 0.449276\n",
      "epoch 84; iter: 0; batch classifier loss: 0.283557; batch adversarial loss: 0.459826\n",
      "epoch 85; iter: 0; batch classifier loss: 0.259177; batch adversarial loss: 0.484013\n",
      "epoch 86; iter: 0; batch classifier loss: 0.324445; batch adversarial loss: 0.468944\n",
      "epoch 87; iter: 0; batch classifier loss: 0.273402; batch adversarial loss: 0.523092\n",
      "epoch 88; iter: 0; batch classifier loss: 0.349333; batch adversarial loss: 0.428001\n",
      "epoch 89; iter: 0; batch classifier loss: 0.304414; batch adversarial loss: 0.456105\n",
      "epoch 90; iter: 0; batch classifier loss: 0.380588; batch adversarial loss: 0.457187\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334017; batch adversarial loss: 0.495871\n",
      "epoch 92; iter: 0; batch classifier loss: 0.266964; batch adversarial loss: 0.603396\n",
      "epoch 93; iter: 0; batch classifier loss: 0.311887; batch adversarial loss: 0.612480\n",
      "epoch 94; iter: 0; batch classifier loss: 0.276184; batch adversarial loss: 0.498404\n",
      "epoch 95; iter: 0; batch classifier loss: 0.242757; batch adversarial loss: 0.489043\n",
      "epoch 96; iter: 0; batch classifier loss: 0.323130; batch adversarial loss: 0.522184\n",
      "epoch 97; iter: 0; batch classifier loss: 0.315638; batch adversarial loss: 0.358805\n",
      "epoch 98; iter: 0; batch classifier loss: 0.302424; batch adversarial loss: 0.485520\n",
      "epoch 99; iter: 0; batch classifier loss: 0.371825; batch adversarial loss: 0.509601\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.076218; batch adversarial loss: 0.855437\n",
      "epoch 2; iter: 0; batch classifier loss: 0.930036; batch adversarial loss: 0.827187\n",
      "epoch 3; iter: 0; batch classifier loss: 0.864106; batch adversarial loss: 0.738337\n",
      "epoch 4; iter: 0; batch classifier loss: 0.691120; batch adversarial loss: 0.725507\n",
      "epoch 5; iter: 0; batch classifier loss: 0.526160; batch adversarial loss: 0.682419\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509525; batch adversarial loss: 0.664740\n",
      "epoch 7; iter: 0; batch classifier loss: 0.488590; batch adversarial loss: 0.631861\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562517; batch adversarial loss: 0.615868\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502354; batch adversarial loss: 0.595901\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568337; batch adversarial loss: 0.591365\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550724; batch adversarial loss: 0.596012\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562500; batch adversarial loss: 0.578590\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530839; batch adversarial loss: 0.550415\n",
      "epoch 14; iter: 0; batch classifier loss: 0.479196; batch adversarial loss: 0.549284\n",
      "epoch 15; iter: 0; batch classifier loss: 0.588910; batch adversarial loss: 0.576086\n",
      "epoch 16; iter: 0; batch classifier loss: 0.546044; batch adversarial loss: 0.520498\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537055; batch adversarial loss: 0.533280\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524005; batch adversarial loss: 0.523804\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525734; batch adversarial loss: 0.541749\n",
      "epoch 20; iter: 0; batch classifier loss: 0.566342; batch adversarial loss: 0.461616\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493582; batch adversarial loss: 0.501321\n",
      "epoch 22; iter: 0; batch classifier loss: 0.526272; batch adversarial loss: 0.514896\n",
      "epoch 23; iter: 0; batch classifier loss: 0.484168; batch adversarial loss: 0.523529\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493429; batch adversarial loss: 0.483774\n",
      "epoch 25; iter: 0; batch classifier loss: 0.639778; batch adversarial loss: 0.569154\n",
      "epoch 26; iter: 0; batch classifier loss: 0.582595; batch adversarial loss: 0.526659\n",
      "epoch 27; iter: 0; batch classifier loss: 0.654244; batch adversarial loss: 0.671200\n",
      "epoch 28; iter: 0; batch classifier loss: 0.585643; batch adversarial loss: 0.535650\n",
      "epoch 29; iter: 0; batch classifier loss: 0.693314; batch adversarial loss: 0.562162\n",
      "epoch 30; iter: 0; batch classifier loss: 0.601890; batch adversarial loss: 0.572899\n",
      "epoch 31; iter: 0; batch classifier loss: 0.586914; batch adversarial loss: 0.507354\n",
      "epoch 32; iter: 0; batch classifier loss: 0.600132; batch adversarial loss: 0.528978\n",
      "epoch 33; iter: 0; batch classifier loss: 0.589494; batch adversarial loss: 0.544778\n",
      "epoch 34; iter: 0; batch classifier loss: 0.577772; batch adversarial loss: 0.561076\n",
      "epoch 35; iter: 0; batch classifier loss: 0.511508; batch adversarial loss: 0.491749\n",
      "epoch 36; iter: 0; batch classifier loss: 0.511720; batch adversarial loss: 0.464764\n",
      "epoch 37; iter: 0; batch classifier loss: 0.558257; batch adversarial loss: 0.536459\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523904; batch adversarial loss: 0.418734\n",
      "epoch 39; iter: 0; batch classifier loss: 0.536792; batch adversarial loss: 0.463238\n",
      "epoch 40; iter: 0; batch classifier loss: 0.537233; batch adversarial loss: 0.448190\n",
      "epoch 41; iter: 0; batch classifier loss: 0.562502; batch adversarial loss: 0.532567\n",
      "epoch 42; iter: 0; batch classifier loss: 0.461156; batch adversarial loss: 0.453124\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459603; batch adversarial loss: 0.462427\n",
      "epoch 44; iter: 0; batch classifier loss: 0.483083; batch adversarial loss: 0.412121\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421864; batch adversarial loss: 0.446466\n",
      "epoch 46; iter: 0; batch classifier loss: 0.490468; batch adversarial loss: 0.540695\n",
      "epoch 47; iter: 0; batch classifier loss: 0.502408; batch adversarial loss: 0.510197\n",
      "epoch 48; iter: 0; batch classifier loss: 0.570815; batch adversarial loss: 0.435797\n",
      "epoch 49; iter: 0; batch classifier loss: 0.530919; batch adversarial loss: 0.474697\n",
      "epoch 50; iter: 0; batch classifier loss: 0.488637; batch adversarial loss: 0.505149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.464446; batch adversarial loss: 0.483672\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442760; batch adversarial loss: 0.426787\n",
      "epoch 53; iter: 0; batch classifier loss: 0.460807; batch adversarial loss: 0.426871\n",
      "epoch 54; iter: 0; batch classifier loss: 0.497232; batch adversarial loss: 0.446394\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487599; batch adversarial loss: 0.366508\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409341; batch adversarial loss: 0.523307\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401724; batch adversarial loss: 0.498091\n",
      "epoch 58; iter: 0; batch classifier loss: 0.445471; batch adversarial loss: 0.452867\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409067; batch adversarial loss: 0.465373\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439156; batch adversarial loss: 0.596780\n",
      "epoch 61; iter: 0; batch classifier loss: 0.403626; batch adversarial loss: 0.538468\n",
      "epoch 62; iter: 0; batch classifier loss: 0.442631; batch adversarial loss: 0.470868\n",
      "epoch 63; iter: 0; batch classifier loss: 0.430082; batch adversarial loss: 0.449601\n",
      "epoch 64; iter: 0; batch classifier loss: 0.371625; batch adversarial loss: 0.439546\n",
      "epoch 65; iter: 0; batch classifier loss: 0.373308; batch adversarial loss: 0.504367\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414545; batch adversarial loss: 0.449695\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399256; batch adversarial loss: 0.456628\n",
      "epoch 68; iter: 0; batch classifier loss: 0.390287; batch adversarial loss: 0.433088\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428687; batch adversarial loss: 0.453565\n",
      "epoch 70; iter: 0; batch classifier loss: 0.462539; batch adversarial loss: 0.469496\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409084; batch adversarial loss: 0.424729\n",
      "epoch 72; iter: 0; batch classifier loss: 0.472165; batch adversarial loss: 0.530700\n",
      "epoch 73; iter: 0; batch classifier loss: 0.420626; batch adversarial loss: 0.529588\n",
      "epoch 74; iter: 0; batch classifier loss: 0.459106; batch adversarial loss: 0.444559\n",
      "epoch 75; iter: 0; batch classifier loss: 0.487256; batch adversarial loss: 0.482273\n",
      "epoch 76; iter: 0; batch classifier loss: 0.445371; batch adversarial loss: 0.527669\n",
      "epoch 77; iter: 0; batch classifier loss: 0.388241; batch adversarial loss: 0.440793\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377711; batch adversarial loss: 0.527143\n",
      "epoch 79; iter: 0; batch classifier loss: 0.397342; batch adversarial loss: 0.415354\n",
      "epoch 80; iter: 0; batch classifier loss: 0.429700; batch adversarial loss: 0.452652\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397681; batch adversarial loss: 0.484577\n",
      "epoch 82; iter: 0; batch classifier loss: 0.372839; batch adversarial loss: 0.435472\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402640; batch adversarial loss: 0.446641\n",
      "epoch 84; iter: 0; batch classifier loss: 0.366953; batch adversarial loss: 0.462675\n",
      "epoch 85; iter: 0; batch classifier loss: 0.333730; batch adversarial loss: 0.483421\n",
      "epoch 86; iter: 0; batch classifier loss: 0.431523; batch adversarial loss: 0.468977\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365927; batch adversarial loss: 0.520991\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417634; batch adversarial loss: 0.419310\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389548; batch adversarial loss: 0.453086\n",
      "epoch 90; iter: 0; batch classifier loss: 0.391688; batch adversarial loss: 0.453411\n",
      "epoch 91; iter: 0; batch classifier loss: 0.387648; batch adversarial loss: 0.494879\n",
      "epoch 92; iter: 0; batch classifier loss: 0.400404; batch adversarial loss: 0.603771\n",
      "epoch 93; iter: 0; batch classifier loss: 0.455614; batch adversarial loss: 0.613647\n",
      "epoch 94; iter: 0; batch classifier loss: 0.304459; batch adversarial loss: 0.495045\n",
      "epoch 95; iter: 0; batch classifier loss: 0.284176; batch adversarial loss: 0.484029\n",
      "epoch 96; iter: 0; batch classifier loss: 0.338000; batch adversarial loss: 0.515257\n",
      "epoch 97; iter: 0; batch classifier loss: 0.437183; batch adversarial loss: 0.360546\n",
      "epoch 98; iter: 0; batch classifier loss: 0.363994; batch adversarial loss: 0.481739\n",
      "epoch 99; iter: 0; batch classifier loss: 0.464705; batch adversarial loss: 0.505428\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698844; batch adversarial loss: 0.829340\n",
      "epoch 1; iter: 0; batch classifier loss: 1.067654; batch adversarial loss: 0.855171\n",
      "epoch 2; iter: 0; batch classifier loss: 0.982908; batch adversarial loss: 0.834340\n",
      "epoch 3; iter: 0; batch classifier loss: 0.949488; batch adversarial loss: 0.746679\n",
      "epoch 4; iter: 0; batch classifier loss: 0.776965; batch adversarial loss: 0.735375\n",
      "epoch 5; iter: 0; batch classifier loss: 0.579831; batch adversarial loss: 0.689520\n",
      "epoch 6; iter: 0; batch classifier loss: 0.496002; batch adversarial loss: 0.667718\n",
      "epoch 7; iter: 0; batch classifier loss: 0.456466; batch adversarial loss: 0.636474\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532231; batch adversarial loss: 0.619846\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496204; batch adversarial loss: 0.595686\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559384; batch adversarial loss: 0.593991\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507735; batch adversarial loss: 0.599683\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530692; batch adversarial loss: 0.580985\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484621; batch adversarial loss: 0.556571\n",
      "epoch 14; iter: 0; batch classifier loss: 0.467500; batch adversarial loss: 0.548742\n",
      "epoch 15; iter: 0; batch classifier loss: 0.553105; batch adversarial loss: 0.580139\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483997; batch adversarial loss: 0.533301\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498381; batch adversarial loss: 0.535947\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511633; batch adversarial loss: 0.530707\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526473; batch adversarial loss: 0.555786\n",
      "epoch 20; iter: 0; batch classifier loss: 0.598719; batch adversarial loss: 0.490603\n",
      "epoch 21; iter: 0; batch classifier loss: 0.528229; batch adversarial loss: 0.536911\n",
      "epoch 22; iter: 0; batch classifier loss: 0.547338; batch adversarial loss: 0.551139\n",
      "epoch 23; iter: 0; batch classifier loss: 0.563268; batch adversarial loss: 0.558162\n",
      "epoch 24; iter: 0; batch classifier loss: 0.567310; batch adversarial loss: 0.508851\n",
      "epoch 25; iter: 0; batch classifier loss: 0.770575; batch adversarial loss: 0.587636\n",
      "epoch 26; iter: 0; batch classifier loss: 0.640335; batch adversarial loss: 0.527420\n",
      "epoch 27; iter: 0; batch classifier loss: 0.647704; batch adversarial loss: 0.641407\n",
      "epoch 28; iter: 0; batch classifier loss: 0.512153; batch adversarial loss: 0.523301\n",
      "epoch 29; iter: 0; batch classifier loss: 0.586632; batch adversarial loss: 0.534481\n",
      "epoch 30; iter: 0; batch classifier loss: 0.470352; batch adversarial loss: 0.544102\n",
      "epoch 31; iter: 0; batch classifier loss: 0.448396; batch adversarial loss: 0.488304\n",
      "epoch 32; iter: 0; batch classifier loss: 0.476034; batch adversarial loss: 0.507499\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412141; batch adversarial loss: 0.512576\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471919; batch adversarial loss: 0.537614\n",
      "epoch 35; iter: 0; batch classifier loss: 0.451948; batch adversarial loss: 0.481498\n",
      "epoch 36; iter: 0; batch classifier loss: 0.497831; batch adversarial loss: 0.464874\n",
      "epoch 37; iter: 0; batch classifier loss: 0.576326; batch adversarial loss: 0.543534\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523863; batch adversarial loss: 0.423029\n",
      "epoch 39; iter: 0; batch classifier loss: 0.521260; batch adversarial loss: 0.466176\n",
      "epoch 40; iter: 0; batch classifier loss: 0.524800; batch adversarial loss: 0.448963\n",
      "epoch 41; iter: 0; batch classifier loss: 0.568999; batch adversarial loss: 0.530041\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424570; batch adversarial loss: 0.451821\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422971; batch adversarial loss: 0.460009\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466237; batch adversarial loss: 0.411287\n",
      "epoch 45; iter: 0; batch classifier loss: 0.368547; batch adversarial loss: 0.446885\n",
      "epoch 46; iter: 0; batch classifier loss: 0.488751; batch adversarial loss: 0.537016\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401183; batch adversarial loss: 0.503983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.450138; batch adversarial loss: 0.431512\n",
      "epoch 49; iter: 0; batch classifier loss: 0.368869; batch adversarial loss: 0.469818\n",
      "epoch 50; iter: 0; batch classifier loss: 0.429051; batch adversarial loss: 0.505108\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392668; batch adversarial loss: 0.483111\n",
      "epoch 52; iter: 0; batch classifier loss: 0.373629; batch adversarial loss: 0.425302\n",
      "epoch 53; iter: 0; batch classifier loss: 0.389045; batch adversarial loss: 0.425745\n",
      "epoch 54; iter: 0; batch classifier loss: 0.467058; batch adversarial loss: 0.445072\n",
      "epoch 55; iter: 0; batch classifier loss: 0.398975; batch adversarial loss: 0.365209\n",
      "epoch 56; iter: 0; batch classifier loss: 0.371205; batch adversarial loss: 0.522385\n",
      "epoch 57; iter: 0; batch classifier loss: 0.365880; batch adversarial loss: 0.499507\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395251; batch adversarial loss: 0.452544\n",
      "epoch 59; iter: 0; batch classifier loss: 0.326377; batch adversarial loss: 0.464892\n",
      "epoch 60; iter: 0; batch classifier loss: 0.390082; batch adversarial loss: 0.597228\n",
      "epoch 61; iter: 0; batch classifier loss: 0.341398; batch adversarial loss: 0.537601\n",
      "epoch 62; iter: 0; batch classifier loss: 0.382992; batch adversarial loss: 0.471792\n",
      "epoch 63; iter: 0; batch classifier loss: 0.406227; batch adversarial loss: 0.453437\n",
      "epoch 64; iter: 0; batch classifier loss: 0.316742; batch adversarial loss: 0.440002\n",
      "epoch 65; iter: 0; batch classifier loss: 0.332419; batch adversarial loss: 0.503390\n",
      "epoch 66; iter: 0; batch classifier loss: 0.420794; batch adversarial loss: 0.450064\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388944; batch adversarial loss: 0.457640\n",
      "epoch 68; iter: 0; batch classifier loss: 0.334755; batch adversarial loss: 0.435364\n",
      "epoch 69; iter: 0; batch classifier loss: 0.343230; batch adversarial loss: 0.453089\n",
      "epoch 70; iter: 0; batch classifier loss: 0.369619; batch adversarial loss: 0.470511\n",
      "epoch 71; iter: 0; batch classifier loss: 0.345636; batch adversarial loss: 0.426846\n",
      "epoch 72; iter: 0; batch classifier loss: 0.321997; batch adversarial loss: 0.528555\n",
      "epoch 73; iter: 0; batch classifier loss: 0.392256; batch adversarial loss: 0.532671\n",
      "epoch 74; iter: 0; batch classifier loss: 0.392758; batch adversarial loss: 0.446367\n",
      "epoch 75; iter: 0; batch classifier loss: 0.409337; batch adversarial loss: 0.483777\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371475; batch adversarial loss: 0.533630\n",
      "epoch 77; iter: 0; batch classifier loss: 0.337245; batch adversarial loss: 0.442098\n",
      "epoch 78; iter: 0; batch classifier loss: 0.301433; batch adversarial loss: 0.528542\n",
      "epoch 79; iter: 0; batch classifier loss: 0.346458; batch adversarial loss: 0.418298\n",
      "epoch 80; iter: 0; batch classifier loss: 0.360020; batch adversarial loss: 0.451727\n",
      "epoch 81; iter: 0; batch classifier loss: 0.330658; batch adversarial loss: 0.486299\n",
      "epoch 82; iter: 0; batch classifier loss: 0.346397; batch adversarial loss: 0.439830\n",
      "epoch 83; iter: 0; batch classifier loss: 0.349793; batch adversarial loss: 0.449188\n",
      "epoch 84; iter: 0; batch classifier loss: 0.301699; batch adversarial loss: 0.459693\n",
      "epoch 85; iter: 0; batch classifier loss: 0.275826; batch adversarial loss: 0.484363\n",
      "epoch 86; iter: 0; batch classifier loss: 0.329578; batch adversarial loss: 0.469510\n",
      "epoch 87; iter: 0; batch classifier loss: 0.274900; batch adversarial loss: 0.523143\n",
      "epoch 88; iter: 0; batch classifier loss: 0.345660; batch adversarial loss: 0.427103\n",
      "epoch 89; iter: 0; batch classifier loss: 0.312129; batch adversarial loss: 0.456269\n",
      "epoch 90; iter: 0; batch classifier loss: 0.380747; batch adversarial loss: 0.457669\n",
      "epoch 91; iter: 0; batch classifier loss: 0.330378; batch adversarial loss: 0.495711\n",
      "epoch 92; iter: 0; batch classifier loss: 0.252685; batch adversarial loss: 0.602873\n",
      "epoch 93; iter: 0; batch classifier loss: 0.313008; batch adversarial loss: 0.612669\n",
      "epoch 94; iter: 0; batch classifier loss: 0.270778; batch adversarial loss: 0.498770\n",
      "epoch 95; iter: 0; batch classifier loss: 0.255292; batch adversarial loss: 0.488780\n",
      "epoch 96; iter: 0; batch classifier loss: 0.331138; batch adversarial loss: 0.522071\n",
      "epoch 97; iter: 0; batch classifier loss: 0.341062; batch adversarial loss: 0.360333\n",
      "epoch 98; iter: 0; batch classifier loss: 0.306602; batch adversarial loss: 0.485904\n",
      "epoch 99; iter: 0; batch classifier loss: 0.359648; batch adversarial loss: 0.510074\n",
      "epoch 100; iter: 0; batch classifier loss: 0.274064; batch adversarial loss: 0.488093\n",
      "epoch 101; iter: 0; batch classifier loss: 0.303974; batch adversarial loss: 0.494360\n",
      "epoch 102; iter: 0; batch classifier loss: 0.335161; batch adversarial loss: 0.490044\n",
      "epoch 103; iter: 0; batch classifier loss: 0.329817; batch adversarial loss: 0.447056\n",
      "epoch 104; iter: 0; batch classifier loss: 0.407470; batch adversarial loss: 0.428172\n",
      "epoch 105; iter: 0; batch classifier loss: 0.255391; batch adversarial loss: 0.499288\n",
      "epoch 106; iter: 0; batch classifier loss: 0.325554; batch adversarial loss: 0.489147\n",
      "epoch 107; iter: 0; batch classifier loss: 0.339000; batch adversarial loss: 0.576968\n",
      "epoch 108; iter: 0; batch classifier loss: 0.250363; batch adversarial loss: 0.538376\n",
      "epoch 109; iter: 0; batch classifier loss: 0.291335; batch adversarial loss: 0.459846\n",
      "epoch 110; iter: 0; batch classifier loss: 0.267210; batch adversarial loss: 0.593326\n",
      "epoch 111; iter: 0; batch classifier loss: 0.292893; batch adversarial loss: 0.559450\n",
      "epoch 112; iter: 0; batch classifier loss: 0.374743; batch adversarial loss: 0.488993\n",
      "epoch 113; iter: 0; batch classifier loss: 0.367249; batch adversarial loss: 0.488233\n",
      "epoch 114; iter: 0; batch classifier loss: 0.400291; batch adversarial loss: 0.532007\n",
      "epoch 115; iter: 0; batch classifier loss: 0.473196; batch adversarial loss: 0.417170\n",
      "epoch 116; iter: 0; batch classifier loss: 0.450105; batch adversarial loss: 0.463306\n",
      "epoch 117; iter: 0; batch classifier loss: 0.429825; batch adversarial loss: 0.482494\n",
      "epoch 118; iter: 0; batch classifier loss: 0.324169; batch adversarial loss: 0.442910\n",
      "epoch 119; iter: 0; batch classifier loss: 0.390337; batch adversarial loss: 0.533428\n",
      "epoch 120; iter: 0; batch classifier loss: 0.352493; batch adversarial loss: 0.459967\n",
      "epoch 121; iter: 0; batch classifier loss: 0.397734; batch adversarial loss: 0.526453\n",
      "epoch 122; iter: 0; batch classifier loss: 0.401587; batch adversarial loss: 0.493802\n",
      "epoch 123; iter: 0; batch classifier loss: 0.354815; batch adversarial loss: 0.468956\n",
      "epoch 124; iter: 0; batch classifier loss: 0.329362; batch adversarial loss: 0.488261\n",
      "epoch 125; iter: 0; batch classifier loss: 0.389622; batch adversarial loss: 0.471806\n",
      "epoch 126; iter: 0; batch classifier loss: 0.455670; batch adversarial loss: 0.437690\n",
      "epoch 127; iter: 0; batch classifier loss: 0.370827; batch adversarial loss: 0.447194\n",
      "epoch 128; iter: 0; batch classifier loss: 0.327349; batch adversarial loss: 0.543491\n",
      "epoch 129; iter: 0; batch classifier loss: 0.349568; batch adversarial loss: 0.435638\n",
      "epoch 130; iter: 0; batch classifier loss: 0.409657; batch adversarial loss: 0.459949\n",
      "epoch 131; iter: 0; batch classifier loss: 0.418559; batch adversarial loss: 0.442107\n",
      "epoch 132; iter: 0; batch classifier loss: 0.367888; batch adversarial loss: 0.463879\n",
      "epoch 133; iter: 0; batch classifier loss: 0.383891; batch adversarial loss: 0.459232\n",
      "epoch 134; iter: 0; batch classifier loss: 0.406876; batch adversarial loss: 0.566384\n",
      "epoch 135; iter: 0; batch classifier loss: 0.388634; batch adversarial loss: 0.424848\n",
      "epoch 136; iter: 0; batch classifier loss: 0.343660; batch adversarial loss: 0.505463\n",
      "epoch 137; iter: 0; batch classifier loss: 0.487597; batch adversarial loss: 0.419107\n",
      "epoch 138; iter: 0; batch classifier loss: 0.394255; batch adversarial loss: 0.504501\n",
      "epoch 139; iter: 0; batch classifier loss: 0.370923; batch adversarial loss: 0.497058\n",
      "epoch 140; iter: 0; batch classifier loss: 0.430638; batch adversarial loss: 0.459407\n",
      "epoch 141; iter: 0; batch classifier loss: 0.322972; batch adversarial loss: 0.479245\n",
      "epoch 142; iter: 0; batch classifier loss: 0.412088; batch adversarial loss: 0.507241\n",
      "epoch 143; iter: 0; batch classifier loss: 0.471260; batch adversarial loss: 0.396040\n",
      "epoch 144; iter: 0; batch classifier loss: 0.371209; batch adversarial loss: 0.459419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 145; iter: 0; batch classifier loss: 0.407677; batch adversarial loss: 0.482308\n",
      "epoch 146; iter: 0; batch classifier loss: 0.399919; batch adversarial loss: 0.493702\n",
      "epoch 147; iter: 0; batch classifier loss: 0.349470; batch adversarial loss: 0.453419\n",
      "epoch 148; iter: 0; batch classifier loss: 0.366257; batch adversarial loss: 0.459375\n",
      "epoch 149; iter: 0; batch classifier loss: 0.434657; batch adversarial loss: 0.434277\n",
      "epoch 150; iter: 0; batch classifier loss: 0.402780; batch adversarial loss: 0.396467\n",
      "epoch 151; iter: 0; batch classifier loss: 0.341362; batch adversarial loss: 0.436433\n",
      "epoch 152; iter: 0; batch classifier loss: 0.382278; batch adversarial loss: 0.470126\n",
      "epoch 153; iter: 0; batch classifier loss: 0.380195; batch adversarial loss: 0.517815\n",
      "epoch 154; iter: 0; batch classifier loss: 0.283861; batch adversarial loss: 0.540979\n",
      "epoch 155; iter: 0; batch classifier loss: 0.346749; batch adversarial loss: 0.495678\n",
      "epoch 156; iter: 0; batch classifier loss: 0.352933; batch adversarial loss: 0.446077\n",
      "epoch 157; iter: 0; batch classifier loss: 0.497035; batch adversarial loss: 0.471032\n",
      "epoch 158; iter: 0; batch classifier loss: 0.390436; batch adversarial loss: 0.493189\n",
      "epoch 159; iter: 0; batch classifier loss: 0.459284; batch adversarial loss: 0.438330\n",
      "epoch 160; iter: 0; batch classifier loss: 0.456841; batch adversarial loss: 0.460890\n",
      "epoch 161; iter: 0; batch classifier loss: 0.424379; batch adversarial loss: 0.495404\n",
      "epoch 162; iter: 0; batch classifier loss: 0.502584; batch adversarial loss: 0.484581\n",
      "epoch 163; iter: 0; batch classifier loss: 0.326569; batch adversarial loss: 0.505502\n",
      "epoch 164; iter: 0; batch classifier loss: 0.431564; batch adversarial loss: 0.413310\n",
      "epoch 165; iter: 0; batch classifier loss: 0.400007; batch adversarial loss: 0.401640\n",
      "epoch 166; iter: 0; batch classifier loss: 0.377048; batch adversarial loss: 0.437000\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371915; batch adversarial loss: 0.436960\n",
      "epoch 168; iter: 0; batch classifier loss: 0.397773; batch adversarial loss: 0.459590\n",
      "epoch 169; iter: 0; batch classifier loss: 0.368651; batch adversarial loss: 0.494361\n",
      "epoch 170; iter: 0; batch classifier loss: 0.358887; batch adversarial loss: 0.482033\n",
      "epoch 171; iter: 0; batch classifier loss: 0.504210; batch adversarial loss: 0.505882\n",
      "epoch 172; iter: 0; batch classifier loss: 0.358266; batch adversarial loss: 0.446718\n",
      "epoch 173; iter: 0; batch classifier loss: 0.393739; batch adversarial loss: 0.415233\n",
      "epoch 174; iter: 0; batch classifier loss: 0.308430; batch adversarial loss: 0.412610\n",
      "epoch 175; iter: 0; batch classifier loss: 0.293030; batch adversarial loss: 0.458695\n",
      "epoch 176; iter: 0; batch classifier loss: 0.339935; batch adversarial loss: 0.517019\n",
      "epoch 177; iter: 0; batch classifier loss: 0.406324; batch adversarial loss: 0.574951\n",
      "epoch 178; iter: 0; batch classifier loss: 0.362054; batch adversarial loss: 0.518531\n",
      "epoch 179; iter: 0; batch classifier loss: 0.476769; batch adversarial loss: 0.449680\n",
      "epoch 180; iter: 0; batch classifier loss: 0.356820; batch adversarial loss: 0.411833\n",
      "epoch 181; iter: 0; batch classifier loss: 0.334939; batch adversarial loss: 0.541591\n",
      "epoch 182; iter: 0; batch classifier loss: 0.498025; batch adversarial loss: 0.376435\n",
      "epoch 183; iter: 0; batch classifier loss: 0.420333; batch adversarial loss: 0.457269\n",
      "epoch 184; iter: 0; batch classifier loss: 0.412011; batch adversarial loss: 0.516402\n",
      "epoch 185; iter: 0; batch classifier loss: 0.410884; batch adversarial loss: 0.436067\n",
      "epoch 186; iter: 0; batch classifier loss: 0.411888; batch adversarial loss: 0.470465\n",
      "epoch 187; iter: 0; batch classifier loss: 0.261962; batch adversarial loss: 0.482908\n",
      "epoch 188; iter: 0; batch classifier loss: 0.442754; batch adversarial loss: 0.518046\n",
      "epoch 189; iter: 0; batch classifier loss: 0.241310; batch adversarial loss: 0.575664\n",
      "epoch 190; iter: 0; batch classifier loss: 0.379065; batch adversarial loss: 0.447303\n",
      "epoch 191; iter: 0; batch classifier loss: 0.288838; batch adversarial loss: 0.423914\n",
      "epoch 192; iter: 0; batch classifier loss: 0.286845; batch adversarial loss: 0.458969\n",
      "epoch 193; iter: 0; batch classifier loss: 0.292637; batch adversarial loss: 0.516202\n",
      "epoch 194; iter: 0; batch classifier loss: 0.414694; batch adversarial loss: 0.528968\n",
      "epoch 195; iter: 0; batch classifier loss: 0.411810; batch adversarial loss: 0.459808\n",
      "epoch 196; iter: 0; batch classifier loss: 0.340140; batch adversarial loss: 0.434549\n",
      "epoch 197; iter: 0; batch classifier loss: 0.289588; batch adversarial loss: 0.414071\n",
      "epoch 198; iter: 0; batch classifier loss: 0.368773; batch adversarial loss: 0.458661\n",
      "epoch 199; iter: 0; batch classifier loss: 0.317153; batch adversarial loss: 0.635107\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.131702; batch adversarial loss: 0.859086\n",
      "epoch 2; iter: 0; batch classifier loss: 0.988032; batch adversarial loss: 0.831479\n",
      "epoch 3; iter: 0; batch classifier loss: 0.943981; batch adversarial loss: 0.742668\n",
      "epoch 4; iter: 0; batch classifier loss: 0.747415; batch adversarial loss: 0.730795\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567772; batch adversarial loss: 0.687316\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513390; batch adversarial loss: 0.665608\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491611; batch adversarial loss: 0.631194\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560568; batch adversarial loss: 0.615657\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501343; batch adversarial loss: 0.595235\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565213; batch adversarial loss: 0.591175\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545597; batch adversarial loss: 0.596084\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558801; batch adversarial loss: 0.578217\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517549; batch adversarial loss: 0.551534\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466801; batch adversarial loss: 0.550245\n",
      "epoch 15; iter: 0; batch classifier loss: 0.576472; batch adversarial loss: 0.579078\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531729; batch adversarial loss: 0.528953\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524555; batch adversarial loss: 0.538811\n",
      "epoch 18; iter: 0; batch classifier loss: 0.527259; batch adversarial loss: 0.528088\n",
      "epoch 19; iter: 0; batch classifier loss: 0.532679; batch adversarial loss: 0.549454\n",
      "epoch 20; iter: 0; batch classifier loss: 0.586202; batch adversarial loss: 0.472915\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539886; batch adversarial loss: 0.521548\n",
      "epoch 22; iter: 0; batch classifier loss: 0.581185; batch adversarial loss: 0.533193\n",
      "epoch 23; iter: 0; batch classifier loss: 0.529952; batch adversarial loss: 0.546135\n",
      "epoch 24; iter: 0; batch classifier loss: 0.540818; batch adversarial loss: 0.501879\n",
      "epoch 25; iter: 0; batch classifier loss: 0.756064; batch adversarial loss: 0.590787\n",
      "epoch 26; iter: 0; batch classifier loss: 0.653344; batch adversarial loss: 0.536099\n",
      "epoch 27; iter: 0; batch classifier loss: 0.721493; batch adversarial loss: 0.663511\n",
      "epoch 28; iter: 0; batch classifier loss: 0.610185; batch adversarial loss: 0.533765\n",
      "epoch 29; iter: 0; batch classifier loss: 0.678895; batch adversarial loss: 0.547960\n",
      "epoch 30; iter: 0; batch classifier loss: 0.558355; batch adversarial loss: 0.552610\n",
      "epoch 31; iter: 0; batch classifier loss: 0.552161; batch adversarial loss: 0.495112\n",
      "epoch 32; iter: 0; batch classifier loss: 0.545770; batch adversarial loss: 0.515899\n",
      "epoch 33; iter: 0; batch classifier loss: 0.503849; batch adversarial loss: 0.525256\n",
      "epoch 34; iter: 0; batch classifier loss: 0.499354; batch adversarial loss: 0.544558\n",
      "epoch 35; iter: 0; batch classifier loss: 0.486767; batch adversarial loss: 0.483712\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508803; batch adversarial loss: 0.459786\n",
      "epoch 37; iter: 0; batch classifier loss: 0.528898; batch adversarial loss: 0.531797\n",
      "epoch 38; iter: 0; batch classifier loss: 0.526477; batch adversarial loss: 0.416140\n",
      "epoch 39; iter: 0; batch classifier loss: 0.553378; batch adversarial loss: 0.464302\n",
      "epoch 40; iter: 0; batch classifier loss: 0.559418; batch adversarial loss: 0.450326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.613290; batch adversarial loss: 0.537272\n",
      "epoch 42; iter: 0; batch classifier loss: 0.497158; batch adversarial loss: 0.456523\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486087; batch adversarial loss: 0.463830\n",
      "epoch 44; iter: 0; batch classifier loss: 0.509720; batch adversarial loss: 0.412907\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430655; batch adversarial loss: 0.447894\n",
      "epoch 46; iter: 0; batch classifier loss: 0.511572; batch adversarial loss: 0.537341\n",
      "epoch 47; iter: 0; batch classifier loss: 0.523463; batch adversarial loss: 0.506330\n",
      "epoch 48; iter: 0; batch classifier loss: 0.562691; batch adversarial loss: 0.433754\n",
      "epoch 49; iter: 0; batch classifier loss: 0.442526; batch adversarial loss: 0.471903\n",
      "epoch 50; iter: 0; batch classifier loss: 0.466231; batch adversarial loss: 0.504655\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468450; batch adversarial loss: 0.483196\n",
      "epoch 52; iter: 0; batch classifier loss: 0.441857; batch adversarial loss: 0.426300\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465988; batch adversarial loss: 0.426323\n",
      "epoch 54; iter: 0; batch classifier loss: 0.506338; batch adversarial loss: 0.446361\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483879; batch adversarial loss: 0.365810\n",
      "epoch 56; iter: 0; batch classifier loss: 0.421635; batch adversarial loss: 0.523868\n",
      "epoch 57; iter: 0; batch classifier loss: 0.404718; batch adversarial loss: 0.498888\n",
      "epoch 58; iter: 0; batch classifier loss: 0.458182; batch adversarial loss: 0.453126\n",
      "epoch 59; iter: 0; batch classifier loss: 0.410127; batch adversarial loss: 0.465531\n",
      "epoch 60; iter: 0; batch classifier loss: 0.446806; batch adversarial loss: 0.596645\n",
      "epoch 61; iter: 0; batch classifier loss: 0.422485; batch adversarial loss: 0.539160\n",
      "epoch 62; iter: 0; batch classifier loss: 0.438039; batch adversarial loss: 0.470929\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425156; batch adversarial loss: 0.449452\n",
      "epoch 64; iter: 0; batch classifier loss: 0.385668; batch adversarial loss: 0.440122\n",
      "epoch 65; iter: 0; batch classifier loss: 0.386569; batch adversarial loss: 0.503863\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427686; batch adversarial loss: 0.450282\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412170; batch adversarial loss: 0.456024\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412925; batch adversarial loss: 0.432603\n",
      "epoch 69; iter: 0; batch classifier loss: 0.441355; batch adversarial loss: 0.454053\n",
      "epoch 70; iter: 0; batch classifier loss: 0.468857; batch adversarial loss: 0.469605\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409360; batch adversarial loss: 0.424991\n",
      "epoch 72; iter: 0; batch classifier loss: 0.478754; batch adversarial loss: 0.530917\n",
      "epoch 73; iter: 0; batch classifier loss: 0.433659; batch adversarial loss: 0.529164\n",
      "epoch 74; iter: 0; batch classifier loss: 0.467702; batch adversarial loss: 0.445124\n",
      "epoch 75; iter: 0; batch classifier loss: 0.504068; batch adversarial loss: 0.481885\n",
      "epoch 76; iter: 0; batch classifier loss: 0.468269; batch adversarial loss: 0.529016\n",
      "epoch 77; iter: 0; batch classifier loss: 0.407846; batch adversarial loss: 0.440830\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368148; batch adversarial loss: 0.526273\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402206; batch adversarial loss: 0.413815\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436711; batch adversarial loss: 0.452585\n",
      "epoch 81; iter: 0; batch classifier loss: 0.401219; batch adversarial loss: 0.485481\n",
      "epoch 82; iter: 0; batch classifier loss: 0.379844; batch adversarial loss: 0.436310\n",
      "epoch 83; iter: 0; batch classifier loss: 0.413532; batch adversarial loss: 0.447563\n",
      "epoch 84; iter: 0; batch classifier loss: 0.371723; batch adversarial loss: 0.462449\n",
      "epoch 85; iter: 0; batch classifier loss: 0.350681; batch adversarial loss: 0.484037\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424973; batch adversarial loss: 0.469110\n",
      "epoch 87; iter: 0; batch classifier loss: 0.356457; batch adversarial loss: 0.522195\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427856; batch adversarial loss: 0.419916\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390140; batch adversarial loss: 0.453547\n",
      "epoch 90; iter: 0; batch classifier loss: 0.395497; batch adversarial loss: 0.454656\n",
      "epoch 91; iter: 0; batch classifier loss: 0.395431; batch adversarial loss: 0.495644\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404997; batch adversarial loss: 0.603950\n",
      "epoch 93; iter: 0; batch classifier loss: 0.452559; batch adversarial loss: 0.613393\n",
      "epoch 94; iter: 0; batch classifier loss: 0.302927; batch adversarial loss: 0.496178\n",
      "epoch 95; iter: 0; batch classifier loss: 0.285788; batch adversarial loss: 0.485690\n",
      "epoch 96; iter: 0; batch classifier loss: 0.328855; batch adversarial loss: 0.514467\n",
      "epoch 97; iter: 0; batch classifier loss: 0.483779; batch adversarial loss: 0.361363\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384827; batch adversarial loss: 0.481732\n",
      "epoch 99; iter: 0; batch classifier loss: 0.461165; batch adversarial loss: 0.506248\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.118494; batch adversarial loss: 0.858321\n",
      "epoch 2; iter: 0; batch classifier loss: 0.974112; batch adversarial loss: 0.830534\n",
      "epoch 3; iter: 0; batch classifier loss: 0.924912; batch adversarial loss: 0.741787\n",
      "epoch 4; iter: 0; batch classifier loss: 0.733601; batch adversarial loss: 0.729518\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555906; batch adversarial loss: 0.686241\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512343; batch adversarial loss: 0.665242\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490112; batch adversarial loss: 0.631462\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561406; batch adversarial loss: 0.615790\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501795; batch adversarial loss: 0.595429\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565015; batch adversarial loss: 0.591339\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546764; batch adversarial loss: 0.596111\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559541; batch adversarial loss: 0.578242\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519695; batch adversarial loss: 0.551553\n",
      "epoch 14; iter: 0; batch classifier loss: 0.468946; batch adversarial loss: 0.549938\n",
      "epoch 15; iter: 0; batch classifier loss: 0.579787; batch adversarial loss: 0.578155\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533113; batch adversarial loss: 0.527036\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527426; batch adversarial loss: 0.537775\n",
      "epoch 18; iter: 0; batch classifier loss: 0.525497; batch adversarial loss: 0.527210\n",
      "epoch 19; iter: 0; batch classifier loss: 0.529109; batch adversarial loss: 0.547003\n",
      "epoch 20; iter: 0; batch classifier loss: 0.581200; batch adversarial loss: 0.469230\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523842; batch adversarial loss: 0.515709\n",
      "epoch 22; iter: 0; batch classifier loss: 0.564557; batch adversarial loss: 0.529258\n",
      "epoch 23; iter: 0; batch classifier loss: 0.515163; batch adversarial loss: 0.540056\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518583; batch adversarial loss: 0.495599\n",
      "epoch 25; iter: 0; batch classifier loss: 0.709174; batch adversarial loss: 0.584792\n",
      "epoch 26; iter: 0; batch classifier loss: 0.638700; batch adversarial loss: 0.537196\n",
      "epoch 27; iter: 0; batch classifier loss: 0.713644; batch adversarial loss: 0.669791\n",
      "epoch 28; iter: 0; batch classifier loss: 0.609942; batch adversarial loss: 0.535423\n",
      "epoch 29; iter: 0; batch classifier loss: 0.694055; batch adversarial loss: 0.552355\n",
      "epoch 30; iter: 0; batch classifier loss: 0.573406; batch adversarial loss: 0.557936\n",
      "epoch 31; iter: 0; batch classifier loss: 0.565260; batch adversarial loss: 0.498807\n",
      "epoch 32; iter: 0; batch classifier loss: 0.557762; batch adversarial loss: 0.518858\n",
      "epoch 33; iter: 0; batch classifier loss: 0.528373; batch adversarial loss: 0.530029\n",
      "epoch 34; iter: 0; batch classifier loss: 0.515887; batch adversarial loss: 0.548267\n",
      "epoch 35; iter: 0; batch classifier loss: 0.491352; batch adversarial loss: 0.485697\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503450; batch adversarial loss: 0.461022\n",
      "epoch 37; iter: 0; batch classifier loss: 0.533246; batch adversarial loss: 0.532754\n",
      "epoch 38; iter: 0; batch classifier loss: 0.524422; batch adversarial loss: 0.416390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.538209; batch adversarial loss: 0.463075\n",
      "epoch 40; iter: 0; batch classifier loss: 0.546445; batch adversarial loss: 0.448852\n",
      "epoch 41; iter: 0; batch classifier loss: 0.587875; batch adversarial loss: 0.535784\n",
      "epoch 42; iter: 0; batch classifier loss: 0.482189; batch adversarial loss: 0.455623\n",
      "epoch 43; iter: 0; batch classifier loss: 0.479043; batch adversarial loss: 0.463707\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500634; batch adversarial loss: 0.413091\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428868; batch adversarial loss: 0.447867\n",
      "epoch 46; iter: 0; batch classifier loss: 0.508825; batch adversarial loss: 0.538471\n",
      "epoch 47; iter: 0; batch classifier loss: 0.527131; batch adversarial loss: 0.507424\n",
      "epoch 48; iter: 0; batch classifier loss: 0.595819; batch adversarial loss: 0.434205\n",
      "epoch 49; iter: 0; batch classifier loss: 0.447133; batch adversarial loss: 0.472039\n",
      "epoch 50; iter: 0; batch classifier loss: 0.461646; batch adversarial loss: 0.504597\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466078; batch adversarial loss: 0.483245\n",
      "epoch 52; iter: 0; batch classifier loss: 0.439453; batch adversarial loss: 0.426095\n",
      "epoch 53; iter: 0; batch classifier loss: 0.463325; batch adversarial loss: 0.426260\n",
      "epoch 54; iter: 0; batch classifier loss: 0.501317; batch adversarial loss: 0.446128\n",
      "epoch 55; iter: 0; batch classifier loss: 0.487403; batch adversarial loss: 0.365752\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417844; batch adversarial loss: 0.523664\n",
      "epoch 57; iter: 0; batch classifier loss: 0.395766; batch adversarial loss: 0.498635\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448935; batch adversarial loss: 0.452965\n",
      "epoch 59; iter: 0; batch classifier loss: 0.413450; batch adversarial loss: 0.465528\n",
      "epoch 60; iter: 0; batch classifier loss: 0.444392; batch adversarial loss: 0.596394\n",
      "epoch 61; iter: 0; batch classifier loss: 0.413980; batch adversarial loss: 0.538602\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436911; batch adversarial loss: 0.470872\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432608; batch adversarial loss: 0.449591\n",
      "epoch 64; iter: 0; batch classifier loss: 0.378679; batch adversarial loss: 0.439843\n",
      "epoch 65; iter: 0; batch classifier loss: 0.384879; batch adversarial loss: 0.503728\n",
      "epoch 66; iter: 0; batch classifier loss: 0.425396; batch adversarial loss: 0.450233\n",
      "epoch 67; iter: 0; batch classifier loss: 0.405480; batch adversarial loss: 0.456279\n",
      "epoch 68; iter: 0; batch classifier loss: 0.398659; batch adversarial loss: 0.432185\n",
      "epoch 69; iter: 0; batch classifier loss: 0.438729; batch adversarial loss: 0.453926\n",
      "epoch 70; iter: 0; batch classifier loss: 0.466789; batch adversarial loss: 0.469911\n",
      "epoch 71; iter: 0; batch classifier loss: 0.406154; batch adversarial loss: 0.424715\n",
      "epoch 72; iter: 0; batch classifier loss: 0.478874; batch adversarial loss: 0.530714\n",
      "epoch 73; iter: 0; batch classifier loss: 0.426623; batch adversarial loss: 0.528884\n",
      "epoch 74; iter: 0; batch classifier loss: 0.460500; batch adversarial loss: 0.445184\n",
      "epoch 75; iter: 0; batch classifier loss: 0.495430; batch adversarial loss: 0.482021\n",
      "epoch 76; iter: 0; batch classifier loss: 0.459784; batch adversarial loss: 0.527259\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402198; batch adversarial loss: 0.440900\n",
      "epoch 78; iter: 0; batch classifier loss: 0.371655; batch adversarial loss: 0.526584\n",
      "epoch 79; iter: 0; batch classifier loss: 0.408281; batch adversarial loss: 0.414549\n",
      "epoch 80; iter: 0; batch classifier loss: 0.441884; batch adversarial loss: 0.452334\n",
      "epoch 81; iter: 0; batch classifier loss: 0.395043; batch adversarial loss: 0.484763\n",
      "epoch 82; iter: 0; batch classifier loss: 0.375912; batch adversarial loss: 0.435974\n",
      "epoch 83; iter: 0; batch classifier loss: 0.404568; batch adversarial loss: 0.446761\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372432; batch adversarial loss: 0.461718\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349874; batch adversarial loss: 0.483387\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421664; batch adversarial loss: 0.469067\n",
      "epoch 87; iter: 0; batch classifier loss: 0.363712; batch adversarial loss: 0.522429\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421071; batch adversarial loss: 0.419210\n",
      "epoch 89; iter: 0; batch classifier loss: 0.408317; batch adversarial loss: 0.453233\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396239; batch adversarial loss: 0.453067\n",
      "epoch 91; iter: 0; batch classifier loss: 0.381405; batch adversarial loss: 0.494938\n",
      "epoch 92; iter: 0; batch classifier loss: 0.401734; batch adversarial loss: 0.604257\n",
      "epoch 93; iter: 0; batch classifier loss: 0.435458; batch adversarial loss: 0.613412\n",
      "epoch 94; iter: 0; batch classifier loss: 0.295171; batch adversarial loss: 0.495947\n",
      "epoch 95; iter: 0; batch classifier loss: 0.284129; batch adversarial loss: 0.485917\n",
      "epoch 96; iter: 0; batch classifier loss: 0.325685; batch adversarial loss: 0.514867\n",
      "epoch 97; iter: 0; batch classifier loss: 0.465673; batch adversarial loss: 0.361119\n",
      "epoch 98; iter: 0; batch classifier loss: 0.362609; batch adversarial loss: 0.481996\n",
      "epoch 99; iter: 0; batch classifier loss: 0.456538; batch adversarial loss: 0.505254\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.151758; batch adversarial loss: 0.860290\n",
      "epoch 2; iter: 0; batch classifier loss: 1.009718; batch adversarial loss: 0.832782\n",
      "epoch 3; iter: 0; batch classifier loss: 0.972153; batch adversarial loss: 0.743956\n",
      "epoch 4; iter: 0; batch classifier loss: 0.770802; batch adversarial loss: 0.732565\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587952; batch adversarial loss: 0.688902\n",
      "epoch 6; iter: 0; batch classifier loss: 0.517835; batch adversarial loss: 0.666165\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495338; batch adversarial loss: 0.630702\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561320; batch adversarial loss: 0.615112\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501688; batch adversarial loss: 0.594727\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565257; batch adversarial loss: 0.590880\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543964; batch adversarial loss: 0.596036\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557416; batch adversarial loss: 0.577987\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515733; batch adversarial loss: 0.551424\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464990; batch adversarial loss: 0.550650\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575757; batch adversarial loss: 0.580029\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528431; batch adversarial loss: 0.531217\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522868; batch adversarial loss: 0.540323\n",
      "epoch 18; iter: 0; batch classifier loss: 0.527696; batch adversarial loss: 0.529903\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537885; batch adversarial loss: 0.553444\n",
      "epoch 20; iter: 0; batch classifier loss: 0.596533; batch adversarial loss: 0.478042\n",
      "epoch 21; iter: 0; batch classifier loss: 0.553827; batch adversarial loss: 0.525776\n",
      "epoch 22; iter: 0; batch classifier loss: 0.596156; batch adversarial loss: 0.538969\n",
      "epoch 23; iter: 0; batch classifier loss: 0.566170; batch adversarial loss: 0.555127\n",
      "epoch 24; iter: 0; batch classifier loss: 0.563947; batch adversarial loss: 0.510437\n",
      "epoch 25; iter: 0; batch classifier loss: 0.786215; batch adversarial loss: 0.590753\n",
      "epoch 26; iter: 0; batch classifier loss: 0.659773; batch adversarial loss: 0.531887\n",
      "epoch 27; iter: 0; batch classifier loss: 0.703256; batch adversarial loss: 0.654785\n",
      "epoch 28; iter: 0; batch classifier loss: 0.601692; batch adversarial loss: 0.530555\n",
      "epoch 29; iter: 0; batch classifier loss: 0.658044; batch adversarial loss: 0.542675\n",
      "epoch 30; iter: 0; batch classifier loss: 0.543821; batch adversarial loss: 0.548647\n",
      "epoch 31; iter: 0; batch classifier loss: 0.542704; batch adversarial loss: 0.492630\n",
      "epoch 32; iter: 0; batch classifier loss: 0.536675; batch adversarial loss: 0.513479\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489524; batch adversarial loss: 0.521862\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488175; batch adversarial loss: 0.541899\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484429; batch adversarial loss: 0.482875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.505425; batch adversarial loss: 0.459394\n",
      "epoch 37; iter: 0; batch classifier loss: 0.534892; batch adversarial loss: 0.532047\n",
      "epoch 38; iter: 0; batch classifier loss: 0.531994; batch adversarial loss: 0.416537\n",
      "epoch 39; iter: 0; batch classifier loss: 0.558748; batch adversarial loss: 0.465195\n",
      "epoch 40; iter: 0; batch classifier loss: 0.571811; batch adversarial loss: 0.450552\n",
      "epoch 41; iter: 0; batch classifier loss: 0.625727; batch adversarial loss: 0.537249\n",
      "epoch 42; iter: 0; batch classifier loss: 0.511135; batch adversarial loss: 0.456401\n",
      "epoch 43; iter: 0; batch classifier loss: 0.479352; batch adversarial loss: 0.462821\n",
      "epoch 44; iter: 0; batch classifier loss: 0.500414; batch adversarial loss: 0.412034\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430171; batch adversarial loss: 0.447381\n",
      "epoch 46; iter: 0; batch classifier loss: 0.503532; batch adversarial loss: 0.536443\n",
      "epoch 47; iter: 0; batch classifier loss: 0.521596; batch adversarial loss: 0.505964\n",
      "epoch 48; iter: 0; batch classifier loss: 0.557822; batch adversarial loss: 0.433460\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434504; batch adversarial loss: 0.471661\n",
      "epoch 50; iter: 0; batch classifier loss: 0.469142; batch adversarial loss: 0.504656\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470078; batch adversarial loss: 0.483090\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446465; batch adversarial loss: 0.426079\n",
      "epoch 53; iter: 0; batch classifier loss: 0.470433; batch adversarial loss: 0.426310\n",
      "epoch 54; iter: 0; batch classifier loss: 0.511794; batch adversarial loss: 0.446595\n",
      "epoch 55; iter: 0; batch classifier loss: 0.483521; batch adversarial loss: 0.365628\n",
      "epoch 56; iter: 0; batch classifier loss: 0.417761; batch adversarial loss: 0.523849\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401363; batch adversarial loss: 0.498848\n",
      "epoch 58; iter: 0; batch classifier loss: 0.457908; batch adversarial loss: 0.452973\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416506; batch adversarial loss: 0.465527\n",
      "epoch 60; iter: 0; batch classifier loss: 0.450163; batch adversarial loss: 0.597259\n",
      "epoch 61; iter: 0; batch classifier loss: 0.415632; batch adversarial loss: 0.539160\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441672; batch adversarial loss: 0.471218\n",
      "epoch 63; iter: 0; batch classifier loss: 0.435802; batch adversarial loss: 0.449487\n",
      "epoch 64; iter: 0; batch classifier loss: 0.385352; batch adversarial loss: 0.439704\n",
      "epoch 65; iter: 0; batch classifier loss: 0.380424; batch adversarial loss: 0.503132\n",
      "epoch 66; iter: 0; batch classifier loss: 0.439039; batch adversarial loss: 0.450728\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408501; batch adversarial loss: 0.455601\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408497; batch adversarial loss: 0.432732\n",
      "epoch 69; iter: 0; batch classifier loss: 0.446066; batch adversarial loss: 0.454203\n",
      "epoch 70; iter: 0; batch classifier loss: 0.461254; batch adversarial loss: 0.469561\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408507; batch adversarial loss: 0.425329\n",
      "epoch 72; iter: 0; batch classifier loss: 0.468970; batch adversarial loss: 0.530403\n",
      "epoch 73; iter: 0; batch classifier loss: 0.439667; batch adversarial loss: 0.528499\n",
      "epoch 74; iter: 0; batch classifier loss: 0.473947; batch adversarial loss: 0.444468\n",
      "epoch 75; iter: 0; batch classifier loss: 0.490687; batch adversarial loss: 0.481884\n",
      "epoch 76; iter: 0; batch classifier loss: 0.468608; batch adversarial loss: 0.528074\n",
      "epoch 77; iter: 0; batch classifier loss: 0.403009; batch adversarial loss: 0.440912\n",
      "epoch 78; iter: 0; batch classifier loss: 0.376024; batch adversarial loss: 0.526310\n",
      "epoch 79; iter: 0; batch classifier loss: 0.396893; batch adversarial loss: 0.413955\n",
      "epoch 80; iter: 0; batch classifier loss: 0.447625; batch adversarial loss: 0.453002\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391875; batch adversarial loss: 0.485617\n",
      "epoch 82; iter: 0; batch classifier loss: 0.388293; batch adversarial loss: 0.437056\n",
      "epoch 83; iter: 0; batch classifier loss: 0.398729; batch adversarial loss: 0.447285\n",
      "epoch 84; iter: 0; batch classifier loss: 0.372511; batch adversarial loss: 0.462119\n",
      "epoch 85; iter: 0; batch classifier loss: 0.353710; batch adversarial loss: 0.483519\n",
      "epoch 86; iter: 0; batch classifier loss: 0.420386; batch adversarial loss: 0.469369\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365409; batch adversarial loss: 0.521778\n",
      "epoch 88; iter: 0; batch classifier loss: 0.424421; batch adversarial loss: 0.419709\n",
      "epoch 89; iter: 0; batch classifier loss: 0.401634; batch adversarial loss: 0.453641\n",
      "epoch 90; iter: 0; batch classifier loss: 0.403504; batch adversarial loss: 0.454418\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384846; batch adversarial loss: 0.495912\n",
      "epoch 92; iter: 0; batch classifier loss: 0.404694; batch adversarial loss: 0.604322\n",
      "epoch 93; iter: 0; batch classifier loss: 0.462811; batch adversarial loss: 0.613563\n",
      "epoch 94; iter: 0; batch classifier loss: 0.303011; batch adversarial loss: 0.497113\n",
      "epoch 95; iter: 0; batch classifier loss: 0.283553; batch adversarial loss: 0.485552\n",
      "epoch 96; iter: 0; batch classifier loss: 0.329156; batch adversarial loss: 0.516536\n",
      "epoch 97; iter: 0; batch classifier loss: 0.471874; batch adversarial loss: 0.361041\n",
      "epoch 98; iter: 0; batch classifier loss: 0.367009; batch adversarial loss: 0.481775\n",
      "epoch 99; iter: 0; batch classifier loss: 0.464560; batch adversarial loss: 0.507100\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.126997; batch adversarial loss: 0.858836\n",
      "epoch 2; iter: 0; batch classifier loss: 0.982152; batch adversarial loss: 0.831117\n",
      "epoch 3; iter: 0; batch classifier loss: 0.936306; batch adversarial loss: 0.742302\n",
      "epoch 4; iter: 0; batch classifier loss: 0.742138; batch adversarial loss: 0.730220\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563546; batch adversarial loss: 0.686932\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512778; batch adversarial loss: 0.665476\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491319; batch adversarial loss: 0.631242\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561163; batch adversarial loss: 0.615676\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501067; batch adversarial loss: 0.595355\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564867; batch adversarial loss: 0.591275\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545461; batch adversarial loss: 0.596202\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558918; batch adversarial loss: 0.578241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518382; batch adversarial loss: 0.551530\n",
      "epoch 14; iter: 0; batch classifier loss: 0.467087; batch adversarial loss: 0.550132\n",
      "epoch 15; iter: 0; batch classifier loss: 0.576762; batch adversarial loss: 0.578738\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531690; batch adversarial loss: 0.528301\n",
      "epoch 17; iter: 0; batch classifier loss: 0.526373; batch adversarial loss: 0.538292\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526005; batch adversarial loss: 0.527759\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531148; batch adversarial loss: 0.547940\n",
      "epoch 20; iter: 0; batch classifier loss: 0.580976; batch adversarial loss: 0.470768\n",
      "epoch 21; iter: 0; batch classifier loss: 0.529670; batch adversarial loss: 0.518518\n",
      "epoch 22; iter: 0; batch classifier loss: 0.574490; batch adversarial loss: 0.531170\n",
      "epoch 23; iter: 0; batch classifier loss: 0.524174; batch adversarial loss: 0.543321\n",
      "epoch 24; iter: 0; batch classifier loss: 0.530537; batch adversarial loss: 0.499162\n",
      "epoch 25; iter: 0; batch classifier loss: 0.736681; batch adversarial loss: 0.589223\n",
      "epoch 26; iter: 0; batch classifier loss: 0.651070; batch adversarial loss: 0.537381\n",
      "epoch 27; iter: 0; batch classifier loss: 0.718865; batch adversarial loss: 0.666836\n",
      "epoch 28; iter: 0; batch classifier loss: 0.611168; batch adversarial loss: 0.534281\n",
      "epoch 29; iter: 0; batch classifier loss: 0.686627; batch adversarial loss: 0.549587\n",
      "epoch 30; iter: 0; batch classifier loss: 0.563083; batch adversarial loss: 0.554900\n",
      "epoch 31; iter: 0; batch classifier loss: 0.559286; batch adversarial loss: 0.496961\n",
      "epoch 32; iter: 0; batch classifier loss: 0.550331; batch adversarial loss: 0.517537\n",
      "epoch 33; iter: 0; batch classifier loss: 0.515523; batch adversarial loss: 0.527439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.506895; batch adversarial loss: 0.546295\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483695; batch adversarial loss: 0.484467\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502498; batch adversarial loss: 0.460320\n",
      "epoch 37; iter: 0; batch classifier loss: 0.529260; batch adversarial loss: 0.531943\n",
      "epoch 38; iter: 0; batch classifier loss: 0.526478; batch adversarial loss: 0.416006\n",
      "epoch 39; iter: 0; batch classifier loss: 0.546248; batch adversarial loss: 0.463861\n",
      "epoch 40; iter: 0; batch classifier loss: 0.551437; batch adversarial loss: 0.449424\n",
      "epoch 41; iter: 0; batch classifier loss: 0.600967; batch adversarial loss: 0.536725\n",
      "epoch 42; iter: 0; batch classifier loss: 0.489442; batch adversarial loss: 0.456205\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483293; batch adversarial loss: 0.463990\n",
      "epoch 44; iter: 0; batch classifier loss: 0.507649; batch adversarial loss: 0.413051\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432748; batch adversarial loss: 0.448088\n",
      "epoch 46; iter: 0; batch classifier loss: 0.513700; batch adversarial loss: 0.537881\n",
      "epoch 47; iter: 0; batch classifier loss: 0.527657; batch adversarial loss: 0.506685\n",
      "epoch 48; iter: 0; batch classifier loss: 0.570016; batch adversarial loss: 0.433861\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434553; batch adversarial loss: 0.471919\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465339; batch adversarial loss: 0.504676\n",
      "epoch 51; iter: 0; batch classifier loss: 0.466907; batch adversarial loss: 0.483305\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438362; batch adversarial loss: 0.426087\n",
      "epoch 53; iter: 0; batch classifier loss: 0.465277; batch adversarial loss: 0.426342\n",
      "epoch 54; iter: 0; batch classifier loss: 0.501174; batch adversarial loss: 0.446320\n",
      "epoch 55; iter: 0; batch classifier loss: 0.484337; batch adversarial loss: 0.365817\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420288; batch adversarial loss: 0.523465\n",
      "epoch 57; iter: 0; batch classifier loss: 0.394877; batch adversarial loss: 0.498445\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452712; batch adversarial loss: 0.453084\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409068; batch adversarial loss: 0.465355\n",
      "epoch 60; iter: 0; batch classifier loss: 0.445856; batch adversarial loss: 0.596458\n",
      "epoch 61; iter: 0; batch classifier loss: 0.418197; batch adversarial loss: 0.538835\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436196; batch adversarial loss: 0.470882\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432757; batch adversarial loss: 0.449676\n",
      "epoch 64; iter: 0; batch classifier loss: 0.382004; batch adversarial loss: 0.440162\n",
      "epoch 65; iter: 0; batch classifier loss: 0.384668; batch adversarial loss: 0.503422\n",
      "epoch 66; iter: 0; batch classifier loss: 0.429237; batch adversarial loss: 0.450366\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411533; batch adversarial loss: 0.456154\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408975; batch adversarial loss: 0.432349\n",
      "epoch 69; iter: 0; batch classifier loss: 0.441799; batch adversarial loss: 0.454258\n",
      "epoch 70; iter: 0; batch classifier loss: 0.458287; batch adversarial loss: 0.469566\n",
      "epoch 71; iter: 0; batch classifier loss: 0.414841; batch adversarial loss: 0.425044\n",
      "epoch 72; iter: 0; batch classifier loss: 0.477574; batch adversarial loss: 0.530528\n",
      "epoch 73; iter: 0; batch classifier loss: 0.423900; batch adversarial loss: 0.528664\n",
      "epoch 74; iter: 0; batch classifier loss: 0.467075; batch adversarial loss: 0.445464\n",
      "epoch 75; iter: 0; batch classifier loss: 0.492515; batch adversarial loss: 0.481632\n",
      "epoch 76; iter: 0; batch classifier loss: 0.462298; batch adversarial loss: 0.528765\n",
      "epoch 77; iter: 0; batch classifier loss: 0.402497; batch adversarial loss: 0.441168\n",
      "epoch 78; iter: 0; batch classifier loss: 0.377750; batch adversarial loss: 0.526052\n",
      "epoch 79; iter: 0; batch classifier loss: 0.400569; batch adversarial loss: 0.414696\n",
      "epoch 80; iter: 0; batch classifier loss: 0.440107; batch adversarial loss: 0.452697\n",
      "epoch 81; iter: 0; batch classifier loss: 0.397387; batch adversarial loss: 0.485316\n",
      "epoch 82; iter: 0; batch classifier loss: 0.370436; batch adversarial loss: 0.436370\n",
      "epoch 83; iter: 0; batch classifier loss: 0.405127; batch adversarial loss: 0.447377\n",
      "epoch 84; iter: 0; batch classifier loss: 0.368351; batch adversarial loss: 0.462094\n",
      "epoch 85; iter: 0; batch classifier loss: 0.348955; batch adversarial loss: 0.483104\n",
      "epoch 86; iter: 0; batch classifier loss: 0.427552; batch adversarial loss: 0.469221\n",
      "epoch 87; iter: 0; batch classifier loss: 0.361928; batch adversarial loss: 0.522067\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417761; batch adversarial loss: 0.419672\n",
      "epoch 89; iter: 0; batch classifier loss: 0.402277; batch adversarial loss: 0.454228\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394600; batch adversarial loss: 0.454219\n",
      "epoch 91; iter: 0; batch classifier loss: 0.379158; batch adversarial loss: 0.494975\n",
      "epoch 92; iter: 0; batch classifier loss: 0.394215; batch adversarial loss: 0.604431\n",
      "epoch 93; iter: 0; batch classifier loss: 0.452725; batch adversarial loss: 0.613980\n",
      "epoch 94; iter: 0; batch classifier loss: 0.292862; batch adversarial loss: 0.496097\n",
      "epoch 95; iter: 0; batch classifier loss: 0.283115; batch adversarial loss: 0.485782\n",
      "epoch 96; iter: 0; batch classifier loss: 0.329980; batch adversarial loss: 0.517082\n",
      "epoch 97; iter: 0; batch classifier loss: 0.449122; batch adversarial loss: 0.360961\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373483; batch adversarial loss: 0.481631\n",
      "epoch 99; iter: 0; batch classifier loss: 0.460083; batch adversarial loss: 0.505830\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.110954; batch adversarial loss: 0.857935\n",
      "epoch 2; iter: 0; batch classifier loss: 0.965936; batch adversarial loss: 0.829902\n",
      "epoch 3; iter: 0; batch classifier loss: 0.914073; batch adversarial loss: 0.741191\n",
      "epoch 4; iter: 0; batch classifier loss: 0.724030; batch adversarial loss: 0.728626\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549818; batch adversarial loss: 0.685636\n",
      "epoch 6; iter: 0; batch classifier loss: 0.510375; batch adversarial loss: 0.665232\n",
      "epoch 7; iter: 0; batch classifier loss: 0.489663; batch adversarial loss: 0.631591\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562200; batch adversarial loss: 0.615726\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501873; batch adversarial loss: 0.595537\n",
      "epoch 10; iter: 0; batch classifier loss: 0.566331; batch adversarial loss: 0.591345\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547219; batch adversarial loss: 0.596091\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560308; batch adversarial loss: 0.578301\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521366; batch adversarial loss: 0.551408\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470777; batch adversarial loss: 0.549811\n",
      "epoch 15; iter: 0; batch classifier loss: 0.580675; batch adversarial loss: 0.577616\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534438; batch adversarial loss: 0.525945\n",
      "epoch 17; iter: 0; batch classifier loss: 0.528943; batch adversarial loss: 0.536916\n",
      "epoch 18; iter: 0; batch classifier loss: 0.525258; batch adversarial loss: 0.526647\n",
      "epoch 19; iter: 0; batch classifier loss: 0.528609; batch adversarial loss: 0.545927\n",
      "epoch 20; iter: 0; batch classifier loss: 0.577093; batch adversarial loss: 0.467478\n",
      "epoch 21; iter: 0; batch classifier loss: 0.516348; batch adversarial loss: 0.513101\n",
      "epoch 22; iter: 0; batch classifier loss: 0.562757; batch adversarial loss: 0.527099\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507376; batch adversarial loss: 0.537908\n",
      "epoch 24; iter: 0; batch classifier loss: 0.515796; batch adversarial loss: 0.493448\n",
      "epoch 25; iter: 0; batch classifier loss: 0.692776; batch adversarial loss: 0.581754\n",
      "epoch 26; iter: 0; batch classifier loss: 0.625654; batch adversarial loss: 0.535833\n",
      "epoch 27; iter: 0; batch classifier loss: 0.704661; batch adversarial loss: 0.671462\n",
      "epoch 28; iter: 0; batch classifier loss: 0.611713; batch adversarial loss: 0.536571\n",
      "epoch 29; iter: 0; batch classifier loss: 0.699487; batch adversarial loss: 0.554667\n",
      "epoch 30; iter: 0; batch classifier loss: 0.581581; batch adversarial loss: 0.560308\n",
      "epoch 31; iter: 0; batch classifier loss: 0.570317; batch adversarial loss: 0.500146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.568191; batch adversarial loss: 0.520370\n",
      "epoch 33; iter: 0; batch classifier loss: 0.539323; batch adversarial loss: 0.532301\n",
      "epoch 34; iter: 0; batch classifier loss: 0.525709; batch adversarial loss: 0.550303\n",
      "epoch 35; iter: 0; batch classifier loss: 0.491253; batch adversarial loss: 0.486722\n",
      "epoch 36; iter: 0; batch classifier loss: 0.505826; batch adversarial loss: 0.461525\n",
      "epoch 37; iter: 0; batch classifier loss: 0.536138; batch adversarial loss: 0.532734\n",
      "epoch 38; iter: 0; batch classifier loss: 0.519321; batch adversarial loss: 0.416328\n",
      "epoch 39; iter: 0; batch classifier loss: 0.532114; batch adversarial loss: 0.462348\n",
      "epoch 40; iter: 0; batch classifier loss: 0.535869; batch adversarial loss: 0.448111\n",
      "epoch 41; iter: 0; batch classifier loss: 0.583565; batch adversarial loss: 0.534982\n",
      "epoch 42; iter: 0; batch classifier loss: 0.479949; batch adversarial loss: 0.455346\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475375; batch adversarial loss: 0.463802\n",
      "epoch 44; iter: 0; batch classifier loss: 0.504914; batch adversarial loss: 0.413232\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425639; batch adversarial loss: 0.447886\n",
      "epoch 46; iter: 0; batch classifier loss: 0.511265; batch adversarial loss: 0.539366\n",
      "epoch 47; iter: 0; batch classifier loss: 0.523599; batch adversarial loss: 0.508080\n",
      "epoch 48; iter: 0; batch classifier loss: 0.610977; batch adversarial loss: 0.434641\n",
      "epoch 49; iter: 0; batch classifier loss: 0.453765; batch adversarial loss: 0.472142\n",
      "epoch 50; iter: 0; batch classifier loss: 0.458230; batch adversarial loss: 0.504421\n",
      "epoch 51; iter: 0; batch classifier loss: 0.470444; batch adversarial loss: 0.483218\n",
      "epoch 52; iter: 0; batch classifier loss: 0.436881; batch adversarial loss: 0.426256\n",
      "epoch 53; iter: 0; batch classifier loss: 0.462263; batch adversarial loss: 0.426453\n",
      "epoch 54; iter: 0; batch classifier loss: 0.499666; batch adversarial loss: 0.446143\n",
      "epoch 55; iter: 0; batch classifier loss: 0.486529; batch adversarial loss: 0.365934\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415079; batch adversarial loss: 0.523639\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400893; batch adversarial loss: 0.498546\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448950; batch adversarial loss: 0.452877\n",
      "epoch 59; iter: 0; batch classifier loss: 0.407726; batch adversarial loss: 0.465508\n",
      "epoch 60; iter: 0; batch classifier loss: 0.439746; batch adversarial loss: 0.596601\n",
      "epoch 61; iter: 0; batch classifier loss: 0.415051; batch adversarial loss: 0.538653\n",
      "epoch 62; iter: 0; batch classifier loss: 0.432644; batch adversarial loss: 0.470798\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432896; batch adversarial loss: 0.449114\n",
      "epoch 64; iter: 0; batch classifier loss: 0.375327; batch adversarial loss: 0.439840\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379456; batch adversarial loss: 0.503765\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426661; batch adversarial loss: 0.450115\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407605; batch adversarial loss: 0.456292\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401793; batch adversarial loss: 0.432852\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442119; batch adversarial loss: 0.453979\n",
      "epoch 70; iter: 0; batch classifier loss: 0.458360; batch adversarial loss: 0.469374\n",
      "epoch 71; iter: 0; batch classifier loss: 0.410939; batch adversarial loss: 0.424881\n",
      "epoch 72; iter: 0; batch classifier loss: 0.478419; batch adversarial loss: 0.530732\n",
      "epoch 73; iter: 0; batch classifier loss: 0.429889; batch adversarial loss: 0.529508\n",
      "epoch 74; iter: 0; batch classifier loss: 0.457973; batch adversarial loss: 0.445401\n",
      "epoch 75; iter: 0; batch classifier loss: 0.495851; batch adversarial loss: 0.481713\n",
      "epoch 76; iter: 0; batch classifier loss: 0.452739; batch adversarial loss: 0.528202\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406769; batch adversarial loss: 0.441425\n",
      "epoch 78; iter: 0; batch classifier loss: 0.375491; batch adversarial loss: 0.527327\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404934; batch adversarial loss: 0.414562\n",
      "epoch 80; iter: 0; batch classifier loss: 0.436419; batch adversarial loss: 0.452647\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391292; batch adversarial loss: 0.484922\n",
      "epoch 82; iter: 0; batch classifier loss: 0.379655; batch adversarial loss: 0.436376\n",
      "epoch 83; iter: 0; batch classifier loss: 0.403081; batch adversarial loss: 0.447089\n",
      "epoch 84; iter: 0; batch classifier loss: 0.362357; batch adversarial loss: 0.462092\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343091; batch adversarial loss: 0.483520\n",
      "epoch 86; iter: 0; batch classifier loss: 0.424434; batch adversarial loss: 0.468856\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365937; batch adversarial loss: 0.521958\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421768; batch adversarial loss: 0.419915\n",
      "epoch 89; iter: 0; batch classifier loss: 0.392509; batch adversarial loss: 0.453942\n",
      "epoch 90; iter: 0; batch classifier loss: 0.389442; batch adversarial loss: 0.453552\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383595; batch adversarial loss: 0.495290\n",
      "epoch 92; iter: 0; batch classifier loss: 0.390830; batch adversarial loss: 0.603954\n",
      "epoch 93; iter: 0; batch classifier loss: 0.445242; batch adversarial loss: 0.614219\n",
      "epoch 94; iter: 0; batch classifier loss: 0.301354; batch adversarial loss: 0.496764\n",
      "epoch 95; iter: 0; batch classifier loss: 0.283155; batch adversarial loss: 0.485980\n",
      "epoch 96; iter: 0; batch classifier loss: 0.322470; batch adversarial loss: 0.515059\n",
      "epoch 97; iter: 0; batch classifier loss: 0.456140; batch adversarial loss: 0.361485\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368243; batch adversarial loss: 0.482292\n",
      "epoch 99; iter: 0; batch classifier loss: 0.451984; batch adversarial loss: 0.505671\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.146828; batch adversarial loss: 0.860012\n",
      "epoch 2; iter: 0; batch classifier loss: 1.005005; batch adversarial loss: 0.832512\n",
      "epoch 3; iter: 0; batch classifier loss: 0.966026; batch adversarial loss: 0.743705\n",
      "epoch 4; iter: 0; batch classifier loss: 0.765146; batch adversarial loss: 0.732107\n",
      "epoch 5; iter: 0; batch classifier loss: 0.583548; batch adversarial loss: 0.688521\n",
      "epoch 6; iter: 0; batch classifier loss: 0.516446; batch adversarial loss: 0.665964\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494797; batch adversarial loss: 0.630722\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561408; batch adversarial loss: 0.615236\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501814; batch adversarial loss: 0.594836\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565763; batch adversarial loss: 0.590880\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544521; batch adversarial loss: 0.596072\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557124; batch adversarial loss: 0.578081\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516297; batch adversarial loss: 0.551467\n",
      "epoch 14; iter: 0; batch classifier loss: 0.465706; batch adversarial loss: 0.550458\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575951; batch adversarial loss: 0.579606\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527924; batch adversarial loss: 0.530550\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522779; batch adversarial loss: 0.540024\n",
      "epoch 18; iter: 0; batch classifier loss: 0.527547; batch adversarial loss: 0.529406\n",
      "epoch 19; iter: 0; batch classifier loss: 0.534887; batch adversarial loss: 0.551790\n",
      "epoch 20; iter: 0; batch classifier loss: 0.592789; batch adversarial loss: 0.475628\n",
      "epoch 21; iter: 0; batch classifier loss: 0.544534; batch adversarial loss: 0.523448\n",
      "epoch 22; iter: 0; batch classifier loss: 0.589015; batch adversarial loss: 0.536468\n",
      "epoch 23; iter: 0; batch classifier loss: 0.553897; batch adversarial loss: 0.551337\n",
      "epoch 24; iter: 0; batch classifier loss: 0.558377; batch adversarial loss: 0.508280\n",
      "epoch 25; iter: 0; batch classifier loss: 0.781146; batch adversarial loss: 0.591558\n",
      "epoch 26; iter: 0; batch classifier loss: 0.657748; batch adversarial loss: 0.533604\n",
      "epoch 27; iter: 0; batch classifier loss: 0.704688; batch adversarial loss: 0.657277\n",
      "epoch 28; iter: 0; batch classifier loss: 0.601134; batch adversarial loss: 0.531319\n",
      "epoch 29; iter: 0; batch classifier loss: 0.663001; batch adversarial loss: 0.544375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.547896; batch adversarial loss: 0.550212\n",
      "epoch 31; iter: 0; batch classifier loss: 0.550780; batch adversarial loss: 0.494092\n",
      "epoch 32; iter: 0; batch classifier loss: 0.537119; batch adversarial loss: 0.513728\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489172; batch adversarial loss: 0.522734\n",
      "epoch 34; iter: 0; batch classifier loss: 0.490612; batch adversarial loss: 0.542810\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483801; batch adversarial loss: 0.483030\n",
      "epoch 36; iter: 0; batch classifier loss: 0.504693; batch adversarial loss: 0.459363\n",
      "epoch 37; iter: 0; batch classifier loss: 0.529666; batch adversarial loss: 0.531880\n",
      "epoch 38; iter: 0; batch classifier loss: 0.527845; batch adversarial loss: 0.416297\n",
      "epoch 39; iter: 0; batch classifier loss: 0.556574; batch adversarial loss: 0.465084\n",
      "epoch 40; iter: 0; batch classifier loss: 0.567709; batch adversarial loss: 0.450752\n",
      "epoch 41; iter: 0; batch classifier loss: 0.624178; batch adversarial loss: 0.537782\n",
      "epoch 42; iter: 0; batch classifier loss: 0.504927; batch adversarial loss: 0.456719\n",
      "epoch 43; iter: 0; batch classifier loss: 0.484784; batch adversarial loss: 0.463312\n",
      "epoch 44; iter: 0; batch classifier loss: 0.507713; batch adversarial loss: 0.412435\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429517; batch adversarial loss: 0.447611\n",
      "epoch 46; iter: 0; batch classifier loss: 0.505715; batch adversarial loss: 0.536448\n",
      "epoch 47; iter: 0; batch classifier loss: 0.522492; batch adversarial loss: 0.505880\n",
      "epoch 48; iter: 0; batch classifier loss: 0.542103; batch adversarial loss: 0.433452\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432008; batch adversarial loss: 0.471655\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465093; batch adversarial loss: 0.504744\n",
      "epoch 51; iter: 0; batch classifier loss: 0.471355; batch adversarial loss: 0.483192\n",
      "epoch 52; iter: 0; batch classifier loss: 0.446365; batch adversarial loss: 0.426039\n",
      "epoch 53; iter: 0; batch classifier loss: 0.468475; batch adversarial loss: 0.426334\n",
      "epoch 54; iter: 0; batch classifier loss: 0.510361; batch adversarial loss: 0.446554\n",
      "epoch 55; iter: 0; batch classifier loss: 0.486288; batch adversarial loss: 0.365637\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419752; batch adversarial loss: 0.523595\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401875; batch adversarial loss: 0.498771\n",
      "epoch 58; iter: 0; batch classifier loss: 0.453693; batch adversarial loss: 0.453016\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409296; batch adversarial loss: 0.465594\n",
      "epoch 60; iter: 0; batch classifier loss: 0.441135; batch adversarial loss: 0.596691\n",
      "epoch 61; iter: 0; batch classifier loss: 0.419440; batch adversarial loss: 0.539234\n",
      "epoch 62; iter: 0; batch classifier loss: 0.444709; batch adversarial loss: 0.470789\n",
      "epoch 63; iter: 0; batch classifier loss: 0.425079; batch adversarial loss: 0.449732\n",
      "epoch 64; iter: 0; batch classifier loss: 0.381593; batch adversarial loss: 0.439702\n",
      "epoch 65; iter: 0; batch classifier loss: 0.380369; batch adversarial loss: 0.503314\n",
      "epoch 66; iter: 0; batch classifier loss: 0.426178; batch adversarial loss: 0.450082\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410563; batch adversarial loss: 0.456639\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410907; batch adversarial loss: 0.432475\n",
      "epoch 69; iter: 0; batch classifier loss: 0.445407; batch adversarial loss: 0.453816\n",
      "epoch 70; iter: 0; batch classifier loss: 0.476144; batch adversarial loss: 0.469337\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409029; batch adversarial loss: 0.425177\n",
      "epoch 72; iter: 0; batch classifier loss: 0.484480; batch adversarial loss: 0.530992\n",
      "epoch 73; iter: 0; batch classifier loss: 0.437376; batch adversarial loss: 0.528458\n",
      "epoch 74; iter: 0; batch classifier loss: 0.471166; batch adversarial loss: 0.444628\n",
      "epoch 75; iter: 0; batch classifier loss: 0.505167; batch adversarial loss: 0.482334\n",
      "epoch 76; iter: 0; batch classifier loss: 0.474660; batch adversarial loss: 0.527920\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409483; batch adversarial loss: 0.439758\n",
      "epoch 78; iter: 0; batch classifier loss: 0.371051; batch adversarial loss: 0.526634\n",
      "epoch 79; iter: 0; batch classifier loss: 0.402813; batch adversarial loss: 0.414304\n",
      "epoch 80; iter: 0; batch classifier loss: 0.442998; batch adversarial loss: 0.452907\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406967; batch adversarial loss: 0.485501\n",
      "epoch 82; iter: 0; batch classifier loss: 0.385070; batch adversarial loss: 0.435795\n",
      "epoch 83; iter: 0; batch classifier loss: 0.399522; batch adversarial loss: 0.446943\n",
      "epoch 84; iter: 0; batch classifier loss: 0.386539; batch adversarial loss: 0.461522\n",
      "epoch 85; iter: 0; batch classifier loss: 0.348081; batch adversarial loss: 0.482173\n",
      "epoch 86; iter: 0; batch classifier loss: 0.414195; batch adversarial loss: 0.469102\n",
      "epoch 87; iter: 0; batch classifier loss: 0.383333; batch adversarial loss: 0.522813\n",
      "epoch 88; iter: 0; batch classifier loss: 0.428896; batch adversarial loss: 0.418650\n",
      "epoch 89; iter: 0; batch classifier loss: 0.407826; batch adversarial loss: 0.453031\n",
      "epoch 90; iter: 0; batch classifier loss: 0.396928; batch adversarial loss: 0.453366\n",
      "epoch 91; iter: 0; batch classifier loss: 0.383092; batch adversarial loss: 0.494447\n",
      "epoch 92; iter: 0; batch classifier loss: 0.402957; batch adversarial loss: 0.604675\n",
      "epoch 93; iter: 0; batch classifier loss: 0.470297; batch adversarial loss: 0.612863\n",
      "epoch 94; iter: 0; batch classifier loss: 0.294484; batch adversarial loss: 0.496821\n",
      "epoch 95; iter: 0; batch classifier loss: 0.277878; batch adversarial loss: 0.485016\n",
      "epoch 96; iter: 0; batch classifier loss: 0.341708; batch adversarial loss: 0.517132\n",
      "epoch 97; iter: 0; batch classifier loss: 0.482692; batch adversarial loss: 0.361047\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368778; batch adversarial loss: 0.481617\n",
      "epoch 99; iter: 0; batch classifier loss: 0.454011; batch adversarial loss: 0.506716\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698844; batch adversarial loss: 0.829340\n",
      "epoch 1; iter: 0; batch classifier loss: 1.058139; batch adversarial loss: 0.854492\n",
      "epoch 2; iter: 0; batch classifier loss: 0.968915; batch adversarial loss: 0.833338\n",
      "epoch 3; iter: 0; batch classifier loss: 0.929894; batch adversarial loss: 0.746177\n",
      "epoch 4; iter: 0; batch classifier loss: 0.763320; batch adversarial loss: 0.734524\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564490; batch adversarial loss: 0.687627\n",
      "epoch 6; iter: 0; batch classifier loss: 0.494236; batch adversarial loss: 0.667641\n",
      "epoch 7; iter: 0; batch classifier loss: 0.456012; batch adversarial loss: 0.636595\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532449; batch adversarial loss: 0.620079\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495768; batch adversarial loss: 0.596168\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558313; batch adversarial loss: 0.594362\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507445; batch adversarial loss: 0.599889\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530044; batch adversarial loss: 0.581313\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483210; batch adversarial loss: 0.556904\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466994; batch adversarial loss: 0.548612\n",
      "epoch 15; iter: 0; batch classifier loss: 0.555212; batch adversarial loss: 0.579296\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484637; batch adversarial loss: 0.531608\n",
      "epoch 17; iter: 0; batch classifier loss: 0.502571; batch adversarial loss: 0.535245\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511598; batch adversarial loss: 0.528682\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516929; batch adversarial loss: 0.550451\n",
      "epoch 20; iter: 0; batch classifier loss: 0.583322; batch adversarial loss: 0.484945\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513980; batch adversarial loss: 0.533265\n",
      "epoch 22; iter: 0; batch classifier loss: 0.525926; batch adversarial loss: 0.544457\n",
      "epoch 23; iter: 0; batch classifier loss: 0.515187; batch adversarial loss: 0.546211\n",
      "epoch 24; iter: 0; batch classifier loss: 0.530638; batch adversarial loss: 0.501988\n",
      "epoch 25; iter: 0; batch classifier loss: 0.768932; batch adversarial loss: 0.592248\n",
      "epoch 26; iter: 0; batch classifier loss: 0.651185; batch adversarial loss: 0.532586\n",
      "epoch 27; iter: 0; batch classifier loss: 0.673774; batch adversarial loss: 0.650185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.522614; batch adversarial loss: 0.526917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.606312; batch adversarial loss: 0.538347\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475689; batch adversarial loss: 0.547132\n",
      "epoch 31; iter: 0; batch classifier loss: 0.451612; batch adversarial loss: 0.490490\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487286; batch adversarial loss: 0.509856\n",
      "epoch 33; iter: 0; batch classifier loss: 0.423353; batch adversarial loss: 0.515068\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483182; batch adversarial loss: 0.540815\n",
      "epoch 35; iter: 0; batch classifier loss: 0.453849; batch adversarial loss: 0.482613\n",
      "epoch 36; iter: 0; batch classifier loss: 0.497318; batch adversarial loss: 0.464196\n",
      "epoch 37; iter: 0; batch classifier loss: 0.556345; batch adversarial loss: 0.541784\n",
      "epoch 38; iter: 0; batch classifier loss: 0.514937; batch adversarial loss: 0.422607\n",
      "epoch 39; iter: 0; batch classifier loss: 0.515098; batch adversarial loss: 0.466032\n",
      "epoch 40; iter: 0; batch classifier loss: 0.505268; batch adversarial loss: 0.448979\n",
      "epoch 41; iter: 0; batch classifier loss: 0.566053; batch adversarial loss: 0.530653\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420610; batch adversarial loss: 0.452108\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434798; batch adversarial loss: 0.460216\n",
      "epoch 44; iter: 0; batch classifier loss: 0.473156; batch adversarial loss: 0.411563\n",
      "epoch 45; iter: 0; batch classifier loss: 0.367551; batch adversarial loss: 0.447142\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495303; batch adversarial loss: 0.537249\n",
      "epoch 47; iter: 0; batch classifier loss: 0.400715; batch adversarial loss: 0.503996\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447805; batch adversarial loss: 0.431621\n",
      "epoch 49; iter: 0; batch classifier loss: 0.372722; batch adversarial loss: 0.469906\n",
      "epoch 50; iter: 0; batch classifier loss: 0.429680; batch adversarial loss: 0.505038\n",
      "epoch 51; iter: 0; batch classifier loss: 0.394959; batch adversarial loss: 0.482959\n",
      "epoch 52; iter: 0; batch classifier loss: 0.371646; batch adversarial loss: 0.425399\n",
      "epoch 53; iter: 0; batch classifier loss: 0.392565; batch adversarial loss: 0.425956\n",
      "epoch 54; iter: 0; batch classifier loss: 0.461757; batch adversarial loss: 0.445222\n",
      "epoch 55; iter: 0; batch classifier loss: 0.393427; batch adversarial loss: 0.364955\n",
      "epoch 56; iter: 0; batch classifier loss: 0.365204; batch adversarial loss: 0.522732\n",
      "epoch 57; iter: 0; batch classifier loss: 0.369525; batch adversarial loss: 0.499426\n",
      "epoch 58; iter: 0; batch classifier loss: 0.401258; batch adversarial loss: 0.452770\n",
      "epoch 59; iter: 0; batch classifier loss: 0.320160; batch adversarial loss: 0.464458\n",
      "epoch 60; iter: 0; batch classifier loss: 0.391286; batch adversarial loss: 0.596930\n",
      "epoch 61; iter: 0; batch classifier loss: 0.337587; batch adversarial loss: 0.537347\n",
      "epoch 62; iter: 0; batch classifier loss: 0.371340; batch adversarial loss: 0.472085\n",
      "epoch 63; iter: 0; batch classifier loss: 0.413684; batch adversarial loss: 0.454081\n",
      "epoch 64; iter: 0; batch classifier loss: 0.310301; batch adversarial loss: 0.439800\n",
      "epoch 65; iter: 0; batch classifier loss: 0.340502; batch adversarial loss: 0.503439\n",
      "epoch 66; iter: 0; batch classifier loss: 0.414878; batch adversarial loss: 0.450168\n",
      "epoch 67; iter: 0; batch classifier loss: 0.388685; batch adversarial loss: 0.457715\n",
      "epoch 68; iter: 0; batch classifier loss: 0.332655; batch adversarial loss: 0.434991\n",
      "epoch 69; iter: 0; batch classifier loss: 0.344554; batch adversarial loss: 0.453032\n",
      "epoch 70; iter: 0; batch classifier loss: 0.383722; batch adversarial loss: 0.470532\n",
      "epoch 71; iter: 0; batch classifier loss: 0.354063; batch adversarial loss: 0.426720\n",
      "epoch 72; iter: 0; batch classifier loss: 0.327159; batch adversarial loss: 0.528736\n",
      "epoch 73; iter: 0; batch classifier loss: 0.390867; batch adversarial loss: 0.533269\n",
      "epoch 74; iter: 0; batch classifier loss: 0.412986; batch adversarial loss: 0.446319\n",
      "epoch 75; iter: 0; batch classifier loss: 0.397512; batch adversarial loss: 0.483025\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370862; batch adversarial loss: 0.533447\n",
      "epoch 77; iter: 0; batch classifier loss: 0.322736; batch adversarial loss: 0.441820\n",
      "epoch 78; iter: 0; batch classifier loss: 0.308658; batch adversarial loss: 0.529160\n",
      "epoch 79; iter: 0; batch classifier loss: 0.354501; batch adversarial loss: 0.418276\n",
      "epoch 80; iter: 0; batch classifier loss: 0.353373; batch adversarial loss: 0.451349\n",
      "epoch 81; iter: 0; batch classifier loss: 0.321262; batch adversarial loss: 0.485739\n",
      "epoch 82; iter: 0; batch classifier loss: 0.339346; batch adversarial loss: 0.439184\n",
      "epoch 83; iter: 0; batch classifier loss: 0.373029; batch adversarial loss: 0.450042\n",
      "epoch 84; iter: 0; batch classifier loss: 0.296154; batch adversarial loss: 0.459587\n",
      "epoch 85; iter: 0; batch classifier loss: 0.260640; batch adversarial loss: 0.484381\n",
      "epoch 86; iter: 0; batch classifier loss: 0.336450; batch adversarial loss: 0.469224\n",
      "epoch 87; iter: 0; batch classifier loss: 0.273683; batch adversarial loss: 0.524221\n",
      "epoch 88; iter: 0; batch classifier loss: 0.348013; batch adversarial loss: 0.427972\n",
      "epoch 89; iter: 0; batch classifier loss: 0.309587; batch adversarial loss: 0.456823\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390860; batch adversarial loss: 0.457262\n",
      "epoch 91; iter: 0; batch classifier loss: 0.325259; batch adversarial loss: 0.495474\n",
      "epoch 92; iter: 0; batch classifier loss: 0.268340; batch adversarial loss: 0.602654\n",
      "epoch 93; iter: 0; batch classifier loss: 0.328382; batch adversarial loss: 0.613390\n",
      "epoch 94; iter: 0; batch classifier loss: 0.279349; batch adversarial loss: 0.498631\n",
      "epoch 95; iter: 0; batch classifier loss: 0.251699; batch adversarial loss: 0.489014\n",
      "epoch 96; iter: 0; batch classifier loss: 0.311036; batch adversarial loss: 0.521463\n",
      "epoch 97; iter: 0; batch classifier loss: 0.331286; batch adversarial loss: 0.359788\n",
      "epoch 98; iter: 0; batch classifier loss: 0.291765; batch adversarial loss: 0.485517\n",
      "epoch 99; iter: 0; batch classifier loss: 0.350421; batch adversarial loss: 0.510274\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.192447; batch adversarial loss: 0.862153\n",
      "epoch 2; iter: 0; batch classifier loss: 1.046000; batch adversarial loss: 0.834719\n",
      "epoch 3; iter: 0; batch classifier loss: 1.023414; batch adversarial loss: 0.745763\n",
      "epoch 4; iter: 0; batch classifier loss: 0.813548; batch adversarial loss: 0.735624\n",
      "epoch 5; iter: 0; batch classifier loss: 0.631893; batch adversarial loss: 0.691671\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532087; batch adversarial loss: 0.668430\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501314; batch adversarial loss: 0.630297\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562340; batch adversarial loss: 0.614488\n",
      "epoch 9; iter: 0; batch classifier loss: 0.505261; batch adversarial loss: 0.593477\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564889; batch adversarial loss: 0.590389\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542132; batch adversarial loss: 0.595929\n",
      "epoch 12; iter: 0; batch classifier loss: 0.554595; batch adversarial loss: 0.577842\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514952; batch adversarial loss: 0.551434\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462064; batch adversarial loss: 0.551807\n",
      "epoch 15; iter: 0; batch classifier loss: 0.570080; batch adversarial loss: 0.582757\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526947; batch adversarial loss: 0.535651\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522528; batch adversarial loss: 0.543232\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533057; batch adversarial loss: 0.533944\n",
      "epoch 19; iter: 0; batch classifier loss: 0.565216; batch adversarial loss: 0.566669\n",
      "epoch 20; iter: 0; batch classifier loss: 0.625894; batch adversarial loss: 0.489809\n",
      "epoch 21; iter: 0; batch classifier loss: 0.590998; batch adversarial loss: 0.537839\n",
      "epoch 22; iter: 0; batch classifier loss: 0.654786; batch adversarial loss: 0.556739\n",
      "epoch 23; iter: 0; batch classifier loss: 0.611797; batch adversarial loss: 0.560536\n",
      "epoch 24; iter: 0; batch classifier loss: 0.595472; batch adversarial loss: 0.512081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25; iter: 0; batch classifier loss: 0.788698; batch adversarial loss: 0.583568\n",
      "epoch 26; iter: 0; batch classifier loss: 0.654699; batch adversarial loss: 0.525527\n",
      "epoch 27; iter: 0; batch classifier loss: 0.679688; batch adversarial loss: 0.643476\n",
      "epoch 28; iter: 0; batch classifier loss: 0.589787; batch adversarial loss: 0.526008\n",
      "epoch 29; iter: 0; batch classifier loss: 0.637526; batch adversarial loss: 0.536539\n",
      "epoch 30; iter: 0; batch classifier loss: 0.523680; batch adversarial loss: 0.542971\n",
      "epoch 31; iter: 0; batch classifier loss: 0.532642; batch adversarial loss: 0.490217\n",
      "epoch 32; iter: 0; batch classifier loss: 0.527588; batch adversarial loss: 0.510622\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467023; batch adversarial loss: 0.518137\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475904; batch adversarial loss: 0.538905\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484976; batch adversarial loss: 0.481126\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503887; batch adversarial loss: 0.458736\n",
      "epoch 37; iter: 0; batch classifier loss: 0.541934; batch adversarial loss: 0.532694\n",
      "epoch 38; iter: 0; batch classifier loss: 0.561681; batch adversarial loss: 0.417812\n",
      "epoch 39; iter: 0; batch classifier loss: 0.591222; batch adversarial loss: 0.466780\n",
      "epoch 40; iter: 0; batch classifier loss: 0.592288; batch adversarial loss: 0.451266\n",
      "epoch 41; iter: 0; batch classifier loss: 0.634066; batch adversarial loss: 0.535700\n",
      "epoch 42; iter: 0; batch classifier loss: 0.505213; batch adversarial loss: 0.454907\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477827; batch adversarial loss: 0.461217\n",
      "epoch 44; iter: 0; batch classifier loss: 0.486306; batch adversarial loss: 0.410966\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422881; batch adversarial loss: 0.446406\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496056; batch adversarial loss: 0.535982\n",
      "epoch 47; iter: 0; batch classifier loss: 0.519516; batch adversarial loss: 0.506290\n",
      "epoch 48; iter: 0; batch classifier loss: 0.605379; batch adversarial loss: 0.433482\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444281; batch adversarial loss: 0.471583\n",
      "epoch 50; iter: 0; batch classifier loss: 0.473952; batch adversarial loss: 0.504475\n",
      "epoch 51; iter: 0; batch classifier loss: 0.473959; batch adversarial loss: 0.483229\n",
      "epoch 52; iter: 0; batch classifier loss: 0.451620; batch adversarial loss: 0.425872\n",
      "epoch 53; iter: 0; batch classifier loss: 0.477939; batch adversarial loss: 0.426433\n",
      "epoch 54; iter: 0; batch classifier loss: 0.510274; batch adversarial loss: 0.446376\n",
      "epoch 55; iter: 0; batch classifier loss: 0.482043; batch adversarial loss: 0.365276\n",
      "epoch 56; iter: 0; batch classifier loss: 0.423804; batch adversarial loss: 0.523567\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398719; batch adversarial loss: 0.498989\n",
      "epoch 58; iter: 0; batch classifier loss: 0.462625; batch adversarial loss: 0.453125\n",
      "epoch 59; iter: 0; batch classifier loss: 0.415309; batch adversarial loss: 0.465788\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443441; batch adversarial loss: 0.597013\n",
      "epoch 61; iter: 0; batch classifier loss: 0.411414; batch adversarial loss: 0.539355\n",
      "epoch 62; iter: 0; batch classifier loss: 0.451380; batch adversarial loss: 0.470541\n",
      "epoch 63; iter: 0; batch classifier loss: 0.422792; batch adversarial loss: 0.450154\n",
      "epoch 64; iter: 0; batch classifier loss: 0.387924; batch adversarial loss: 0.440265\n",
      "epoch 65; iter: 0; batch classifier loss: 0.387025; batch adversarial loss: 0.503220\n",
      "epoch 66; iter: 0; batch classifier loss: 0.435598; batch adversarial loss: 0.450290\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410401; batch adversarial loss: 0.456144\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410867; batch adversarial loss: 0.432607\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444035; batch adversarial loss: 0.454208\n",
      "epoch 70; iter: 0; batch classifier loss: 0.465269; batch adversarial loss: 0.469822\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403637; batch adversarial loss: 0.425702\n",
      "epoch 72; iter: 0; batch classifier loss: 0.466660; batch adversarial loss: 0.530131\n",
      "epoch 73; iter: 0; batch classifier loss: 0.437092; batch adversarial loss: 0.526728\n",
      "epoch 74; iter: 0; batch classifier loss: 0.481462; batch adversarial loss: 0.443169\n",
      "epoch 75; iter: 0; batch classifier loss: 0.509651; batch adversarial loss: 0.482145\n",
      "epoch 76; iter: 0; batch classifier loss: 0.465010; batch adversarial loss: 0.527908\n",
      "epoch 77; iter: 0; batch classifier loss: 0.399142; batch adversarial loss: 0.439394\n",
      "epoch 78; iter: 0; batch classifier loss: 0.374811; batch adversarial loss: 0.525999\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405195; batch adversarial loss: 0.413216\n",
      "epoch 80; iter: 0; batch classifier loss: 0.449125; batch adversarial loss: 0.452505\n",
      "epoch 81; iter: 0; batch classifier loss: 0.393016; batch adversarial loss: 0.485853\n",
      "epoch 82; iter: 0; batch classifier loss: 0.400120; batch adversarial loss: 0.437129\n",
      "epoch 83; iter: 0; batch classifier loss: 0.414397; batch adversarial loss: 0.447065\n",
      "epoch 84; iter: 0; batch classifier loss: 0.370557; batch adversarial loss: 0.462501\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343488; batch adversarial loss: 0.482646\n",
      "epoch 86; iter: 0; batch classifier loss: 0.428341; batch adversarial loss: 0.469391\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369104; batch adversarial loss: 0.521066\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421860; batch adversarial loss: 0.420025\n",
      "epoch 89; iter: 0; batch classifier loss: 0.414591; batch adversarial loss: 0.452970\n",
      "epoch 90; iter: 0; batch classifier loss: 0.441431; batch adversarial loss: 0.455622\n",
      "epoch 91; iter: 0; batch classifier loss: 0.384040; batch adversarial loss: 0.495366\n",
      "epoch 92; iter: 0; batch classifier loss: 0.407350; batch adversarial loss: 0.604116\n",
      "epoch 93; iter: 0; batch classifier loss: 0.475208; batch adversarial loss: 0.613729\n",
      "epoch 94; iter: 0; batch classifier loss: 0.303348; batch adversarial loss: 0.497980\n",
      "epoch 95; iter: 0; batch classifier loss: 0.277489; batch adversarial loss: 0.487563\n",
      "epoch 96; iter: 0; batch classifier loss: 0.335299; batch adversarial loss: 0.515043\n",
      "epoch 97; iter: 0; batch classifier loss: 0.465000; batch adversarial loss: 0.361583\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365958; batch adversarial loss: 0.481241\n",
      "epoch 99; iter: 0; batch classifier loss: 0.486115; batch adversarial loss: 0.507258\n",
      "epoch 100; iter: 0; batch classifier loss: 0.388518; batch adversarial loss: 0.488335\n",
      "epoch 101; iter: 0; batch classifier loss: 0.423545; batch adversarial loss: 0.493438\n",
      "epoch 102; iter: 0; batch classifier loss: 0.380788; batch adversarial loss: 0.487090\n",
      "epoch 103; iter: 0; batch classifier loss: 0.364533; batch adversarial loss: 0.443063\n",
      "epoch 104; iter: 0; batch classifier loss: 0.401786; batch adversarial loss: 0.424511\n",
      "epoch 105; iter: 0; batch classifier loss: 0.323935; batch adversarial loss: 0.499595\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394097; batch adversarial loss: 0.488610\n",
      "epoch 107; iter: 0; batch classifier loss: 0.350423; batch adversarial loss: 0.578691\n",
      "epoch 108; iter: 0; batch classifier loss: 0.389974; batch adversarial loss: 0.542035\n",
      "epoch 109; iter: 0; batch classifier loss: 0.318972; batch adversarial loss: 0.456899\n",
      "epoch 110; iter: 0; batch classifier loss: 0.348884; batch adversarial loss: 0.593974\n",
      "epoch 111; iter: 0; batch classifier loss: 0.343580; batch adversarial loss: 0.553502\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368825; batch adversarial loss: 0.481720\n",
      "epoch 113; iter: 0; batch classifier loss: 0.352494; batch adversarial loss: 0.481493\n",
      "epoch 114; iter: 0; batch classifier loss: 0.350417; batch adversarial loss: 0.523956\n",
      "epoch 115; iter: 0; batch classifier loss: 0.445449; batch adversarial loss: 0.414838\n",
      "epoch 116; iter: 0; batch classifier loss: 0.377626; batch adversarial loss: 0.454842\n",
      "epoch 117; iter: 0; batch classifier loss: 0.418548; batch adversarial loss: 0.481680\n",
      "epoch 118; iter: 0; batch classifier loss: 0.365724; batch adversarial loss: 0.438567\n",
      "epoch 119; iter: 0; batch classifier loss: 0.338653; batch adversarial loss: 0.528556\n",
      "epoch 120; iter: 0; batch classifier loss: 0.347944; batch adversarial loss: 0.455727\n",
      "epoch 121; iter: 0; batch classifier loss: 0.389089; batch adversarial loss: 0.518071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.397039; batch adversarial loss: 0.491742\n",
      "epoch 123; iter: 0; batch classifier loss: 0.418200; batch adversarial loss: 0.467890\n",
      "epoch 124; iter: 0; batch classifier loss: 0.361878; batch adversarial loss: 0.482726\n",
      "epoch 125; iter: 0; batch classifier loss: 0.398707; batch adversarial loss: 0.465242\n",
      "epoch 126; iter: 0; batch classifier loss: 0.459276; batch adversarial loss: 0.438832\n",
      "epoch 127; iter: 0; batch classifier loss: 0.356408; batch adversarial loss: 0.442612\n",
      "epoch 128; iter: 0; batch classifier loss: 0.308021; batch adversarial loss: 0.537099\n",
      "epoch 129; iter: 0; batch classifier loss: 0.459955; batch adversarial loss: 0.432819\n",
      "epoch 130; iter: 0; batch classifier loss: 0.367966; batch adversarial loss: 0.454488\n",
      "epoch 131; iter: 0; batch classifier loss: 0.363989; batch adversarial loss: 0.442863\n",
      "epoch 132; iter: 0; batch classifier loss: 0.381839; batch adversarial loss: 0.456321\n",
      "epoch 133; iter: 0; batch classifier loss: 0.331026; batch adversarial loss: 0.452619\n",
      "epoch 134; iter: 0; batch classifier loss: 0.378510; batch adversarial loss: 0.562281\n",
      "epoch 135; iter: 0; batch classifier loss: 0.429370; batch adversarial loss: 0.421366\n",
      "epoch 136; iter: 0; batch classifier loss: 0.320921; batch adversarial loss: 0.502821\n",
      "epoch 137; iter: 0; batch classifier loss: 0.486437; batch adversarial loss: 0.420318\n",
      "epoch 138; iter: 0; batch classifier loss: 0.319584; batch adversarial loss: 0.498371\n",
      "epoch 139; iter: 0; batch classifier loss: 0.376860; batch adversarial loss: 0.497496\n",
      "epoch 140; iter: 0; batch classifier loss: 0.482562; batch adversarial loss: 0.458121\n",
      "epoch 141; iter: 0; batch classifier loss: 0.361684; batch adversarial loss: 0.475274\n",
      "epoch 142; iter: 0; batch classifier loss: 0.415950; batch adversarial loss: 0.507062\n",
      "epoch 143; iter: 0; batch classifier loss: 0.454024; batch adversarial loss: 0.401253\n",
      "epoch 144; iter: 0; batch classifier loss: 0.411683; batch adversarial loss: 0.457481\n",
      "epoch 145; iter: 0; batch classifier loss: 0.388476; batch adversarial loss: 0.481711\n",
      "epoch 146; iter: 0; batch classifier loss: 0.385678; batch adversarial loss: 0.489690\n",
      "epoch 147; iter: 0; batch classifier loss: 0.384579; batch adversarial loss: 0.460274\n",
      "epoch 148; iter: 0; batch classifier loss: 0.339739; batch adversarial loss: 0.454046\n",
      "epoch 149; iter: 0; batch classifier loss: 0.365282; batch adversarial loss: 0.425663\n",
      "epoch 150; iter: 0; batch classifier loss: 0.384551; batch adversarial loss: 0.407839\n",
      "epoch 151; iter: 0; batch classifier loss: 0.368052; batch adversarial loss: 0.435980\n",
      "epoch 152; iter: 0; batch classifier loss: 0.402424; batch adversarial loss: 0.466323\n",
      "epoch 153; iter: 0; batch classifier loss: 0.352936; batch adversarial loss: 0.514604\n",
      "epoch 154; iter: 0; batch classifier loss: 0.279196; batch adversarial loss: 0.538441\n",
      "epoch 155; iter: 0; batch classifier loss: 0.295180; batch adversarial loss: 0.497743\n",
      "epoch 156; iter: 0; batch classifier loss: 0.317744; batch adversarial loss: 0.437568\n",
      "epoch 157; iter: 0; batch classifier loss: 0.440074; batch adversarial loss: 0.465347\n",
      "epoch 158; iter: 0; batch classifier loss: 0.368912; batch adversarial loss: 0.486629\n",
      "epoch 159; iter: 0; batch classifier loss: 0.331947; batch adversarial loss: 0.440717\n",
      "epoch 160; iter: 0; batch classifier loss: 0.501055; batch adversarial loss: 0.465732\n",
      "epoch 161; iter: 0; batch classifier loss: 0.335654; batch adversarial loss: 0.497457\n",
      "epoch 162; iter: 0; batch classifier loss: 0.399606; batch adversarial loss: 0.488635\n",
      "epoch 163; iter: 0; batch classifier loss: 0.310586; batch adversarial loss: 0.501008\n",
      "epoch 164; iter: 0; batch classifier loss: 0.471496; batch adversarial loss: 0.414873\n",
      "epoch 165; iter: 0; batch classifier loss: 0.389511; batch adversarial loss: 0.401053\n",
      "epoch 166; iter: 0; batch classifier loss: 0.413376; batch adversarial loss: 0.437746\n",
      "epoch 167; iter: 0; batch classifier loss: 0.373033; batch adversarial loss: 0.438737\n",
      "epoch 168; iter: 0; batch classifier loss: 0.349856; batch adversarial loss: 0.456878\n",
      "epoch 169; iter: 0; batch classifier loss: 0.357571; batch adversarial loss: 0.493675\n",
      "epoch 170; iter: 0; batch classifier loss: 0.398960; batch adversarial loss: 0.480829\n",
      "epoch 171; iter: 0; batch classifier loss: 0.476257; batch adversarial loss: 0.503681\n",
      "epoch 172; iter: 0; batch classifier loss: 0.512283; batch adversarial loss: 0.447585\n",
      "epoch 173; iter: 0; batch classifier loss: 0.430164; batch adversarial loss: 0.422725\n",
      "epoch 174; iter: 0; batch classifier loss: 0.359093; batch adversarial loss: 0.410554\n",
      "epoch 175; iter: 0; batch classifier loss: 0.322157; batch adversarial loss: 0.455743\n",
      "epoch 176; iter: 0; batch classifier loss: 0.344552; batch adversarial loss: 0.515263\n",
      "epoch 177; iter: 0; batch classifier loss: 0.512419; batch adversarial loss: 0.575977\n",
      "epoch 178; iter: 0; batch classifier loss: 0.421717; batch adversarial loss: 0.523041\n",
      "epoch 179; iter: 0; batch classifier loss: 0.453217; batch adversarial loss: 0.455117\n",
      "epoch 180; iter: 0; batch classifier loss: 0.498314; batch adversarial loss: 0.409114\n",
      "epoch 181; iter: 0; batch classifier loss: 0.371688; batch adversarial loss: 0.541437\n",
      "epoch 182; iter: 0; batch classifier loss: 0.519232; batch adversarial loss: 0.366359\n",
      "epoch 183; iter: 0; batch classifier loss: 0.407849; batch adversarial loss: 0.447378\n",
      "epoch 184; iter: 0; batch classifier loss: 0.415462; batch adversarial loss: 0.510209\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383695; batch adversarial loss: 0.432987\n",
      "epoch 186; iter: 0; batch classifier loss: 0.459062; batch adversarial loss: 0.466722\n",
      "epoch 187; iter: 0; batch classifier loss: 0.358991; batch adversarial loss: 0.486047\n",
      "epoch 188; iter: 0; batch classifier loss: 0.389910; batch adversarial loss: 0.516555\n",
      "epoch 189; iter: 0; batch classifier loss: 0.288113; batch adversarial loss: 0.580876\n",
      "epoch 190; iter: 0; batch classifier loss: 0.378464; batch adversarial loss: 0.443488\n",
      "epoch 191; iter: 0; batch classifier loss: 0.356631; batch adversarial loss: 0.422666\n",
      "epoch 192; iter: 0; batch classifier loss: 0.318269; batch adversarial loss: 0.458579\n",
      "epoch 193; iter: 0; batch classifier loss: 0.394444; batch adversarial loss: 0.514510\n",
      "epoch 194; iter: 0; batch classifier loss: 0.372233; batch adversarial loss: 0.525675\n",
      "epoch 195; iter: 0; batch classifier loss: 0.482600; batch adversarial loss: 0.462358\n",
      "epoch 196; iter: 0; batch classifier loss: 0.394318; batch adversarial loss: 0.430318\n",
      "epoch 197; iter: 0; batch classifier loss: 0.320188; batch adversarial loss: 0.418011\n",
      "epoch 198; iter: 0; batch classifier loss: 0.385353; batch adversarial loss: 0.455824\n",
      "epoch 199; iter: 0; batch classifier loss: 0.409736; batch adversarial loss: 0.641461\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.135167; batch adversarial loss: 0.859310\n",
      "epoch 2; iter: 0; batch classifier loss: 0.992179; batch adversarial loss: 0.831687\n",
      "epoch 3; iter: 0; batch classifier loss: 0.949320; batch adversarial loss: 0.742964\n",
      "epoch 4; iter: 0; batch classifier loss: 0.752348; batch adversarial loss: 0.731072\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571349; batch adversarial loss: 0.687683\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513801; batch adversarial loss: 0.665660\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492475; batch adversarial loss: 0.631049\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561245; batch adversarial loss: 0.615550\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501445; batch adversarial loss: 0.595118\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565021; batch adversarial loss: 0.591174\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545672; batch adversarial loss: 0.596126\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558803; batch adversarial loss: 0.578081\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517902; batch adversarial loss: 0.551390\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466622; batch adversarial loss: 0.550286\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575486; batch adversarial loss: 0.579216\n",
      "epoch 16; iter: 0; batch classifier loss: 0.530540; batch adversarial loss: 0.529612\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527166; batch adversarial loss: 0.539047\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526566; batch adversarial loss: 0.528531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19; iter: 0; batch classifier loss: 0.532687; batch adversarial loss: 0.549663\n",
      "epoch 20; iter: 0; batch classifier loss: 0.588478; batch adversarial loss: 0.473474\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539760; batch adversarial loss: 0.522131\n",
      "epoch 22; iter: 0; batch classifier loss: 0.582524; batch adversarial loss: 0.534436\n",
      "epoch 23; iter: 0; batch classifier loss: 0.534338; batch adversarial loss: 0.546689\n",
      "epoch 24; iter: 0; batch classifier loss: 0.546116; batch adversarial loss: 0.503633\n",
      "epoch 25; iter: 0; batch classifier loss: 0.765291; batch adversarial loss: 0.592202\n",
      "epoch 26; iter: 0; batch classifier loss: 0.658854; batch adversarial loss: 0.535986\n",
      "epoch 27; iter: 0; batch classifier loss: 0.715690; batch adversarial loss: 0.662208\n",
      "epoch 28; iter: 0; batch classifier loss: 0.605226; batch adversarial loss: 0.532714\n",
      "epoch 29; iter: 0; batch classifier loss: 0.677692; batch adversarial loss: 0.546919\n",
      "epoch 30; iter: 0; batch classifier loss: 0.554949; batch adversarial loss: 0.552232\n",
      "epoch 31; iter: 0; batch classifier loss: 0.553239; batch adversarial loss: 0.495153\n",
      "epoch 32; iter: 0; batch classifier loss: 0.544018; batch adversarial loss: 0.515496\n",
      "epoch 33; iter: 0; batch classifier loss: 0.503093; batch adversarial loss: 0.525011\n",
      "epoch 34; iter: 0; batch classifier loss: 0.498463; batch adversarial loss: 0.544139\n",
      "epoch 35; iter: 0; batch classifier loss: 0.486690; batch adversarial loss: 0.483880\n",
      "epoch 36; iter: 0; batch classifier loss: 0.506326; batch adversarial loss: 0.459843\n",
      "epoch 37; iter: 0; batch classifier loss: 0.529785; batch adversarial loss: 0.531867\n",
      "epoch 38; iter: 0; batch classifier loss: 0.526474; batch adversarial loss: 0.416224\n",
      "epoch 39; iter: 0; batch classifier loss: 0.550164; batch adversarial loss: 0.464493\n",
      "epoch 40; iter: 0; batch classifier loss: 0.558552; batch adversarial loss: 0.449922\n",
      "epoch 41; iter: 0; batch classifier loss: 0.612595; batch adversarial loss: 0.537120\n",
      "epoch 42; iter: 0; batch classifier loss: 0.497046; batch adversarial loss: 0.456416\n",
      "epoch 43; iter: 0; batch classifier loss: 0.483559; batch adversarial loss: 0.463586\n",
      "epoch 44; iter: 0; batch classifier loss: 0.509413; batch adversarial loss: 0.412746\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428381; batch adversarial loss: 0.447829\n",
      "epoch 46; iter: 0; batch classifier loss: 0.509999; batch adversarial loss: 0.537150\n",
      "epoch 47; iter: 0; batch classifier loss: 0.522354; batch adversarial loss: 0.506199\n",
      "epoch 48; iter: 0; batch classifier loss: 0.552037; batch adversarial loss: 0.433617\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432476; batch adversarial loss: 0.471760\n",
      "epoch 50; iter: 0; batch classifier loss: 0.466561; batch adversarial loss: 0.504711\n",
      "epoch 51; iter: 0; batch classifier loss: 0.469627; batch adversarial loss: 0.483303\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442141; batch adversarial loss: 0.426094\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466818; batch adversarial loss: 0.426330\n",
      "epoch 54; iter: 0; batch classifier loss: 0.506337; batch adversarial loss: 0.446366\n",
      "epoch 55; iter: 0; batch classifier loss: 0.490656; batch adversarial loss: 0.365743\n",
      "epoch 56; iter: 0; batch classifier loss: 0.420094; batch adversarial loss: 0.523487\n",
      "epoch 57; iter: 0; batch classifier loss: 0.400404; batch adversarial loss: 0.498670\n",
      "epoch 58; iter: 0; batch classifier loss: 0.453611; batch adversarial loss: 0.453089\n",
      "epoch 59; iter: 0; batch classifier loss: 0.409791; batch adversarial loss: 0.465443\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443626; batch adversarial loss: 0.596558\n",
      "epoch 61; iter: 0; batch classifier loss: 0.424723; batch adversarial loss: 0.539012\n",
      "epoch 62; iter: 0; batch classifier loss: 0.436825; batch adversarial loss: 0.470976\n",
      "epoch 63; iter: 0; batch classifier loss: 0.432092; batch adversarial loss: 0.449794\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376040; batch adversarial loss: 0.439769\n",
      "epoch 65; iter: 0; batch classifier loss: 0.388141; batch adversarial loss: 0.503718\n",
      "epoch 66; iter: 0; batch classifier loss: 0.431539; batch adversarial loss: 0.450260\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403591; batch adversarial loss: 0.456070\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408071; batch adversarial loss: 0.432421\n",
      "epoch 69; iter: 0; batch classifier loss: 0.442764; batch adversarial loss: 0.454191\n",
      "epoch 70; iter: 0; batch classifier loss: 0.467770; batch adversarial loss: 0.469527\n",
      "epoch 71; iter: 0; batch classifier loss: 0.408442; batch adversarial loss: 0.424948\n",
      "epoch 72; iter: 0; batch classifier loss: 0.475981; batch adversarial loss: 0.530631\n",
      "epoch 73; iter: 0; batch classifier loss: 0.430930; batch adversarial loss: 0.528671\n",
      "epoch 74; iter: 0; batch classifier loss: 0.464421; batch adversarial loss: 0.445401\n",
      "epoch 75; iter: 0; batch classifier loss: 0.497879; batch adversarial loss: 0.481808\n",
      "epoch 76; iter: 0; batch classifier loss: 0.451180; batch adversarial loss: 0.529084\n",
      "epoch 77; iter: 0; batch classifier loss: 0.412140; batch adversarial loss: 0.440926\n",
      "epoch 78; iter: 0; batch classifier loss: 0.368778; batch adversarial loss: 0.526745\n",
      "epoch 79; iter: 0; batch classifier loss: 0.398998; batch adversarial loss: 0.414150\n",
      "epoch 80; iter: 0; batch classifier loss: 0.439052; batch adversarial loss: 0.452815\n",
      "epoch 81; iter: 0; batch classifier loss: 0.385812; batch adversarial loss: 0.484999\n",
      "epoch 82; iter: 0; batch classifier loss: 0.394537; batch adversarial loss: 0.436715\n",
      "epoch 83; iter: 0; batch classifier loss: 0.402993; batch adversarial loss: 0.447238\n",
      "epoch 84; iter: 0; batch classifier loss: 0.380521; batch adversarial loss: 0.462502\n",
      "epoch 85; iter: 0; batch classifier loss: 0.343033; batch adversarial loss: 0.482355\n",
      "epoch 86; iter: 0; batch classifier loss: 0.413096; batch adversarial loss: 0.468771\n",
      "epoch 87; iter: 0; batch classifier loss: 0.365434; batch adversarial loss: 0.522455\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417511; batch adversarial loss: 0.420596\n",
      "epoch 89; iter: 0; batch classifier loss: 0.392220; batch adversarial loss: 0.453419\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393083; batch adversarial loss: 0.454135\n",
      "epoch 91; iter: 0; batch classifier loss: 0.382051; batch adversarial loss: 0.495563\n",
      "epoch 92; iter: 0; batch classifier loss: 0.395700; batch adversarial loss: 0.604875\n",
      "epoch 93; iter: 0; batch classifier loss: 0.458075; batch adversarial loss: 0.613727\n",
      "epoch 94; iter: 0; batch classifier loss: 0.284553; batch adversarial loss: 0.496614\n",
      "epoch 95; iter: 0; batch classifier loss: 0.287717; batch adversarial loss: 0.484806\n",
      "epoch 96; iter: 0; batch classifier loss: 0.333675; batch adversarial loss: 0.514877\n",
      "epoch 97; iter: 0; batch classifier loss: 0.481586; batch adversarial loss: 0.361425\n",
      "epoch 98; iter: 0; batch classifier loss: 0.368956; batch adversarial loss: 0.482477\n",
      "epoch 99; iter: 0; batch classifier loss: 0.469871; batch adversarial loss: 0.505825\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.166618; batch adversarial loss: 0.861016\n",
      "epoch 2; iter: 0; batch classifier loss: 1.023026; batch adversarial loss: 0.833584\n",
      "epoch 3; iter: 0; batch classifier loss: 0.990509; batch adversarial loss: 0.744598\n",
      "epoch 4; iter: 0; batch classifier loss: 0.785628; batch adversarial loss: 0.733740\n",
      "epoch 5; iter: 0; batch classifier loss: 0.600896; batch adversarial loss: 0.689709\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521506; batch adversarial loss: 0.666818\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496772; batch adversarial loss: 0.630516\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561329; batch adversarial loss: 0.614994\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502307; batch adversarial loss: 0.594415\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564619; batch adversarial loss: 0.590778\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542136; batch adversarial loss: 0.596112\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556966; batch adversarial loss: 0.577853\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514557; batch adversarial loss: 0.551539\n",
      "epoch 14; iter: 0; batch classifier loss: 0.463666; batch adversarial loss: 0.551144\n",
      "epoch 15; iter: 0; batch classifier loss: 0.573912; batch adversarial loss: 0.580796\n",
      "epoch 16; iter: 0; batch classifier loss: 0.527229; batch adversarial loss: 0.532733\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522295; batch adversarial loss: 0.541272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.528415; batch adversarial loss: 0.531229\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543922; batch adversarial loss: 0.557776\n",
      "epoch 20; iter: 0; batch classifier loss: 0.607836; batch adversarial loss: 0.482444\n",
      "epoch 21; iter: 0; batch classifier loss: 0.566306; batch adversarial loss: 0.529516\n",
      "epoch 22; iter: 0; batch classifier loss: 0.613655; batch adversarial loss: 0.544258\n",
      "epoch 23; iter: 0; batch classifier loss: 0.588860; batch adversarial loss: 0.559513\n",
      "epoch 24; iter: 0; batch classifier loss: 0.579334; batch adversarial loss: 0.511913\n",
      "epoch 25; iter: 0; batch classifier loss: 0.790290; batch adversarial loss: 0.588540\n",
      "epoch 26; iter: 0; batch classifier loss: 0.660868; batch adversarial loss: 0.529387\n",
      "epoch 27; iter: 0; batch classifier loss: 0.699482; batch adversarial loss: 0.650676\n",
      "epoch 28; iter: 0; batch classifier loss: 0.596832; batch adversarial loss: 0.528833\n",
      "epoch 29; iter: 0; batch classifier loss: 0.649897; batch adversarial loss: 0.540012\n",
      "epoch 30; iter: 0; batch classifier loss: 0.535382; batch adversarial loss: 0.546162\n",
      "epoch 31; iter: 0; batch classifier loss: 0.538335; batch adversarial loss: 0.491341\n",
      "epoch 32; iter: 0; batch classifier loss: 0.533265; batch adversarial loss: 0.512508\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477915; batch adversarial loss: 0.519994\n",
      "epoch 34; iter: 0; batch classifier loss: 0.478797; batch adversarial loss: 0.540282\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488618; batch adversarial loss: 0.481978\n",
      "epoch 36; iter: 0; batch classifier loss: 0.510247; batch adversarial loss: 0.459111\n",
      "epoch 37; iter: 0; batch classifier loss: 0.540717; batch adversarial loss: 0.532472\n",
      "epoch 38; iter: 0; batch classifier loss: 0.540174; batch adversarial loss: 0.416822\n",
      "epoch 39; iter: 0; batch classifier loss: 0.568427; batch adversarial loss: 0.466113\n",
      "epoch 40; iter: 0; batch classifier loss: 0.585201; batch adversarial loss: 0.451131\n",
      "epoch 41; iter: 0; batch classifier loss: 0.631237; batch adversarial loss: 0.536764\n",
      "epoch 42; iter: 0; batch classifier loss: 0.511403; batch adversarial loss: 0.455713\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477321; batch adversarial loss: 0.462078\n",
      "epoch 44; iter: 0; batch classifier loss: 0.494313; batch adversarial loss: 0.411561\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427635; batch adversarial loss: 0.447059\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500520; batch adversarial loss: 0.536182\n",
      "epoch 47; iter: 0; batch classifier loss: 0.526297; batch adversarial loss: 0.505975\n",
      "epoch 48; iter: 0; batch classifier loss: 0.572106; batch adversarial loss: 0.433413\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437730; batch adversarial loss: 0.471613\n",
      "epoch 50; iter: 0; batch classifier loss: 0.471178; batch adversarial loss: 0.504575\n",
      "epoch 51; iter: 0; batch classifier loss: 0.473195; batch adversarial loss: 0.483170\n",
      "epoch 52; iter: 0; batch classifier loss: 0.442640; batch adversarial loss: 0.425985\n",
      "epoch 53; iter: 0; batch classifier loss: 0.471611; batch adversarial loss: 0.426529\n",
      "epoch 54; iter: 0; batch classifier loss: 0.512485; batch adversarial loss: 0.446510\n",
      "epoch 55; iter: 0; batch classifier loss: 0.482409; batch adversarial loss: 0.365354\n",
      "epoch 56; iter: 0; batch classifier loss: 0.415850; batch adversarial loss: 0.523732\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398930; batch adversarial loss: 0.498983\n",
      "epoch 58; iter: 0; batch classifier loss: 0.460284; batch adversarial loss: 0.452998\n",
      "epoch 59; iter: 0; batch classifier loss: 0.415365; batch adversarial loss: 0.465590\n",
      "epoch 60; iter: 0; batch classifier loss: 0.449865; batch adversarial loss: 0.596764\n",
      "epoch 61; iter: 0; batch classifier loss: 0.418600; batch adversarial loss: 0.539126\n",
      "epoch 62; iter: 0; batch classifier loss: 0.441434; batch adversarial loss: 0.470512\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429514; batch adversarial loss: 0.449672\n",
      "epoch 64; iter: 0; batch classifier loss: 0.388685; batch adversarial loss: 0.439863\n",
      "epoch 65; iter: 0; batch classifier loss: 0.387971; batch adversarial loss: 0.503452\n",
      "epoch 66; iter: 0; batch classifier loss: 0.430039; batch adversarial loss: 0.450317\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412392; batch adversarial loss: 0.456354\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411997; batch adversarial loss: 0.432975\n",
      "epoch 69; iter: 0; batch classifier loss: 0.451618; batch adversarial loss: 0.454282\n",
      "epoch 70; iter: 0; batch classifier loss: 0.476591; batch adversarial loss: 0.469166\n",
      "epoch 71; iter: 0; batch classifier loss: 0.400350; batch adversarial loss: 0.425504\n",
      "epoch 72; iter: 0; batch classifier loss: 0.478827; batch adversarial loss: 0.530327\n",
      "epoch 73; iter: 0; batch classifier loss: 0.434320; batch adversarial loss: 0.528020\n",
      "epoch 74; iter: 0; batch classifier loss: 0.483357; batch adversarial loss: 0.444460\n",
      "epoch 75; iter: 0; batch classifier loss: 0.501932; batch adversarial loss: 0.482288\n",
      "epoch 76; iter: 0; batch classifier loss: 0.465933; batch adversarial loss: 0.528176\n",
      "epoch 77; iter: 0; batch classifier loss: 0.401429; batch adversarial loss: 0.440213\n",
      "epoch 78; iter: 0; batch classifier loss: 0.378696; batch adversarial loss: 0.527568\n",
      "epoch 79; iter: 0; batch classifier loss: 0.404235; batch adversarial loss: 0.412965\n",
      "epoch 80; iter: 0; batch classifier loss: 0.440791; batch adversarial loss: 0.452620\n",
      "epoch 81; iter: 0; batch classifier loss: 0.392733; batch adversarial loss: 0.485536\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398760; batch adversarial loss: 0.436917\n",
      "epoch 83; iter: 0; batch classifier loss: 0.409845; batch adversarial loss: 0.447567\n",
      "epoch 84; iter: 0; batch classifier loss: 0.374563; batch adversarial loss: 0.462085\n",
      "epoch 85; iter: 0; batch classifier loss: 0.358734; batch adversarial loss: 0.483312\n",
      "epoch 86; iter: 0; batch classifier loss: 0.430491; batch adversarial loss: 0.469283\n",
      "epoch 87; iter: 0; batch classifier loss: 0.368430; batch adversarial loss: 0.521605\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423042; batch adversarial loss: 0.418341\n",
      "epoch 89; iter: 0; batch classifier loss: 0.398621; batch adversarial loss: 0.453315\n",
      "epoch 90; iter: 0; batch classifier loss: 0.409727; batch adversarial loss: 0.453970\n",
      "epoch 91; iter: 0; batch classifier loss: 0.391211; batch adversarial loss: 0.495447\n",
      "epoch 92; iter: 0; batch classifier loss: 0.417523; batch adversarial loss: 0.604013\n",
      "epoch 93; iter: 0; batch classifier loss: 0.485847; batch adversarial loss: 0.612717\n",
      "epoch 94; iter: 0; batch classifier loss: 0.300873; batch adversarial loss: 0.497087\n",
      "epoch 95; iter: 0; batch classifier loss: 0.287233; batch adversarial loss: 0.485247\n",
      "epoch 96; iter: 0; batch classifier loss: 0.343866; batch adversarial loss: 0.516017\n",
      "epoch 97; iter: 0; batch classifier loss: 0.476058; batch adversarial loss: 0.361279\n",
      "epoch 98; iter: 0; batch classifier loss: 0.372073; batch adversarial loss: 0.482070\n",
      "epoch 99; iter: 0; batch classifier loss: 0.460907; batch adversarial loss: 0.506632\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714043; batch adversarial loss: 0.835813\n",
      "epoch 1; iter: 0; batch classifier loss: 1.130143; batch adversarial loss: 0.858998\n",
      "epoch 2; iter: 0; batch classifier loss: 0.986391; batch adversarial loss: 0.831385\n",
      "epoch 3; iter: 0; batch classifier loss: 0.941853; batch adversarial loss: 0.742646\n",
      "epoch 4; iter: 0; batch classifier loss: 0.746258; batch adversarial loss: 0.730588\n",
      "epoch 5; iter: 0; batch classifier loss: 0.566662; batch adversarial loss: 0.687199\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513268; batch adversarial loss: 0.665557\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491297; batch adversarial loss: 0.631256\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561010; batch adversarial loss: 0.615650\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501570; batch adversarial loss: 0.595208\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565150; batch adversarial loss: 0.591229\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545729; batch adversarial loss: 0.596125\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558776; batch adversarial loss: 0.578174\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518515; batch adversarial loss: 0.551425\n",
      "epoch 14; iter: 0; batch classifier loss: 0.467174; batch adversarial loss: 0.550082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.576554; batch adversarial loss: 0.578912\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531617; batch adversarial loss: 0.528757\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524747; batch adversarial loss: 0.538722\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526717; batch adversarial loss: 0.528112\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531445; batch adversarial loss: 0.548940\n",
      "epoch 20; iter: 0; batch classifier loss: 0.586452; batch adversarial loss: 0.471996\n",
      "epoch 21; iter: 0; batch classifier loss: 0.535108; batch adversarial loss: 0.520293\n",
      "epoch 22; iter: 0; batch classifier loss: 0.578297; batch adversarial loss: 0.532853\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528600; batch adversarial loss: 0.545078\n",
      "epoch 24; iter: 0; batch classifier loss: 0.537223; batch adversarial loss: 0.501005\n",
      "epoch 25; iter: 0; batch classifier loss: 0.750667; batch adversarial loss: 0.590339\n",
      "epoch 26; iter: 0; batch classifier loss: 0.650078; batch adversarial loss: 0.536617\n",
      "epoch 27; iter: 0; batch classifier loss: 0.720179; batch adversarial loss: 0.664760\n",
      "epoch 28; iter: 0; batch classifier loss: 0.608830; batch adversarial loss: 0.533615\n",
      "epoch 29; iter: 0; batch classifier loss: 0.676939; batch adversarial loss: 0.548137\n",
      "epoch 30; iter: 0; batch classifier loss: 0.562556; batch adversarial loss: 0.553742\n",
      "epoch 31; iter: 0; batch classifier loss: 0.557356; batch adversarial loss: 0.495979\n",
      "epoch 32; iter: 0; batch classifier loss: 0.545928; batch adversarial loss: 0.516188\n",
      "epoch 33; iter: 0; batch classifier loss: 0.506542; batch adversarial loss: 0.525954\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501575; batch adversarial loss: 0.545293\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484942; batch adversarial loss: 0.483941\n",
      "epoch 36; iter: 0; batch classifier loss: 0.504179; batch adversarial loss: 0.460008\n",
      "epoch 37; iter: 0; batch classifier loss: 0.524725; batch adversarial loss: 0.531771\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523676; batch adversarial loss: 0.416021\n",
      "epoch 39; iter: 0; batch classifier loss: 0.546587; batch adversarial loss: 0.463924\n",
      "epoch 40; iter: 0; batch classifier loss: 0.556603; batch adversarial loss: 0.449938\n",
      "epoch 41; iter: 0; batch classifier loss: 0.607321; batch adversarial loss: 0.537154\n",
      "epoch 42; iter: 0; batch classifier loss: 0.494162; batch adversarial loss: 0.456479\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486374; batch adversarial loss: 0.463944\n",
      "epoch 44; iter: 0; batch classifier loss: 0.509452; batch adversarial loss: 0.413041\n",
      "epoch 45; iter: 0; batch classifier loss: 0.431573; batch adversarial loss: 0.448003\n",
      "epoch 46; iter: 0; batch classifier loss: 0.511674; batch adversarial loss: 0.537549\n",
      "epoch 47; iter: 0; batch classifier loss: 0.523656; batch adversarial loss: 0.506550\n",
      "epoch 48; iter: 0; batch classifier loss: 0.565423; batch adversarial loss: 0.433800\n",
      "epoch 49; iter: 0; batch classifier loss: 0.441333; batch adversarial loss: 0.471954\n",
      "epoch 50; iter: 0; batch classifier loss: 0.465702; batch adversarial loss: 0.504653\n",
      "epoch 51; iter: 0; batch classifier loss: 0.468889; batch adversarial loss: 0.483165\n",
      "epoch 52; iter: 0; batch classifier loss: 0.440644; batch adversarial loss: 0.426234\n",
      "epoch 53; iter: 0; batch classifier loss: 0.464825; batch adversarial loss: 0.426327\n",
      "epoch 54; iter: 0; batch classifier loss: 0.506644; batch adversarial loss: 0.446389\n",
      "epoch 55; iter: 0; batch classifier loss: 0.479463; batch adversarial loss: 0.365874\n",
      "epoch 56; iter: 0; batch classifier loss: 0.414870; batch adversarial loss: 0.523619\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399653; batch adversarial loss: 0.498793\n",
      "epoch 58; iter: 0; batch classifier loss: 0.452979; batch adversarial loss: 0.453064\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406997; batch adversarial loss: 0.465580\n",
      "epoch 60; iter: 0; batch classifier loss: 0.443897; batch adversarial loss: 0.596486\n",
      "epoch 61; iter: 0; batch classifier loss: 0.423148; batch adversarial loss: 0.539085\n",
      "epoch 62; iter: 0; batch classifier loss: 0.434198; batch adversarial loss: 0.470925\n",
      "epoch 63; iter: 0; batch classifier loss: 0.429804; batch adversarial loss: 0.449944\n",
      "epoch 64; iter: 0; batch classifier loss: 0.379583; batch adversarial loss: 0.440149\n",
      "epoch 65; iter: 0; batch classifier loss: 0.383779; batch adversarial loss: 0.503731\n",
      "epoch 66; iter: 0; batch classifier loss: 0.427375; batch adversarial loss: 0.450202\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411576; batch adversarial loss: 0.456202\n",
      "epoch 68; iter: 0; batch classifier loss: 0.402658; batch adversarial loss: 0.432404\n",
      "epoch 69; iter: 0; batch classifier loss: 0.444677; batch adversarial loss: 0.454053\n",
      "epoch 70; iter: 0; batch classifier loss: 0.466346; batch adversarial loss: 0.469747\n",
      "epoch 71; iter: 0; batch classifier loss: 0.409510; batch adversarial loss: 0.424934\n",
      "epoch 72; iter: 0; batch classifier loss: 0.476261; batch adversarial loss: 0.530716\n",
      "epoch 73; iter: 0; batch classifier loss: 0.437223; batch adversarial loss: 0.528774\n",
      "epoch 74; iter: 0; batch classifier loss: 0.470614; batch adversarial loss: 0.445905\n",
      "epoch 75; iter: 0; batch classifier loss: 0.493898; batch adversarial loss: 0.481512\n",
      "epoch 76; iter: 0; batch classifier loss: 0.466355; batch adversarial loss: 0.528241\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409106; batch adversarial loss: 0.440995\n",
      "epoch 78; iter: 0; batch classifier loss: 0.370610; batch adversarial loss: 0.526661\n",
      "epoch 79; iter: 0; batch classifier loss: 0.405402; batch adversarial loss: 0.414081\n",
      "epoch 80; iter: 0; batch classifier loss: 0.441666; batch adversarial loss: 0.452858\n",
      "epoch 81; iter: 0; batch classifier loss: 0.390095; batch adversarial loss: 0.485107\n",
      "epoch 82; iter: 0; batch classifier loss: 0.377487; batch adversarial loss: 0.436561\n",
      "epoch 83; iter: 0; batch classifier loss: 0.415597; batch adversarial loss: 0.447269\n",
      "epoch 84; iter: 0; batch classifier loss: 0.373904; batch adversarial loss: 0.462163\n",
      "epoch 85; iter: 0; batch classifier loss: 0.337183; batch adversarial loss: 0.483071\n",
      "epoch 86; iter: 0; batch classifier loss: 0.421719; batch adversarial loss: 0.469155\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373382; batch adversarial loss: 0.522598\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417872; batch adversarial loss: 0.420325\n",
      "epoch 89; iter: 0; batch classifier loss: 0.404317; batch adversarial loss: 0.453202\n",
      "epoch 90; iter: 0; batch classifier loss: 0.387225; batch adversarial loss: 0.453959\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386362; batch adversarial loss: 0.495537\n",
      "epoch 92; iter: 0; batch classifier loss: 0.399936; batch adversarial loss: 0.604775\n",
      "epoch 93; iter: 0; batch classifier loss: 0.453709; batch adversarial loss: 0.614593\n",
      "epoch 94; iter: 0; batch classifier loss: 0.297768; batch adversarial loss: 0.496304\n",
      "epoch 95; iter: 0; batch classifier loss: 0.286071; batch adversarial loss: 0.486033\n",
      "epoch 96; iter: 0; batch classifier loss: 0.330099; batch adversarial loss: 0.514232\n",
      "epoch 97; iter: 0; batch classifier loss: 0.469247; batch adversarial loss: 0.361364\n",
      "epoch 98; iter: 0; batch classifier loss: 0.369643; batch adversarial loss: 0.482417\n",
      "epoch 99; iter: 0; batch classifier loss: 0.465329; batch adversarial loss: 0.505858\n",
      "Probas: [[0.77307823 0.22692177]\n",
      " [0.8642585  0.1357415 ]\n",
      " [0.01077807 0.98922193]\n",
      " [0.86685668 0.13314332]\n",
      " [0.96780843 0.03219157]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[7.21216202e-06 9.99992788e-01]\n",
      " [8.64258498e-01 1.35741502e-01]\n",
      " [1.07780695e-02 9.89221931e-01]\n",
      " [8.66856679e-01 1.33143321e-01]\n",
      " [9.67808433e-01 3.21915671e-02]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.91189642 0.08810358]\n",
      " [0.8642585  0.1357415 ]\n",
      " [0.01077807 0.98922193]\n",
      " [0.86685668 0.13314332]\n",
      " [0.96780843 0.03219157]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.90871258 0.09128742]\n",
      " [0.8642585  0.1357415 ]\n",
      " [0.01077807 0.98922193]\n",
      " [0.86685668 0.13314332]\n",
      " [0.96780843 0.03219157]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.8736829  0.1263171 ]\n",
      " [0.8642585  0.1357415 ]\n",
      " [0.01077807 0.98922193]\n",
      " [0.86685668 0.13314332]\n",
      " [0.96780843 0.03219157]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.83611465 0.16388535]\n",
      " [0.8642585  0.1357415 ]\n",
      " [0.01077807 0.98922193]\n",
      " [0.86685668 0.13314332]\n",
      " [0.96780843 0.03219157]] Sums: [1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probas: [[0.82422154 0.17577846]\n",
      " [0.8642585  0.1357415 ]\n",
      " [0.01077807 0.98922193]\n",
      " [0.86685668 0.13314332]\n",
      " [0.96780843 0.03219157]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[9.99690839e-01 3.09161405e-04]\n",
      " [8.64258498e-01 1.35741502e-01]\n",
      " [1.07780695e-02 9.89221931e-01]\n",
      " [8.66856679e-01 1.33143321e-01]\n",
      " [9.67808433e-01 3.21915671e-02]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.77421716 0.22578284]\n",
      " [0.8642585  0.1357415 ]\n",
      " [0.01077807 0.98922193]\n",
      " [0.86685668 0.13314332]\n",
      " [0.96780843 0.03219157]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.90007299 0.09992701]\n",
      " [0.8642585  0.1357415 ]\n",
      " [0.01077807 0.98922193]\n",
      " [0.86685668 0.13314332]\n",
      " [0.96780843 0.03219157]] Sums: [1. 1. 1. 1. 1.]\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.004039; batch adversarial loss: 0.910671\n",
      "epoch 2; iter: 0; batch classifier loss: 0.930742; batch adversarial loss: 0.786474\n",
      "epoch 3; iter: 0; batch classifier loss: 0.732486; batch adversarial loss: 0.797039\n",
      "epoch 4; iter: 0; batch classifier loss: 0.654812; batch adversarial loss: 0.696292\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595015; batch adversarial loss: 0.643999\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569152; batch adversarial loss: 0.636045\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595558; batch adversarial loss: 0.609884\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559438; batch adversarial loss: 0.601048\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539109; batch adversarial loss: 0.575723\n",
      "epoch 10; iter: 0; batch classifier loss: 0.568291; batch adversarial loss: 0.580868\n",
      "epoch 11; iter: 0; batch classifier loss: 0.588943; batch adversarial loss: 0.541554\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553302; batch adversarial loss: 0.535045\n",
      "epoch 13; iter: 0; batch classifier loss: 0.555683; batch adversarial loss: 0.530618\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533664; batch adversarial loss: 0.493097\n",
      "epoch 15; iter: 0; batch classifier loss: 0.558487; batch adversarial loss: 0.469377\n",
      "epoch 16; iter: 0; batch classifier loss: 0.611950; batch adversarial loss: 0.451559\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519140; batch adversarial loss: 0.453247\n",
      "epoch 18; iter: 0; batch classifier loss: 0.578114; batch adversarial loss: 0.439613\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526296; batch adversarial loss: 0.440392\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511141; batch adversarial loss: 0.413181\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502608; batch adversarial loss: 0.421923\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519949; batch adversarial loss: 0.432936\n",
      "epoch 23; iter: 0; batch classifier loss: 0.459804; batch adversarial loss: 0.462336\n",
      "epoch 24; iter: 0; batch classifier loss: 0.526752; batch adversarial loss: 0.344626\n",
      "epoch 25; iter: 0; batch classifier loss: 0.499009; batch adversarial loss: 0.403224\n",
      "epoch 26; iter: 0; batch classifier loss: 0.527582; batch adversarial loss: 0.447833\n",
      "epoch 27; iter: 0; batch classifier loss: 0.584164; batch adversarial loss: 0.480745\n",
      "epoch 28; iter: 0; batch classifier loss: 0.513190; batch adversarial loss: 0.387761\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445034; batch adversarial loss: 0.445071\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495174; batch adversarial loss: 0.370524\n",
      "epoch 31; iter: 0; batch classifier loss: 0.514407; batch adversarial loss: 0.389854\n",
      "epoch 32; iter: 0; batch classifier loss: 0.525881; batch adversarial loss: 0.420430\n",
      "epoch 33; iter: 0; batch classifier loss: 0.522645; batch adversarial loss: 0.382702\n",
      "epoch 34; iter: 0; batch classifier loss: 0.520005; batch adversarial loss: 0.331580\n",
      "epoch 35; iter: 0; batch classifier loss: 0.578775; batch adversarial loss: 0.442807\n",
      "epoch 36; iter: 0; batch classifier loss: 0.512315; batch adversarial loss: 0.385970\n",
      "epoch 37; iter: 0; batch classifier loss: 0.546216; batch adversarial loss: 0.417997\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434659; batch adversarial loss: 0.348930\n",
      "epoch 39; iter: 0; batch classifier loss: 0.551040; batch adversarial loss: 0.321827\n",
      "epoch 40; iter: 0; batch classifier loss: 0.498232; batch adversarial loss: 0.396220\n",
      "epoch 41; iter: 0; batch classifier loss: 0.579216; batch adversarial loss: 0.423822\n",
      "epoch 42; iter: 0; batch classifier loss: 0.479708; batch adversarial loss: 0.344133\n",
      "epoch 43; iter: 0; batch classifier loss: 0.530261; batch adversarial loss: 0.363712\n",
      "epoch 44; iter: 0; batch classifier loss: 0.472528; batch adversarial loss: 0.320960\n",
      "epoch 45; iter: 0; batch classifier loss: 0.537983; batch adversarial loss: 0.351400\n",
      "epoch 46; iter: 0; batch classifier loss: 0.551262; batch adversarial loss: 0.308840\n",
      "epoch 47; iter: 0; batch classifier loss: 0.499723; batch adversarial loss: 0.272892\n",
      "epoch 48; iter: 0; batch classifier loss: 0.603683; batch adversarial loss: 0.400356\n",
      "epoch 49; iter: 0; batch classifier loss: 0.534037; batch adversarial loss: 0.382706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.601320; batch adversarial loss: 0.323377\n",
      "epoch 51; iter: 0; batch classifier loss: 0.598671; batch adversarial loss: 0.378293\n",
      "epoch 52; iter: 0; batch classifier loss: 0.496981; batch adversarial loss: 0.286572\n",
      "epoch 53; iter: 0; batch classifier loss: 0.549505; batch adversarial loss: 0.416468\n",
      "epoch 54; iter: 0; batch classifier loss: 0.524780; batch adversarial loss: 0.283326\n",
      "epoch 55; iter: 0; batch classifier loss: 0.495668; batch adversarial loss: 0.253648\n",
      "epoch 56; iter: 0; batch classifier loss: 0.552981; batch adversarial loss: 0.363032\n",
      "epoch 57; iter: 0; batch classifier loss: 0.626540; batch adversarial loss: 0.362007\n",
      "epoch 58; iter: 0; batch classifier loss: 0.543740; batch adversarial loss: 0.372762\n",
      "epoch 59; iter: 0; batch classifier loss: 0.539787; batch adversarial loss: 0.379349\n",
      "epoch 60; iter: 0; batch classifier loss: 0.482495; batch adversarial loss: 0.322536\n",
      "epoch 61; iter: 0; batch classifier loss: 0.466684; batch adversarial loss: 0.252501\n",
      "epoch 62; iter: 0; batch classifier loss: 0.484165; batch adversarial loss: 0.305865\n",
      "epoch 63; iter: 0; batch classifier loss: 0.449077; batch adversarial loss: 0.403591\n",
      "epoch 64; iter: 0; batch classifier loss: 0.373532; batch adversarial loss: 0.322157\n",
      "epoch 65; iter: 0; batch classifier loss: 0.433882; batch adversarial loss: 0.259528\n",
      "epoch 66; iter: 0; batch classifier loss: 0.310030; batch adversarial loss: 0.331102\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407918; batch adversarial loss: 0.344464\n",
      "epoch 68; iter: 0; batch classifier loss: 0.392633; batch adversarial loss: 0.343888\n",
      "epoch 69; iter: 0; batch classifier loss: 0.415791; batch adversarial loss: 0.281016\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417622; batch adversarial loss: 0.343729\n",
      "epoch 71; iter: 0; batch classifier loss: 0.451978; batch adversarial loss: 0.280344\n",
      "epoch 72; iter: 0; batch classifier loss: 0.405919; batch adversarial loss: 0.286948\n",
      "epoch 73; iter: 0; batch classifier loss: 0.377307; batch adversarial loss: 0.287945\n",
      "epoch 74; iter: 0; batch classifier loss: 0.441374; batch adversarial loss: 0.365622\n",
      "epoch 75; iter: 0; batch classifier loss: 0.346767; batch adversarial loss: 0.308415\n",
      "epoch 76; iter: 0; batch classifier loss: 0.380624; batch adversarial loss: 0.314804\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419435; batch adversarial loss: 0.336376\n",
      "epoch 78; iter: 0; batch classifier loss: 0.343986; batch adversarial loss: 0.228085\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376663; batch adversarial loss: 0.368236\n",
      "epoch 80; iter: 0; batch classifier loss: 0.448243; batch adversarial loss: 0.418604\n",
      "epoch 81; iter: 0; batch classifier loss: 0.382425; batch adversarial loss: 0.276810\n",
      "epoch 82; iter: 0; batch classifier loss: 0.453090; batch adversarial loss: 0.270426\n",
      "epoch 83; iter: 0; batch classifier loss: 0.364515; batch adversarial loss: 0.277352\n",
      "epoch 84; iter: 0; batch classifier loss: 0.453309; batch adversarial loss: 0.269275\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392061; batch adversarial loss: 0.395957\n",
      "epoch 86; iter: 0; batch classifier loss: 0.410449; batch adversarial loss: 0.297275\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378815; batch adversarial loss: 0.312146\n",
      "epoch 88; iter: 0; batch classifier loss: 0.440621; batch adversarial loss: 0.258604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.385315; batch adversarial loss: 0.269399\n",
      "epoch 90; iter: 0; batch classifier loss: 0.407357; batch adversarial loss: 0.260831\n",
      "epoch 91; iter: 0; batch classifier loss: 0.386613; batch adversarial loss: 0.360563\n",
      "epoch 92; iter: 0; batch classifier loss: 0.369878; batch adversarial loss: 0.241832\n",
      "epoch 93; iter: 0; batch classifier loss: 0.334191; batch adversarial loss: 0.287901\n",
      "epoch 94; iter: 0; batch classifier loss: 0.360819; batch adversarial loss: 0.286491\n",
      "epoch 95; iter: 0; batch classifier loss: 0.404571; batch adversarial loss: 0.292784\n",
      "epoch 96; iter: 0; batch classifier loss: 0.371077; batch adversarial loss: 0.309538\n",
      "epoch 97; iter: 0; batch classifier loss: 0.344472; batch adversarial loss: 0.290099\n",
      "epoch 98; iter: 0; batch classifier loss: 0.356374; batch adversarial loss: 0.254002\n",
      "epoch 99; iter: 0; batch classifier loss: 0.349063; batch adversarial loss: 0.227408\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697777; batch adversarial loss: 0.845058\n",
      "epoch 1; iter: 0; batch classifier loss: 0.773847; batch adversarial loss: 0.860175\n",
      "epoch 2; iter: 0; batch classifier loss: 0.711020; batch adversarial loss: 0.757756\n",
      "epoch 3; iter: 0; batch classifier loss: 0.632034; batch adversarial loss: 0.731536\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603101; batch adversarial loss: 0.660301\n",
      "epoch 5; iter: 0; batch classifier loss: 0.565440; batch adversarial loss: 0.637340\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561933; batch adversarial loss: 0.633868\n",
      "epoch 7; iter: 0; batch classifier loss: 0.600888; batch adversarial loss: 0.606992\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579320; batch adversarial loss: 0.595123\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530810; batch adversarial loss: 0.576946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.573951; batch adversarial loss: 0.575843\n",
      "epoch 11; iter: 0; batch classifier loss: 0.598443; batch adversarial loss: 0.540138\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548040; batch adversarial loss: 0.538097\n",
      "epoch 13; iter: 0; batch classifier loss: 0.563831; batch adversarial loss: 0.531881\n",
      "epoch 14; iter: 0; batch classifier loss: 0.486837; batch adversarial loss: 0.501513\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537590; batch adversarial loss: 0.476004\n",
      "epoch 16; iter: 0; batch classifier loss: 0.629715; batch adversarial loss: 0.449562\n",
      "epoch 17; iter: 0; batch classifier loss: 0.496644; batch adversarial loss: 0.452942\n",
      "epoch 18; iter: 0; batch classifier loss: 0.560672; batch adversarial loss: 0.435756\n",
      "epoch 19; iter: 0; batch classifier loss: 0.498566; batch adversarial loss: 0.425160\n",
      "epoch 20; iter: 0; batch classifier loss: 0.496563; batch adversarial loss: 0.395358\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509165; batch adversarial loss: 0.403455\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507390; batch adversarial loss: 0.405946\n",
      "epoch 23; iter: 0; batch classifier loss: 0.444924; batch adversarial loss: 0.432004\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458940; batch adversarial loss: 0.318187\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489664; batch adversarial loss: 0.380446\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455816; batch adversarial loss: 0.421743\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458712; batch adversarial loss: 0.440081\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465814; batch adversarial loss: 0.365805\n",
      "epoch 29; iter: 0; batch classifier loss: 0.398764; batch adversarial loss: 0.430657\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428839; batch adversarial loss: 0.350547\n",
      "epoch 31; iter: 0; batch classifier loss: 0.451449; batch adversarial loss: 0.362227\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445988; batch adversarial loss: 0.395516\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442756; batch adversarial loss: 0.354762\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474453; batch adversarial loss: 0.318349\n",
      "epoch 35; iter: 0; batch classifier loss: 0.462172; batch adversarial loss: 0.410874\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403837; batch adversarial loss: 0.358544\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460497; batch adversarial loss: 0.397736\n",
      "epoch 38; iter: 0; batch classifier loss: 0.373652; batch adversarial loss: 0.331185\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433805; batch adversarial loss: 0.321021\n",
      "epoch 40; iter: 0; batch classifier loss: 0.410122; batch adversarial loss: 0.390010\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418411; batch adversarial loss: 0.395800\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407701; batch adversarial loss: 0.333986\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427357; batch adversarial loss: 0.370417\n",
      "epoch 44; iter: 0; batch classifier loss: 0.372136; batch adversarial loss: 0.309874\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412520; batch adversarial loss: 0.347699\n",
      "epoch 46; iter: 0; batch classifier loss: 0.454552; batch adversarial loss: 0.303537\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424728; batch adversarial loss: 0.261082\n",
      "epoch 48; iter: 0; batch classifier loss: 0.550843; batch adversarial loss: 0.420457\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416828; batch adversarial loss: 0.391029\n",
      "epoch 50; iter: 0; batch classifier loss: 0.472794; batch adversarial loss: 0.324454\n",
      "epoch 51; iter: 0; batch classifier loss: 0.428462; batch adversarial loss: 0.392788\n",
      "epoch 52; iter: 0; batch classifier loss: 0.382058; batch adversarial loss: 0.286303\n",
      "epoch 53; iter: 0; batch classifier loss: 0.450584; batch adversarial loss: 0.436393\n",
      "epoch 54; iter: 0; batch classifier loss: 0.443463; batch adversarial loss: 0.285348\n",
      "epoch 55; iter: 0; batch classifier loss: 0.398251; batch adversarial loss: 0.254224\n",
      "epoch 56; iter: 0; batch classifier loss: 0.403185; batch adversarial loss: 0.367390\n",
      "epoch 57; iter: 0; batch classifier loss: 0.434630; batch adversarial loss: 0.377461\n",
      "epoch 58; iter: 0; batch classifier loss: 0.363294; batch adversarial loss: 0.394871\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447185; batch adversarial loss: 0.398122\n",
      "epoch 60; iter: 0; batch classifier loss: 0.455226; batch adversarial loss: 0.335490\n",
      "epoch 61; iter: 0; batch classifier loss: 0.457072; batch adversarial loss: 0.261502\n",
      "epoch 62; iter: 0; batch classifier loss: 0.501946; batch adversarial loss: 0.316260\n",
      "epoch 63; iter: 0; batch classifier loss: 0.506456; batch adversarial loss: 0.420036\n",
      "epoch 64; iter: 0; batch classifier loss: 0.429654; batch adversarial loss: 0.335920\n",
      "epoch 65; iter: 0; batch classifier loss: 0.453857; batch adversarial loss: 0.265124\n",
      "epoch 66; iter: 0; batch classifier loss: 0.277666; batch adversarial loss: 0.332805\n",
      "epoch 67; iter: 0; batch classifier loss: 0.339150; batch adversarial loss: 0.345234\n",
      "epoch 68; iter: 0; batch classifier loss: 0.336053; batch adversarial loss: 0.343334\n",
      "epoch 69; iter: 0; batch classifier loss: 0.353787; batch adversarial loss: 0.281998\n",
      "epoch 70; iter: 0; batch classifier loss: 0.305908; batch adversarial loss: 0.343712\n",
      "epoch 71; iter: 0; batch classifier loss: 0.346171; batch adversarial loss: 0.280410\n",
      "epoch 72; iter: 0; batch classifier loss: 0.340494; batch adversarial loss: 0.289025\n",
      "epoch 73; iter: 0; batch classifier loss: 0.273278; batch adversarial loss: 0.291611\n",
      "epoch 74; iter: 0; batch classifier loss: 0.338033; batch adversarial loss: 0.365404\n",
      "epoch 75; iter: 0; batch classifier loss: 0.284936; batch adversarial loss: 0.305989\n",
      "epoch 76; iter: 0; batch classifier loss: 0.261250; batch adversarial loss: 0.316375\n",
      "epoch 77; iter: 0; batch classifier loss: 0.321972; batch adversarial loss: 0.332649\n",
      "epoch 78; iter: 0; batch classifier loss: 0.288143; batch adversarial loss: 0.228374\n",
      "epoch 79; iter: 0; batch classifier loss: 0.269974; batch adversarial loss: 0.370662\n",
      "epoch 80; iter: 0; batch classifier loss: 0.326397; batch adversarial loss: 0.417610\n",
      "epoch 81; iter: 0; batch classifier loss: 0.327446; batch adversarial loss: 0.280209\n",
      "epoch 82; iter: 0; batch classifier loss: 0.356892; batch adversarial loss: 0.269566\n",
      "epoch 83; iter: 0; batch classifier loss: 0.246704; batch adversarial loss: 0.277858\n",
      "epoch 84; iter: 0; batch classifier loss: 0.326987; batch adversarial loss: 0.274417\n",
      "epoch 85; iter: 0; batch classifier loss: 0.314283; batch adversarial loss: 0.398606\n",
      "epoch 86; iter: 0; batch classifier loss: 0.286246; batch adversarial loss: 0.293778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87; iter: 0; batch classifier loss: 0.279707; batch adversarial loss: 0.317179\n",
      "epoch 88; iter: 0; batch classifier loss: 0.376647; batch adversarial loss: 0.261766\n",
      "epoch 89; iter: 0; batch classifier loss: 0.291946; batch adversarial loss: 0.267491\n",
      "epoch 90; iter: 0; batch classifier loss: 0.370436; batch adversarial loss: 0.257039\n",
      "epoch 91; iter: 0; batch classifier loss: 0.322864; batch adversarial loss: 0.356931\n",
      "epoch 92; iter: 0; batch classifier loss: 0.306046; batch adversarial loss: 0.242336\n",
      "epoch 93; iter: 0; batch classifier loss: 0.231174; batch adversarial loss: 0.288644\n",
      "epoch 94; iter: 0; batch classifier loss: 0.309220; batch adversarial loss: 0.288679\n",
      "epoch 95; iter: 0; batch classifier loss: 0.268738; batch adversarial loss: 0.295376\n",
      "epoch 96; iter: 0; batch classifier loss: 0.296263; batch adversarial loss: 0.308030\n",
      "epoch 97; iter: 0; batch classifier loss: 0.214202; batch adversarial loss: 0.289733\n",
      "epoch 98; iter: 0; batch classifier loss: 0.261324; batch adversarial loss: 0.251953\n",
      "epoch 99; iter: 0; batch classifier loss: 0.288379; batch adversarial loss: 0.228892\n",
      "epoch 100; iter: 0; batch classifier loss: 0.290627; batch adversarial loss: 0.297190\n",
      "epoch 101; iter: 0; batch classifier loss: 0.280671; batch adversarial loss: 0.258346\n",
      "epoch 102; iter: 0; batch classifier loss: 0.303612; batch adversarial loss: 0.272939\n",
      "epoch 103; iter: 0; batch classifier loss: 0.317929; batch adversarial loss: 0.363008\n",
      "epoch 104; iter: 0; batch classifier loss: 0.317478; batch adversarial loss: 0.288101\n",
      "epoch 105; iter: 0; batch classifier loss: 0.178328; batch adversarial loss: 0.335945\n",
      "epoch 106; iter: 0; batch classifier loss: 0.269500; batch adversarial loss: 0.270120\n",
      "epoch 107; iter: 0; batch classifier loss: 0.264383; batch adversarial loss: 0.284883\n",
      "epoch 108; iter: 0; batch classifier loss: 0.234477; batch adversarial loss: 0.315381\n",
      "epoch 109; iter: 0; batch classifier loss: 0.280811; batch adversarial loss: 0.287869\n",
      "epoch 110; iter: 0; batch classifier loss: 0.269673; batch adversarial loss: 0.307219\n",
      "epoch 111; iter: 0; batch classifier loss: 0.216899; batch adversarial loss: 0.361406\n",
      "epoch 112; iter: 0; batch classifier loss: 0.368110; batch adversarial loss: 0.371379\n",
      "epoch 113; iter: 0; batch classifier loss: 0.311706; batch adversarial loss: 0.320820\n",
      "epoch 114; iter: 0; batch classifier loss: 0.230349; batch adversarial loss: 0.231504\n",
      "epoch 115; iter: 0; batch classifier loss: 0.191608; batch adversarial loss: 0.218748\n",
      "epoch 116; iter: 0; batch classifier loss: 0.293312; batch adversarial loss: 0.225766\n",
      "epoch 117; iter: 0; batch classifier loss: 0.204058; batch adversarial loss: 0.274017\n",
      "epoch 118; iter: 0; batch classifier loss: 0.205131; batch adversarial loss: 0.294420\n",
      "epoch 119; iter: 0; batch classifier loss: 0.231504; batch adversarial loss: 0.325941\n",
      "epoch 120; iter: 0; batch classifier loss: 0.224524; batch adversarial loss: 0.219145\n",
      "epoch 121; iter: 0; batch classifier loss: 0.220803; batch adversarial loss: 0.284141\n",
      "epoch 122; iter: 0; batch classifier loss: 0.341576; batch adversarial loss: 0.253492\n",
      "epoch 123; iter: 0; batch classifier loss: 0.264062; batch adversarial loss: 0.347188\n",
      "epoch 124; iter: 0; batch classifier loss: 0.233804; batch adversarial loss: 0.358868\n",
      "epoch 125; iter: 0; batch classifier loss: 0.271845; batch adversarial loss: 0.372231\n",
      "epoch 126; iter: 0; batch classifier loss: 0.279311; batch adversarial loss: 0.380378\n",
      "epoch 127; iter: 0; batch classifier loss: 0.189228; batch adversarial loss: 0.286535\n",
      "epoch 128; iter: 0; batch classifier loss: 0.207538; batch adversarial loss: 0.220523\n",
      "epoch 129; iter: 0; batch classifier loss: 0.184183; batch adversarial loss: 0.338589\n",
      "epoch 130; iter: 0; batch classifier loss: 0.273519; batch adversarial loss: 0.167735\n",
      "epoch 131; iter: 0; batch classifier loss: 0.223590; batch adversarial loss: 0.321088\n",
      "epoch 132; iter: 0; batch classifier loss: 0.234184; batch adversarial loss: 0.347957\n",
      "epoch 133; iter: 0; batch classifier loss: 0.203223; batch adversarial loss: 0.314639\n",
      "epoch 134; iter: 0; batch classifier loss: 0.198525; batch adversarial loss: 0.223422\n",
      "epoch 135; iter: 0; batch classifier loss: 0.242739; batch adversarial loss: 0.356472\n",
      "epoch 136; iter: 0; batch classifier loss: 0.215637; batch adversarial loss: 0.269171\n",
      "epoch 137; iter: 0; batch classifier loss: 0.248832; batch adversarial loss: 0.305256\n",
      "epoch 138; iter: 0; batch classifier loss: 0.263369; batch adversarial loss: 0.263711\n",
      "epoch 139; iter: 0; batch classifier loss: 0.263485; batch adversarial loss: 0.273449\n",
      "epoch 140; iter: 0; batch classifier loss: 0.278892; batch adversarial loss: 0.294847\n",
      "epoch 141; iter: 0; batch classifier loss: 0.240137; batch adversarial loss: 0.299242\n",
      "epoch 142; iter: 0; batch classifier loss: 0.263336; batch adversarial loss: 0.191359\n",
      "epoch 143; iter: 0; batch classifier loss: 0.202074; batch adversarial loss: 0.299494\n",
      "epoch 144; iter: 0; batch classifier loss: 0.243932; batch adversarial loss: 0.254756\n",
      "epoch 145; iter: 0; batch classifier loss: 0.209674; batch adversarial loss: 0.343360\n",
      "epoch 146; iter: 0; batch classifier loss: 0.222980; batch adversarial loss: 0.226971\n",
      "epoch 147; iter: 0; batch classifier loss: 0.228173; batch adversarial loss: 0.167771\n",
      "epoch 148; iter: 0; batch classifier loss: 0.206346; batch adversarial loss: 0.347326\n",
      "epoch 149; iter: 0; batch classifier loss: 0.254512; batch adversarial loss: 0.244353\n",
      "epoch 150; iter: 0; batch classifier loss: 0.233311; batch adversarial loss: 0.323023\n",
      "epoch 151; iter: 0; batch classifier loss: 0.278396; batch adversarial loss: 0.274433\n",
      "epoch 152; iter: 0; batch classifier loss: 0.292457; batch adversarial loss: 0.294907\n",
      "epoch 153; iter: 0; batch classifier loss: 0.261601; batch adversarial loss: 0.320074\n",
      "epoch 154; iter: 0; batch classifier loss: 0.209407; batch adversarial loss: 0.327445\n",
      "epoch 155; iter: 0; batch classifier loss: 0.237624; batch adversarial loss: 0.167193\n",
      "epoch 156; iter: 0; batch classifier loss: 0.251302; batch adversarial loss: 0.277185\n",
      "epoch 157; iter: 0; batch classifier loss: 0.202381; batch adversarial loss: 0.332221\n",
      "epoch 158; iter: 0; batch classifier loss: 0.230886; batch adversarial loss: 0.338739\n",
      "epoch 159; iter: 0; batch classifier loss: 0.225037; batch adversarial loss: 0.317291\n",
      "epoch 160; iter: 0; batch classifier loss: 0.210739; batch adversarial loss: 0.290756\n",
      "epoch 161; iter: 0; batch classifier loss: 0.257255; batch adversarial loss: 0.219082\n",
      "epoch 162; iter: 0; batch classifier loss: 0.182707; batch adversarial loss: 0.208589\n",
      "epoch 163; iter: 0; batch classifier loss: 0.203947; batch adversarial loss: 0.306255\n",
      "epoch 164; iter: 0; batch classifier loss: 0.196573; batch adversarial loss: 0.313292\n",
      "epoch 165; iter: 0; batch classifier loss: 0.244407; batch adversarial loss: 0.220508\n",
      "epoch 166; iter: 0; batch classifier loss: 0.259409; batch adversarial loss: 0.378957\n",
      "epoch 167; iter: 0; batch classifier loss: 0.241087; batch adversarial loss: 0.398158\n",
      "epoch 168; iter: 0; batch classifier loss: 0.233506; batch adversarial loss: 0.453190\n",
      "epoch 169; iter: 0; batch classifier loss: 0.194276; batch adversarial loss: 0.342587\n",
      "epoch 170; iter: 0; batch classifier loss: 0.218028; batch adversarial loss: 0.339828\n",
      "epoch 171; iter: 0; batch classifier loss: 0.217072; batch adversarial loss: 0.257202\n",
      "epoch 172; iter: 0; batch classifier loss: 0.200147; batch adversarial loss: 0.290878\n",
      "epoch 173; iter: 0; batch classifier loss: 0.232854; batch adversarial loss: 0.331173\n",
      "epoch 174; iter: 0; batch classifier loss: 0.248524; batch adversarial loss: 0.432631\n",
      "epoch 175; iter: 0; batch classifier loss: 0.214173; batch adversarial loss: 0.425842\n",
      "epoch 176; iter: 0; batch classifier loss: 0.223132; batch adversarial loss: 0.317118\n",
      "epoch 177; iter: 0; batch classifier loss: 0.291102; batch adversarial loss: 0.224994\n",
      "epoch 178; iter: 0; batch classifier loss: 0.255119; batch adversarial loss: 0.343466\n",
      "epoch 179; iter: 0; batch classifier loss: 0.226977; batch adversarial loss: 0.270176\n",
      "epoch 180; iter: 0; batch classifier loss: 0.249276; batch adversarial loss: 0.398820\n",
      "epoch 181; iter: 0; batch classifier loss: 0.210489; batch adversarial loss: 0.293195\n",
      "epoch 182; iter: 0; batch classifier loss: 0.186687; batch adversarial loss: 0.351595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.182649; batch adversarial loss: 0.355358\n",
      "epoch 184; iter: 0; batch classifier loss: 0.268565; batch adversarial loss: 0.290583\n",
      "epoch 185; iter: 0; batch classifier loss: 0.208565; batch adversarial loss: 0.362624\n",
      "epoch 186; iter: 0; batch classifier loss: 0.229016; batch adversarial loss: 0.312418\n",
      "epoch 187; iter: 0; batch classifier loss: 0.216985; batch adversarial loss: 0.380349\n",
      "epoch 188; iter: 0; batch classifier loss: 0.204056; batch adversarial loss: 0.235633\n",
      "epoch 189; iter: 0; batch classifier loss: 0.225322; batch adversarial loss: 0.364125\n",
      "epoch 190; iter: 0; batch classifier loss: 0.151954; batch adversarial loss: 0.361644\n",
      "epoch 191; iter: 0; batch classifier loss: 0.226851; batch adversarial loss: 0.295529\n",
      "epoch 192; iter: 0; batch classifier loss: 0.218477; batch adversarial loss: 0.313823\n",
      "epoch 193; iter: 0; batch classifier loss: 0.178554; batch adversarial loss: 0.305937\n",
      "epoch 194; iter: 0; batch classifier loss: 0.228460; batch adversarial loss: 0.389558\n",
      "epoch 195; iter: 0; batch classifier loss: 0.213661; batch adversarial loss: 0.222484\n",
      "epoch 196; iter: 0; batch classifier loss: 0.195770; batch adversarial loss: 0.287984\n",
      "epoch 197; iter: 0; batch classifier loss: 0.254499; batch adversarial loss: 0.239900\n",
      "epoch 198; iter: 0; batch classifier loss: 0.182390; batch adversarial loss: 0.364923\n",
      "epoch 199; iter: 0; batch classifier loss: 0.203874; batch adversarial loss: 0.420770\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697777; batch adversarial loss: 0.845058\n",
      "epoch 1; iter: 0; batch classifier loss: 1.059995; batch adversarial loss: 0.915764\n",
      "epoch 2; iter: 0; batch classifier loss: 1.060394; batch adversarial loss: 0.800567\n",
      "epoch 3; iter: 0; batch classifier loss: 0.804402; batch adversarial loss: 0.812100\n",
      "epoch 4; iter: 0; batch classifier loss: 0.727608; batch adversarial loss: 0.723822\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621019; batch adversarial loss: 0.669872\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561808; batch adversarial loss: 0.641325\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563018; batch adversarial loss: 0.613829\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555182; batch adversarial loss: 0.601793\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528197; batch adversarial loss: 0.576250\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517072; batch adversarial loss: 0.584613\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550716; batch adversarial loss: 0.546666\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514959; batch adversarial loss: 0.539102\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521322; batch adversarial loss: 0.534651\n",
      "epoch 14; iter: 0; batch classifier loss: 0.485226; batch adversarial loss: 0.498920\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493664; batch adversarial loss: 0.476886\n",
      "epoch 16; iter: 0; batch classifier loss: 0.613602; batch adversarial loss: 0.450065\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474646; batch adversarial loss: 0.462195\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523627; batch adversarial loss: 0.458577\n",
      "epoch 19; iter: 0; batch classifier loss: 0.503675; batch adversarial loss: 0.450728\n",
      "epoch 20; iter: 0; batch classifier loss: 0.472892; batch adversarial loss: 0.425645\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509913; batch adversarial loss: 0.438742\n",
      "epoch 22; iter: 0; batch classifier loss: 0.510348; batch adversarial loss: 0.450728\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464417; batch adversarial loss: 0.495948\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477697; batch adversarial loss: 0.359741\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506388; batch adversarial loss: 0.415491\n",
      "epoch 26; iter: 0; batch classifier loss: 0.553943; batch adversarial loss: 0.470251\n",
      "epoch 27; iter: 0; batch classifier loss: 0.603604; batch adversarial loss: 0.495711\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538008; batch adversarial loss: 0.405575\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489819; batch adversarial loss: 0.461296\n",
      "epoch 30; iter: 0; batch classifier loss: 0.491914; batch adversarial loss: 0.379262\n",
      "epoch 31; iter: 0; batch classifier loss: 0.525373; batch adversarial loss: 0.401473\n",
      "epoch 32; iter: 0; batch classifier loss: 0.547797; batch adversarial loss: 0.430995\n",
      "epoch 33; iter: 0; batch classifier loss: 0.535136; batch adversarial loss: 0.392600\n",
      "epoch 34; iter: 0; batch classifier loss: 0.548018; batch adversarial loss: 0.337490\n",
      "epoch 35; iter: 0; batch classifier loss: 0.582589; batch adversarial loss: 0.442565\n",
      "epoch 36; iter: 0; batch classifier loss: 0.484767; batch adversarial loss: 0.383006\n",
      "epoch 37; iter: 0; batch classifier loss: 0.535328; batch adversarial loss: 0.417934\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442058; batch adversarial loss: 0.343935\n",
      "epoch 39; iter: 0; batch classifier loss: 0.480253; batch adversarial loss: 0.325232\n",
      "epoch 40; iter: 0; batch classifier loss: 0.468245; batch adversarial loss: 0.393276\n",
      "epoch 41; iter: 0; batch classifier loss: 0.529393; batch adversarial loss: 0.412360\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457363; batch adversarial loss: 0.338913\n",
      "epoch 43; iter: 0; batch classifier loss: 0.481472; batch adversarial loss: 0.355886\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402859; batch adversarial loss: 0.316363\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479694; batch adversarial loss: 0.343035\n",
      "epoch 46; iter: 0; batch classifier loss: 0.505976; batch adversarial loss: 0.302372\n",
      "epoch 47; iter: 0; batch classifier loss: 0.468551; batch adversarial loss: 0.270667\n",
      "epoch 48; iter: 0; batch classifier loss: 0.589939; batch adversarial loss: 0.387896\n",
      "epoch 49; iter: 0; batch classifier loss: 0.486736; batch adversarial loss: 0.370793\n",
      "epoch 50; iter: 0; batch classifier loss: 0.531999; batch adversarial loss: 0.315706\n",
      "epoch 51; iter: 0; batch classifier loss: 0.545106; batch adversarial loss: 0.366307\n",
      "epoch 52; iter: 0; batch classifier loss: 0.453962; batch adversarial loss: 0.283625\n",
      "epoch 53; iter: 0; batch classifier loss: 0.652414; batch adversarial loss: 0.399207\n",
      "epoch 54; iter: 0; batch classifier loss: 0.449988; batch adversarial loss: 0.277959\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419469; batch adversarial loss: 0.249334\n",
      "epoch 56; iter: 0; batch classifier loss: 0.395674; batch adversarial loss: 0.351547\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402672; batch adversarial loss: 0.352536\n",
      "epoch 58; iter: 0; batch classifier loss: 0.328562; batch adversarial loss: 0.365712\n",
      "epoch 59; iter: 0; batch classifier loss: 0.406300; batch adversarial loss: 0.377632\n",
      "epoch 60; iter: 0; batch classifier loss: 0.357914; batch adversarial loss: 0.318353\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379958; batch adversarial loss: 0.247966\n",
      "epoch 62; iter: 0; batch classifier loss: 0.404647; batch adversarial loss: 0.302631\n",
      "epoch 63; iter: 0; batch classifier loss: 0.351538; batch adversarial loss: 0.404081\n",
      "epoch 64; iter: 0; batch classifier loss: 0.338146; batch adversarial loss: 0.323106\n",
      "epoch 65; iter: 0; batch classifier loss: 0.321617; batch adversarial loss: 0.256399\n",
      "epoch 66; iter: 0; batch classifier loss: 0.282033; batch adversarial loss: 0.330279\n",
      "epoch 67; iter: 0; batch classifier loss: 0.317643; batch adversarial loss: 0.343819\n",
      "epoch 68; iter: 0; batch classifier loss: 0.364875; batch adversarial loss: 0.341983\n",
      "epoch 69; iter: 0; batch classifier loss: 0.373554; batch adversarial loss: 0.279807\n",
      "epoch 70; iter: 0; batch classifier loss: 0.346796; batch adversarial loss: 0.343784\n",
      "epoch 71; iter: 0; batch classifier loss: 0.368251; batch adversarial loss: 0.279723\n",
      "epoch 72; iter: 0; batch classifier loss: 0.366804; batch adversarial loss: 0.287446\n",
      "epoch 73; iter: 0; batch classifier loss: 0.284011; batch adversarial loss: 0.289079\n",
      "epoch 74; iter: 0; batch classifier loss: 0.357875; batch adversarial loss: 0.366606\n",
      "epoch 75; iter: 0; batch classifier loss: 0.292128; batch adversarial loss: 0.307663\n",
      "epoch 76; iter: 0; batch classifier loss: 0.290934; batch adversarial loss: 0.314520\n",
      "epoch 77; iter: 0; batch classifier loss: 0.350019; batch adversarial loss: 0.334328\n",
      "epoch 78; iter: 0; batch classifier loss: 0.301121; batch adversarial loss: 0.228142\n",
      "epoch 79; iter: 0; batch classifier loss: 0.290662; batch adversarial loss: 0.369157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.352211; batch adversarial loss: 0.418406\n",
      "epoch 81; iter: 0; batch classifier loss: 0.322741; batch adversarial loss: 0.279091\n",
      "epoch 82; iter: 0; batch classifier loss: 0.375522; batch adversarial loss: 0.271440\n",
      "epoch 83; iter: 0; batch classifier loss: 0.279420; batch adversarial loss: 0.277130\n",
      "epoch 84; iter: 0; batch classifier loss: 0.341323; batch adversarial loss: 0.271053\n",
      "epoch 85; iter: 0; batch classifier loss: 0.335606; batch adversarial loss: 0.397889\n",
      "epoch 86; iter: 0; batch classifier loss: 0.299295; batch adversarial loss: 0.295495\n",
      "epoch 87; iter: 0; batch classifier loss: 0.304411; batch adversarial loss: 0.314015\n",
      "epoch 88; iter: 0; batch classifier loss: 0.379769; batch adversarial loss: 0.262065\n",
      "epoch 89; iter: 0; batch classifier loss: 0.336442; batch adversarial loss: 0.269286\n",
      "epoch 90; iter: 0; batch classifier loss: 0.374056; batch adversarial loss: 0.258210\n",
      "epoch 91; iter: 0; batch classifier loss: 0.311332; batch adversarial loss: 0.358493\n",
      "epoch 92; iter: 0; batch classifier loss: 0.336457; batch adversarial loss: 0.242388\n",
      "epoch 93; iter: 0; batch classifier loss: 0.270666; batch adversarial loss: 0.289803\n",
      "epoch 94; iter: 0; batch classifier loss: 0.303707; batch adversarial loss: 0.284848\n",
      "epoch 95; iter: 0; batch classifier loss: 0.322347; batch adversarial loss: 0.295369\n",
      "epoch 96; iter: 0; batch classifier loss: 0.312184; batch adversarial loss: 0.308909\n",
      "epoch 97; iter: 0; batch classifier loss: 0.264650; batch adversarial loss: 0.290993\n",
      "epoch 98; iter: 0; batch classifier loss: 0.292692; batch adversarial loss: 0.254713\n",
      "epoch 99; iter: 0; batch classifier loss: 0.316793; batch adversarial loss: 0.227601\n",
      "epoch 100; iter: 0; batch classifier loss: 0.305076; batch adversarial loss: 0.299049\n",
      "epoch 101; iter: 0; batch classifier loss: 0.318239; batch adversarial loss: 0.259220\n",
      "epoch 102; iter: 0; batch classifier loss: 0.326276; batch adversarial loss: 0.272879\n",
      "epoch 103; iter: 0; batch classifier loss: 0.337160; batch adversarial loss: 0.363543\n",
      "epoch 104; iter: 0; batch classifier loss: 0.373432; batch adversarial loss: 0.290197\n",
      "epoch 105; iter: 0; batch classifier loss: 0.212753; batch adversarial loss: 0.337904\n",
      "epoch 106; iter: 0; batch classifier loss: 0.269867; batch adversarial loss: 0.270522\n",
      "epoch 107; iter: 0; batch classifier loss: 0.275633; batch adversarial loss: 0.282368\n",
      "epoch 108; iter: 0; batch classifier loss: 0.243233; batch adversarial loss: 0.314561\n",
      "epoch 109; iter: 0; batch classifier loss: 0.296785; batch adversarial loss: 0.289376\n",
      "epoch 110; iter: 0; batch classifier loss: 0.291665; batch adversarial loss: 0.307571\n",
      "epoch 111; iter: 0; batch classifier loss: 0.274164; batch adversarial loss: 0.364476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.366158; batch adversarial loss: 0.372317\n",
      "epoch 113; iter: 0; batch classifier loss: 0.312287; batch adversarial loss: 0.321607\n",
      "epoch 114; iter: 0; batch classifier loss: 0.233227; batch adversarial loss: 0.232767\n",
      "epoch 115; iter: 0; batch classifier loss: 0.228199; batch adversarial loss: 0.219382\n",
      "epoch 116; iter: 0; batch classifier loss: 0.314832; batch adversarial loss: 0.225317\n",
      "epoch 117; iter: 0; batch classifier loss: 0.236368; batch adversarial loss: 0.274129\n",
      "epoch 118; iter: 0; batch classifier loss: 0.219341; batch adversarial loss: 0.294661\n",
      "epoch 119; iter: 0; batch classifier loss: 0.247586; batch adversarial loss: 0.325192\n",
      "epoch 120; iter: 0; batch classifier loss: 0.257203; batch adversarial loss: 0.220029\n",
      "epoch 121; iter: 0; batch classifier loss: 0.245452; batch adversarial loss: 0.285578\n",
      "epoch 122; iter: 0; batch classifier loss: 0.331900; batch adversarial loss: 0.253952\n",
      "epoch 123; iter: 0; batch classifier loss: 0.283967; batch adversarial loss: 0.349124\n",
      "epoch 124; iter: 0; batch classifier loss: 0.261809; batch adversarial loss: 0.359021\n",
      "epoch 125; iter: 0; batch classifier loss: 0.324827; batch adversarial loss: 0.370991\n",
      "epoch 126; iter: 0; batch classifier loss: 0.329159; batch adversarial loss: 0.379785\n",
      "epoch 127; iter: 0; batch classifier loss: 0.249731; batch adversarial loss: 0.287995\n",
      "epoch 128; iter: 0; batch classifier loss: 0.264259; batch adversarial loss: 0.221122\n",
      "epoch 129; iter: 0; batch classifier loss: 0.221672; batch adversarial loss: 0.340208\n",
      "epoch 130; iter: 0; batch classifier loss: 0.248411; batch adversarial loss: 0.167738\n",
      "epoch 131; iter: 0; batch classifier loss: 0.251734; batch adversarial loss: 0.322954\n",
      "epoch 132; iter: 0; batch classifier loss: 0.242526; batch adversarial loss: 0.347922\n",
      "epoch 133; iter: 0; batch classifier loss: 0.259968; batch adversarial loss: 0.316428\n",
      "epoch 134; iter: 0; batch classifier loss: 0.220340; batch adversarial loss: 0.223899\n",
      "epoch 135; iter: 0; batch classifier loss: 0.253357; batch adversarial loss: 0.357554\n",
      "epoch 136; iter: 0; batch classifier loss: 0.236985; batch adversarial loss: 0.270634\n",
      "epoch 137; iter: 0; batch classifier loss: 0.255709; batch adversarial loss: 0.306303\n",
      "epoch 138; iter: 0; batch classifier loss: 0.274676; batch adversarial loss: 0.261613\n",
      "epoch 139; iter: 0; batch classifier loss: 0.297448; batch adversarial loss: 0.274046\n",
      "epoch 140; iter: 0; batch classifier loss: 0.280316; batch adversarial loss: 0.294337\n",
      "epoch 141; iter: 0; batch classifier loss: 0.310198; batch adversarial loss: 0.298565\n",
      "epoch 142; iter: 0; batch classifier loss: 0.295369; batch adversarial loss: 0.191067\n",
      "epoch 143; iter: 0; batch classifier loss: 0.223486; batch adversarial loss: 0.297107\n",
      "epoch 144; iter: 0; batch classifier loss: 0.244099; batch adversarial loss: 0.254918\n",
      "epoch 145; iter: 0; batch classifier loss: 0.250279; batch adversarial loss: 0.344135\n",
      "epoch 146; iter: 0; batch classifier loss: 0.273932; batch adversarial loss: 0.226848\n",
      "epoch 147; iter: 0; batch classifier loss: 0.233805; batch adversarial loss: 0.167369\n",
      "epoch 148; iter: 0; batch classifier loss: 0.252250; batch adversarial loss: 0.346883\n",
      "epoch 149; iter: 0; batch classifier loss: 0.263757; batch adversarial loss: 0.243910\n",
      "epoch 150; iter: 0; batch classifier loss: 0.251408; batch adversarial loss: 0.324411\n",
      "epoch 151; iter: 0; batch classifier loss: 0.295248; batch adversarial loss: 0.276093\n",
      "epoch 152; iter: 0; batch classifier loss: 0.337754; batch adversarial loss: 0.295312\n",
      "epoch 153; iter: 0; batch classifier loss: 0.279035; batch adversarial loss: 0.322058\n",
      "epoch 154; iter: 0; batch classifier loss: 0.245786; batch adversarial loss: 0.329228\n",
      "epoch 155; iter: 0; batch classifier loss: 0.278521; batch adversarial loss: 0.168084\n",
      "epoch 156; iter: 0; batch classifier loss: 0.255404; batch adversarial loss: 0.277037\n",
      "epoch 157; iter: 0; batch classifier loss: 0.267715; batch adversarial loss: 0.331233\n",
      "epoch 158; iter: 0; batch classifier loss: 0.270121; batch adversarial loss: 0.340583\n",
      "epoch 159; iter: 0; batch classifier loss: 0.252326; batch adversarial loss: 0.316151\n",
      "epoch 160; iter: 0; batch classifier loss: 0.269514; batch adversarial loss: 0.292294\n",
      "epoch 161; iter: 0; batch classifier loss: 0.281597; batch adversarial loss: 0.220038\n",
      "epoch 162; iter: 0; batch classifier loss: 0.235474; batch adversarial loss: 0.208297\n",
      "epoch 163; iter: 0; batch classifier loss: 0.235300; batch adversarial loss: 0.307389\n",
      "epoch 164; iter: 0; batch classifier loss: 0.211665; batch adversarial loss: 0.312728\n",
      "epoch 165; iter: 0; batch classifier loss: 0.313356; batch adversarial loss: 0.221388\n",
      "epoch 166; iter: 0; batch classifier loss: 0.347930; batch adversarial loss: 0.380560\n",
      "epoch 167; iter: 0; batch classifier loss: 0.267985; batch adversarial loss: 0.398432\n",
      "epoch 168; iter: 0; batch classifier loss: 0.241730; batch adversarial loss: 0.454643\n",
      "epoch 169; iter: 0; batch classifier loss: 0.208845; batch adversarial loss: 0.344269\n",
      "epoch 170; iter: 0; batch classifier loss: 0.237670; batch adversarial loss: 0.341239\n",
      "epoch 171; iter: 0; batch classifier loss: 0.260403; batch adversarial loss: 0.257925\n",
      "epoch 172; iter: 0; batch classifier loss: 0.252877; batch adversarial loss: 0.291461\n",
      "epoch 173; iter: 0; batch classifier loss: 0.250437; batch adversarial loss: 0.331104\n",
      "epoch 174; iter: 0; batch classifier loss: 0.214277; batch adversarial loss: 0.432550\n",
      "epoch 175; iter: 0; batch classifier loss: 0.188291; batch adversarial loss: 0.423139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.246003; batch adversarial loss: 0.315102\n",
      "epoch 177; iter: 0; batch classifier loss: 0.278174; batch adversarial loss: 0.224589\n",
      "epoch 178; iter: 0; batch classifier loss: 0.272057; batch adversarial loss: 0.343413\n",
      "epoch 179; iter: 0; batch classifier loss: 0.245139; batch adversarial loss: 0.271785\n",
      "epoch 180; iter: 0; batch classifier loss: 0.256899; batch adversarial loss: 0.399806\n",
      "epoch 181; iter: 0; batch classifier loss: 0.233740; batch adversarial loss: 0.293368\n",
      "epoch 182; iter: 0; batch classifier loss: 0.219090; batch adversarial loss: 0.350169\n",
      "epoch 183; iter: 0; batch classifier loss: 0.182843; batch adversarial loss: 0.357357\n",
      "epoch 184; iter: 0; batch classifier loss: 0.234248; batch adversarial loss: 0.291293\n",
      "epoch 185; iter: 0; batch classifier loss: 0.280556; batch adversarial loss: 0.363118\n",
      "epoch 186; iter: 0; batch classifier loss: 0.231425; batch adversarial loss: 0.313341\n",
      "epoch 187; iter: 0; batch classifier loss: 0.248971; batch adversarial loss: 0.381290\n",
      "epoch 188; iter: 0; batch classifier loss: 0.249706; batch adversarial loss: 0.237438\n",
      "epoch 189; iter: 0; batch classifier loss: 0.233028; batch adversarial loss: 0.365457\n",
      "epoch 190; iter: 0; batch classifier loss: 0.172735; batch adversarial loss: 0.362905\n",
      "epoch 191; iter: 0; batch classifier loss: 0.221365; batch adversarial loss: 0.294367\n",
      "epoch 192; iter: 0; batch classifier loss: 0.249462; batch adversarial loss: 0.313701\n",
      "epoch 193; iter: 0; batch classifier loss: 0.211545; batch adversarial loss: 0.307360\n",
      "epoch 194; iter: 0; batch classifier loss: 0.253120; batch adversarial loss: 0.389590\n",
      "epoch 195; iter: 0; batch classifier loss: 0.269450; batch adversarial loss: 0.222618\n",
      "epoch 196; iter: 0; batch classifier loss: 0.231539; batch adversarial loss: 0.289368\n",
      "epoch 197; iter: 0; batch classifier loss: 0.279668; batch adversarial loss: 0.240121\n",
      "epoch 198; iter: 0; batch classifier loss: 0.219744; batch adversarial loss: 0.365136\n",
      "epoch 199; iter: 0; batch classifier loss: 0.231640; batch adversarial loss: 0.419937\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.072509; batch adversarial loss: 0.917091\n",
      "epoch 2; iter: 0; batch classifier loss: 0.991961; batch adversarial loss: 0.791958\n",
      "epoch 3; iter: 0; batch classifier loss: 0.774631; batch adversarial loss: 0.806130\n",
      "epoch 4; iter: 0; batch classifier loss: 0.698287; batch adversarial loss: 0.707756\n",
      "epoch 5; iter: 0; batch classifier loss: 0.605933; batch adversarial loss: 0.649659\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572178; batch adversarial loss: 0.636210\n",
      "epoch 7; iter: 0; batch classifier loss: 0.589766; batch adversarial loss: 0.610902\n",
      "epoch 8; iter: 0; batch classifier loss: 0.556382; batch adversarial loss: 0.601526\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538291; batch adversarial loss: 0.575363\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558448; batch adversarial loss: 0.582236\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579118; batch adversarial loss: 0.542778\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545880; batch adversarial loss: 0.535525\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546520; batch adversarial loss: 0.530858\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530857; batch adversarial loss: 0.491686\n",
      "epoch 15; iter: 0; batch classifier loss: 0.547568; batch adversarial loss: 0.469005\n",
      "epoch 16; iter: 0; batch classifier loss: 0.604210; batch adversarial loss: 0.451027\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508051; batch adversarial loss: 0.455865\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559830; batch adversarial loss: 0.445821\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527276; batch adversarial loss: 0.445733\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506660; batch adversarial loss: 0.417487\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503793; batch adversarial loss: 0.426365\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519024; batch adversarial loss: 0.440708\n",
      "epoch 23; iter: 0; batch classifier loss: 0.467446; batch adversarial loss: 0.480118\n",
      "epoch 24; iter: 0; batch classifier loss: 0.541472; batch adversarial loss: 0.352969\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508748; batch adversarial loss: 0.413377\n",
      "epoch 26; iter: 0; batch classifier loss: 0.555267; batch adversarial loss: 0.461770\n",
      "epoch 27; iter: 0; batch classifier loss: 0.619901; batch adversarial loss: 0.489710\n",
      "epoch 28; iter: 0; batch classifier loss: 0.548576; batch adversarial loss: 0.398129\n",
      "epoch 29; iter: 0; batch classifier loss: 0.478726; batch adversarial loss: 0.458236\n",
      "epoch 30; iter: 0; batch classifier loss: 0.515712; batch adversarial loss: 0.377336\n",
      "epoch 31; iter: 0; batch classifier loss: 0.540878; batch adversarial loss: 0.396876\n",
      "epoch 32; iter: 0; batch classifier loss: 0.577452; batch adversarial loss: 0.431469\n",
      "epoch 33; iter: 0; batch classifier loss: 0.554160; batch adversarial loss: 0.392220\n",
      "epoch 34; iter: 0; batch classifier loss: 0.533109; batch adversarial loss: 0.335464\n",
      "epoch 35; iter: 0; batch classifier loss: 0.622514; batch adversarial loss: 0.446081\n",
      "epoch 36; iter: 0; batch classifier loss: 0.538898; batch adversarial loss: 0.387623\n",
      "epoch 37; iter: 0; batch classifier loss: 0.584809; batch adversarial loss: 0.421893\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445712; batch adversarial loss: 0.348263\n",
      "epoch 39; iter: 0; batch classifier loss: 0.557139; batch adversarial loss: 0.322679\n",
      "epoch 40; iter: 0; batch classifier loss: 0.515473; batch adversarial loss: 0.394263\n",
      "epoch 41; iter: 0; batch classifier loss: 0.595092; batch adversarial loss: 0.418466\n",
      "epoch 42; iter: 0; batch classifier loss: 0.495855; batch adversarial loss: 0.342874\n",
      "epoch 43; iter: 0; batch classifier loss: 0.542740; batch adversarial loss: 0.359443\n",
      "epoch 44; iter: 0; batch classifier loss: 0.470879; batch adversarial loss: 0.319334\n",
      "epoch 45; iter: 0; batch classifier loss: 0.533552; batch adversarial loss: 0.347139\n",
      "epoch 46; iter: 0; batch classifier loss: 0.553340; batch adversarial loss: 0.305776\n",
      "epoch 47; iter: 0; batch classifier loss: 0.505251; batch adversarial loss: 0.271810\n",
      "epoch 48; iter: 0; batch classifier loss: 0.609392; batch adversarial loss: 0.392944\n",
      "epoch 49; iter: 0; batch classifier loss: 0.531481; batch adversarial loss: 0.376582\n",
      "epoch 50; iter: 0; batch classifier loss: 0.589554; batch adversarial loss: 0.319450\n",
      "epoch 51; iter: 0; batch classifier loss: 0.601542; batch adversarial loss: 0.371835\n",
      "epoch 52; iter: 0; batch classifier loss: 0.506383; batch adversarial loss: 0.284879\n",
      "epoch 53; iter: 0; batch classifier loss: 0.554519; batch adversarial loss: 0.408510\n",
      "epoch 54; iter: 0; batch classifier loss: 0.549330; batch adversarial loss: 0.281323\n",
      "epoch 55; iter: 0; batch classifier loss: 0.533495; batch adversarial loss: 0.252771\n",
      "epoch 56; iter: 0; batch classifier loss: 0.615783; batch adversarial loss: 0.357395\n",
      "epoch 57; iter: 0; batch classifier loss: 0.621812; batch adversarial loss: 0.355154\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425962; batch adversarial loss: 0.366558\n",
      "epoch 59; iter: 0; batch classifier loss: 0.441433; batch adversarial loss: 0.377685\n",
      "epoch 60; iter: 0; batch classifier loss: 0.473001; batch adversarial loss: 0.321130\n",
      "epoch 61; iter: 0; batch classifier loss: 0.451262; batch adversarial loss: 0.250437\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479641; batch adversarial loss: 0.304507\n",
      "epoch 63; iter: 0; batch classifier loss: 0.454740; batch adversarial loss: 0.404164\n",
      "epoch 64; iter: 0; batch classifier loss: 0.369967; batch adversarial loss: 0.321898\n",
      "epoch 65; iter: 0; batch classifier loss: 0.432577; batch adversarial loss: 0.258520\n",
      "epoch 66; iter: 0; batch classifier loss: 0.313306; batch adversarial loss: 0.330864\n",
      "epoch 67; iter: 0; batch classifier loss: 0.398236; batch adversarial loss: 0.344670\n",
      "epoch 68; iter: 0; batch classifier loss: 0.394680; batch adversarial loss: 0.343536\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405657; batch adversarial loss: 0.280738\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419421; batch adversarial loss: 0.343768\n",
      "epoch 71; iter: 0; batch classifier loss: 0.461958; batch adversarial loss: 0.280169\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415943; batch adversarial loss: 0.287146\n",
      "epoch 73; iter: 0; batch classifier loss: 0.370645; batch adversarial loss: 0.287942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.434120; batch adversarial loss: 0.364941\n",
      "epoch 75; iter: 0; batch classifier loss: 0.342078; batch adversarial loss: 0.308335\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373316; batch adversarial loss: 0.314946\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409833; batch adversarial loss: 0.336514\n",
      "epoch 78; iter: 0; batch classifier loss: 0.346999; batch adversarial loss: 0.228185\n",
      "epoch 79; iter: 0; batch classifier loss: 0.362591; batch adversarial loss: 0.367284\n",
      "epoch 80; iter: 0; batch classifier loss: 0.460546; batch adversarial loss: 0.419060\n",
      "epoch 81; iter: 0; batch classifier loss: 0.391625; batch adversarial loss: 0.277781\n",
      "epoch 82; iter: 0; batch classifier loss: 0.462021; batch adversarial loss: 0.270891\n",
      "epoch 83; iter: 0; batch classifier loss: 0.371393; batch adversarial loss: 0.277130\n",
      "epoch 84; iter: 0; batch classifier loss: 0.441567; batch adversarial loss: 0.269238\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383793; batch adversarial loss: 0.396735\n",
      "epoch 86; iter: 0; batch classifier loss: 0.413860; batch adversarial loss: 0.297038\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371773; batch adversarial loss: 0.312946\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427339; batch adversarial loss: 0.258537\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395557; batch adversarial loss: 0.269678\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444128; batch adversarial loss: 0.260909\n",
      "epoch 91; iter: 0; batch classifier loss: 0.388550; batch adversarial loss: 0.360522\n",
      "epoch 92; iter: 0; batch classifier loss: 0.367821; batch adversarial loss: 0.241708\n",
      "epoch 93; iter: 0; batch classifier loss: 0.335284; batch adversarial loss: 0.288138\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372148; batch adversarial loss: 0.285906\n",
      "epoch 95; iter: 0; batch classifier loss: 0.420077; batch adversarial loss: 0.293750\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375267; batch adversarial loss: 0.309732\n",
      "epoch 97; iter: 0; batch classifier loss: 0.354198; batch adversarial loss: 0.289221\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376358; batch adversarial loss: 0.253085\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344577; batch adversarial loss: 0.227568\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697777; batch adversarial loss: 0.845058\n",
      "epoch 1; iter: 0; batch classifier loss: 0.936942; batch adversarial loss: 0.901089\n",
      "epoch 2; iter: 0; batch classifier loss: 0.898712; batch adversarial loss: 0.789081\n",
      "epoch 3; iter: 0; batch classifier loss: 0.699425; batch adversarial loss: 0.787307\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616277; batch adversarial loss: 0.700664\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550711; batch adversarial loss: 0.649696\n",
      "epoch 6; iter: 0; batch classifier loss: 0.551217; batch adversarial loss: 0.640421\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583615; batch adversarial loss: 0.612594\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559296; batch adversarial loss: 0.602987\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523802; batch adversarial loss: 0.580314\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533315; batch adversarial loss: 0.585847\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559244; batch adversarial loss: 0.548903\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513290; batch adversarial loss: 0.543522\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522855; batch adversarial loss: 0.538299\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478553; batch adversarial loss: 0.501118\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499676; batch adversarial loss: 0.477775\n",
      "epoch 16; iter: 0; batch classifier loss: 0.622467; batch adversarial loss: 0.448064\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481343; batch adversarial loss: 0.455070\n",
      "epoch 18; iter: 0; batch classifier loss: 0.530605; batch adversarial loss: 0.448504\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496780; batch adversarial loss: 0.438890\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478589; batch adversarial loss: 0.415024\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495891; batch adversarial loss: 0.424916\n",
      "epoch 22; iter: 0; batch classifier loss: 0.488633; batch adversarial loss: 0.432112\n",
      "epoch 23; iter: 0; batch classifier loss: 0.432001; batch adversarial loss: 0.461251\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464202; batch adversarial loss: 0.342178\n",
      "epoch 25; iter: 0; batch classifier loss: 0.487737; batch adversarial loss: 0.402179\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478168; batch adversarial loss: 0.445803\n",
      "epoch 27; iter: 0; batch classifier loss: 0.514859; batch adversarial loss: 0.479554\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481691; batch adversarial loss: 0.388839\n",
      "epoch 29; iter: 0; batch classifier loss: 0.427699; batch adversarial loss: 0.445583\n",
      "epoch 30; iter: 0; batch classifier loss: 0.451679; batch adversarial loss: 0.365053\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471317; batch adversarial loss: 0.383704\n",
      "epoch 32; iter: 0; batch classifier loss: 0.485058; batch adversarial loss: 0.413266\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475510; batch adversarial loss: 0.374463\n",
      "epoch 34; iter: 0; batch classifier loss: 0.499587; batch adversarial loss: 0.326717\n",
      "epoch 35; iter: 0; batch classifier loss: 0.508545; batch adversarial loss: 0.435519\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451894; batch adversarial loss: 0.374043\n",
      "epoch 37; iter: 0; batch classifier loss: 0.494995; batch adversarial loss: 0.407968\n",
      "epoch 38; iter: 0; batch classifier loss: 0.412990; batch adversarial loss: 0.343940\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463407; batch adversarial loss: 0.326752\n",
      "epoch 40; iter: 0; batch classifier loss: 0.442859; batch adversarial loss: 0.395602\n",
      "epoch 41; iter: 0; batch classifier loss: 0.497050; batch adversarial loss: 0.418754\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436734; batch adversarial loss: 0.340927\n",
      "epoch 43; iter: 0; batch classifier loss: 0.460223; batch adversarial loss: 0.363884\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406501; batch adversarial loss: 0.318853\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463749; batch adversarial loss: 0.350705\n",
      "epoch 46; iter: 0; batch classifier loss: 0.482801; batch adversarial loss: 0.307338\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439439; batch adversarial loss: 0.270257\n",
      "epoch 48; iter: 0; batch classifier loss: 0.581088; batch adversarial loss: 0.402495\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460907; batch adversarial loss: 0.382350\n",
      "epoch 50; iter: 0; batch classifier loss: 0.520060; batch adversarial loss: 0.322742\n",
      "epoch 51; iter: 0; batch classifier loss: 0.502078; batch adversarial loss: 0.379553\n",
      "epoch 52; iter: 0; batch classifier loss: 0.404149; batch adversarial loss: 0.287162\n",
      "epoch 53; iter: 0; batch classifier loss: 0.520978; batch adversarial loss: 0.418303\n",
      "epoch 54; iter: 0; batch classifier loss: 0.484532; batch adversarial loss: 0.283740\n",
      "epoch 55; iter: 0; batch classifier loss: 0.457382; batch adversarial loss: 0.254807\n",
      "epoch 56; iter: 0; batch classifier loss: 0.519948; batch adversarial loss: 0.362517\n",
      "epoch 57; iter: 0; batch classifier loss: 0.577587; batch adversarial loss: 0.362418\n",
      "epoch 58; iter: 0; batch classifier loss: 0.478542; batch adversarial loss: 0.372103\n",
      "epoch 59; iter: 0; batch classifier loss: 0.420205; batch adversarial loss: 0.378202\n",
      "epoch 60; iter: 0; batch classifier loss: 0.351701; batch adversarial loss: 0.320303\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379396; batch adversarial loss: 0.251202\n",
      "epoch 62; iter: 0; batch classifier loss: 0.385399; batch adversarial loss: 0.304175\n",
      "epoch 63; iter: 0; batch classifier loss: 0.334613; batch adversarial loss: 0.403086\n",
      "epoch 64; iter: 0; batch classifier loss: 0.336095; batch adversarial loss: 0.323987\n",
      "epoch 65; iter: 0; batch classifier loss: 0.327007; batch adversarial loss: 0.258048\n",
      "epoch 66; iter: 0; batch classifier loss: 0.271872; batch adversarial loss: 0.330880\n",
      "epoch 67; iter: 0; batch classifier loss: 0.330457; batch adversarial loss: 0.343848\n",
      "epoch 68; iter: 0; batch classifier loss: 0.338160; batch adversarial loss: 0.341780\n",
      "epoch 69; iter: 0; batch classifier loss: 0.375595; batch adversarial loss: 0.280337\n",
      "epoch 70; iter: 0; batch classifier loss: 0.328347; batch adversarial loss: 0.344284\n",
      "epoch 71; iter: 0; batch classifier loss: 0.352458; batch adversarial loss: 0.279392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.374724; batch adversarial loss: 0.287472\n",
      "epoch 73; iter: 0; batch classifier loss: 0.280800; batch adversarial loss: 0.289285\n",
      "epoch 74; iter: 0; batch classifier loss: 0.357365; batch adversarial loss: 0.366370\n",
      "epoch 75; iter: 0; batch classifier loss: 0.269559; batch adversarial loss: 0.306992\n",
      "epoch 76; iter: 0; batch classifier loss: 0.281562; batch adversarial loss: 0.314742\n",
      "epoch 77; iter: 0; batch classifier loss: 0.338447; batch adversarial loss: 0.333842\n",
      "epoch 78; iter: 0; batch classifier loss: 0.287428; batch adversarial loss: 0.228167\n",
      "epoch 79; iter: 0; batch classifier loss: 0.289970; batch adversarial loss: 0.369735\n",
      "epoch 80; iter: 0; batch classifier loss: 0.341649; batch adversarial loss: 0.419547\n",
      "epoch 81; iter: 0; batch classifier loss: 0.312183; batch adversarial loss: 0.280111\n",
      "epoch 82; iter: 0; batch classifier loss: 0.352283; batch adversarial loss: 0.270946\n",
      "epoch 83; iter: 0; batch classifier loss: 0.244156; batch adversarial loss: 0.277317\n",
      "epoch 84; iter: 0; batch classifier loss: 0.345967; batch adversarial loss: 0.272083\n",
      "epoch 85; iter: 0; batch classifier loss: 0.336430; batch adversarial loss: 0.398265\n",
      "epoch 86; iter: 0; batch classifier loss: 0.279515; batch adversarial loss: 0.294783\n",
      "epoch 87; iter: 0; batch classifier loss: 0.309800; batch adversarial loss: 0.315355\n",
      "epoch 88; iter: 0; batch classifier loss: 0.357639; batch adversarial loss: 0.261463\n",
      "epoch 89; iter: 0; batch classifier loss: 0.303076; batch adversarial loss: 0.268380\n",
      "epoch 90; iter: 0; batch classifier loss: 0.384501; batch adversarial loss: 0.258005\n",
      "epoch 91; iter: 0; batch classifier loss: 0.317114; batch adversarial loss: 0.358027\n",
      "epoch 92; iter: 0; batch classifier loss: 0.324580; batch adversarial loss: 0.241714\n",
      "epoch 93; iter: 0; batch classifier loss: 0.265755; batch adversarial loss: 0.289337\n",
      "epoch 94; iter: 0; batch classifier loss: 0.316459; batch adversarial loss: 0.287349\n",
      "epoch 95; iter: 0; batch classifier loss: 0.300546; batch adversarial loss: 0.295235\n",
      "epoch 96; iter: 0; batch classifier loss: 0.319708; batch adversarial loss: 0.309176\n",
      "epoch 97; iter: 0; batch classifier loss: 0.271927; batch adversarial loss: 0.290393\n",
      "epoch 98; iter: 0; batch classifier loss: 0.295222; batch adversarial loss: 0.254414\n",
      "epoch 99; iter: 0; batch classifier loss: 0.302359; batch adversarial loss: 0.227545\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.234069; batch adversarial loss: 0.925716\n",
      "epoch 2; iter: 0; batch classifier loss: 1.121588; batch adversarial loss: 0.799559\n",
      "epoch 3; iter: 0; batch classifier loss: 0.876695; batch adversarial loss: 0.818640\n",
      "epoch 4; iter: 0; batch classifier loss: 0.808951; batch adversarial loss: 0.723857\n",
      "epoch 5; iter: 0; batch classifier loss: 0.674711; batch adversarial loss: 0.663043\n",
      "epoch 6; iter: 0; batch classifier loss: 0.583609; batch adversarial loss: 0.635921\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580970; batch adversarial loss: 0.612354\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551904; batch adversarial loss: 0.601424\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539876; batch adversarial loss: 0.573164\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541693; batch adversarial loss: 0.582456\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568731; batch adversarial loss: 0.541494\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529769; batch adversarial loss: 0.535174\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533931; batch adversarial loss: 0.528868\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514897; batch adversarial loss: 0.493057\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524920; batch adversarial loss: 0.474024\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591765; batch adversarial loss: 0.456197\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507398; batch adversarial loss: 0.463066\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543851; batch adversarial loss: 0.453719\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550102; batch adversarial loss: 0.460642\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518736; batch adversarial loss: 0.432860\n",
      "epoch 21; iter: 0; batch classifier loss: 0.538030; batch adversarial loss: 0.449023\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573984; batch adversarial loss: 0.464555\n",
      "epoch 23; iter: 0; batch classifier loss: 0.526468; batch adversarial loss: 0.506223\n",
      "epoch 24; iter: 0; batch classifier loss: 0.583356; batch adversarial loss: 0.366245\n",
      "epoch 25; iter: 0; batch classifier loss: 0.554292; batch adversarial loss: 0.431215\n",
      "epoch 26; iter: 0; batch classifier loss: 0.641167; batch adversarial loss: 0.484394\n",
      "epoch 27; iter: 0; batch classifier loss: 0.697607; batch adversarial loss: 0.500263\n",
      "epoch 28; iter: 0; batch classifier loss: 0.609049; batch adversarial loss: 0.410243\n",
      "epoch 29; iter: 0; batch classifier loss: 0.526503; batch adversarial loss: 0.466571\n",
      "epoch 30; iter: 0; batch classifier loss: 0.548652; batch adversarial loss: 0.381987\n",
      "epoch 31; iter: 0; batch classifier loss: 0.602683; batch adversarial loss: 0.403569\n",
      "epoch 32; iter: 0; batch classifier loss: 0.629116; batch adversarial loss: 0.431650\n",
      "epoch 33; iter: 0; batch classifier loss: 0.591429; batch adversarial loss: 0.395551\n",
      "epoch 34; iter: 0; batch classifier loss: 0.540782; batch adversarial loss: 0.335947\n",
      "epoch 35; iter: 0; batch classifier loss: 0.661675; batch adversarial loss: 0.438863\n",
      "epoch 36; iter: 0; batch classifier loss: 0.548573; batch adversarial loss: 0.382383\n",
      "epoch 37; iter: 0; batch classifier loss: 0.596881; batch adversarial loss: 0.415027\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441273; batch adversarial loss: 0.344288\n",
      "epoch 39; iter: 0; batch classifier loss: 0.559868; batch adversarial loss: 0.321008\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522168; batch adversarial loss: 0.387966\n",
      "epoch 41; iter: 0; batch classifier loss: 0.596179; batch adversarial loss: 0.408191\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501926; batch adversarial loss: 0.338095\n",
      "epoch 43; iter: 0; batch classifier loss: 0.539760; batch adversarial loss: 0.352041\n",
      "epoch 44; iter: 0; batch classifier loss: 0.465479; batch adversarial loss: 0.315103\n",
      "epoch 45; iter: 0; batch classifier loss: 0.517809; batch adversarial loss: 0.341064\n",
      "epoch 46; iter: 0; batch classifier loss: 0.537892; batch adversarial loss: 0.301318\n",
      "epoch 47; iter: 0; batch classifier loss: 0.488488; batch adversarial loss: 0.268955\n",
      "epoch 48; iter: 0; batch classifier loss: 0.597688; batch adversarial loss: 0.383798\n",
      "epoch 49; iter: 0; batch classifier loss: 0.523244; batch adversarial loss: 0.369100\n",
      "epoch 50; iter: 0; batch classifier loss: 0.590391; batch adversarial loss: 0.314311\n",
      "epoch 51; iter: 0; batch classifier loss: 0.597942; batch adversarial loss: 0.365053\n",
      "epoch 52; iter: 0; batch classifier loss: 0.514258; batch adversarial loss: 0.282393\n",
      "epoch 53; iter: 0; batch classifier loss: 0.571849; batch adversarial loss: 0.399991\n",
      "epoch 54; iter: 0; batch classifier loss: 0.603641; batch adversarial loss: 0.278567\n",
      "epoch 55; iter: 0; batch classifier loss: 0.498292; batch adversarial loss: 0.249969\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449162; batch adversarial loss: 0.352474\n",
      "epoch 57; iter: 0; batch classifier loss: 0.492425; batch adversarial loss: 0.352685\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426482; batch adversarial loss: 0.365676\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458082; batch adversarial loss: 0.377542\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481547; batch adversarial loss: 0.320020\n",
      "epoch 61; iter: 0; batch classifier loss: 0.460210; batch adversarial loss: 0.248973\n",
      "epoch 62; iter: 0; batch classifier loss: 0.476652; batch adversarial loss: 0.303420\n",
      "epoch 63; iter: 0; batch classifier loss: 0.458925; batch adversarial loss: 0.404337\n",
      "epoch 64; iter: 0; batch classifier loss: 0.363498; batch adversarial loss: 0.321176\n",
      "epoch 65; iter: 0; batch classifier loss: 0.445757; batch adversarial loss: 0.257659\n",
      "epoch 66; iter: 0; batch classifier loss: 0.326490; batch adversarial loss: 0.330593\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407356; batch adversarial loss: 0.344199\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412450; batch adversarial loss: 0.343430\n",
      "epoch 69; iter: 0; batch classifier loss: 0.431443; batch adversarial loss: 0.280898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.421172; batch adversarial loss: 0.343314\n",
      "epoch 71; iter: 0; batch classifier loss: 0.474215; batch adversarial loss: 0.279891\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413409; batch adversarial loss: 0.286497\n",
      "epoch 73; iter: 0; batch classifier loss: 0.365723; batch adversarial loss: 0.287075\n",
      "epoch 74; iter: 0; batch classifier loss: 0.460873; batch adversarial loss: 0.363643\n",
      "epoch 75; iter: 0; batch classifier loss: 0.358843; batch adversarial loss: 0.308580\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369836; batch adversarial loss: 0.314715\n",
      "epoch 77; iter: 0; batch classifier loss: 0.406952; batch adversarial loss: 0.336516\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358692; batch adversarial loss: 0.228473\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381861; batch adversarial loss: 0.366893\n",
      "epoch 80; iter: 0; batch classifier loss: 0.485962; batch adversarial loss: 0.418357\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414804; batch adversarial loss: 0.278252\n",
      "epoch 82; iter: 0; batch classifier loss: 0.467034; batch adversarial loss: 0.271570\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383159; batch adversarial loss: 0.276310\n",
      "epoch 84; iter: 0; batch classifier loss: 0.432376; batch adversarial loss: 0.268803\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393068; batch adversarial loss: 0.396443\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412017; batch adversarial loss: 0.297006\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376897; batch adversarial loss: 0.312130\n",
      "epoch 88; iter: 0; batch classifier loss: 0.433346; batch adversarial loss: 0.259402\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386050; batch adversarial loss: 0.269821\n",
      "epoch 90; iter: 0; batch classifier loss: 0.464493; batch adversarial loss: 0.260666\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400854; batch adversarial loss: 0.359660\n",
      "epoch 92; iter: 0; batch classifier loss: 0.388671; batch adversarial loss: 0.241513\n",
      "epoch 93; iter: 0; batch classifier loss: 0.354649; batch adversarial loss: 0.288309\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374998; batch adversarial loss: 0.285124\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416384; batch adversarial loss: 0.293963\n",
      "epoch 96; iter: 0; batch classifier loss: 0.362148; batch adversarial loss: 0.309039\n",
      "epoch 97; iter: 0; batch classifier loss: 0.372419; batch adversarial loss: 0.290039\n",
      "epoch 98; iter: 0; batch classifier loss: 0.377198; batch adversarial loss: 0.254355\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363548; batch adversarial loss: 0.227321\n",
      "epoch 100; iter: 0; batch classifier loss: 0.424823; batch adversarial loss: 0.299877\n",
      "epoch 101; iter: 0; batch classifier loss: 0.367755; batch adversarial loss: 0.259948\n",
      "epoch 102; iter: 0; batch classifier loss: 0.327649; batch adversarial loss: 0.273260\n",
      "epoch 103; iter: 0; batch classifier loss: 0.389106; batch adversarial loss: 0.363600\n",
      "epoch 104; iter: 0; batch classifier loss: 0.422787; batch adversarial loss: 0.290844\n",
      "epoch 105; iter: 0; batch classifier loss: 0.291086; batch adversarial loss: 0.337349\n",
      "epoch 106; iter: 0; batch classifier loss: 0.398998; batch adversarial loss: 0.270448\n",
      "epoch 107; iter: 0; batch classifier loss: 0.368824; batch adversarial loss: 0.281424\n",
      "epoch 108; iter: 0; batch classifier loss: 0.371823; batch adversarial loss: 0.315669\n",
      "epoch 109; iter: 0; batch classifier loss: 0.388141; batch adversarial loss: 0.289484\n",
      "epoch 110; iter: 0; batch classifier loss: 0.411980; batch adversarial loss: 0.307668\n",
      "epoch 111; iter: 0; batch classifier loss: 0.319184; batch adversarial loss: 0.363644\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383328; batch adversarial loss: 0.371188\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362995; batch adversarial loss: 0.320962\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362276; batch adversarial loss: 0.233055\n",
      "epoch 115; iter: 0; batch classifier loss: 0.331417; batch adversarial loss: 0.219112\n",
      "epoch 116; iter: 0; batch classifier loss: 0.359083; batch adversarial loss: 0.223364\n",
      "epoch 117; iter: 0; batch classifier loss: 0.330212; batch adversarial loss: 0.273721\n",
      "epoch 118; iter: 0; batch classifier loss: 0.294782; batch adversarial loss: 0.296946\n",
      "epoch 119; iter: 0; batch classifier loss: 0.374420; batch adversarial loss: 0.324270\n",
      "epoch 120; iter: 0; batch classifier loss: 0.297187; batch adversarial loss: 0.219452\n",
      "epoch 121; iter: 0; batch classifier loss: 0.312729; batch adversarial loss: 0.284843\n",
      "epoch 122; iter: 0; batch classifier loss: 0.403940; batch adversarial loss: 0.253518\n",
      "epoch 123; iter: 0; batch classifier loss: 0.356274; batch adversarial loss: 0.344678\n",
      "epoch 124; iter: 0; batch classifier loss: 0.341386; batch adversarial loss: 0.360572\n",
      "epoch 125; iter: 0; batch classifier loss: 0.413517; batch adversarial loss: 0.369389\n",
      "epoch 126; iter: 0; batch classifier loss: 0.366913; batch adversarial loss: 0.378352\n",
      "epoch 127; iter: 0; batch classifier loss: 0.456805; batch adversarial loss: 0.289153\n",
      "epoch 128; iter: 0; batch classifier loss: 0.322130; batch adversarial loss: 0.220887\n",
      "epoch 129; iter: 0; batch classifier loss: 0.298818; batch adversarial loss: 0.338446\n",
      "epoch 130; iter: 0; batch classifier loss: 0.372461; batch adversarial loss: 0.168045\n",
      "epoch 131; iter: 0; batch classifier loss: 0.331900; batch adversarial loss: 0.324479\n",
      "epoch 132; iter: 0; batch classifier loss: 0.304507; batch adversarial loss: 0.345594\n",
      "epoch 133; iter: 0; batch classifier loss: 0.331323; batch adversarial loss: 0.317705\n",
      "epoch 134; iter: 0; batch classifier loss: 0.288924; batch adversarial loss: 0.222030\n",
      "epoch 135; iter: 0; batch classifier loss: 0.308628; batch adversarial loss: 0.357134\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346217; batch adversarial loss: 0.270731\n",
      "epoch 137; iter: 0; batch classifier loss: 0.385183; batch adversarial loss: 0.306277\n",
      "epoch 138; iter: 0; batch classifier loss: 0.317770; batch adversarial loss: 0.264715\n",
      "epoch 139; iter: 0; batch classifier loss: 0.365536; batch adversarial loss: 0.272177\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378023; batch adversarial loss: 0.294605\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351934; batch adversarial loss: 0.299445\n",
      "epoch 142; iter: 0; batch classifier loss: 0.311228; batch adversarial loss: 0.190789\n",
      "epoch 143; iter: 0; batch classifier loss: 0.295638; batch adversarial loss: 0.300417\n",
      "epoch 144; iter: 0; batch classifier loss: 0.340969; batch adversarial loss: 0.254886\n",
      "epoch 145; iter: 0; batch classifier loss: 0.383621; batch adversarial loss: 0.344206\n",
      "epoch 146; iter: 0; batch classifier loss: 0.386829; batch adversarial loss: 0.227648\n",
      "epoch 147; iter: 0; batch classifier loss: 0.293634; batch adversarial loss: 0.166822\n",
      "epoch 148; iter: 0; batch classifier loss: 0.326149; batch adversarial loss: 0.347667\n",
      "epoch 149; iter: 0; batch classifier loss: 0.365977; batch adversarial loss: 0.244155\n",
      "epoch 150; iter: 0; batch classifier loss: 0.358469; batch adversarial loss: 0.323499\n",
      "epoch 151; iter: 0; batch classifier loss: 0.380909; batch adversarial loss: 0.275485\n",
      "epoch 152; iter: 0; batch classifier loss: 0.333734; batch adversarial loss: 0.293711\n",
      "epoch 153; iter: 0; batch classifier loss: 0.389508; batch adversarial loss: 0.321913\n",
      "epoch 154; iter: 0; batch classifier loss: 0.342403; batch adversarial loss: 0.329308\n",
      "epoch 155; iter: 0; batch classifier loss: 0.326141; batch adversarial loss: 0.167335\n",
      "epoch 156; iter: 0; batch classifier loss: 0.370830; batch adversarial loss: 0.278209\n",
      "epoch 157; iter: 0; batch classifier loss: 0.318816; batch adversarial loss: 0.331235\n",
      "epoch 158; iter: 0; batch classifier loss: 0.292063; batch adversarial loss: 0.339314\n",
      "epoch 159; iter: 0; batch classifier loss: 0.293502; batch adversarial loss: 0.314990\n",
      "epoch 160; iter: 0; batch classifier loss: 0.311034; batch adversarial loss: 0.290909\n",
      "epoch 161; iter: 0; batch classifier loss: 0.375623; batch adversarial loss: 0.219347\n",
      "epoch 162; iter: 0; batch classifier loss: 0.263338; batch adversarial loss: 0.208472\n",
      "epoch 163; iter: 0; batch classifier loss: 0.248540; batch adversarial loss: 0.306330\n",
      "epoch 164; iter: 0; batch classifier loss: 0.352995; batch adversarial loss: 0.313765\n",
      "epoch 165; iter: 0; batch classifier loss: 0.380332; batch adversarial loss: 0.220268\n",
      "epoch 166; iter: 0; batch classifier loss: 0.359960; batch adversarial loss: 0.378921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.373933; batch adversarial loss: 0.398862\n",
      "epoch 168; iter: 0; batch classifier loss: 0.340058; batch adversarial loss: 0.455573\n",
      "epoch 169; iter: 0; batch classifier loss: 0.288846; batch adversarial loss: 0.344594\n",
      "epoch 170; iter: 0; batch classifier loss: 0.291760; batch adversarial loss: 0.340480\n",
      "epoch 171; iter: 0; batch classifier loss: 0.387546; batch adversarial loss: 0.257706\n",
      "epoch 172; iter: 0; batch classifier loss: 0.288928; batch adversarial loss: 0.290343\n",
      "epoch 173; iter: 0; batch classifier loss: 0.346406; batch adversarial loss: 0.331081\n",
      "epoch 174; iter: 0; batch classifier loss: 0.374736; batch adversarial loss: 0.432780\n",
      "epoch 175; iter: 0; batch classifier loss: 0.320382; batch adversarial loss: 0.424674\n",
      "epoch 176; iter: 0; batch classifier loss: 0.348600; batch adversarial loss: 0.316630\n",
      "epoch 177; iter: 0; batch classifier loss: 0.291163; batch adversarial loss: 0.223935\n",
      "epoch 178; iter: 0; batch classifier loss: 0.328223; batch adversarial loss: 0.342680\n",
      "epoch 179; iter: 0; batch classifier loss: 0.282836; batch adversarial loss: 0.270119\n",
      "epoch 180; iter: 0; batch classifier loss: 0.295321; batch adversarial loss: 0.399621\n",
      "epoch 181; iter: 0; batch classifier loss: 0.265277; batch adversarial loss: 0.292475\n",
      "epoch 182; iter: 0; batch classifier loss: 0.359357; batch adversarial loss: 0.351120\n",
      "epoch 183; iter: 0; batch classifier loss: 0.253497; batch adversarial loss: 0.356089\n",
      "epoch 184; iter: 0; batch classifier loss: 0.385167; batch adversarial loss: 0.291667\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377752; batch adversarial loss: 0.363240\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315660; batch adversarial loss: 0.314891\n",
      "epoch 187; iter: 0; batch classifier loss: 0.335327; batch adversarial loss: 0.379435\n",
      "epoch 188; iter: 0; batch classifier loss: 0.277551; batch adversarial loss: 0.237352\n",
      "epoch 189; iter: 0; batch classifier loss: 0.337355; batch adversarial loss: 0.366219\n",
      "epoch 190; iter: 0; batch classifier loss: 0.246046; batch adversarial loss: 0.361875\n",
      "epoch 191; iter: 0; batch classifier loss: 0.317780; batch adversarial loss: 0.295634\n",
      "epoch 192; iter: 0; batch classifier loss: 0.297035; batch adversarial loss: 0.314199\n",
      "epoch 193; iter: 0; batch classifier loss: 0.255884; batch adversarial loss: 0.306543\n",
      "epoch 194; iter: 0; batch classifier loss: 0.369839; batch adversarial loss: 0.390849\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309896; batch adversarial loss: 0.222563\n",
      "epoch 196; iter: 0; batch classifier loss: 0.327597; batch adversarial loss: 0.288727\n",
      "epoch 197; iter: 0; batch classifier loss: 0.325375; batch adversarial loss: 0.240117\n",
      "epoch 198; iter: 0; batch classifier loss: 0.341954; batch adversarial loss: 0.366513\n",
      "epoch 199; iter: 0; batch classifier loss: 0.295083; batch adversarial loss: 0.419771\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697777; batch adversarial loss: 0.845058\n",
      "epoch 1; iter: 0; batch classifier loss: 1.106877; batch adversarial loss: 0.919286\n",
      "epoch 2; iter: 0; batch classifier loss: 1.109872; batch adversarial loss: 0.802712\n",
      "epoch 3; iter: 0; batch classifier loss: 0.842588; batch adversarial loss: 0.816958\n",
      "epoch 4; iter: 0; batch classifier loss: 0.763849; batch adversarial loss: 0.727498\n",
      "epoch 5; iter: 0; batch classifier loss: 0.666024; batch adversarial loss: 0.675422\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567199; batch adversarial loss: 0.642648\n",
      "epoch 7; iter: 0; batch classifier loss: 0.554429; batch adversarial loss: 0.614979\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554976; batch adversarial loss: 0.601704\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533822; batch adversarial loss: 0.574500\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511069; batch adversarial loss: 0.584420\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549058; batch adversarial loss: 0.545699\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513316; batch adversarial loss: 0.537907\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521922; batch adversarial loss: 0.533769\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481784; batch adversarial loss: 0.499415\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489126; batch adversarial loss: 0.477854\n",
      "epoch 16; iter: 0; batch classifier loss: 0.610672; batch adversarial loss: 0.451546\n",
      "epoch 17; iter: 0; batch classifier loss: 0.476319; batch adversarial loss: 0.464364\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513325; batch adversarial loss: 0.460025\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518661; batch adversarial loss: 0.457517\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475940; batch adversarial loss: 0.433900\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525419; batch adversarial loss: 0.444411\n",
      "epoch 22; iter: 0; batch classifier loss: 0.532073; batch adversarial loss: 0.457287\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490160; batch adversarial loss: 0.503257\n",
      "epoch 24; iter: 0; batch classifier loss: 0.493398; batch adversarial loss: 0.364965\n",
      "epoch 25; iter: 0; batch classifier loss: 0.524529; batch adversarial loss: 0.422099\n",
      "epoch 26; iter: 0; batch classifier loss: 0.611850; batch adversarial loss: 0.483521\n",
      "epoch 27; iter: 0; batch classifier loss: 0.630944; batch adversarial loss: 0.499690\n",
      "epoch 28; iter: 0; batch classifier loss: 0.572035; batch adversarial loss: 0.409197\n",
      "epoch 29; iter: 0; batch classifier loss: 0.516578; batch adversarial loss: 0.465404\n",
      "epoch 30; iter: 0; batch classifier loss: 0.505009; batch adversarial loss: 0.380620\n",
      "epoch 31; iter: 0; batch classifier loss: 0.542058; batch adversarial loss: 0.402672\n",
      "epoch 32; iter: 0; batch classifier loss: 0.573720; batch adversarial loss: 0.431276\n",
      "epoch 33; iter: 0; batch classifier loss: 0.544718; batch adversarial loss: 0.393057\n",
      "epoch 34; iter: 0; batch classifier loss: 0.539863; batch adversarial loss: 0.337573\n",
      "epoch 35; iter: 0; batch classifier loss: 0.601578; batch adversarial loss: 0.440005\n",
      "epoch 36; iter: 0; batch classifier loss: 0.499053; batch adversarial loss: 0.382018\n",
      "epoch 37; iter: 0; batch classifier loss: 0.538150; batch adversarial loss: 0.414517\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434287; batch adversarial loss: 0.341331\n",
      "epoch 39; iter: 0; batch classifier loss: 0.477881; batch adversarial loss: 0.323563\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471211; batch adversarial loss: 0.390471\n",
      "epoch 41; iter: 0; batch classifier loss: 0.529801; batch adversarial loss: 0.409184\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451389; batch adversarial loss: 0.337049\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478215; batch adversarial loss: 0.352597\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410396; batch adversarial loss: 0.315579\n",
      "epoch 45; iter: 0; batch classifier loss: 0.491020; batch adversarial loss: 0.341597\n",
      "epoch 46; iter: 0; batch classifier loss: 0.503650; batch adversarial loss: 0.301212\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466534; batch adversarial loss: 0.270143\n",
      "epoch 48; iter: 0; batch classifier loss: 0.602984; batch adversarial loss: 0.384817\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487951; batch adversarial loss: 0.368331\n",
      "epoch 50; iter: 0; batch classifier loss: 0.524801; batch adversarial loss: 0.314156\n",
      "epoch 51; iter: 0; batch classifier loss: 0.563022; batch adversarial loss: 0.363403\n",
      "epoch 52; iter: 0; batch classifier loss: 0.491775; batch adversarial loss: 0.282330\n",
      "epoch 53; iter: 0; batch classifier loss: 0.475822; batch adversarial loss: 0.394098\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408428; batch adversarial loss: 0.276535\n",
      "epoch 55; iter: 0; batch classifier loss: 0.397753; batch adversarial loss: 0.248184\n",
      "epoch 56; iter: 0; batch classifier loss: 0.388279; batch adversarial loss: 0.350991\n",
      "epoch 57; iter: 0; batch classifier loss: 0.410419; batch adversarial loss: 0.352560\n",
      "epoch 58; iter: 0; batch classifier loss: 0.327525; batch adversarial loss: 0.365729\n",
      "epoch 59; iter: 0; batch classifier loss: 0.424032; batch adversarial loss: 0.377840\n",
      "epoch 60; iter: 0; batch classifier loss: 0.362323; batch adversarial loss: 0.318017\n",
      "epoch 61; iter: 0; batch classifier loss: 0.392802; batch adversarial loss: 0.247781\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407127; batch adversarial loss: 0.302433\n",
      "epoch 63; iter: 0; batch classifier loss: 0.354217; batch adversarial loss: 0.404355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.341614; batch adversarial loss: 0.323045\n",
      "epoch 65; iter: 0; batch classifier loss: 0.326748; batch adversarial loss: 0.256143\n",
      "epoch 66; iter: 0; batch classifier loss: 0.278845; batch adversarial loss: 0.330255\n",
      "epoch 67; iter: 0; batch classifier loss: 0.327693; batch adversarial loss: 0.343998\n",
      "epoch 68; iter: 0; batch classifier loss: 0.347166; batch adversarial loss: 0.342029\n",
      "epoch 69; iter: 0; batch classifier loss: 0.383430; batch adversarial loss: 0.279837\n",
      "epoch 70; iter: 0; batch classifier loss: 0.355892; batch adversarial loss: 0.343763\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373849; batch adversarial loss: 0.279441\n",
      "epoch 72; iter: 0; batch classifier loss: 0.380156; batch adversarial loss: 0.287282\n",
      "epoch 73; iter: 0; batch classifier loss: 0.290612; batch adversarial loss: 0.288264\n",
      "epoch 74; iter: 0; batch classifier loss: 0.366633; batch adversarial loss: 0.365708\n",
      "epoch 75; iter: 0; batch classifier loss: 0.291365; batch adversarial loss: 0.307385\n",
      "epoch 76; iter: 0; batch classifier loss: 0.288467; batch adversarial loss: 0.314572\n",
      "epoch 77; iter: 0; batch classifier loss: 0.355673; batch adversarial loss: 0.334279\n",
      "epoch 78; iter: 0; batch classifier loss: 0.290686; batch adversarial loss: 0.227910\n",
      "epoch 79; iter: 0; batch classifier loss: 0.299080; batch adversarial loss: 0.369132\n",
      "epoch 80; iter: 0; batch classifier loss: 0.359160; batch adversarial loss: 0.417499\n",
      "epoch 81; iter: 0; batch classifier loss: 0.326853; batch adversarial loss: 0.279678\n",
      "epoch 82; iter: 0; batch classifier loss: 0.409525; batch adversarial loss: 0.271535\n",
      "epoch 83; iter: 0; batch classifier loss: 0.273054; batch adversarial loss: 0.276910\n",
      "epoch 84; iter: 0; batch classifier loss: 0.355578; batch adversarial loss: 0.270372\n",
      "epoch 85; iter: 0; batch classifier loss: 0.360814; batch adversarial loss: 0.398038\n",
      "epoch 86; iter: 0; batch classifier loss: 0.296499; batch adversarial loss: 0.295401\n",
      "epoch 87; iter: 0; batch classifier loss: 0.321866; batch adversarial loss: 0.313745\n",
      "epoch 88; iter: 0; batch classifier loss: 0.402452; batch adversarial loss: 0.261805\n",
      "epoch 89; iter: 0; batch classifier loss: 0.348061; batch adversarial loss: 0.269730\n",
      "epoch 90; iter: 0; batch classifier loss: 0.371218; batch adversarial loss: 0.258088\n",
      "epoch 91; iter: 0; batch classifier loss: 0.337565; batch adversarial loss: 0.358737\n",
      "epoch 92; iter: 0; batch classifier loss: 0.321377; batch adversarial loss: 0.241935\n",
      "epoch 93; iter: 0; batch classifier loss: 0.268302; batch adversarial loss: 0.289897\n",
      "epoch 94; iter: 0; batch classifier loss: 0.311736; batch adversarial loss: 0.285160\n",
      "epoch 95; iter: 0; batch classifier loss: 0.305725; batch adversarial loss: 0.295217\n",
      "epoch 96; iter: 0; batch classifier loss: 0.301784; batch adversarial loss: 0.308961\n",
      "epoch 97; iter: 0; batch classifier loss: 0.282013; batch adversarial loss: 0.291253\n",
      "epoch 98; iter: 0; batch classifier loss: 0.302838; batch adversarial loss: 0.254950\n",
      "epoch 99; iter: 0; batch classifier loss: 0.329567; batch adversarial loss: 0.227775\n",
      "epoch 100; iter: 0; batch classifier loss: 0.315418; batch adversarial loss: 0.298911\n",
      "epoch 101; iter: 0; batch classifier loss: 0.342570; batch adversarial loss: 0.259358\n",
      "epoch 102; iter: 0; batch classifier loss: 0.310161; batch adversarial loss: 0.273267\n",
      "epoch 103; iter: 0; batch classifier loss: 0.334374; batch adversarial loss: 0.363495\n",
      "epoch 104; iter: 0; batch classifier loss: 0.370238; batch adversarial loss: 0.289693\n",
      "epoch 105; iter: 0; batch classifier loss: 0.214676; batch adversarial loss: 0.338327\n",
      "epoch 106; iter: 0; batch classifier loss: 0.263309; batch adversarial loss: 0.270504\n",
      "epoch 107; iter: 0; batch classifier loss: 0.263312; batch adversarial loss: 0.281826\n",
      "epoch 108; iter: 0; batch classifier loss: 0.261910; batch adversarial loss: 0.315245\n",
      "epoch 109; iter: 0; batch classifier loss: 0.306876; batch adversarial loss: 0.289358\n",
      "epoch 110; iter: 0; batch classifier loss: 0.255961; batch adversarial loss: 0.307511\n",
      "epoch 111; iter: 0; batch classifier loss: 0.238547; batch adversarial loss: 0.363581\n",
      "epoch 112; iter: 0; batch classifier loss: 0.372770; batch adversarial loss: 0.372080\n",
      "epoch 113; iter: 0; batch classifier loss: 0.308775; batch adversarial loss: 0.321105\n",
      "epoch 114; iter: 0; batch classifier loss: 0.238727; batch adversarial loss: 0.232723\n",
      "epoch 115; iter: 0; batch classifier loss: 0.237465; batch adversarial loss: 0.219241\n",
      "epoch 116; iter: 0; batch classifier loss: 0.323692; batch adversarial loss: 0.225203\n",
      "epoch 117; iter: 0; batch classifier loss: 0.249125; batch adversarial loss: 0.273886\n",
      "epoch 118; iter: 0; batch classifier loss: 0.218766; batch adversarial loss: 0.295013\n",
      "epoch 119; iter: 0; batch classifier loss: 0.244076; batch adversarial loss: 0.325934\n",
      "epoch 120; iter: 0; batch classifier loss: 0.245740; batch adversarial loss: 0.219856\n",
      "epoch 121; iter: 0; batch classifier loss: 0.253091; batch adversarial loss: 0.285830\n",
      "epoch 122; iter: 0; batch classifier loss: 0.321530; batch adversarial loss: 0.254348\n",
      "epoch 123; iter: 0; batch classifier loss: 0.265494; batch adversarial loss: 0.348248\n",
      "epoch 124; iter: 0; batch classifier loss: 0.273192; batch adversarial loss: 0.359708\n",
      "epoch 125; iter: 0; batch classifier loss: 0.316266; batch adversarial loss: 0.371373\n",
      "epoch 126; iter: 0; batch classifier loss: 0.336806; batch adversarial loss: 0.380756\n",
      "epoch 127; iter: 0; batch classifier loss: 0.242608; batch adversarial loss: 0.288785\n",
      "epoch 128; iter: 0; batch classifier loss: 0.267075; batch adversarial loss: 0.221413\n",
      "epoch 129; iter: 0; batch classifier loss: 0.245647; batch adversarial loss: 0.340107\n",
      "epoch 130; iter: 0; batch classifier loss: 0.247031; batch adversarial loss: 0.167906\n",
      "epoch 131; iter: 0; batch classifier loss: 0.254567; batch adversarial loss: 0.323988\n",
      "epoch 132; iter: 0; batch classifier loss: 0.233718; batch adversarial loss: 0.348193\n",
      "epoch 133; iter: 0; batch classifier loss: 0.278931; batch adversarial loss: 0.316332\n",
      "epoch 134; iter: 0; batch classifier loss: 0.227719; batch adversarial loss: 0.223873\n",
      "epoch 135; iter: 0; batch classifier loss: 0.257088; batch adversarial loss: 0.357800\n",
      "epoch 136; iter: 0; batch classifier loss: 0.251782; batch adversarial loss: 0.271145\n",
      "epoch 137; iter: 0; batch classifier loss: 0.251018; batch adversarial loss: 0.306616\n",
      "epoch 138; iter: 0; batch classifier loss: 0.303760; batch adversarial loss: 0.261888\n",
      "epoch 139; iter: 0; batch classifier loss: 0.305437; batch adversarial loss: 0.273940\n",
      "epoch 140; iter: 0; batch classifier loss: 0.296902; batch adversarial loss: 0.294777\n",
      "epoch 141; iter: 0; batch classifier loss: 0.308971; batch adversarial loss: 0.298220\n",
      "epoch 142; iter: 0; batch classifier loss: 0.293105; batch adversarial loss: 0.190945\n",
      "epoch 143; iter: 0; batch classifier loss: 0.235759; batch adversarial loss: 0.298881\n",
      "epoch 144; iter: 0; batch classifier loss: 0.231792; batch adversarial loss: 0.255292\n",
      "epoch 145; iter: 0; batch classifier loss: 0.265916; batch adversarial loss: 0.344442\n",
      "epoch 146; iter: 0; batch classifier loss: 0.265714; batch adversarial loss: 0.226111\n",
      "epoch 147; iter: 0; batch classifier loss: 0.254801; batch adversarial loss: 0.167791\n",
      "epoch 148; iter: 0; batch classifier loss: 0.235430; batch adversarial loss: 0.347292\n",
      "epoch 149; iter: 0; batch classifier loss: 0.253773; batch adversarial loss: 0.243815\n",
      "epoch 150; iter: 0; batch classifier loss: 0.254698; batch adversarial loss: 0.324713\n",
      "epoch 151; iter: 0; batch classifier loss: 0.278212; batch adversarial loss: 0.275242\n",
      "epoch 152; iter: 0; batch classifier loss: 0.301289; batch adversarial loss: 0.294905\n",
      "epoch 153; iter: 0; batch classifier loss: 0.306100; batch adversarial loss: 0.323073\n",
      "epoch 154; iter: 0; batch classifier loss: 0.234350; batch adversarial loss: 0.328572\n",
      "epoch 155; iter: 0; batch classifier loss: 0.257554; batch adversarial loss: 0.167961\n",
      "epoch 156; iter: 0; batch classifier loss: 0.255142; batch adversarial loss: 0.276955\n",
      "epoch 157; iter: 0; batch classifier loss: 0.256005; batch adversarial loss: 0.331105\n",
      "epoch 158; iter: 0; batch classifier loss: 0.288468; batch adversarial loss: 0.340996\n",
      "epoch 159; iter: 0; batch classifier loss: 0.246412; batch adversarial loss: 0.316055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.240595; batch adversarial loss: 0.291998\n",
      "epoch 161; iter: 0; batch classifier loss: 0.280705; batch adversarial loss: 0.220040\n",
      "epoch 162; iter: 0; batch classifier loss: 0.216592; batch adversarial loss: 0.208134\n",
      "epoch 163; iter: 0; batch classifier loss: 0.248102; batch adversarial loss: 0.307638\n",
      "epoch 164; iter: 0; batch classifier loss: 0.202577; batch adversarial loss: 0.312650\n",
      "epoch 165; iter: 0; batch classifier loss: 0.293595; batch adversarial loss: 0.221609\n",
      "epoch 166; iter: 0; batch classifier loss: 0.299229; batch adversarial loss: 0.380363\n",
      "epoch 167; iter: 0; batch classifier loss: 0.257107; batch adversarial loss: 0.398608\n",
      "epoch 168; iter: 0; batch classifier loss: 0.228617; batch adversarial loss: 0.454627\n",
      "epoch 169; iter: 0; batch classifier loss: 0.211319; batch adversarial loss: 0.344164\n",
      "epoch 170; iter: 0; batch classifier loss: 0.257452; batch adversarial loss: 0.341594\n",
      "epoch 171; iter: 0; batch classifier loss: 0.256545; batch adversarial loss: 0.258278\n",
      "epoch 172; iter: 0; batch classifier loss: 0.271654; batch adversarial loss: 0.291946\n",
      "epoch 173; iter: 0; batch classifier loss: 0.243530; batch adversarial loss: 0.330910\n",
      "epoch 174; iter: 0; batch classifier loss: 0.212349; batch adversarial loss: 0.432631\n",
      "epoch 175; iter: 0; batch classifier loss: 0.217860; batch adversarial loss: 0.423249\n",
      "epoch 176; iter: 0; batch classifier loss: 0.228900; batch adversarial loss: 0.314676\n",
      "epoch 177; iter: 0; batch classifier loss: 0.322509; batch adversarial loss: 0.224435\n",
      "epoch 178; iter: 0; batch classifier loss: 0.295556; batch adversarial loss: 0.343999\n",
      "epoch 179; iter: 0; batch classifier loss: 0.243961; batch adversarial loss: 0.272058\n",
      "epoch 180; iter: 0; batch classifier loss: 0.235138; batch adversarial loss: 0.399395\n",
      "epoch 181; iter: 0; batch classifier loss: 0.218377; batch adversarial loss: 0.293438\n",
      "epoch 182; iter: 0; batch classifier loss: 0.209051; batch adversarial loss: 0.350104\n",
      "epoch 183; iter: 0; batch classifier loss: 0.195382; batch adversarial loss: 0.357957\n",
      "epoch 184; iter: 0; batch classifier loss: 0.246842; batch adversarial loss: 0.291509\n",
      "epoch 185; iter: 0; batch classifier loss: 0.277315; batch adversarial loss: 0.363253\n",
      "epoch 186; iter: 0; batch classifier loss: 0.203354; batch adversarial loss: 0.312847\n",
      "epoch 187; iter: 0; batch classifier loss: 0.265779; batch adversarial loss: 0.381271\n",
      "epoch 188; iter: 0; batch classifier loss: 0.244107; batch adversarial loss: 0.237346\n",
      "epoch 189; iter: 0; batch classifier loss: 0.239986; batch adversarial loss: 0.365566\n",
      "epoch 190; iter: 0; batch classifier loss: 0.156359; batch adversarial loss: 0.362830\n",
      "epoch 191; iter: 0; batch classifier loss: 0.229460; batch adversarial loss: 0.294106\n",
      "epoch 192; iter: 0; batch classifier loss: 0.229994; batch adversarial loss: 0.313539\n",
      "epoch 193; iter: 0; batch classifier loss: 0.202356; batch adversarial loss: 0.307608\n",
      "epoch 194; iter: 0; batch classifier loss: 0.296554; batch adversarial loss: 0.389750\n",
      "epoch 195; iter: 0; batch classifier loss: 0.306848; batch adversarial loss: 0.222834\n",
      "epoch 196; iter: 0; batch classifier loss: 0.259241; batch adversarial loss: 0.289961\n",
      "epoch 197; iter: 0; batch classifier loss: 0.235581; batch adversarial loss: 0.239797\n",
      "epoch 198; iter: 0; batch classifier loss: 0.222141; batch adversarial loss: 0.365254\n",
      "epoch 199; iter: 0; batch classifier loss: 0.256266; batch adversarial loss: 0.420090\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.055777; batch adversarial loss: 0.915775\n",
      "epoch 2; iter: 0; batch classifier loss: 0.977490; batch adversarial loss: 0.790802\n",
      "epoch 3; iter: 0; batch classifier loss: 0.764438; batch adversarial loss: 0.804188\n",
      "epoch 4; iter: 0; batch classifier loss: 0.686780; batch adversarial loss: 0.705328\n",
      "epoch 5; iter: 0; batch classifier loss: 0.602115; batch adversarial loss: 0.648261\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571943; batch adversarial loss: 0.636119\n",
      "epoch 7; iter: 0; batch classifier loss: 0.591064; batch adversarial loss: 0.610694\n",
      "epoch 8; iter: 0; batch classifier loss: 0.558035; batch adversarial loss: 0.601371\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538121; batch adversarial loss: 0.575595\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560513; batch adversarial loss: 0.581988\n",
      "epoch 11; iter: 0; batch classifier loss: 0.581649; batch adversarial loss: 0.542516\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547535; batch adversarial loss: 0.535385\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548471; batch adversarial loss: 0.530872\n",
      "epoch 14; iter: 0; batch classifier loss: 0.531191; batch adversarial loss: 0.492059\n",
      "epoch 15; iter: 0; batch classifier loss: 0.551222; batch adversarial loss: 0.468812\n",
      "epoch 16; iter: 0; batch classifier loss: 0.606885; batch adversarial loss: 0.450801\n",
      "epoch 17; iter: 0; batch classifier loss: 0.511017; batch adversarial loss: 0.454837\n",
      "epoch 18; iter: 0; batch classifier loss: 0.564756; batch adversarial loss: 0.444262\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527840; batch adversarial loss: 0.444558\n",
      "epoch 20; iter: 0; batch classifier loss: 0.508159; batch adversarial loss: 0.416677\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504009; batch adversarial loss: 0.424909\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519226; batch adversarial loss: 0.438569\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462581; batch adversarial loss: 0.475862\n",
      "epoch 24; iter: 0; batch classifier loss: 0.539981; batch adversarial loss: 0.351142\n",
      "epoch 25; iter: 0; batch classifier loss: 0.504672; batch adversarial loss: 0.411033\n",
      "epoch 26; iter: 0; batch classifier loss: 0.547139; batch adversarial loss: 0.458482\n",
      "epoch 27; iter: 0; batch classifier loss: 0.608600; batch adversarial loss: 0.488351\n",
      "epoch 28; iter: 0; batch classifier loss: 0.542086; batch adversarial loss: 0.395508\n",
      "epoch 29; iter: 0; batch classifier loss: 0.469366; batch adversarial loss: 0.454831\n",
      "epoch 30; iter: 0; batch classifier loss: 0.509480; batch adversarial loss: 0.375648\n",
      "epoch 31; iter: 0; batch classifier loss: 0.534196; batch adversarial loss: 0.395245\n",
      "epoch 32; iter: 0; batch classifier loss: 0.565672; batch adversarial loss: 0.429123\n",
      "epoch 33; iter: 0; batch classifier loss: 0.544515; batch adversarial loss: 0.390048\n",
      "epoch 34; iter: 0; batch classifier loss: 0.530591; batch adversarial loss: 0.334640\n",
      "epoch 35; iter: 0; batch classifier loss: 0.613414; batch adversarial loss: 0.446030\n",
      "epoch 36; iter: 0; batch classifier loss: 0.532547; batch adversarial loss: 0.387378\n",
      "epoch 37; iter: 0; batch classifier loss: 0.575274; batch adversarial loss: 0.422450\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447432; batch adversarial loss: 0.348785\n",
      "epoch 39; iter: 0; batch classifier loss: 0.555645; batch adversarial loss: 0.322608\n",
      "epoch 40; iter: 0; batch classifier loss: 0.513968; batch adversarial loss: 0.395082\n",
      "epoch 41; iter: 0; batch classifier loss: 0.596916; batch adversarial loss: 0.420393\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498031; batch adversarial loss: 0.343205\n",
      "epoch 43; iter: 0; batch classifier loss: 0.540564; batch adversarial loss: 0.360238\n",
      "epoch 44; iter: 0; batch classifier loss: 0.472866; batch adversarial loss: 0.319709\n",
      "epoch 45; iter: 0; batch classifier loss: 0.532172; batch adversarial loss: 0.348213\n",
      "epoch 46; iter: 0; batch classifier loss: 0.551324; batch adversarial loss: 0.306247\n",
      "epoch 47; iter: 0; batch classifier loss: 0.502062; batch adversarial loss: 0.272248\n",
      "epoch 48; iter: 0; batch classifier loss: 0.607546; batch adversarial loss: 0.394677\n",
      "epoch 49; iter: 0; batch classifier loss: 0.533181; batch adversarial loss: 0.378079\n",
      "epoch 50; iter: 0; batch classifier loss: 0.592440; batch adversarial loss: 0.320410\n",
      "epoch 51; iter: 0; batch classifier loss: 0.606886; batch adversarial loss: 0.373150\n",
      "epoch 52; iter: 0; batch classifier loss: 0.510758; batch adversarial loss: 0.285338\n",
      "epoch 53; iter: 0; batch classifier loss: 0.555161; batch adversarial loss: 0.410076\n",
      "epoch 54; iter: 0; batch classifier loss: 0.548641; batch adversarial loss: 0.281784\n",
      "epoch 55; iter: 0; batch classifier loss: 0.519369; batch adversarial loss: 0.253069\n",
      "epoch 56; iter: 0; batch classifier loss: 0.606534; batch adversarial loss: 0.358632\n",
      "epoch 57; iter: 0; batch classifier loss: 0.686435; batch adversarial loss: 0.356752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.436692; batch adversarial loss: 0.366725\n",
      "epoch 59; iter: 0; batch classifier loss: 0.439006; batch adversarial loss: 0.377734\n",
      "epoch 60; iter: 0; batch classifier loss: 0.477245; batch adversarial loss: 0.321436\n",
      "epoch 61; iter: 0; batch classifier loss: 0.445634; batch adversarial loss: 0.250822\n",
      "epoch 62; iter: 0; batch classifier loss: 0.486712; batch adversarial loss: 0.304812\n",
      "epoch 63; iter: 0; batch classifier loss: 0.448320; batch adversarial loss: 0.404098\n",
      "epoch 64; iter: 0; batch classifier loss: 0.372364; batch adversarial loss: 0.321982\n",
      "epoch 65; iter: 0; batch classifier loss: 0.430042; batch adversarial loss: 0.258691\n",
      "epoch 66; iter: 0; batch classifier loss: 0.315451; batch adversarial loss: 0.330849\n",
      "epoch 67; iter: 0; batch classifier loss: 0.399923; batch adversarial loss: 0.344582\n",
      "epoch 68; iter: 0; batch classifier loss: 0.397938; batch adversarial loss: 0.343702\n",
      "epoch 69; iter: 0; batch classifier loss: 0.406240; batch adversarial loss: 0.280643\n",
      "epoch 70; iter: 0; batch classifier loss: 0.428493; batch adversarial loss: 0.343619\n",
      "epoch 71; iter: 0; batch classifier loss: 0.465590; batch adversarial loss: 0.280281\n",
      "epoch 72; iter: 0; batch classifier loss: 0.421679; batch adversarial loss: 0.287042\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374457; batch adversarial loss: 0.287945\n",
      "epoch 74; iter: 0; batch classifier loss: 0.435078; batch adversarial loss: 0.364836\n",
      "epoch 75; iter: 0; batch classifier loss: 0.340076; batch adversarial loss: 0.308312\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370803; batch adversarial loss: 0.314779\n",
      "epoch 77; iter: 0; batch classifier loss: 0.420401; batch adversarial loss: 0.336562\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352334; batch adversarial loss: 0.228177\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367025; batch adversarial loss: 0.367553\n",
      "epoch 80; iter: 0; batch classifier loss: 0.454927; batch adversarial loss: 0.419026\n",
      "epoch 81; iter: 0; batch classifier loss: 0.388471; batch adversarial loss: 0.277719\n",
      "epoch 82; iter: 0; batch classifier loss: 0.468203; batch adversarial loss: 0.271205\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377710; batch adversarial loss: 0.277045\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446475; batch adversarial loss: 0.268745\n",
      "epoch 85; iter: 0; batch classifier loss: 0.376328; batch adversarial loss: 0.396518\n",
      "epoch 86; iter: 0; batch classifier loss: 0.414959; batch adversarial loss: 0.297076\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378843; batch adversarial loss: 0.312694\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427051; batch adversarial loss: 0.258807\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390165; batch adversarial loss: 0.269447\n",
      "epoch 90; iter: 0; batch classifier loss: 0.435261; batch adversarial loss: 0.260715\n",
      "epoch 91; iter: 0; batch classifier loss: 0.385821; batch adversarial loss: 0.360590\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374268; batch adversarial loss: 0.241800\n",
      "epoch 93; iter: 0; batch classifier loss: 0.340095; batch adversarial loss: 0.288074\n",
      "epoch 94; iter: 0; batch classifier loss: 0.358446; batch adversarial loss: 0.286006\n",
      "epoch 95; iter: 0; batch classifier loss: 0.412776; batch adversarial loss: 0.293657\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370358; batch adversarial loss: 0.309652\n",
      "epoch 97; iter: 0; batch classifier loss: 0.355001; batch adversarial loss: 0.289686\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373620; batch adversarial loss: 0.253260\n",
      "epoch 99; iter: 0; batch classifier loss: 0.347120; batch adversarial loss: 0.227283\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697777; batch adversarial loss: 0.845058\n",
      "epoch 1; iter: 0; batch classifier loss: 1.083601; batch adversarial loss: 0.917572\n",
      "epoch 2; iter: 0; batch classifier loss: 1.085881; batch adversarial loss: 0.801669\n",
      "epoch 3; iter: 0; batch classifier loss: 0.823981; batch adversarial loss: 0.814800\n",
      "epoch 4; iter: 0; batch classifier loss: 0.746675; batch adversarial loss: 0.725981\n",
      "epoch 5; iter: 0; batch classifier loss: 0.643709; batch adversarial loss: 0.673076\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564727; batch adversarial loss: 0.641723\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558237; batch adversarial loss: 0.614428\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554943; batch adversarial loss: 0.601773\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530887; batch adversarial loss: 0.575351\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513124; batch adversarial loss: 0.584639\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549330; batch adversarial loss: 0.546219\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514369; batch adversarial loss: 0.538367\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520580; batch adversarial loss: 0.534281\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483223; batch adversarial loss: 0.499177\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490159; batch adversarial loss: 0.477644\n",
      "epoch 16; iter: 0; batch classifier loss: 0.613637; batch adversarial loss: 0.450585\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477832; batch adversarial loss: 0.463111\n",
      "epoch 18; iter: 0; batch classifier loss: 0.520756; batch adversarial loss: 0.459421\n",
      "epoch 19; iter: 0; batch classifier loss: 0.512780; batch adversarial loss: 0.454229\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473943; batch adversarial loss: 0.430154\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521725; batch adversarial loss: 0.440930\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522274; batch adversarial loss: 0.453980\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474117; batch adversarial loss: 0.499895\n",
      "epoch 24; iter: 0; batch classifier loss: 0.486916; batch adversarial loss: 0.362261\n",
      "epoch 25; iter: 0; batch classifier loss: 0.514613; batch adversarial loss: 0.418133\n",
      "epoch 26; iter: 0; batch classifier loss: 0.581414; batch adversarial loss: 0.476654\n",
      "epoch 27; iter: 0; batch classifier loss: 0.623301; batch adversarial loss: 0.498220\n",
      "epoch 28; iter: 0; batch classifier loss: 0.556977; batch adversarial loss: 0.407751\n",
      "epoch 29; iter: 0; batch classifier loss: 0.506112; batch adversarial loss: 0.463981\n",
      "epoch 30; iter: 0; batch classifier loss: 0.503998; batch adversarial loss: 0.380227\n",
      "epoch 31; iter: 0; batch classifier loss: 0.530771; batch adversarial loss: 0.402218\n",
      "epoch 32; iter: 0; batch classifier loss: 0.564556; batch adversarial loss: 0.431498\n",
      "epoch 33; iter: 0; batch classifier loss: 0.534941; batch adversarial loss: 0.392522\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544587; batch adversarial loss: 0.337607\n",
      "epoch 35; iter: 0; batch classifier loss: 0.594085; batch adversarial loss: 0.441009\n",
      "epoch 36; iter: 0; batch classifier loss: 0.485412; batch adversarial loss: 0.381890\n",
      "epoch 37; iter: 0; batch classifier loss: 0.535773; batch adversarial loss: 0.415808\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440941; batch adversarial loss: 0.342964\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479092; batch adversarial loss: 0.324270\n",
      "epoch 40; iter: 0; batch classifier loss: 0.480194; batch adversarial loss: 0.391920\n",
      "epoch 41; iter: 0; batch classifier loss: 0.520796; batch adversarial loss: 0.410335\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459636; batch adversarial loss: 0.337934\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477357; batch adversarial loss: 0.353623\n",
      "epoch 44; iter: 0; batch classifier loss: 0.404601; batch adversarial loss: 0.316361\n",
      "epoch 45; iter: 0; batch classifier loss: 0.489379; batch adversarial loss: 0.342459\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500909; batch adversarial loss: 0.301955\n",
      "epoch 47; iter: 0; batch classifier loss: 0.473242; batch adversarial loss: 0.270484\n",
      "epoch 48; iter: 0; batch classifier loss: 0.592912; batch adversarial loss: 0.386135\n",
      "epoch 49; iter: 0; batch classifier loss: 0.484448; batch adversarial loss: 0.369536\n",
      "epoch 50; iter: 0; batch classifier loss: 0.538152; batch adversarial loss: 0.314895\n",
      "epoch 51; iter: 0; batch classifier loss: 0.554741; batch adversarial loss: 0.364671\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466017; batch adversarial loss: 0.282879\n",
      "epoch 53; iter: 0; batch classifier loss: 0.622937; batch adversarial loss: 0.396243\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416659; batch adversarial loss: 0.277167\n",
      "epoch 55; iter: 0; batch classifier loss: 0.409484; batch adversarial loss: 0.248546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.392226; batch adversarial loss: 0.351302\n",
      "epoch 57; iter: 0; batch classifier loss: 0.413993; batch adversarial loss: 0.352511\n",
      "epoch 58; iter: 0; batch classifier loss: 0.329754; batch adversarial loss: 0.365673\n",
      "epoch 59; iter: 0; batch classifier loss: 0.422804; batch adversarial loss: 0.377725\n",
      "epoch 60; iter: 0; batch classifier loss: 0.352024; batch adversarial loss: 0.318096\n",
      "epoch 61; iter: 0; batch classifier loss: 0.389383; batch adversarial loss: 0.247815\n",
      "epoch 62; iter: 0; batch classifier loss: 0.403762; batch adversarial loss: 0.302429\n",
      "epoch 63; iter: 0; batch classifier loss: 0.353947; batch adversarial loss: 0.404313\n",
      "epoch 64; iter: 0; batch classifier loss: 0.339099; batch adversarial loss: 0.323123\n",
      "epoch 65; iter: 0; batch classifier loss: 0.313225; batch adversarial loss: 0.256166\n",
      "epoch 66; iter: 0; batch classifier loss: 0.275931; batch adversarial loss: 0.330392\n",
      "epoch 67; iter: 0; batch classifier loss: 0.325467; batch adversarial loss: 0.344105\n",
      "epoch 68; iter: 0; batch classifier loss: 0.349099; batch adversarial loss: 0.341761\n",
      "epoch 69; iter: 0; batch classifier loss: 0.387455; batch adversarial loss: 0.279877\n",
      "epoch 70; iter: 0; batch classifier loss: 0.344781; batch adversarial loss: 0.343834\n",
      "epoch 71; iter: 0; batch classifier loss: 0.360638; batch adversarial loss: 0.279395\n",
      "epoch 72; iter: 0; batch classifier loss: 0.379394; batch adversarial loss: 0.286951\n",
      "epoch 73; iter: 0; batch classifier loss: 0.287342; batch adversarial loss: 0.288642\n",
      "epoch 74; iter: 0; batch classifier loss: 0.380103; batch adversarial loss: 0.366594\n",
      "epoch 75; iter: 0; batch classifier loss: 0.281426; batch adversarial loss: 0.307038\n",
      "epoch 76; iter: 0; batch classifier loss: 0.290856; batch adversarial loss: 0.314843\n",
      "epoch 77; iter: 0; batch classifier loss: 0.343395; batch adversarial loss: 0.334095\n",
      "epoch 78; iter: 0; batch classifier loss: 0.296047; batch adversarial loss: 0.228023\n",
      "epoch 79; iter: 0; batch classifier loss: 0.276620; batch adversarial loss: 0.368745\n",
      "epoch 80; iter: 0; batch classifier loss: 0.355156; batch adversarial loss: 0.417265\n",
      "epoch 81; iter: 0; batch classifier loss: 0.323661; batch adversarial loss: 0.279341\n",
      "epoch 82; iter: 0; batch classifier loss: 0.384691; batch adversarial loss: 0.271116\n",
      "epoch 83; iter: 0; batch classifier loss: 0.264001; batch adversarial loss: 0.277650\n",
      "epoch 84; iter: 0; batch classifier loss: 0.361617; batch adversarial loss: 0.270279\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349577; batch adversarial loss: 0.396955\n",
      "epoch 86; iter: 0; batch classifier loss: 0.305132; batch adversarial loss: 0.295464\n",
      "epoch 87; iter: 0; batch classifier loss: 0.324755; batch adversarial loss: 0.313778\n",
      "epoch 88; iter: 0; batch classifier loss: 0.401256; batch adversarial loss: 0.261799\n",
      "epoch 89; iter: 0; batch classifier loss: 0.334158; batch adversarial loss: 0.269249\n",
      "epoch 90; iter: 0; batch classifier loss: 0.394675; batch adversarial loss: 0.257675\n",
      "epoch 91; iter: 0; batch classifier loss: 0.326799; batch adversarial loss: 0.358727\n",
      "epoch 92; iter: 0; batch classifier loss: 0.322226; batch adversarial loss: 0.241655\n",
      "epoch 93; iter: 0; batch classifier loss: 0.280808; batch adversarial loss: 0.289606\n",
      "epoch 94; iter: 0; batch classifier loss: 0.304204; batch adversarial loss: 0.284831\n",
      "epoch 95; iter: 0; batch classifier loss: 0.302948; batch adversarial loss: 0.295304\n",
      "epoch 96; iter: 0; batch classifier loss: 0.303149; batch adversarial loss: 0.308785\n",
      "epoch 97; iter: 0; batch classifier loss: 0.268677; batch adversarial loss: 0.290842\n",
      "epoch 98; iter: 0; batch classifier loss: 0.285825; batch adversarial loss: 0.254479\n",
      "epoch 99; iter: 0; batch classifier loss: 0.311664; batch adversarial loss: 0.227547\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697777; batch adversarial loss: 0.845058\n",
      "epoch 1; iter: 0; batch classifier loss: 1.085361; batch adversarial loss: 0.917699\n",
      "epoch 2; iter: 0; batch classifier loss: 1.087404; batch adversarial loss: 0.801726\n",
      "epoch 3; iter: 0; batch classifier loss: 0.825269; batch adversarial loss: 0.814982\n",
      "epoch 4; iter: 0; batch classifier loss: 0.747431; batch adversarial loss: 0.725887\n",
      "epoch 5; iter: 0; batch classifier loss: 0.644775; batch adversarial loss: 0.673209\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564543; batch adversarial loss: 0.641873\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558171; batch adversarial loss: 0.614576\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554886; batch adversarial loss: 0.601821\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531619; batch adversarial loss: 0.575457\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512367; batch adversarial loss: 0.584838\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549575; batch adversarial loss: 0.546164\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513833; batch adversarial loss: 0.538426\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521200; batch adversarial loss: 0.534170\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483195; batch adversarial loss: 0.499023\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490624; batch adversarial loss: 0.477515\n",
      "epoch 16; iter: 0; batch classifier loss: 0.610767; batch adversarial loss: 0.450922\n",
      "epoch 17; iter: 0; batch classifier loss: 0.476483; batch adversarial loss: 0.463010\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522110; batch adversarial loss: 0.459403\n",
      "epoch 19; iter: 0; batch classifier loss: 0.511324; batch adversarial loss: 0.454391\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475494; batch adversarial loss: 0.430460\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521959; batch adversarial loss: 0.441153\n",
      "epoch 22; iter: 0; batch classifier loss: 0.524561; batch adversarial loss: 0.453715\n",
      "epoch 23; iter: 0; batch classifier loss: 0.474654; batch adversarial loss: 0.500117\n",
      "epoch 24; iter: 0; batch classifier loss: 0.485901; batch adversarial loss: 0.362343\n",
      "epoch 25; iter: 0; batch classifier loss: 0.515060; batch adversarial loss: 0.418517\n",
      "epoch 26; iter: 0; batch classifier loss: 0.576465; batch adversarial loss: 0.476311\n",
      "epoch 27; iter: 0; batch classifier loss: 0.618322; batch adversarial loss: 0.498113\n",
      "epoch 28; iter: 0; batch classifier loss: 0.562009; batch adversarial loss: 0.408039\n",
      "epoch 29; iter: 0; batch classifier loss: 0.510063; batch adversarial loss: 0.464426\n",
      "epoch 30; iter: 0; batch classifier loss: 0.495195; batch adversarial loss: 0.379822\n",
      "epoch 31; iter: 0; batch classifier loss: 0.531010; batch adversarial loss: 0.402415\n",
      "epoch 32; iter: 0; batch classifier loss: 0.566616; batch adversarial loss: 0.431853\n",
      "epoch 33; iter: 0; batch classifier loss: 0.539867; batch adversarial loss: 0.392338\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544390; batch adversarial loss: 0.337877\n",
      "epoch 35; iter: 0; batch classifier loss: 0.594167; batch adversarial loss: 0.440743\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480262; batch adversarial loss: 0.381665\n",
      "epoch 37; iter: 0; batch classifier loss: 0.521324; batch adversarial loss: 0.415780\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445827; batch adversarial loss: 0.342980\n",
      "epoch 39; iter: 0; batch classifier loss: 0.475621; batch adversarial loss: 0.323937\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474050; batch adversarial loss: 0.391708\n",
      "epoch 41; iter: 0; batch classifier loss: 0.532860; batch adversarial loss: 0.410660\n",
      "epoch 42; iter: 0; batch classifier loss: 0.455602; batch adversarial loss: 0.338093\n",
      "epoch 43; iter: 0; batch classifier loss: 0.484291; batch adversarial loss: 0.354134\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410947; batch adversarial loss: 0.315995\n",
      "epoch 45; iter: 0; batch classifier loss: 0.485612; batch adversarial loss: 0.342427\n",
      "epoch 46; iter: 0; batch classifier loss: 0.503023; batch adversarial loss: 0.301912\n",
      "epoch 47; iter: 0; batch classifier loss: 0.463587; batch adversarial loss: 0.270578\n",
      "epoch 48; iter: 0; batch classifier loss: 0.589337; batch adversarial loss: 0.385808\n",
      "epoch 49; iter: 0; batch classifier loss: 0.478512; batch adversarial loss: 0.369227\n",
      "epoch 50; iter: 0; batch classifier loss: 0.537491; batch adversarial loss: 0.315048\n",
      "epoch 51; iter: 0; batch classifier loss: 0.557215; batch adversarial loss: 0.364672\n",
      "epoch 52; iter: 0; batch classifier loss: 0.466938; batch adversarial loss: 0.282857\n",
      "epoch 53; iter: 0; batch classifier loss: 0.601087; batch adversarial loss: 0.396029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54; iter: 0; batch classifier loss: 0.417637; batch adversarial loss: 0.277156\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410347; batch adversarial loss: 0.248572\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398278; batch adversarial loss: 0.351197\n",
      "epoch 57; iter: 0; batch classifier loss: 0.408030; batch adversarial loss: 0.352543\n",
      "epoch 58; iter: 0; batch classifier loss: 0.327777; batch adversarial loss: 0.365695\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414331; batch adversarial loss: 0.377551\n",
      "epoch 60; iter: 0; batch classifier loss: 0.356313; batch adversarial loss: 0.318078\n",
      "epoch 61; iter: 0; batch classifier loss: 0.382038; batch adversarial loss: 0.247800\n",
      "epoch 62; iter: 0; batch classifier loss: 0.404441; batch adversarial loss: 0.302544\n",
      "epoch 63; iter: 0; batch classifier loss: 0.349283; batch adversarial loss: 0.403987\n",
      "epoch 64; iter: 0; batch classifier loss: 0.338822; batch adversarial loss: 0.323155\n",
      "epoch 65; iter: 0; batch classifier loss: 0.312349; batch adversarial loss: 0.256244\n",
      "epoch 66; iter: 0; batch classifier loss: 0.274238; batch adversarial loss: 0.330355\n",
      "epoch 67; iter: 0; batch classifier loss: 0.311850; batch adversarial loss: 0.344049\n",
      "epoch 68; iter: 0; batch classifier loss: 0.350036; batch adversarial loss: 0.341712\n",
      "epoch 69; iter: 0; batch classifier loss: 0.381615; batch adversarial loss: 0.279872\n",
      "epoch 70; iter: 0; batch classifier loss: 0.352396; batch adversarial loss: 0.343663\n",
      "epoch 71; iter: 0; batch classifier loss: 0.365844; batch adversarial loss: 0.279589\n",
      "epoch 72; iter: 0; batch classifier loss: 0.383250; batch adversarial loss: 0.286899\n",
      "epoch 73; iter: 0; batch classifier loss: 0.285774; batch adversarial loss: 0.288415\n",
      "epoch 74; iter: 0; batch classifier loss: 0.368522; batch adversarial loss: 0.366162\n",
      "epoch 75; iter: 0; batch classifier loss: 0.281104; batch adversarial loss: 0.307348\n",
      "epoch 76; iter: 0; batch classifier loss: 0.286465; batch adversarial loss: 0.314530\n",
      "epoch 77; iter: 0; batch classifier loss: 0.353794; batch adversarial loss: 0.334153\n",
      "epoch 78; iter: 0; batch classifier loss: 0.299503; batch adversarial loss: 0.227860\n",
      "epoch 79; iter: 0; batch classifier loss: 0.281628; batch adversarial loss: 0.368736\n",
      "epoch 80; iter: 0; batch classifier loss: 0.344619; batch adversarial loss: 0.417231\n",
      "epoch 81; iter: 0; batch classifier loss: 0.337356; batch adversarial loss: 0.279553\n",
      "epoch 82; iter: 0; batch classifier loss: 0.390303; batch adversarial loss: 0.271513\n",
      "epoch 83; iter: 0; batch classifier loss: 0.276567; batch adversarial loss: 0.277511\n",
      "epoch 84; iter: 0; batch classifier loss: 0.341695; batch adversarial loss: 0.270317\n",
      "epoch 85; iter: 0; batch classifier loss: 0.349411; batch adversarial loss: 0.397218\n",
      "epoch 86; iter: 0; batch classifier loss: 0.298952; batch adversarial loss: 0.295248\n",
      "epoch 87; iter: 0; batch classifier loss: 0.325777; batch adversarial loss: 0.313829\n",
      "epoch 88; iter: 0; batch classifier loss: 0.398919; batch adversarial loss: 0.261673\n",
      "epoch 89; iter: 0; batch classifier loss: 0.347055; batch adversarial loss: 0.269273\n",
      "epoch 90; iter: 0; batch classifier loss: 0.383826; batch adversarial loss: 0.257385\n",
      "epoch 91; iter: 0; batch classifier loss: 0.340268; batch adversarial loss: 0.358426\n",
      "epoch 92; iter: 0; batch classifier loss: 0.324018; batch adversarial loss: 0.241598\n",
      "epoch 93; iter: 0; batch classifier loss: 0.266263; batch adversarial loss: 0.289679\n",
      "epoch 94; iter: 0; batch classifier loss: 0.302480; batch adversarial loss: 0.285113\n",
      "epoch 95; iter: 0; batch classifier loss: 0.306215; batch adversarial loss: 0.295302\n",
      "epoch 96; iter: 0; batch classifier loss: 0.305500; batch adversarial loss: 0.308636\n",
      "epoch 97; iter: 0; batch classifier loss: 0.265222; batch adversarial loss: 0.290588\n",
      "epoch 98; iter: 0; batch classifier loss: 0.289838; batch adversarial loss: 0.254601\n",
      "epoch 99; iter: 0; batch classifier loss: 0.314053; batch adversarial loss: 0.227452\n",
      "epoch 100; iter: 0; batch classifier loss: 0.326477; batch adversarial loss: 0.298952\n",
      "epoch 101; iter: 0; batch classifier loss: 0.310220; batch adversarial loss: 0.258931\n",
      "epoch 102; iter: 0; batch classifier loss: 0.311120; batch adversarial loss: 0.273287\n",
      "epoch 103; iter: 0; batch classifier loss: 0.346232; batch adversarial loss: 0.363295\n",
      "epoch 104; iter: 0; batch classifier loss: 0.351380; batch adversarial loss: 0.289396\n",
      "epoch 105; iter: 0; batch classifier loss: 0.213713; batch adversarial loss: 0.337820\n",
      "epoch 106; iter: 0; batch classifier loss: 0.278977; batch adversarial loss: 0.270313\n",
      "epoch 107; iter: 0; batch classifier loss: 0.274201; batch adversarial loss: 0.282433\n",
      "epoch 108; iter: 0; batch classifier loss: 0.259070; batch adversarial loss: 0.315684\n",
      "epoch 109; iter: 0; batch classifier loss: 0.291900; batch adversarial loss: 0.289507\n",
      "epoch 110; iter: 0; batch classifier loss: 0.268622; batch adversarial loss: 0.307235\n",
      "epoch 111; iter: 0; batch classifier loss: 0.257520; batch adversarial loss: 0.363819\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383971; batch adversarial loss: 0.371929\n",
      "epoch 113; iter: 0; batch classifier loss: 0.289729; batch adversarial loss: 0.321021\n",
      "epoch 114; iter: 0; batch classifier loss: 0.232074; batch adversarial loss: 0.232244\n",
      "epoch 115; iter: 0; batch classifier loss: 0.229641; batch adversarial loss: 0.219017\n",
      "epoch 116; iter: 0; batch classifier loss: 0.321841; batch adversarial loss: 0.225476\n",
      "epoch 117; iter: 0; batch classifier loss: 0.238895; batch adversarial loss: 0.274085\n",
      "epoch 118; iter: 0; batch classifier loss: 0.220377; batch adversarial loss: 0.294992\n",
      "epoch 119; iter: 0; batch classifier loss: 0.238716; batch adversarial loss: 0.325557\n",
      "epoch 120; iter: 0; batch classifier loss: 0.247013; batch adversarial loss: 0.219731\n",
      "epoch 121; iter: 0; batch classifier loss: 0.254167; batch adversarial loss: 0.285414\n",
      "epoch 122; iter: 0; batch classifier loss: 0.305773; batch adversarial loss: 0.253815\n",
      "epoch 123; iter: 0; batch classifier loss: 0.273448; batch adversarial loss: 0.348810\n",
      "epoch 124; iter: 0; batch classifier loss: 0.280575; batch adversarial loss: 0.358769\n",
      "epoch 125; iter: 0; batch classifier loss: 0.308511; batch adversarial loss: 0.370536\n",
      "epoch 126; iter: 0; batch classifier loss: 0.320133; batch adversarial loss: 0.379638\n",
      "epoch 127; iter: 0; batch classifier loss: 0.258634; batch adversarial loss: 0.287776\n",
      "epoch 128; iter: 0; batch classifier loss: 0.267361; batch adversarial loss: 0.221050\n",
      "epoch 129; iter: 0; batch classifier loss: 0.214558; batch adversarial loss: 0.339632\n",
      "epoch 130; iter: 0; batch classifier loss: 0.235912; batch adversarial loss: 0.167614\n",
      "epoch 131; iter: 0; batch classifier loss: 0.232836; batch adversarial loss: 0.323096\n",
      "epoch 132; iter: 0; batch classifier loss: 0.234497; batch adversarial loss: 0.348002\n",
      "epoch 133; iter: 0; batch classifier loss: 0.311481; batch adversarial loss: 0.315880\n",
      "epoch 134; iter: 0; batch classifier loss: 0.215301; batch adversarial loss: 0.223980\n",
      "epoch 135; iter: 0; batch classifier loss: 0.242625; batch adversarial loss: 0.357098\n",
      "epoch 136; iter: 0; batch classifier loss: 0.229169; batch adversarial loss: 0.270324\n",
      "epoch 137; iter: 0; batch classifier loss: 0.235799; batch adversarial loss: 0.305794\n",
      "epoch 138; iter: 0; batch classifier loss: 0.276661; batch adversarial loss: 0.261573\n",
      "epoch 139; iter: 0; batch classifier loss: 0.276290; batch adversarial loss: 0.273538\n",
      "epoch 140; iter: 0; batch classifier loss: 0.276319; batch adversarial loss: 0.294563\n",
      "epoch 141; iter: 0; batch classifier loss: 0.297924; batch adversarial loss: 0.298779\n",
      "epoch 142; iter: 0; batch classifier loss: 0.268399; batch adversarial loss: 0.190722\n",
      "epoch 143; iter: 0; batch classifier loss: 0.242696; batch adversarial loss: 0.297316\n",
      "epoch 144; iter: 0; batch classifier loss: 0.226388; batch adversarial loss: 0.254788\n",
      "epoch 145; iter: 0; batch classifier loss: 0.259680; batch adversarial loss: 0.344404\n",
      "epoch 146; iter: 0; batch classifier loss: 0.279415; batch adversarial loss: 0.226627\n",
      "epoch 147; iter: 0; batch classifier loss: 0.255055; batch adversarial loss: 0.167244\n",
      "epoch 148; iter: 0; batch classifier loss: 0.240876; batch adversarial loss: 0.346394\n",
      "epoch 149; iter: 0; batch classifier loss: 0.254135; batch adversarial loss: 0.244223\n",
      "epoch 150; iter: 0; batch classifier loss: 0.264446; batch adversarial loss: 0.323695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 151; iter: 0; batch classifier loss: 0.295267; batch adversarial loss: 0.275560\n",
      "epoch 152; iter: 0; batch classifier loss: 0.306340; batch adversarial loss: 0.295156\n",
      "epoch 153; iter: 0; batch classifier loss: 0.318646; batch adversarial loss: 0.322242\n",
      "epoch 154; iter: 0; batch classifier loss: 0.246348; batch adversarial loss: 0.329029\n",
      "epoch 155; iter: 0; batch classifier loss: 0.264629; batch adversarial loss: 0.167810\n",
      "epoch 156; iter: 0; batch classifier loss: 0.246727; batch adversarial loss: 0.277089\n",
      "epoch 157; iter: 0; batch classifier loss: 0.268248; batch adversarial loss: 0.330533\n",
      "epoch 158; iter: 0; batch classifier loss: 0.280684; batch adversarial loss: 0.340207\n",
      "epoch 159; iter: 0; batch classifier loss: 0.247152; batch adversarial loss: 0.316467\n",
      "epoch 160; iter: 0; batch classifier loss: 0.260837; batch adversarial loss: 0.292165\n",
      "epoch 161; iter: 0; batch classifier loss: 0.255854; batch adversarial loss: 0.219318\n",
      "epoch 162; iter: 0; batch classifier loss: 0.211726; batch adversarial loss: 0.208302\n",
      "epoch 163; iter: 0; batch classifier loss: 0.221948; batch adversarial loss: 0.307130\n",
      "epoch 164; iter: 0; batch classifier loss: 0.210907; batch adversarial loss: 0.312633\n",
      "epoch 165; iter: 0; batch classifier loss: 0.282792; batch adversarial loss: 0.220673\n",
      "epoch 166; iter: 0; batch classifier loss: 0.321281; batch adversarial loss: 0.380231\n",
      "epoch 167; iter: 0; batch classifier loss: 0.258776; batch adversarial loss: 0.398355\n",
      "epoch 168; iter: 0; batch classifier loss: 0.225097; batch adversarial loss: 0.453672\n",
      "epoch 169; iter: 0; batch classifier loss: 0.205880; batch adversarial loss: 0.343486\n",
      "epoch 170; iter: 0; batch classifier loss: 0.243542; batch adversarial loss: 0.340961\n",
      "epoch 171; iter: 0; batch classifier loss: 0.269512; batch adversarial loss: 0.257823\n",
      "epoch 172; iter: 0; batch classifier loss: 0.239779; batch adversarial loss: 0.291307\n",
      "epoch 173; iter: 0; batch classifier loss: 0.251223; batch adversarial loss: 0.330965\n",
      "epoch 174; iter: 0; batch classifier loss: 0.208229; batch adversarial loss: 0.432147\n",
      "epoch 175; iter: 0; batch classifier loss: 0.207167; batch adversarial loss: 0.423835\n",
      "epoch 176; iter: 0; batch classifier loss: 0.246497; batch adversarial loss: 0.315091\n",
      "epoch 177; iter: 0; batch classifier loss: 0.269958; batch adversarial loss: 0.224584\n",
      "epoch 178; iter: 0; batch classifier loss: 0.296858; batch adversarial loss: 0.343551\n",
      "epoch 179; iter: 0; batch classifier loss: 0.229958; batch adversarial loss: 0.271353\n",
      "epoch 180; iter: 0; batch classifier loss: 0.222837; batch adversarial loss: 0.399357\n",
      "epoch 181; iter: 0; batch classifier loss: 0.234125; batch adversarial loss: 0.293538\n",
      "epoch 182; iter: 0; batch classifier loss: 0.203639; batch adversarial loss: 0.350910\n",
      "epoch 183; iter: 0; batch classifier loss: 0.167716; batch adversarial loss: 0.356809\n",
      "epoch 184; iter: 0; batch classifier loss: 0.219308; batch adversarial loss: 0.290935\n",
      "epoch 185; iter: 0; batch classifier loss: 0.265995; batch adversarial loss: 0.362535\n",
      "epoch 186; iter: 0; batch classifier loss: 0.215595; batch adversarial loss: 0.313296\n",
      "epoch 187; iter: 0; batch classifier loss: 0.256395; batch adversarial loss: 0.381311\n",
      "epoch 188; iter: 0; batch classifier loss: 0.227172; batch adversarial loss: 0.236945\n",
      "epoch 189; iter: 0; batch classifier loss: 0.262494; batch adversarial loss: 0.365842\n",
      "epoch 190; iter: 0; batch classifier loss: 0.167090; batch adversarial loss: 0.362615\n",
      "epoch 191; iter: 0; batch classifier loss: 0.234136; batch adversarial loss: 0.294809\n",
      "epoch 192; iter: 0; batch classifier loss: 0.238880; batch adversarial loss: 0.313751\n",
      "epoch 193; iter: 0; batch classifier loss: 0.185262; batch adversarial loss: 0.306681\n",
      "epoch 194; iter: 0; batch classifier loss: 0.273418; batch adversarial loss: 0.390698\n",
      "epoch 195; iter: 0; batch classifier loss: 0.273653; batch adversarial loss: 0.222707\n",
      "epoch 196; iter: 0; batch classifier loss: 0.255333; batch adversarial loss: 0.289267\n",
      "epoch 197; iter: 0; batch classifier loss: 0.247014; batch adversarial loss: 0.239571\n",
      "epoch 198; iter: 0; batch classifier loss: 0.223455; batch adversarial loss: 0.365350\n",
      "epoch 199; iter: 0; batch classifier loss: 0.232265; batch adversarial loss: 0.420363\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.249861; batch adversarial loss: 0.926239\n",
      "epoch 2; iter: 0; batch classifier loss: 1.131922; batch adversarial loss: 0.800069\n",
      "epoch 3; iter: 0; batch classifier loss: 0.885355; batch adversarial loss: 0.819357\n",
      "epoch 4; iter: 0; batch classifier loss: 0.821117; batch adversarial loss: 0.724639\n",
      "epoch 5; iter: 0; batch classifier loss: 0.681664; batch adversarial loss: 0.663968\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585319; batch adversarial loss: 0.635960\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580780; batch adversarial loss: 0.612460\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551696; batch adversarial loss: 0.601481\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540234; batch adversarial loss: 0.572991\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540506; batch adversarial loss: 0.582393\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568948; batch adversarial loss: 0.541292\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529016; batch adversarial loss: 0.535012\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532940; batch adversarial loss: 0.528790\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513345; batch adversarial loss: 0.493497\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525339; batch adversarial loss: 0.474397\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592656; batch adversarial loss: 0.456592\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508042; batch adversarial loss: 0.463685\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542679; batch adversarial loss: 0.454317\n",
      "epoch 19; iter: 0; batch classifier loss: 0.555201; batch adversarial loss: 0.463059\n",
      "epoch 20; iter: 0; batch classifier loss: 0.525370; batch adversarial loss: 0.436124\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545281; batch adversarial loss: 0.451910\n",
      "epoch 22; iter: 0; batch classifier loss: 0.582088; batch adversarial loss: 0.467094\n",
      "epoch 23; iter: 0; batch classifier loss: 0.533304; batch adversarial loss: 0.507319\n",
      "epoch 24; iter: 0; batch classifier loss: 0.586087; batch adversarial loss: 0.366891\n",
      "epoch 25; iter: 0; batch classifier loss: 0.559754; batch adversarial loss: 0.432430\n",
      "epoch 26; iter: 0; batch classifier loss: 0.649244; batch adversarial loss: 0.485350\n",
      "epoch 27; iter: 0; batch classifier loss: 0.705759; batch adversarial loss: 0.500616\n",
      "epoch 28; iter: 0; batch classifier loss: 0.614638; batch adversarial loss: 0.410646\n",
      "epoch 29; iter: 0; batch classifier loss: 0.533455; batch adversarial loss: 0.466733\n",
      "epoch 30; iter: 0; batch classifier loss: 0.553152; batch adversarial loss: 0.382106\n",
      "epoch 31; iter: 0; batch classifier loss: 0.605426; batch adversarial loss: 0.403813\n",
      "epoch 32; iter: 0; batch classifier loss: 0.629727; batch adversarial loss: 0.431022\n",
      "epoch 33; iter: 0; batch classifier loss: 0.592109; batch adversarial loss: 0.395281\n",
      "epoch 34; iter: 0; batch classifier loss: 0.545938; batch adversarial loss: 0.335726\n",
      "epoch 35; iter: 0; batch classifier loss: 0.667377; batch adversarial loss: 0.438353\n",
      "epoch 36; iter: 0; batch classifier loss: 0.547799; batch adversarial loss: 0.382122\n",
      "epoch 37; iter: 0; batch classifier loss: 0.594310; batch adversarial loss: 0.414541\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444007; batch adversarial loss: 0.343794\n",
      "epoch 39; iter: 0; batch classifier loss: 0.563572; batch adversarial loss: 0.320737\n",
      "epoch 40; iter: 0; batch classifier loss: 0.520489; batch adversarial loss: 0.387669\n",
      "epoch 41; iter: 0; batch classifier loss: 0.591367; batch adversarial loss: 0.407197\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496543; batch adversarial loss: 0.337569\n",
      "epoch 43; iter: 0; batch classifier loss: 0.544950; batch adversarial loss: 0.351495\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462626; batch adversarial loss: 0.314851\n",
      "epoch 45; iter: 0; batch classifier loss: 0.518452; batch adversarial loss: 0.340762\n",
      "epoch 46; iter: 0; batch classifier loss: 0.536972; batch adversarial loss: 0.301057\n",
      "epoch 47; iter: 0; batch classifier loss: 0.485057; batch adversarial loss: 0.268828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.596116; batch adversarial loss: 0.383262\n",
      "epoch 49; iter: 0; batch classifier loss: 0.518471; batch adversarial loss: 0.368690\n",
      "epoch 50; iter: 0; batch classifier loss: 0.587916; batch adversarial loss: 0.313878\n",
      "epoch 51; iter: 0; batch classifier loss: 0.591918; batch adversarial loss: 0.364580\n",
      "epoch 52; iter: 0; batch classifier loss: 0.520324; batch adversarial loss: 0.282193\n",
      "epoch 53; iter: 0; batch classifier loss: 0.572014; batch adversarial loss: 0.399425\n",
      "epoch 54; iter: 0; batch classifier loss: 0.627633; batch adversarial loss: 0.278386\n",
      "epoch 55; iter: 0; batch classifier loss: 0.466619; batch adversarial loss: 0.249690\n",
      "epoch 56; iter: 0; batch classifier loss: 0.446765; batch adversarial loss: 0.352403\n",
      "epoch 57; iter: 0; batch classifier loss: 0.494608; batch adversarial loss: 0.352771\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427478; batch adversarial loss: 0.365723\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464466; batch adversarial loss: 0.377515\n",
      "epoch 60; iter: 0; batch classifier loss: 0.483551; batch adversarial loss: 0.320129\n",
      "epoch 61; iter: 0; batch classifier loss: 0.466107; batch adversarial loss: 0.248990\n",
      "epoch 62; iter: 0; batch classifier loss: 0.475776; batch adversarial loss: 0.303404\n",
      "epoch 63; iter: 0; batch classifier loss: 0.460740; batch adversarial loss: 0.404402\n",
      "epoch 64; iter: 0; batch classifier loss: 0.362669; batch adversarial loss: 0.321216\n",
      "epoch 65; iter: 0; batch classifier loss: 0.444824; batch adversarial loss: 0.257603\n",
      "epoch 66; iter: 0; batch classifier loss: 0.316490; batch adversarial loss: 0.330377\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410846; batch adversarial loss: 0.344242\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408994; batch adversarial loss: 0.343413\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430513; batch adversarial loss: 0.280776\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423392; batch adversarial loss: 0.343246\n",
      "epoch 71; iter: 0; batch classifier loss: 0.485534; batch adversarial loss: 0.279998\n",
      "epoch 72; iter: 0; batch classifier loss: 0.417367; batch adversarial loss: 0.286495\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373519; batch adversarial loss: 0.287002\n",
      "epoch 74; iter: 0; batch classifier loss: 0.466131; batch adversarial loss: 0.364275\n",
      "epoch 75; iter: 0; batch classifier loss: 0.349488; batch adversarial loss: 0.308472\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371098; batch adversarial loss: 0.314974\n",
      "epoch 77; iter: 0; batch classifier loss: 0.424206; batch adversarial loss: 0.336722\n",
      "epoch 78; iter: 0; batch classifier loss: 0.351972; batch adversarial loss: 0.228275\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384528; batch adversarial loss: 0.366941\n",
      "epoch 80; iter: 0; batch classifier loss: 0.486785; batch adversarial loss: 0.418066\n",
      "epoch 81; iter: 0; batch classifier loss: 0.416253; batch adversarial loss: 0.278910\n",
      "epoch 82; iter: 0; batch classifier loss: 0.459532; batch adversarial loss: 0.271619\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386641; batch adversarial loss: 0.276495\n",
      "epoch 84; iter: 0; batch classifier loss: 0.444984; batch adversarial loss: 0.268422\n",
      "epoch 85; iter: 0; batch classifier loss: 0.394844; batch adversarial loss: 0.396895\n",
      "epoch 86; iter: 0; batch classifier loss: 0.414261; batch adversarial loss: 0.297104\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377754; batch adversarial loss: 0.312552\n",
      "epoch 88; iter: 0; batch classifier loss: 0.427675; batch adversarial loss: 0.259433\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388685; batch adversarial loss: 0.270013\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443986; batch adversarial loss: 0.260166\n",
      "epoch 91; iter: 0; batch classifier loss: 0.418001; batch adversarial loss: 0.359976\n",
      "epoch 92; iter: 0; batch classifier loss: 0.384394; batch adversarial loss: 0.242003\n",
      "epoch 93; iter: 0; batch classifier loss: 0.343468; batch adversarial loss: 0.288614\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385458; batch adversarial loss: 0.285379\n",
      "epoch 95; iter: 0; batch classifier loss: 0.413622; batch adversarial loss: 0.294189\n",
      "epoch 96; iter: 0; batch classifier loss: 0.366969; batch adversarial loss: 0.309182\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366174; batch adversarial loss: 0.290210\n",
      "epoch 98; iter: 0; batch classifier loss: 0.377484; batch adversarial loss: 0.254372\n",
      "epoch 99; iter: 0; batch classifier loss: 0.362848; batch adversarial loss: 0.227889\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421400; batch adversarial loss: 0.300460\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379875; batch adversarial loss: 0.259938\n",
      "epoch 102; iter: 0; batch classifier loss: 0.330289; batch adversarial loss: 0.273358\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402192; batch adversarial loss: 0.362892\n",
      "epoch 104; iter: 0; batch classifier loss: 0.417594; batch adversarial loss: 0.290788\n",
      "epoch 105; iter: 0; batch classifier loss: 0.298865; batch adversarial loss: 0.337882\n",
      "epoch 106; iter: 0; batch classifier loss: 0.390721; batch adversarial loss: 0.270627\n",
      "epoch 107; iter: 0; batch classifier loss: 0.377098; batch adversarial loss: 0.281659\n",
      "epoch 108; iter: 0; batch classifier loss: 0.387647; batch adversarial loss: 0.316343\n",
      "epoch 109; iter: 0; batch classifier loss: 0.379053; batch adversarial loss: 0.289711\n",
      "epoch 110; iter: 0; batch classifier loss: 0.411948; batch adversarial loss: 0.308615\n",
      "epoch 111; iter: 0; batch classifier loss: 0.329716; batch adversarial loss: 0.363956\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375622; batch adversarial loss: 0.371233\n",
      "epoch 113; iter: 0; batch classifier loss: 0.352329; batch adversarial loss: 0.321020\n",
      "epoch 114; iter: 0; batch classifier loss: 0.374882; batch adversarial loss: 0.233311\n",
      "epoch 115; iter: 0; batch classifier loss: 0.327635; batch adversarial loss: 0.219202\n",
      "epoch 116; iter: 0; batch classifier loss: 0.342411; batch adversarial loss: 0.223659\n",
      "epoch 117; iter: 0; batch classifier loss: 0.341535; batch adversarial loss: 0.273586\n",
      "epoch 118; iter: 0; batch classifier loss: 0.300254; batch adversarial loss: 0.297093\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373636; batch adversarial loss: 0.324933\n",
      "epoch 120; iter: 0; batch classifier loss: 0.289247; batch adversarial loss: 0.219523\n",
      "epoch 121; iter: 0; batch classifier loss: 0.313047; batch adversarial loss: 0.285105\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385859; batch adversarial loss: 0.253471\n",
      "epoch 123; iter: 0; batch classifier loss: 0.356032; batch adversarial loss: 0.344929\n",
      "epoch 124; iter: 0; batch classifier loss: 0.344882; batch adversarial loss: 0.360563\n",
      "epoch 125; iter: 0; batch classifier loss: 0.426110; batch adversarial loss: 0.369437\n",
      "epoch 126; iter: 0; batch classifier loss: 0.363081; batch adversarial loss: 0.378216\n",
      "epoch 127; iter: 0; batch classifier loss: 0.453788; batch adversarial loss: 0.289100\n",
      "epoch 128; iter: 0; batch classifier loss: 0.324535; batch adversarial loss: 0.220928\n",
      "epoch 129; iter: 0; batch classifier loss: 0.295973; batch adversarial loss: 0.339206\n",
      "epoch 130; iter: 0; batch classifier loss: 0.379894; batch adversarial loss: 0.168167\n",
      "epoch 131; iter: 0; batch classifier loss: 0.328967; batch adversarial loss: 0.325194\n",
      "epoch 132; iter: 0; batch classifier loss: 0.312361; batch adversarial loss: 0.346304\n",
      "epoch 133; iter: 0; batch classifier loss: 0.338551; batch adversarial loss: 0.316791\n",
      "epoch 134; iter: 0; batch classifier loss: 0.281854; batch adversarial loss: 0.222143\n",
      "epoch 135; iter: 0; batch classifier loss: 0.315855; batch adversarial loss: 0.357239\n",
      "epoch 136; iter: 0; batch classifier loss: 0.356551; batch adversarial loss: 0.270747\n",
      "epoch 137; iter: 0; batch classifier loss: 0.350254; batch adversarial loss: 0.306285\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318025; batch adversarial loss: 0.264342\n",
      "epoch 139; iter: 0; batch classifier loss: 0.371251; batch adversarial loss: 0.272879\n",
      "epoch 140; iter: 0; batch classifier loss: 0.384820; batch adversarial loss: 0.295540\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351502; batch adversarial loss: 0.299522\n",
      "epoch 142; iter: 0; batch classifier loss: 0.321418; batch adversarial loss: 0.190597\n",
      "epoch 143; iter: 0; batch classifier loss: 0.303414; batch adversarial loss: 0.300539\n",
      "epoch 144; iter: 0; batch classifier loss: 0.342289; batch adversarial loss: 0.255010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 145; iter: 0; batch classifier loss: 0.384626; batch adversarial loss: 0.344272\n",
      "epoch 146; iter: 0; batch classifier loss: 0.380301; batch adversarial loss: 0.227164\n",
      "epoch 147; iter: 0; batch classifier loss: 0.296829; batch adversarial loss: 0.167160\n",
      "epoch 148; iter: 0; batch classifier loss: 0.332300; batch adversarial loss: 0.347037\n",
      "epoch 149; iter: 0; batch classifier loss: 0.368211; batch adversarial loss: 0.244579\n",
      "epoch 150; iter: 0; batch classifier loss: 0.354748; batch adversarial loss: 0.323597\n",
      "epoch 151; iter: 0; batch classifier loss: 0.372427; batch adversarial loss: 0.274933\n",
      "epoch 152; iter: 0; batch classifier loss: 0.343337; batch adversarial loss: 0.293924\n",
      "epoch 153; iter: 0; batch classifier loss: 0.404324; batch adversarial loss: 0.322174\n",
      "epoch 154; iter: 0; batch classifier loss: 0.320920; batch adversarial loss: 0.329192\n",
      "epoch 155; iter: 0; batch classifier loss: 0.348067; batch adversarial loss: 0.167613\n",
      "epoch 156; iter: 0; batch classifier loss: 0.374958; batch adversarial loss: 0.278151\n",
      "epoch 157; iter: 0; batch classifier loss: 0.344326; batch adversarial loss: 0.331449\n",
      "epoch 158; iter: 0; batch classifier loss: 0.298021; batch adversarial loss: 0.339239\n",
      "epoch 159; iter: 0; batch classifier loss: 0.275282; batch adversarial loss: 0.314635\n",
      "epoch 160; iter: 0; batch classifier loss: 0.309284; batch adversarial loss: 0.291416\n",
      "epoch 161; iter: 0; batch classifier loss: 0.358410; batch adversarial loss: 0.219714\n",
      "epoch 162; iter: 0; batch classifier loss: 0.270466; batch adversarial loss: 0.207770\n",
      "epoch 163; iter: 0; batch classifier loss: 0.236601; batch adversarial loss: 0.306267\n",
      "epoch 164; iter: 0; batch classifier loss: 0.352362; batch adversarial loss: 0.314352\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386617; batch adversarial loss: 0.220682\n",
      "epoch 166; iter: 0; batch classifier loss: 0.353409; batch adversarial loss: 0.379353\n",
      "epoch 167; iter: 0; batch classifier loss: 0.402877; batch adversarial loss: 0.399046\n",
      "epoch 168; iter: 0; batch classifier loss: 0.323230; batch adversarial loss: 0.455735\n",
      "epoch 169; iter: 0; batch classifier loss: 0.292599; batch adversarial loss: 0.344250\n",
      "epoch 170; iter: 0; batch classifier loss: 0.289030; batch adversarial loss: 0.340595\n",
      "epoch 171; iter: 0; batch classifier loss: 0.411653; batch adversarial loss: 0.258221\n",
      "epoch 172; iter: 0; batch classifier loss: 0.281777; batch adversarial loss: 0.290977\n",
      "epoch 173; iter: 0; batch classifier loss: 0.361709; batch adversarial loss: 0.331161\n",
      "epoch 174; iter: 0; batch classifier loss: 0.396503; batch adversarial loss: 0.433490\n",
      "epoch 175; iter: 0; batch classifier loss: 0.314179; batch adversarial loss: 0.424850\n",
      "epoch 176; iter: 0; batch classifier loss: 0.341037; batch adversarial loss: 0.315730\n",
      "epoch 177; iter: 0; batch classifier loss: 0.303722; batch adversarial loss: 0.223932\n",
      "epoch 178; iter: 0; batch classifier loss: 0.314604; batch adversarial loss: 0.342763\n",
      "epoch 179; iter: 0; batch classifier loss: 0.302795; batch adversarial loss: 0.270379\n",
      "epoch 180; iter: 0; batch classifier loss: 0.295161; batch adversarial loss: 0.400123\n",
      "epoch 181; iter: 0; batch classifier loss: 0.257129; batch adversarial loss: 0.291454\n",
      "epoch 182; iter: 0; batch classifier loss: 0.320569; batch adversarial loss: 0.350406\n",
      "epoch 183; iter: 0; batch classifier loss: 0.259613; batch adversarial loss: 0.356205\n",
      "epoch 184; iter: 0; batch classifier loss: 0.361222; batch adversarial loss: 0.291592\n",
      "epoch 185; iter: 0; batch classifier loss: 0.393809; batch adversarial loss: 0.363940\n",
      "epoch 186; iter: 0; batch classifier loss: 0.323831; batch adversarial loss: 0.314873\n",
      "epoch 187; iter: 0; batch classifier loss: 0.345581; batch adversarial loss: 0.379633\n",
      "epoch 188; iter: 0; batch classifier loss: 0.280836; batch adversarial loss: 0.237595\n",
      "epoch 189; iter: 0; batch classifier loss: 0.338539; batch adversarial loss: 0.365961\n",
      "epoch 190; iter: 0; batch classifier loss: 0.240152; batch adversarial loss: 0.361591\n",
      "epoch 191; iter: 0; batch classifier loss: 0.328681; batch adversarial loss: 0.295059\n",
      "epoch 192; iter: 0; batch classifier loss: 0.310882; batch adversarial loss: 0.314390\n",
      "epoch 193; iter: 0; batch classifier loss: 0.269880; batch adversarial loss: 0.306674\n",
      "epoch 194; iter: 0; batch classifier loss: 0.390456; batch adversarial loss: 0.390223\n",
      "epoch 195; iter: 0; batch classifier loss: 0.308695; batch adversarial loss: 0.222310\n",
      "epoch 196; iter: 0; batch classifier loss: 0.321626; batch adversarial loss: 0.288705\n",
      "epoch 197; iter: 0; batch classifier loss: 0.334412; batch adversarial loss: 0.240317\n",
      "epoch 198; iter: 0; batch classifier loss: 0.351195; batch adversarial loss: 0.366542\n",
      "epoch 199; iter: 0; batch classifier loss: 0.269756; batch adversarial loss: 0.419124\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.262755; batch adversarial loss: 0.926709\n",
      "epoch 2; iter: 0; batch classifier loss: 1.142845; batch adversarial loss: 0.800523\n",
      "epoch 3; iter: 0; batch classifier loss: 0.895251; batch adversarial loss: 0.820097\n",
      "epoch 4; iter: 0; batch classifier loss: 0.830403; batch adversarial loss: 0.725666\n",
      "epoch 5; iter: 0; batch classifier loss: 0.689885; batch adversarial loss: 0.664946\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587057; batch adversarial loss: 0.635994\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580984; batch adversarial loss: 0.612459\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550865; batch adversarial loss: 0.601553\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540329; batch adversarial loss: 0.572831\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539475; batch adversarial loss: 0.582313\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568534; batch adversarial loss: 0.541157\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528315; batch adversarial loss: 0.534868\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532443; batch adversarial loss: 0.528880\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510300; batch adversarial loss: 0.494100\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525598; batch adversarial loss: 0.474942\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592393; batch adversarial loss: 0.456986\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507266; batch adversarial loss: 0.464590\n",
      "epoch 18; iter: 0; batch classifier loss: 0.540404; batch adversarial loss: 0.454729\n",
      "epoch 19; iter: 0; batch classifier loss: 0.565262; batch adversarial loss: 0.465784\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529258; batch adversarial loss: 0.439286\n",
      "epoch 21; iter: 0; batch classifier loss: 0.554171; batch adversarial loss: 0.454269\n",
      "epoch 22; iter: 0; batch classifier loss: 0.588037; batch adversarial loss: 0.468912\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538690; batch adversarial loss: 0.507829\n",
      "epoch 24; iter: 0; batch classifier loss: 0.590104; batch adversarial loss: 0.367816\n",
      "epoch 25; iter: 0; batch classifier loss: 0.566437; batch adversarial loss: 0.433508\n",
      "epoch 26; iter: 0; batch classifier loss: 0.658881; batch adversarial loss: 0.485919\n",
      "epoch 27; iter: 0; batch classifier loss: 0.707715; batch adversarial loss: 0.500796\n",
      "epoch 28; iter: 0; batch classifier loss: 0.618425; batch adversarial loss: 0.410712\n",
      "epoch 29; iter: 0; batch classifier loss: 0.532924; batch adversarial loss: 0.465874\n",
      "epoch 30; iter: 0; batch classifier loss: 0.553765; batch adversarial loss: 0.382064\n",
      "epoch 31; iter: 0; batch classifier loss: 0.607751; batch adversarial loss: 0.403581\n",
      "epoch 32; iter: 0; batch classifier loss: 0.633950; batch adversarial loss: 0.430293\n",
      "epoch 33; iter: 0; batch classifier loss: 0.593448; batch adversarial loss: 0.395095\n",
      "epoch 34; iter: 0; batch classifier loss: 0.545804; batch adversarial loss: 0.335398\n",
      "epoch 35; iter: 0; batch classifier loss: 0.663799; batch adversarial loss: 0.437812\n",
      "epoch 36; iter: 0; batch classifier loss: 0.550039; batch adversarial loss: 0.381696\n",
      "epoch 37; iter: 0; batch classifier loss: 0.589710; batch adversarial loss: 0.413913\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444965; batch adversarial loss: 0.343468\n",
      "epoch 39; iter: 0; batch classifier loss: 0.562425; batch adversarial loss: 0.320201\n",
      "epoch 40; iter: 0; batch classifier loss: 0.518887; batch adversarial loss: 0.387126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.590530; batch adversarial loss: 0.406485\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496432; batch adversarial loss: 0.337386\n",
      "epoch 43; iter: 0; batch classifier loss: 0.538030; batch adversarial loss: 0.350954\n",
      "epoch 44; iter: 0; batch classifier loss: 0.467739; batch adversarial loss: 0.314907\n",
      "epoch 45; iter: 0; batch classifier loss: 0.514018; batch adversarial loss: 0.340447\n",
      "epoch 46; iter: 0; batch classifier loss: 0.525847; batch adversarial loss: 0.300741\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484904; batch adversarial loss: 0.268652\n",
      "epoch 48; iter: 0; batch classifier loss: 0.593563; batch adversarial loss: 0.382846\n",
      "epoch 49; iter: 0; batch classifier loss: 0.520554; batch adversarial loss: 0.368346\n",
      "epoch 50; iter: 0; batch classifier loss: 0.592580; batch adversarial loss: 0.313804\n",
      "epoch 51; iter: 0; batch classifier loss: 0.600217; batch adversarial loss: 0.364337\n",
      "epoch 52; iter: 0; batch classifier loss: 0.515500; batch adversarial loss: 0.282147\n",
      "epoch 53; iter: 0; batch classifier loss: 0.573574; batch adversarial loss: 0.398781\n",
      "epoch 54; iter: 0; batch classifier loss: 0.629996; batch adversarial loss: 0.278120\n",
      "epoch 55; iter: 0; batch classifier loss: 0.461513; batch adversarial loss: 0.249518\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451754; batch adversarial loss: 0.352273\n",
      "epoch 57; iter: 0; batch classifier loss: 0.495323; batch adversarial loss: 0.352793\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426867; batch adversarial loss: 0.365702\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466230; batch adversarial loss: 0.377526\n",
      "epoch 60; iter: 0; batch classifier loss: 0.484887; batch adversarial loss: 0.320110\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463558; batch adversarial loss: 0.248875\n",
      "epoch 62; iter: 0; batch classifier loss: 0.485361; batch adversarial loss: 0.303518\n",
      "epoch 63; iter: 0; batch classifier loss: 0.466210; batch adversarial loss: 0.404438\n",
      "epoch 64; iter: 0; batch classifier loss: 0.362969; batch adversarial loss: 0.321190\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447765; batch adversarial loss: 0.257534\n",
      "epoch 66; iter: 0; batch classifier loss: 0.321365; batch adversarial loss: 0.330482\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409291; batch adversarial loss: 0.344264\n",
      "epoch 68; iter: 0; batch classifier loss: 0.414845; batch adversarial loss: 0.343518\n",
      "epoch 69; iter: 0; batch classifier loss: 0.429212; batch adversarial loss: 0.280742\n",
      "epoch 70; iter: 0; batch classifier loss: 0.430747; batch adversarial loss: 0.343285\n",
      "epoch 71; iter: 0; batch classifier loss: 0.482584; batch adversarial loss: 0.279899\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416526; batch adversarial loss: 0.286393\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369031; batch adversarial loss: 0.286854\n",
      "epoch 74; iter: 0; batch classifier loss: 0.462773; batch adversarial loss: 0.364075\n",
      "epoch 75; iter: 0; batch classifier loss: 0.358680; batch adversarial loss: 0.308521\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370571; batch adversarial loss: 0.314792\n",
      "epoch 77; iter: 0; batch classifier loss: 0.426793; batch adversarial loss: 0.336670\n",
      "epoch 78; iter: 0; batch classifier loss: 0.351884; batch adversarial loss: 0.228318\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380316; batch adversarial loss: 0.366979\n",
      "epoch 80; iter: 0; batch classifier loss: 0.476295; batch adversarial loss: 0.418204\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419418; batch adversarial loss: 0.278407\n",
      "epoch 82; iter: 0; batch classifier loss: 0.457679; batch adversarial loss: 0.271834\n",
      "epoch 83; iter: 0; batch classifier loss: 0.379865; batch adversarial loss: 0.276591\n",
      "epoch 84; iter: 0; batch classifier loss: 0.452769; batch adversarial loss: 0.269029\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390247; batch adversarial loss: 0.396606\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406242; batch adversarial loss: 0.297233\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375159; batch adversarial loss: 0.313157\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426750; batch adversarial loss: 0.259389\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386910; batch adversarial loss: 0.270079\n",
      "epoch 90; iter: 0; batch classifier loss: 0.449238; batch adversarial loss: 0.260062\n",
      "epoch 91; iter: 0; batch classifier loss: 0.414492; batch adversarial loss: 0.359815\n",
      "epoch 92; iter: 0; batch classifier loss: 0.368415; batch adversarial loss: 0.241756\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349512; batch adversarial loss: 0.288272\n",
      "epoch 94; iter: 0; batch classifier loss: 0.373227; batch adversarial loss: 0.285370\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417502; batch adversarial loss: 0.293755\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377279; batch adversarial loss: 0.309024\n",
      "epoch 97; iter: 0; batch classifier loss: 0.368674; batch adversarial loss: 0.289402\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389659; batch adversarial loss: 0.254478\n",
      "epoch 99; iter: 0; batch classifier loss: 0.365524; batch adversarial loss: 0.227537\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417988; batch adversarial loss: 0.300013\n",
      "epoch 101; iter: 0; batch classifier loss: 0.372781; batch adversarial loss: 0.259888\n",
      "epoch 102; iter: 0; batch classifier loss: 0.353886; batch adversarial loss: 0.273357\n",
      "epoch 103; iter: 0; batch classifier loss: 0.393310; batch adversarial loss: 0.362809\n",
      "epoch 104; iter: 0; batch classifier loss: 0.430389; batch adversarial loss: 0.290681\n",
      "epoch 105; iter: 0; batch classifier loss: 0.302297; batch adversarial loss: 0.337539\n",
      "epoch 106; iter: 0; batch classifier loss: 0.386373; batch adversarial loss: 0.270270\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355019; batch adversarial loss: 0.281535\n",
      "epoch 108; iter: 0; batch classifier loss: 0.375026; batch adversarial loss: 0.316164\n",
      "epoch 109; iter: 0; batch classifier loss: 0.368716; batch adversarial loss: 0.289387\n",
      "epoch 110; iter: 0; batch classifier loss: 0.420803; batch adversarial loss: 0.307894\n",
      "epoch 111; iter: 0; batch classifier loss: 0.334807; batch adversarial loss: 0.363774\n",
      "epoch 112; iter: 0; batch classifier loss: 0.384467; batch adversarial loss: 0.371720\n",
      "epoch 113; iter: 0; batch classifier loss: 0.351355; batch adversarial loss: 0.320937\n",
      "epoch 114; iter: 0; batch classifier loss: 0.367843; batch adversarial loss: 0.233092\n",
      "epoch 115; iter: 0; batch classifier loss: 0.326537; batch adversarial loss: 0.219237\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346515; batch adversarial loss: 0.223698\n",
      "epoch 117; iter: 0; batch classifier loss: 0.324707; batch adversarial loss: 0.272922\n",
      "epoch 118; iter: 0; batch classifier loss: 0.296554; batch adversarial loss: 0.296932\n",
      "epoch 119; iter: 0; batch classifier loss: 0.376323; batch adversarial loss: 0.324989\n",
      "epoch 120; iter: 0; batch classifier loss: 0.295607; batch adversarial loss: 0.219446\n",
      "epoch 121; iter: 0; batch classifier loss: 0.324168; batch adversarial loss: 0.284909\n",
      "epoch 122; iter: 0; batch classifier loss: 0.382226; batch adversarial loss: 0.253055\n",
      "epoch 123; iter: 0; batch classifier loss: 0.353579; batch adversarial loss: 0.344603\n",
      "epoch 124; iter: 0; batch classifier loss: 0.330057; batch adversarial loss: 0.360836\n",
      "epoch 125; iter: 0; batch classifier loss: 0.405371; batch adversarial loss: 0.369655\n",
      "epoch 126; iter: 0; batch classifier loss: 0.373516; batch adversarial loss: 0.378580\n",
      "epoch 127; iter: 0; batch classifier loss: 0.451742; batch adversarial loss: 0.289106\n",
      "epoch 128; iter: 0; batch classifier loss: 0.311074; batch adversarial loss: 0.220855\n",
      "epoch 129; iter: 0; batch classifier loss: 0.284316; batch adversarial loss: 0.339269\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364148; batch adversarial loss: 0.168065\n",
      "epoch 131; iter: 0; batch classifier loss: 0.345228; batch adversarial loss: 0.325950\n",
      "epoch 132; iter: 0; batch classifier loss: 0.326474; batch adversarial loss: 0.347103\n",
      "epoch 133; iter: 0; batch classifier loss: 0.342749; batch adversarial loss: 0.316850\n",
      "epoch 134; iter: 0; batch classifier loss: 0.295081; batch adversarial loss: 0.221991\n",
      "epoch 135; iter: 0; batch classifier loss: 0.320277; batch adversarial loss: 0.357220\n",
      "epoch 136; iter: 0; batch classifier loss: 0.343014; batch adversarial loss: 0.270724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.354637; batch adversarial loss: 0.306169\n",
      "epoch 138; iter: 0; batch classifier loss: 0.323030; batch adversarial loss: 0.264451\n",
      "epoch 139; iter: 0; batch classifier loss: 0.378851; batch adversarial loss: 0.272843\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386643; batch adversarial loss: 0.295877\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368862; batch adversarial loss: 0.299614\n",
      "epoch 142; iter: 0; batch classifier loss: 0.322130; batch adversarial loss: 0.190615\n",
      "epoch 143; iter: 0; batch classifier loss: 0.293910; batch adversarial loss: 0.300614\n",
      "epoch 144; iter: 0; batch classifier loss: 0.334656; batch adversarial loss: 0.254818\n",
      "epoch 145; iter: 0; batch classifier loss: 0.387567; batch adversarial loss: 0.344491\n",
      "epoch 146; iter: 0; batch classifier loss: 0.363365; batch adversarial loss: 0.227856\n",
      "epoch 147; iter: 0; batch classifier loss: 0.307974; batch adversarial loss: 0.167238\n",
      "epoch 148; iter: 0; batch classifier loss: 0.320736; batch adversarial loss: 0.347127\n",
      "epoch 149; iter: 0; batch classifier loss: 0.371967; batch adversarial loss: 0.244617\n",
      "epoch 150; iter: 0; batch classifier loss: 0.356777; batch adversarial loss: 0.323740\n",
      "epoch 151; iter: 0; batch classifier loss: 0.397673; batch adversarial loss: 0.276120\n",
      "epoch 152; iter: 0; batch classifier loss: 0.341118; batch adversarial loss: 0.294054\n",
      "epoch 153; iter: 0; batch classifier loss: 0.386825; batch adversarial loss: 0.322170\n",
      "epoch 154; iter: 0; batch classifier loss: 0.310355; batch adversarial loss: 0.329206\n",
      "epoch 155; iter: 0; batch classifier loss: 0.350883; batch adversarial loss: 0.167478\n",
      "epoch 156; iter: 0; batch classifier loss: 0.366969; batch adversarial loss: 0.277944\n",
      "epoch 157; iter: 0; batch classifier loss: 0.326224; batch adversarial loss: 0.331601\n",
      "epoch 158; iter: 0; batch classifier loss: 0.320947; batch adversarial loss: 0.339577\n",
      "epoch 159; iter: 0; batch classifier loss: 0.273246; batch adversarial loss: 0.315035\n",
      "epoch 160; iter: 0; batch classifier loss: 0.320016; batch adversarial loss: 0.291377\n",
      "epoch 161; iter: 0; batch classifier loss: 0.378736; batch adversarial loss: 0.219692\n",
      "epoch 162; iter: 0; batch classifier loss: 0.266870; batch adversarial loss: 0.207897\n",
      "epoch 163; iter: 0; batch classifier loss: 0.247035; batch adversarial loss: 0.306413\n",
      "epoch 164; iter: 0; batch classifier loss: 0.363214; batch adversarial loss: 0.314322\n",
      "epoch 165; iter: 0; batch classifier loss: 0.378308; batch adversarial loss: 0.221010\n",
      "epoch 166; iter: 0; batch classifier loss: 0.371904; batch adversarial loss: 0.379171\n",
      "epoch 167; iter: 0; batch classifier loss: 0.398707; batch adversarial loss: 0.398491\n",
      "epoch 168; iter: 0; batch classifier loss: 0.325636; batch adversarial loss: 0.455710\n",
      "epoch 169; iter: 0; batch classifier loss: 0.300675; batch adversarial loss: 0.344320\n",
      "epoch 170; iter: 0; batch classifier loss: 0.297902; batch adversarial loss: 0.340348\n",
      "epoch 171; iter: 0; batch classifier loss: 0.385929; batch adversarial loss: 0.257555\n",
      "epoch 172; iter: 0; batch classifier loss: 0.276915; batch adversarial loss: 0.290748\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350938; batch adversarial loss: 0.331415\n",
      "epoch 174; iter: 0; batch classifier loss: 0.373994; batch adversarial loss: 0.433489\n",
      "epoch 175; iter: 0; batch classifier loss: 0.297470; batch adversarial loss: 0.423991\n",
      "epoch 176; iter: 0; batch classifier loss: 0.352278; batch adversarial loss: 0.315601\n",
      "epoch 177; iter: 0; batch classifier loss: 0.319213; batch adversarial loss: 0.223811\n",
      "epoch 178; iter: 0; batch classifier loss: 0.332881; batch adversarial loss: 0.343269\n",
      "epoch 179; iter: 0; batch classifier loss: 0.275014; batch adversarial loss: 0.270287\n",
      "epoch 180; iter: 0; batch classifier loss: 0.287135; batch adversarial loss: 0.399856\n",
      "epoch 181; iter: 0; batch classifier loss: 0.260223; batch adversarial loss: 0.292627\n",
      "epoch 182; iter: 0; batch classifier loss: 0.338408; batch adversarial loss: 0.350746\n",
      "epoch 183; iter: 0; batch classifier loss: 0.253523; batch adversarial loss: 0.356278\n",
      "epoch 184; iter: 0; batch classifier loss: 0.374708; batch adversarial loss: 0.291712\n",
      "epoch 185; iter: 0; batch classifier loss: 0.392170; batch adversarial loss: 0.364260\n",
      "epoch 186; iter: 0; batch classifier loss: 0.303456; batch adversarial loss: 0.314675\n",
      "epoch 187; iter: 0; batch classifier loss: 0.338510; batch adversarial loss: 0.379308\n",
      "epoch 188; iter: 0; batch classifier loss: 0.274485; batch adversarial loss: 0.237460\n",
      "epoch 189; iter: 0; batch classifier loss: 0.329310; batch adversarial loss: 0.366171\n",
      "epoch 190; iter: 0; batch classifier loss: 0.240149; batch adversarial loss: 0.361563\n",
      "epoch 191; iter: 0; batch classifier loss: 0.311409; batch adversarial loss: 0.295441\n",
      "epoch 192; iter: 0; batch classifier loss: 0.316244; batch adversarial loss: 0.314492\n",
      "epoch 193; iter: 0; batch classifier loss: 0.262534; batch adversarial loss: 0.306469\n",
      "epoch 194; iter: 0; batch classifier loss: 0.391067; batch adversarial loss: 0.390528\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317524; batch adversarial loss: 0.222263\n",
      "epoch 196; iter: 0; batch classifier loss: 0.317343; batch adversarial loss: 0.288737\n",
      "epoch 197; iter: 0; batch classifier loss: 0.327529; batch adversarial loss: 0.240044\n",
      "epoch 198; iter: 0; batch classifier loss: 0.340126; batch adversarial loss: 0.366338\n",
      "epoch 199; iter: 0; batch classifier loss: 0.286076; batch adversarial loss: 0.418889\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.265479; batch adversarial loss: 0.926785\n",
      "epoch 2; iter: 0; batch classifier loss: 1.144242; batch adversarial loss: 0.800571\n",
      "epoch 3; iter: 0; batch classifier loss: 0.897121; batch adversarial loss: 0.820291\n",
      "epoch 4; iter: 0; batch classifier loss: 0.832807; batch adversarial loss: 0.725789\n",
      "epoch 5; iter: 0; batch classifier loss: 0.690538; batch adversarial loss: 0.665038\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587504; batch adversarial loss: 0.636010\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580427; batch adversarial loss: 0.612618\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550624; batch adversarial loss: 0.601639\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540715; batch adversarial loss: 0.572722\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539003; batch adversarial loss: 0.582297\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568039; batch adversarial loss: 0.541165\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528573; batch adversarial loss: 0.534830\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532719; batch adversarial loss: 0.528744\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510124; batch adversarial loss: 0.494116\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525288; batch adversarial loss: 0.474961\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591145; batch adversarial loss: 0.457144\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508287; batch adversarial loss: 0.464682\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539142; batch adversarial loss: 0.454864\n",
      "epoch 19; iter: 0; batch classifier loss: 0.564899; batch adversarial loss: 0.466129\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532786; batch adversarial loss: 0.440131\n",
      "epoch 21; iter: 0; batch classifier loss: 0.555400; batch adversarial loss: 0.454796\n",
      "epoch 22; iter: 0; batch classifier loss: 0.589407; batch adversarial loss: 0.469179\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538821; batch adversarial loss: 0.507795\n",
      "epoch 24; iter: 0; batch classifier loss: 0.588539; batch adversarial loss: 0.367642\n",
      "epoch 25; iter: 0; batch classifier loss: 0.565754; batch adversarial loss: 0.433279\n",
      "epoch 26; iter: 0; batch classifier loss: 0.655898; batch adversarial loss: 0.485503\n",
      "epoch 27; iter: 0; batch classifier loss: 0.708072; batch adversarial loss: 0.500184\n",
      "epoch 28; iter: 0; batch classifier loss: 0.618735; batch adversarial loss: 0.410811\n",
      "epoch 29; iter: 0; batch classifier loss: 0.533331; batch adversarial loss: 0.465632\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550227; batch adversarial loss: 0.381990\n",
      "epoch 31; iter: 0; batch classifier loss: 0.606557; batch adversarial loss: 0.403485\n",
      "epoch 32; iter: 0; batch classifier loss: 0.637624; batch adversarial loss: 0.430676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.591244; batch adversarial loss: 0.395275\n",
      "epoch 34; iter: 0; batch classifier loss: 0.547848; batch adversarial loss: 0.335628\n",
      "epoch 35; iter: 0; batch classifier loss: 0.672219; batch adversarial loss: 0.437784\n",
      "epoch 36; iter: 0; batch classifier loss: 0.549804; batch adversarial loss: 0.381516\n",
      "epoch 37; iter: 0; batch classifier loss: 0.591833; batch adversarial loss: 0.414110\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442495; batch adversarial loss: 0.343606\n",
      "epoch 39; iter: 0; batch classifier loss: 0.563556; batch adversarial loss: 0.320199\n",
      "epoch 40; iter: 0; batch classifier loss: 0.520720; batch adversarial loss: 0.387157\n",
      "epoch 41; iter: 0; batch classifier loss: 0.597370; batch adversarial loss: 0.406597\n",
      "epoch 42; iter: 0; batch classifier loss: 0.499598; batch adversarial loss: 0.337273\n",
      "epoch 43; iter: 0; batch classifier loss: 0.537613; batch adversarial loss: 0.350907\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468179; batch adversarial loss: 0.314961\n",
      "epoch 45; iter: 0; batch classifier loss: 0.511783; batch adversarial loss: 0.340412\n",
      "epoch 46; iter: 0; batch classifier loss: 0.529937; batch adversarial loss: 0.300709\n",
      "epoch 47; iter: 0; batch classifier loss: 0.488026; batch adversarial loss: 0.268575\n",
      "epoch 48; iter: 0; batch classifier loss: 0.592231; batch adversarial loss: 0.382758\n",
      "epoch 49; iter: 0; batch classifier loss: 0.516213; batch adversarial loss: 0.368260\n",
      "epoch 50; iter: 0; batch classifier loss: 0.589572; batch adversarial loss: 0.313783\n",
      "epoch 51; iter: 0; batch classifier loss: 0.604832; batch adversarial loss: 0.364297\n",
      "epoch 52; iter: 0; batch classifier loss: 0.521859; batch adversarial loss: 0.282148\n",
      "epoch 53; iter: 0; batch classifier loss: 0.572840; batch adversarial loss: 0.398713\n",
      "epoch 54; iter: 0; batch classifier loss: 0.625150; batch adversarial loss: 0.278081\n",
      "epoch 55; iter: 0; batch classifier loss: 0.467503; batch adversarial loss: 0.249497\n",
      "epoch 56; iter: 0; batch classifier loss: 0.452706; batch adversarial loss: 0.352244\n",
      "epoch 57; iter: 0; batch classifier loss: 0.490685; batch adversarial loss: 0.352790\n",
      "epoch 58; iter: 0; batch classifier loss: 0.428341; batch adversarial loss: 0.365675\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467658; batch adversarial loss: 0.377475\n",
      "epoch 60; iter: 0; batch classifier loss: 0.487978; batch adversarial loss: 0.320099\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459495; batch adversarial loss: 0.248882\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479907; batch adversarial loss: 0.303519\n",
      "epoch 63; iter: 0; batch classifier loss: 0.460183; batch adversarial loss: 0.404350\n",
      "epoch 64; iter: 0; batch classifier loss: 0.372143; batch adversarial loss: 0.321182\n",
      "epoch 65; iter: 0; batch classifier loss: 0.455121; batch adversarial loss: 0.257608\n",
      "epoch 66; iter: 0; batch classifier loss: 0.323215; batch adversarial loss: 0.330468\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406229; batch adversarial loss: 0.344366\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413192; batch adversarial loss: 0.343437\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432229; batch adversarial loss: 0.280886\n",
      "epoch 70; iter: 0; batch classifier loss: 0.430254; batch adversarial loss: 0.343434\n",
      "epoch 71; iter: 0; batch classifier loss: 0.479380; batch adversarial loss: 0.279921\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414221; batch adversarial loss: 0.286467\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366009; batch adversarial loss: 0.286964\n",
      "epoch 74; iter: 0; batch classifier loss: 0.457067; batch adversarial loss: 0.364134\n",
      "epoch 75; iter: 0; batch classifier loss: 0.357466; batch adversarial loss: 0.308581\n",
      "epoch 76; iter: 0; batch classifier loss: 0.368224; batch adversarial loss: 0.314741\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413496; batch adversarial loss: 0.336622\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352557; batch adversarial loss: 0.228384\n",
      "epoch 79; iter: 0; batch classifier loss: 0.393730; batch adversarial loss: 0.367073\n",
      "epoch 80; iter: 0; batch classifier loss: 0.484437; batch adversarial loss: 0.418360\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417885; batch adversarial loss: 0.278311\n",
      "epoch 82; iter: 0; batch classifier loss: 0.458533; batch adversarial loss: 0.271827\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381864; batch adversarial loss: 0.276448\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446235; batch adversarial loss: 0.268733\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392873; batch adversarial loss: 0.396518\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415148; batch adversarial loss: 0.297218\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384161; batch adversarial loss: 0.312735\n",
      "epoch 88; iter: 0; batch classifier loss: 0.416538; batch adversarial loss: 0.259401\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391633; batch adversarial loss: 0.270207\n",
      "epoch 90; iter: 0; batch classifier loss: 0.451901; batch adversarial loss: 0.260225\n",
      "epoch 91; iter: 0; batch classifier loss: 0.412109; batch adversarial loss: 0.359538\n",
      "epoch 92; iter: 0; batch classifier loss: 0.385068; batch adversarial loss: 0.241859\n",
      "epoch 93; iter: 0; batch classifier loss: 0.339128; batch adversarial loss: 0.288569\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375067; batch adversarial loss: 0.285353\n",
      "epoch 95; iter: 0; batch classifier loss: 0.429842; batch adversarial loss: 0.293951\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380985; batch adversarial loss: 0.309056\n",
      "epoch 97; iter: 0; batch classifier loss: 0.361180; batch adversarial loss: 0.289628\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384828; batch adversarial loss: 0.254457\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351797; batch adversarial loss: 0.227545\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421828; batch adversarial loss: 0.300201\n",
      "epoch 101; iter: 0; batch classifier loss: 0.376354; batch adversarial loss: 0.260056\n",
      "epoch 102; iter: 0; batch classifier loss: 0.344767; batch adversarial loss: 0.273364\n",
      "epoch 103; iter: 0; batch classifier loss: 0.392927; batch adversarial loss: 0.363050\n",
      "epoch 104; iter: 0; batch classifier loss: 0.433594; batch adversarial loss: 0.290822\n",
      "epoch 105; iter: 0; batch classifier loss: 0.300466; batch adversarial loss: 0.337371\n",
      "epoch 106; iter: 0; batch classifier loss: 0.394281; batch adversarial loss: 0.270441\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364461; batch adversarial loss: 0.282054\n",
      "epoch 108; iter: 0; batch classifier loss: 0.371134; batch adversarial loss: 0.316064\n",
      "epoch 109; iter: 0; batch classifier loss: 0.374130; batch adversarial loss: 0.289523\n",
      "epoch 110; iter: 0; batch classifier loss: 0.416119; batch adversarial loss: 0.308474\n",
      "epoch 111; iter: 0; batch classifier loss: 0.335908; batch adversarial loss: 0.363709\n",
      "epoch 112; iter: 0; batch classifier loss: 0.384534; batch adversarial loss: 0.371691\n",
      "epoch 113; iter: 0; batch classifier loss: 0.347365; batch adversarial loss: 0.320869\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380568; batch adversarial loss: 0.233338\n",
      "epoch 115; iter: 0; batch classifier loss: 0.326148; batch adversarial loss: 0.219129\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355350; batch adversarial loss: 0.223779\n",
      "epoch 117; iter: 0; batch classifier loss: 0.335512; batch adversarial loss: 0.272813\n",
      "epoch 118; iter: 0; batch classifier loss: 0.292272; batch adversarial loss: 0.296808\n",
      "epoch 119; iter: 0; batch classifier loss: 0.372875; batch adversarial loss: 0.324779\n",
      "epoch 120; iter: 0; batch classifier loss: 0.295860; batch adversarial loss: 0.219624\n",
      "epoch 121; iter: 0; batch classifier loss: 0.318434; batch adversarial loss: 0.284881\n",
      "epoch 122; iter: 0; batch classifier loss: 0.397565; batch adversarial loss: 0.253456\n",
      "epoch 123; iter: 0; batch classifier loss: 0.361626; batch adversarial loss: 0.344383\n",
      "epoch 124; iter: 0; batch classifier loss: 0.334022; batch adversarial loss: 0.360489\n",
      "epoch 125; iter: 0; batch classifier loss: 0.407570; batch adversarial loss: 0.370156\n",
      "epoch 126; iter: 0; batch classifier loss: 0.367952; batch adversarial loss: 0.378461\n",
      "epoch 127; iter: 0; batch classifier loss: 0.449336; batch adversarial loss: 0.288683\n",
      "epoch 128; iter: 0; batch classifier loss: 0.309434; batch adversarial loss: 0.220884\n",
      "epoch 129; iter: 0; batch classifier loss: 0.283405; batch adversarial loss: 0.339517\n",
      "epoch 130; iter: 0; batch classifier loss: 0.369764; batch adversarial loss: 0.168123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.351708; batch adversarial loss: 0.325697\n",
      "epoch 132; iter: 0; batch classifier loss: 0.321259; batch adversarial loss: 0.347074\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346836; batch adversarial loss: 0.316494\n",
      "epoch 134; iter: 0; batch classifier loss: 0.289826; batch adversarial loss: 0.221916\n",
      "epoch 135; iter: 0; batch classifier loss: 0.314288; batch adversarial loss: 0.357237\n",
      "epoch 136; iter: 0; batch classifier loss: 0.350209; batch adversarial loss: 0.270805\n",
      "epoch 137; iter: 0; batch classifier loss: 0.356187; batch adversarial loss: 0.306294\n",
      "epoch 138; iter: 0; batch classifier loss: 0.316365; batch adversarial loss: 0.264359\n",
      "epoch 139; iter: 0; batch classifier loss: 0.376236; batch adversarial loss: 0.273089\n",
      "epoch 140; iter: 0; batch classifier loss: 0.386717; batch adversarial loss: 0.295682\n",
      "epoch 141; iter: 0; batch classifier loss: 0.351184; batch adversarial loss: 0.299288\n",
      "epoch 142; iter: 0; batch classifier loss: 0.310829; batch adversarial loss: 0.190552\n",
      "epoch 143; iter: 0; batch classifier loss: 0.299448; batch adversarial loss: 0.300509\n",
      "epoch 144; iter: 0; batch classifier loss: 0.345846; batch adversarial loss: 0.255011\n",
      "epoch 145; iter: 0; batch classifier loss: 0.368582; batch adversarial loss: 0.344772\n",
      "epoch 146; iter: 0; batch classifier loss: 0.377183; batch adversarial loss: 0.227912\n",
      "epoch 147; iter: 0; batch classifier loss: 0.313453; batch adversarial loss: 0.167303\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330400; batch adversarial loss: 0.347256\n",
      "epoch 149; iter: 0; batch classifier loss: 0.363985; batch adversarial loss: 0.244348\n",
      "epoch 150; iter: 0; batch classifier loss: 0.358105; batch adversarial loss: 0.323807\n",
      "epoch 151; iter: 0; batch classifier loss: 0.398208; batch adversarial loss: 0.275708\n",
      "epoch 152; iter: 0; batch classifier loss: 0.339049; batch adversarial loss: 0.294092\n",
      "epoch 153; iter: 0; batch classifier loss: 0.394420; batch adversarial loss: 0.322344\n",
      "epoch 154; iter: 0; batch classifier loss: 0.317898; batch adversarial loss: 0.329213\n",
      "epoch 155; iter: 0; batch classifier loss: 0.349928; batch adversarial loss: 0.167544\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373705; batch adversarial loss: 0.278152\n",
      "epoch 157; iter: 0; batch classifier loss: 0.324084; batch adversarial loss: 0.331816\n",
      "epoch 158; iter: 0; batch classifier loss: 0.314641; batch adversarial loss: 0.339562\n",
      "epoch 159; iter: 0; batch classifier loss: 0.270163; batch adversarial loss: 0.314296\n",
      "epoch 160; iter: 0; batch classifier loss: 0.325595; batch adversarial loss: 0.291753\n",
      "epoch 161; iter: 0; batch classifier loss: 0.372777; batch adversarial loss: 0.219527\n",
      "epoch 162; iter: 0; batch classifier loss: 0.276572; batch adversarial loss: 0.207974\n",
      "epoch 163; iter: 0; batch classifier loss: 0.238560; batch adversarial loss: 0.306502\n",
      "epoch 164; iter: 0; batch classifier loss: 0.356971; batch adversarial loss: 0.314050\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373652; batch adversarial loss: 0.220438\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367735; batch adversarial loss: 0.379174\n",
      "epoch 167; iter: 0; batch classifier loss: 0.395739; batch adversarial loss: 0.398632\n",
      "epoch 168; iter: 0; batch classifier loss: 0.321464; batch adversarial loss: 0.455482\n",
      "epoch 169; iter: 0; batch classifier loss: 0.307423; batch adversarial loss: 0.343825\n",
      "epoch 170; iter: 0; batch classifier loss: 0.302282; batch adversarial loss: 0.340640\n",
      "epoch 171; iter: 0; batch classifier loss: 0.401278; batch adversarial loss: 0.257697\n",
      "epoch 172; iter: 0; batch classifier loss: 0.283196; batch adversarial loss: 0.290286\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357462; batch adversarial loss: 0.331321\n",
      "epoch 174; iter: 0; batch classifier loss: 0.391163; batch adversarial loss: 0.433076\n",
      "epoch 175; iter: 0; batch classifier loss: 0.310410; batch adversarial loss: 0.424506\n",
      "epoch 176; iter: 0; batch classifier loss: 0.356361; batch adversarial loss: 0.315547\n",
      "epoch 177; iter: 0; batch classifier loss: 0.324116; batch adversarial loss: 0.223566\n",
      "epoch 178; iter: 0; batch classifier loss: 0.313846; batch adversarial loss: 0.343042\n",
      "epoch 179; iter: 0; batch classifier loss: 0.274412; batch adversarial loss: 0.270452\n",
      "epoch 180; iter: 0; batch classifier loss: 0.293881; batch adversarial loss: 0.399755\n",
      "epoch 181; iter: 0; batch classifier loss: 0.268099; batch adversarial loss: 0.292607\n",
      "epoch 182; iter: 0; batch classifier loss: 0.322687; batch adversarial loss: 0.350165\n",
      "epoch 183; iter: 0; batch classifier loss: 0.262435; batch adversarial loss: 0.356447\n",
      "epoch 184; iter: 0; batch classifier loss: 0.393738; batch adversarial loss: 0.291899\n",
      "epoch 185; iter: 0; batch classifier loss: 0.378711; batch adversarial loss: 0.363943\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315451; batch adversarial loss: 0.314769\n",
      "epoch 187; iter: 0; batch classifier loss: 0.339093; batch adversarial loss: 0.379415\n",
      "epoch 188; iter: 0; batch classifier loss: 0.272561; batch adversarial loss: 0.237510\n",
      "epoch 189; iter: 0; batch classifier loss: 0.341544; batch adversarial loss: 0.366024\n",
      "epoch 190; iter: 0; batch classifier loss: 0.256194; batch adversarial loss: 0.362171\n",
      "epoch 191; iter: 0; batch classifier loss: 0.321353; batch adversarial loss: 0.294856\n",
      "epoch 192; iter: 0; batch classifier loss: 0.305930; batch adversarial loss: 0.314324\n",
      "epoch 193; iter: 0; batch classifier loss: 0.271130; batch adversarial loss: 0.306737\n",
      "epoch 194; iter: 0; batch classifier loss: 0.382194; batch adversarial loss: 0.390162\n",
      "epoch 195; iter: 0; batch classifier loss: 0.306466; batch adversarial loss: 0.222508\n",
      "epoch 196; iter: 0; batch classifier loss: 0.326768; batch adversarial loss: 0.288978\n",
      "epoch 197; iter: 0; batch classifier loss: 0.305306; batch adversarial loss: 0.240071\n",
      "epoch 198; iter: 0; batch classifier loss: 0.347866; batch adversarial loss: 0.366943\n",
      "epoch 199; iter: 0; batch classifier loss: 0.278871; batch adversarial loss: 0.418824\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.149274; batch adversarial loss: 0.922015\n",
      "epoch 2; iter: 0; batch classifier loss: 1.056286; batch adversarial loss: 0.796183\n",
      "epoch 3; iter: 0; batch classifier loss: 0.823759; batch adversarial loss: 0.813106\n",
      "epoch 4; iter: 0; batch classifier loss: 0.749255; batch adversarial loss: 0.716821\n",
      "epoch 5; iter: 0; batch classifier loss: 0.632705; batch adversarial loss: 0.656523\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575254; batch adversarial loss: 0.636282\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584672; batch adversarial loss: 0.611883\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553303; batch adversarial loss: 0.601723\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537525; batch adversarial loss: 0.574588\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548483; batch adversarial loss: 0.582842\n",
      "epoch 11; iter: 0; batch classifier loss: 0.572853; batch adversarial loss: 0.542512\n",
      "epoch 12; iter: 0; batch classifier loss: 0.534074; batch adversarial loss: 0.536139\n",
      "epoch 13; iter: 0; batch classifier loss: 0.538109; batch adversarial loss: 0.529826\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524855; batch adversarial loss: 0.491365\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531557; batch adversarial loss: 0.470927\n",
      "epoch 16; iter: 0; batch classifier loss: 0.595210; batch adversarial loss: 0.453305\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505339; batch adversarial loss: 0.459565\n",
      "epoch 18; iter: 0; batch classifier loss: 0.549158; batch adversarial loss: 0.450505\n",
      "epoch 19; iter: 0; batch classifier loss: 0.532966; batch adversarial loss: 0.452005\n",
      "epoch 20; iter: 0; batch classifier loss: 0.507807; batch adversarial loss: 0.422283\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512461; batch adversarial loss: 0.434783\n",
      "epoch 22; iter: 0; batch classifier loss: 0.539172; batch adversarial loss: 0.450682\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497682; batch adversarial loss: 0.497203\n",
      "epoch 24; iter: 0; batch classifier loss: 0.561197; batch adversarial loss: 0.361078\n",
      "epoch 25; iter: 0; batch classifier loss: 0.522710; batch adversarial loss: 0.423121\n",
      "epoch 26; iter: 0; batch classifier loss: 0.591148; batch adversarial loss: 0.474378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.655035; batch adversarial loss: 0.496112\n",
      "epoch 28; iter: 0; batch classifier loss: 0.585428; batch adversarial loss: 0.406891\n",
      "epoch 29; iter: 0; batch classifier loss: 0.503009; batch adversarial loss: 0.465005\n",
      "epoch 30; iter: 0; batch classifier loss: 0.530951; batch adversarial loss: 0.380783\n",
      "epoch 31; iter: 0; batch classifier loss: 0.568497; batch adversarial loss: 0.402108\n",
      "epoch 32; iter: 0; batch classifier loss: 0.612818; batch adversarial loss: 0.432731\n",
      "epoch 33; iter: 0; batch classifier loss: 0.574781; batch adversarial loss: 0.395356\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544443; batch adversarial loss: 0.335888\n",
      "epoch 35; iter: 0; batch classifier loss: 0.645993; batch adversarial loss: 0.443153\n",
      "epoch 36; iter: 0; batch classifier loss: 0.553577; batch adversarial loss: 0.385570\n",
      "epoch 37; iter: 0; batch classifier loss: 0.589130; batch adversarial loss: 0.418582\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454520; batch adversarial loss: 0.346610\n",
      "epoch 39; iter: 0; batch classifier loss: 0.556729; batch adversarial loss: 0.322063\n",
      "epoch 40; iter: 0; batch classifier loss: 0.511365; batch adversarial loss: 0.390728\n",
      "epoch 41; iter: 0; batch classifier loss: 0.598347; batch adversarial loss: 0.412375\n",
      "epoch 42; iter: 0; batch classifier loss: 0.494011; batch adversarial loss: 0.340236\n",
      "epoch 43; iter: 0; batch classifier loss: 0.528257; batch adversarial loss: 0.354647\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466700; batch adversarial loss: 0.316549\n",
      "epoch 45; iter: 0; batch classifier loss: 0.525383; batch adversarial loss: 0.343566\n",
      "epoch 46; iter: 0; batch classifier loss: 0.544164; batch adversarial loss: 0.303136\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487675; batch adversarial loss: 0.269845\n",
      "epoch 48; iter: 0; batch classifier loss: 0.607526; batch adversarial loss: 0.387777\n",
      "epoch 49; iter: 0; batch classifier loss: 0.527594; batch adversarial loss: 0.372324\n",
      "epoch 50; iter: 0; batch classifier loss: 0.588735; batch adversarial loss: 0.316520\n",
      "epoch 51; iter: 0; batch classifier loss: 0.600185; batch adversarial loss: 0.367952\n",
      "epoch 52; iter: 0; batch classifier loss: 0.512569; batch adversarial loss: 0.283602\n",
      "epoch 53; iter: 0; batch classifier loss: 0.567935; batch adversarial loss: 0.403262\n",
      "epoch 54; iter: 0; batch classifier loss: 0.579222; batch adversarial loss: 0.279932\n",
      "epoch 55; iter: 0; batch classifier loss: 0.584280; batch adversarial loss: 0.251652\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451868; batch adversarial loss: 0.352988\n",
      "epoch 57; iter: 0; batch classifier loss: 0.503614; batch adversarial loss: 0.353178\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427880; batch adversarial loss: 0.366097\n",
      "epoch 59; iter: 0; batch classifier loss: 0.457345; batch adversarial loss: 0.377628\n",
      "epoch 60; iter: 0; batch classifier loss: 0.480097; batch adversarial loss: 0.320393\n",
      "epoch 61; iter: 0; batch classifier loss: 0.458378; batch adversarial loss: 0.249518\n",
      "epoch 62; iter: 0; batch classifier loss: 0.478855; batch adversarial loss: 0.303873\n",
      "epoch 63; iter: 0; batch classifier loss: 0.456867; batch adversarial loss: 0.404327\n",
      "epoch 64; iter: 0; batch classifier loss: 0.357163; batch adversarial loss: 0.321550\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441359; batch adversarial loss: 0.258073\n",
      "epoch 66; iter: 0; batch classifier loss: 0.317168; batch adversarial loss: 0.330716\n",
      "epoch 67; iter: 0; batch classifier loss: 0.400044; batch adversarial loss: 0.344506\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403126; batch adversarial loss: 0.343152\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419636; batch adversarial loss: 0.280839\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414759; batch adversarial loss: 0.343604\n",
      "epoch 71; iter: 0; batch classifier loss: 0.479206; batch adversarial loss: 0.280091\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412258; batch adversarial loss: 0.286835\n",
      "epoch 73; iter: 0; batch classifier loss: 0.379195; batch adversarial loss: 0.287893\n",
      "epoch 74; iter: 0; batch classifier loss: 0.444234; batch adversarial loss: 0.364192\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354509; batch adversarial loss: 0.308423\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376283; batch adversarial loss: 0.315075\n",
      "epoch 77; iter: 0; batch classifier loss: 0.415868; batch adversarial loss: 0.336620\n",
      "epoch 78; iter: 0; batch classifier loss: 0.351266; batch adversarial loss: 0.228274\n",
      "epoch 79; iter: 0; batch classifier loss: 0.370686; batch adversarial loss: 0.367353\n",
      "epoch 80; iter: 0; batch classifier loss: 0.473617; batch adversarial loss: 0.418841\n",
      "epoch 81; iter: 0; batch classifier loss: 0.407552; batch adversarial loss: 0.277965\n",
      "epoch 82; iter: 0; batch classifier loss: 0.450599; batch adversarial loss: 0.271411\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382354; batch adversarial loss: 0.276502\n",
      "epoch 84; iter: 0; batch classifier loss: 0.441818; batch adversarial loss: 0.269143\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387332; batch adversarial loss: 0.396829\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407943; batch adversarial loss: 0.297088\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367961; batch adversarial loss: 0.312918\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417567; batch adversarial loss: 0.259313\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383996; batch adversarial loss: 0.269779\n",
      "epoch 90; iter: 0; batch classifier loss: 0.448845; batch adversarial loss: 0.260353\n",
      "epoch 91; iter: 0; batch classifier loss: 0.400761; batch adversarial loss: 0.360430\n",
      "epoch 92; iter: 0; batch classifier loss: 0.366779; batch adversarial loss: 0.241359\n",
      "epoch 93; iter: 0; batch classifier loss: 0.340928; batch adversarial loss: 0.288298\n",
      "epoch 94; iter: 0; batch classifier loss: 0.371448; batch adversarial loss: 0.285036\n",
      "epoch 95; iter: 0; batch classifier loss: 0.416969; batch adversarial loss: 0.294276\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370916; batch adversarial loss: 0.309245\n",
      "epoch 97; iter: 0; batch classifier loss: 0.373988; batch adversarial loss: 0.289093\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384181; batch adversarial loss: 0.254066\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351226; batch adversarial loss: 0.227980\n",
      "epoch 100; iter: 0; batch classifier loss: 0.425764; batch adversarial loss: 0.299932\n",
      "epoch 101; iter: 0; batch classifier loss: 0.393890; batch adversarial loss: 0.260225\n",
      "epoch 102; iter: 0; batch classifier loss: 0.331845; batch adversarial loss: 0.273160\n",
      "epoch 103; iter: 0; batch classifier loss: 0.406983; batch adversarial loss: 0.363399\n",
      "epoch 104; iter: 0; batch classifier loss: 0.438099; batch adversarial loss: 0.291338\n",
      "epoch 105; iter: 0; batch classifier loss: 0.294006; batch adversarial loss: 0.337534\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383498; batch adversarial loss: 0.269972\n",
      "epoch 107; iter: 0; batch classifier loss: 0.353888; batch adversarial loss: 0.281902\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378320; batch adversarial loss: 0.315519\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367243; batch adversarial loss: 0.289672\n",
      "epoch 110; iter: 0; batch classifier loss: 0.413117; batch adversarial loss: 0.308308\n",
      "epoch 111; iter: 0; batch classifier loss: 0.329160; batch adversarial loss: 0.363344\n",
      "epoch 112; iter: 0; batch classifier loss: 0.375449; batch adversarial loss: 0.371466\n",
      "epoch 113; iter: 0; batch classifier loss: 0.344446; batch adversarial loss: 0.320731\n",
      "epoch 114; iter: 0; batch classifier loss: 0.366519; batch adversarial loss: 0.232772\n",
      "epoch 115; iter: 0; batch classifier loss: 0.326045; batch adversarial loss: 0.219139\n",
      "epoch 116; iter: 0; batch classifier loss: 0.343965; batch adversarial loss: 0.223642\n",
      "epoch 117; iter: 0; batch classifier loss: 0.312671; batch adversarial loss: 0.272388\n",
      "epoch 118; iter: 0; batch classifier loss: 0.300061; batch adversarial loss: 0.297265\n",
      "epoch 119; iter: 0; batch classifier loss: 0.362767; batch adversarial loss: 0.324238\n",
      "epoch 120; iter: 0; batch classifier loss: 0.295849; batch adversarial loss: 0.219353\n",
      "epoch 121; iter: 0; batch classifier loss: 0.309665; batch adversarial loss: 0.284601\n",
      "epoch 122; iter: 0; batch classifier loss: 0.399903; batch adversarial loss: 0.252688\n",
      "epoch 123; iter: 0; batch classifier loss: 0.348949; batch adversarial loss: 0.345016\n",
      "epoch 124; iter: 0; batch classifier loss: 0.330967; batch adversarial loss: 0.361431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125; iter: 0; batch classifier loss: 0.399642; batch adversarial loss: 0.369429\n",
      "epoch 126; iter: 0; batch classifier loss: 0.371791; batch adversarial loss: 0.378409\n",
      "epoch 127; iter: 0; batch classifier loss: 0.419964; batch adversarial loss: 0.289281\n",
      "epoch 128; iter: 0; batch classifier loss: 0.312409; batch adversarial loss: 0.220690\n",
      "epoch 129; iter: 0; batch classifier loss: 0.282752; batch adversarial loss: 0.338525\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364088; batch adversarial loss: 0.167854\n",
      "epoch 131; iter: 0; batch classifier loss: 0.342221; batch adversarial loss: 0.325080\n",
      "epoch 132; iter: 0; batch classifier loss: 0.320284; batch adversarial loss: 0.346670\n",
      "epoch 133; iter: 0; batch classifier loss: 0.346923; batch adversarial loss: 0.317167\n",
      "epoch 134; iter: 0; batch classifier loss: 0.282836; batch adversarial loss: 0.221602\n",
      "epoch 135; iter: 0; batch classifier loss: 0.324843; batch adversarial loss: 0.357382\n",
      "epoch 136; iter: 0; batch classifier loss: 0.332128; batch adversarial loss: 0.270459\n",
      "epoch 137; iter: 0; batch classifier loss: 0.357065; batch adversarial loss: 0.306004\n",
      "epoch 138; iter: 0; batch classifier loss: 0.318273; batch adversarial loss: 0.264713\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368154; batch adversarial loss: 0.272815\n",
      "epoch 140; iter: 0; batch classifier loss: 0.379291; batch adversarial loss: 0.295363\n",
      "epoch 141; iter: 0; batch classifier loss: 0.348063; batch adversarial loss: 0.300072\n",
      "epoch 142; iter: 0; batch classifier loss: 0.328143; batch adversarial loss: 0.190618\n",
      "epoch 143; iter: 0; batch classifier loss: 0.298486; batch adversarial loss: 0.301600\n",
      "epoch 144; iter: 0; batch classifier loss: 0.349753; batch adversarial loss: 0.254617\n",
      "epoch 145; iter: 0; batch classifier loss: 0.376586; batch adversarial loss: 0.342891\n",
      "epoch 146; iter: 0; batch classifier loss: 0.373973; batch adversarial loss: 0.227839\n",
      "epoch 147; iter: 0; batch classifier loss: 0.312883; batch adversarial loss: 0.167078\n",
      "epoch 148; iter: 0; batch classifier loss: 0.328203; batch adversarial loss: 0.347359\n",
      "epoch 149; iter: 0; batch classifier loss: 0.370027; batch adversarial loss: 0.244500\n",
      "epoch 150; iter: 0; batch classifier loss: 0.342258; batch adversarial loss: 0.323413\n",
      "epoch 151; iter: 0; batch classifier loss: 0.384762; batch adversarial loss: 0.275548\n",
      "epoch 152; iter: 0; batch classifier loss: 0.331717; batch adversarial loss: 0.293881\n",
      "epoch 153; iter: 0; batch classifier loss: 0.382802; batch adversarial loss: 0.321506\n",
      "epoch 154; iter: 0; batch classifier loss: 0.314410; batch adversarial loss: 0.328904\n",
      "epoch 155; iter: 0; batch classifier loss: 0.334875; batch adversarial loss: 0.167472\n",
      "epoch 156; iter: 0; batch classifier loss: 0.362236; batch adversarial loss: 0.278004\n",
      "epoch 157; iter: 0; batch classifier loss: 0.307639; batch adversarial loss: 0.332134\n",
      "epoch 158; iter: 0; batch classifier loss: 0.330356; batch adversarial loss: 0.339295\n",
      "epoch 159; iter: 0; batch classifier loss: 0.278035; batch adversarial loss: 0.314405\n",
      "epoch 160; iter: 0; batch classifier loss: 0.293327; batch adversarial loss: 0.291002\n",
      "epoch 161; iter: 0; batch classifier loss: 0.365106; batch adversarial loss: 0.218557\n",
      "epoch 162; iter: 0; batch classifier loss: 0.253029; batch adversarial loss: 0.207732\n",
      "epoch 163; iter: 0; batch classifier loss: 0.247328; batch adversarial loss: 0.306210\n",
      "epoch 164; iter: 0; batch classifier loss: 0.347961; batch adversarial loss: 0.314698\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386232; batch adversarial loss: 0.220467\n",
      "epoch 166; iter: 0; batch classifier loss: 0.371993; batch adversarial loss: 0.378738\n",
      "epoch 167; iter: 0; batch classifier loss: 0.362381; batch adversarial loss: 0.399415\n",
      "epoch 168; iter: 0; batch classifier loss: 0.325760; batch adversarial loss: 0.455466\n",
      "epoch 169; iter: 0; batch classifier loss: 0.302371; batch adversarial loss: 0.344178\n",
      "epoch 170; iter: 0; batch classifier loss: 0.291494; batch adversarial loss: 0.339889\n",
      "epoch 171; iter: 0; batch classifier loss: 0.407021; batch adversarial loss: 0.257381\n",
      "epoch 172; iter: 0; batch classifier loss: 0.282591; batch adversarial loss: 0.290611\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354997; batch adversarial loss: 0.331627\n",
      "epoch 174; iter: 0; batch classifier loss: 0.347712; batch adversarial loss: 0.431898\n",
      "epoch 175; iter: 0; batch classifier loss: 0.281673; batch adversarial loss: 0.424987\n",
      "epoch 176; iter: 0; batch classifier loss: 0.352339; batch adversarial loss: 0.315814\n",
      "epoch 177; iter: 0; batch classifier loss: 0.303224; batch adversarial loss: 0.223832\n",
      "epoch 178; iter: 0; batch classifier loss: 0.320910; batch adversarial loss: 0.342270\n",
      "epoch 179; iter: 0; batch classifier loss: 0.271824; batch adversarial loss: 0.269819\n",
      "epoch 180; iter: 0; batch classifier loss: 0.287191; batch adversarial loss: 0.399978\n",
      "epoch 181; iter: 0; batch classifier loss: 0.271192; batch adversarial loss: 0.292190\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336609; batch adversarial loss: 0.350483\n",
      "epoch 183; iter: 0; batch classifier loss: 0.250896; batch adversarial loss: 0.355657\n",
      "epoch 184; iter: 0; batch classifier loss: 0.369136; batch adversarial loss: 0.290885\n",
      "epoch 185; iter: 0; batch classifier loss: 0.389206; batch adversarial loss: 0.363261\n",
      "epoch 186; iter: 0; batch classifier loss: 0.304972; batch adversarial loss: 0.315245\n",
      "epoch 187; iter: 0; batch classifier loss: 0.353117; batch adversarial loss: 0.379268\n",
      "epoch 188; iter: 0; batch classifier loss: 0.265878; batch adversarial loss: 0.237059\n",
      "epoch 189; iter: 0; batch classifier loss: 0.344826; batch adversarial loss: 0.366274\n",
      "epoch 190; iter: 0; batch classifier loss: 0.240064; batch adversarial loss: 0.361822\n",
      "epoch 191; iter: 0; batch classifier loss: 0.337695; batch adversarial loss: 0.296194\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317015; batch adversarial loss: 0.314160\n",
      "epoch 193; iter: 0; batch classifier loss: 0.251783; batch adversarial loss: 0.305964\n",
      "epoch 194; iter: 0; batch classifier loss: 0.369176; batch adversarial loss: 0.391085\n",
      "epoch 195; iter: 0; batch classifier loss: 0.321530; batch adversarial loss: 0.222341\n",
      "epoch 196; iter: 0; batch classifier loss: 0.301746; batch adversarial loss: 0.288364\n",
      "epoch 197; iter: 0; batch classifier loss: 0.328012; batch adversarial loss: 0.239731\n",
      "epoch 198; iter: 0; batch classifier loss: 0.359479; batch adversarial loss: 0.367105\n",
      "epoch 199; iter: 0; batch classifier loss: 0.256421; batch adversarial loss: 0.418369\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.222147; batch adversarial loss: 0.925272\n",
      "epoch 2; iter: 0; batch classifier loss: 1.112455; batch adversarial loss: 0.799199\n",
      "epoch 3; iter: 0; batch classifier loss: 0.868499; batch adversarial loss: 0.818016\n",
      "epoch 4; iter: 0; batch classifier loss: 0.799895; batch adversarial loss: 0.723098\n",
      "epoch 5; iter: 0; batch classifier loss: 0.667402; batch adversarial loss: 0.662094\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581884; batch adversarial loss: 0.636120\n",
      "epoch 7; iter: 0; batch classifier loss: 0.581175; batch adversarial loss: 0.612356\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551478; batch adversarial loss: 0.601604\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539283; batch adversarial loss: 0.573393\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542581; batch adversarial loss: 0.582556\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568625; batch adversarial loss: 0.541763\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531774; batch adversarial loss: 0.535060\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534272; batch adversarial loss: 0.528847\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515677; batch adversarial loss: 0.492785\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526104; batch adversarial loss: 0.473355\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591869; batch adversarial loss: 0.456007\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506725; batch adversarial loss: 0.462505\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543854; batch adversarial loss: 0.453472\n",
      "epoch 19; iter: 0; batch classifier loss: 0.544596; batch adversarial loss: 0.459420\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517097; batch adversarial loss: 0.431314\n",
      "epoch 21; iter: 0; batch classifier loss: 0.532241; batch adversarial loss: 0.446764\n",
      "epoch 22; iter: 0; batch classifier loss: 0.568146; batch adversarial loss: 0.461917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.523025; batch adversarial loss: 0.505747\n",
      "epoch 24; iter: 0; batch classifier loss: 0.579547; batch adversarial loss: 0.365648\n",
      "epoch 25; iter: 0; batch classifier loss: 0.549083; batch adversarial loss: 0.430132\n",
      "epoch 26; iter: 0; batch classifier loss: 0.634158; batch adversarial loss: 0.483301\n",
      "epoch 27; iter: 0; batch classifier loss: 0.690808; batch adversarial loss: 0.500313\n",
      "epoch 28; iter: 0; batch classifier loss: 0.610276; batch adversarial loss: 0.410037\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524764; batch adversarial loss: 0.467046\n",
      "epoch 30; iter: 0; batch classifier loss: 0.548422; batch adversarial loss: 0.382098\n",
      "epoch 31; iter: 0; batch classifier loss: 0.597891; batch adversarial loss: 0.403711\n",
      "epoch 32; iter: 0; batch classifier loss: 0.627896; batch adversarial loss: 0.431826\n",
      "epoch 33; iter: 0; batch classifier loss: 0.587292; batch adversarial loss: 0.395561\n",
      "epoch 34; iter: 0; batch classifier loss: 0.545803; batch adversarial loss: 0.335751\n",
      "epoch 35; iter: 0; batch classifier loss: 0.661441; batch adversarial loss: 0.439299\n",
      "epoch 36; iter: 0; batch classifier loss: 0.551783; batch adversarial loss: 0.383199\n",
      "epoch 37; iter: 0; batch classifier loss: 0.590764; batch adversarial loss: 0.415587\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440803; batch adversarial loss: 0.344365\n",
      "epoch 39; iter: 0; batch classifier loss: 0.560768; batch adversarial loss: 0.320903\n",
      "epoch 40; iter: 0; batch classifier loss: 0.517747; batch adversarial loss: 0.388319\n",
      "epoch 41; iter: 0; batch classifier loss: 0.592576; batch adversarial loss: 0.408504\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498193; batch adversarial loss: 0.338367\n",
      "epoch 43; iter: 0; batch classifier loss: 0.540588; batch adversarial loss: 0.352248\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462218; batch adversarial loss: 0.315215\n",
      "epoch 45; iter: 0; batch classifier loss: 0.519356; batch adversarial loss: 0.341320\n",
      "epoch 46; iter: 0; batch classifier loss: 0.538762; batch adversarial loss: 0.301616\n",
      "epoch 47; iter: 0; batch classifier loss: 0.493171; batch adversarial loss: 0.269128\n",
      "epoch 48; iter: 0; batch classifier loss: 0.594371; batch adversarial loss: 0.384259\n",
      "epoch 49; iter: 0; batch classifier loss: 0.523637; batch adversarial loss: 0.369513\n",
      "epoch 50; iter: 0; batch classifier loss: 0.593701; batch adversarial loss: 0.314404\n",
      "epoch 51; iter: 0; batch classifier loss: 0.592922; batch adversarial loss: 0.365284\n",
      "epoch 52; iter: 0; batch classifier loss: 0.520304; batch adversarial loss: 0.282552\n",
      "epoch 53; iter: 0; batch classifier loss: 0.575455; batch adversarial loss: 0.400267\n",
      "epoch 54; iter: 0; batch classifier loss: 0.610908; batch adversarial loss: 0.278753\n",
      "epoch 55; iter: 0; batch classifier loss: 0.507002; batch adversarial loss: 0.250156\n",
      "epoch 56; iter: 0; batch classifier loss: 0.444311; batch adversarial loss: 0.352573\n",
      "epoch 57; iter: 0; batch classifier loss: 0.493104; batch adversarial loss: 0.352767\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421237; batch adversarial loss: 0.365751\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466983; batch adversarial loss: 0.377525\n",
      "epoch 60; iter: 0; batch classifier loss: 0.479544; batch adversarial loss: 0.320182\n",
      "epoch 61; iter: 0; batch classifier loss: 0.461404; batch adversarial loss: 0.249103\n",
      "epoch 62; iter: 0; batch classifier loss: 0.480757; batch adversarial loss: 0.303527\n",
      "epoch 63; iter: 0; batch classifier loss: 0.468793; batch adversarial loss: 0.404527\n",
      "epoch 64; iter: 0; batch classifier loss: 0.359965; batch adversarial loss: 0.321355\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448554; batch adversarial loss: 0.257730\n",
      "epoch 66; iter: 0; batch classifier loss: 0.319762; batch adversarial loss: 0.330560\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408561; batch adversarial loss: 0.344197\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404776; batch adversarial loss: 0.343424\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428529; batch adversarial loss: 0.280792\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421883; batch adversarial loss: 0.343456\n",
      "epoch 71; iter: 0; batch classifier loss: 0.479157; batch adversarial loss: 0.279961\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412079; batch adversarial loss: 0.286482\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369937; batch adversarial loss: 0.287185\n",
      "epoch 74; iter: 0; batch classifier loss: 0.457966; batch adversarial loss: 0.364619\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354952; batch adversarial loss: 0.308439\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369755; batch adversarial loss: 0.314940\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411444; batch adversarial loss: 0.336571\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362222; batch adversarial loss: 0.228374\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381638; batch adversarial loss: 0.367007\n",
      "epoch 80; iter: 0; batch classifier loss: 0.477926; batch adversarial loss: 0.418106\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422495; batch adversarial loss: 0.278106\n",
      "epoch 82; iter: 0; batch classifier loss: 0.462938; batch adversarial loss: 0.271744\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381175; batch adversarial loss: 0.276263\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440719; batch adversarial loss: 0.268878\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395620; batch adversarial loss: 0.396584\n",
      "epoch 86; iter: 0; batch classifier loss: 0.408290; batch adversarial loss: 0.296931\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377137; batch adversarial loss: 0.312645\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422305; batch adversarial loss: 0.258787\n",
      "epoch 89; iter: 0; batch classifier loss: 0.390141; batch adversarial loss: 0.269931\n",
      "epoch 90; iter: 0; batch classifier loss: 0.456433; batch adversarial loss: 0.260429\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409145; batch adversarial loss: 0.360059\n",
      "epoch 92; iter: 0; batch classifier loss: 0.373047; batch adversarial loss: 0.241835\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353097; batch adversarial loss: 0.288369\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378077; batch adversarial loss: 0.285377\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407613; batch adversarial loss: 0.294077\n",
      "epoch 96; iter: 0; batch classifier loss: 0.365976; batch adversarial loss: 0.309042\n",
      "epoch 97; iter: 0; batch classifier loss: 0.362533; batch adversarial loss: 0.290067\n",
      "epoch 98; iter: 0; batch classifier loss: 0.394327; batch adversarial loss: 0.254527\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355099; batch adversarial loss: 0.227658\n",
      "epoch 100; iter: 0; batch classifier loss: 0.430667; batch adversarial loss: 0.300266\n",
      "epoch 101; iter: 0; batch classifier loss: 0.379148; batch adversarial loss: 0.260106\n",
      "epoch 102; iter: 0; batch classifier loss: 0.325984; batch adversarial loss: 0.273167\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398625; batch adversarial loss: 0.362738\n",
      "epoch 104; iter: 0; batch classifier loss: 0.424045; batch adversarial loss: 0.290787\n",
      "epoch 105; iter: 0; batch classifier loss: 0.292827; batch adversarial loss: 0.336814\n",
      "epoch 106; iter: 0; batch classifier loss: 0.387807; batch adversarial loss: 0.270499\n",
      "epoch 107; iter: 0; batch classifier loss: 0.365730; batch adversarial loss: 0.282026\n",
      "epoch 108; iter: 0; batch classifier loss: 0.378479; batch adversarial loss: 0.315967\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386763; batch adversarial loss: 0.289658\n",
      "epoch 110; iter: 0; batch classifier loss: 0.412400; batch adversarial loss: 0.308073\n",
      "epoch 111; iter: 0; batch classifier loss: 0.312991; batch adversarial loss: 0.363470\n",
      "epoch 112; iter: 0; batch classifier loss: 0.391946; batch adversarial loss: 0.371596\n",
      "epoch 113; iter: 0; batch classifier loss: 0.345320; batch adversarial loss: 0.321063\n",
      "epoch 114; iter: 0; batch classifier loss: 0.380520; batch adversarial loss: 0.233193\n",
      "epoch 115; iter: 0; batch classifier loss: 0.340442; batch adversarial loss: 0.219336\n",
      "epoch 116; iter: 0; batch classifier loss: 0.341053; batch adversarial loss: 0.223819\n",
      "epoch 117; iter: 0; batch classifier loss: 0.339647; batch adversarial loss: 0.272974\n",
      "epoch 118; iter: 0; batch classifier loss: 0.297592; batch adversarial loss: 0.296820\n",
      "epoch 119; iter: 0; batch classifier loss: 0.380511; batch adversarial loss: 0.325038\n",
      "epoch 120; iter: 0; batch classifier loss: 0.294582; batch adversarial loss: 0.219454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 121; iter: 0; batch classifier loss: 0.320284; batch adversarial loss: 0.285088\n",
      "epoch 122; iter: 0; batch classifier loss: 0.389607; batch adversarial loss: 0.253326\n",
      "epoch 123; iter: 0; batch classifier loss: 0.351306; batch adversarial loss: 0.344136\n",
      "epoch 124; iter: 0; batch classifier loss: 0.338175; batch adversarial loss: 0.361136\n",
      "epoch 125; iter: 0; batch classifier loss: 0.393872; batch adversarial loss: 0.370223\n",
      "epoch 126; iter: 0; batch classifier loss: 0.362981; batch adversarial loss: 0.377857\n",
      "epoch 127; iter: 0; batch classifier loss: 0.457547; batch adversarial loss: 0.288379\n",
      "epoch 128; iter: 0; batch classifier loss: 0.316918; batch adversarial loss: 0.220871\n",
      "epoch 129; iter: 0; batch classifier loss: 0.287090; batch adversarial loss: 0.339392\n",
      "epoch 130; iter: 0; batch classifier loss: 0.378021; batch adversarial loss: 0.168113\n",
      "epoch 131; iter: 0; batch classifier loss: 0.338819; batch adversarial loss: 0.325055\n",
      "epoch 132; iter: 0; batch classifier loss: 0.325989; batch adversarial loss: 0.346179\n",
      "epoch 133; iter: 0; batch classifier loss: 0.344157; batch adversarial loss: 0.317320\n",
      "epoch 134; iter: 0; batch classifier loss: 0.283534; batch adversarial loss: 0.222656\n",
      "epoch 135; iter: 0; batch classifier loss: 0.320836; batch adversarial loss: 0.357437\n",
      "epoch 136; iter: 0; batch classifier loss: 0.357291; batch adversarial loss: 0.270478\n",
      "epoch 137; iter: 0; batch classifier loss: 0.353126; batch adversarial loss: 0.306195\n",
      "epoch 138; iter: 0; batch classifier loss: 0.310217; batch adversarial loss: 0.264192\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368965; batch adversarial loss: 0.272645\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383433; batch adversarial loss: 0.295638\n",
      "epoch 141; iter: 0; batch classifier loss: 0.357913; batch adversarial loss: 0.299632\n",
      "epoch 142; iter: 0; batch classifier loss: 0.318409; batch adversarial loss: 0.190795\n",
      "epoch 143; iter: 0; batch classifier loss: 0.297570; batch adversarial loss: 0.300741\n",
      "epoch 144; iter: 0; batch classifier loss: 0.339110; batch adversarial loss: 0.254837\n",
      "epoch 145; iter: 0; batch classifier loss: 0.371086; batch adversarial loss: 0.344456\n",
      "epoch 146; iter: 0; batch classifier loss: 0.377794; batch adversarial loss: 0.227701\n",
      "epoch 147; iter: 0; batch classifier loss: 0.297634; batch adversarial loss: 0.167139\n",
      "epoch 148; iter: 0; batch classifier loss: 0.327290; batch adversarial loss: 0.347441\n",
      "epoch 149; iter: 0; batch classifier loss: 0.366156; batch adversarial loss: 0.244078\n",
      "epoch 150; iter: 0; batch classifier loss: 0.335700; batch adversarial loss: 0.323676\n",
      "epoch 151; iter: 0; batch classifier loss: 0.387140; batch adversarial loss: 0.275737\n",
      "epoch 152; iter: 0; batch classifier loss: 0.332929; batch adversarial loss: 0.294013\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391553; batch adversarial loss: 0.322124\n",
      "epoch 154; iter: 0; batch classifier loss: 0.306764; batch adversarial loss: 0.329331\n",
      "epoch 155; iter: 0; batch classifier loss: 0.339194; batch adversarial loss: 0.167574\n",
      "epoch 156; iter: 0; batch classifier loss: 0.380053; batch adversarial loss: 0.278366\n",
      "epoch 157; iter: 0; batch classifier loss: 0.334921; batch adversarial loss: 0.331692\n",
      "epoch 158; iter: 0; batch classifier loss: 0.306525; batch adversarial loss: 0.339358\n",
      "epoch 159; iter: 0; batch classifier loss: 0.277224; batch adversarial loss: 0.314280\n",
      "epoch 160; iter: 0; batch classifier loss: 0.311988; batch adversarial loss: 0.291235\n",
      "epoch 161; iter: 0; batch classifier loss: 0.351424; batch adversarial loss: 0.218874\n",
      "epoch 162; iter: 0; batch classifier loss: 0.265209; batch adversarial loss: 0.208055\n",
      "epoch 163; iter: 0; batch classifier loss: 0.241859; batch adversarial loss: 0.306059\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345653; batch adversarial loss: 0.314044\n",
      "epoch 165; iter: 0; batch classifier loss: 0.373812; batch adversarial loss: 0.220253\n",
      "epoch 166; iter: 0; batch classifier loss: 0.368302; batch adversarial loss: 0.378560\n",
      "epoch 167; iter: 0; batch classifier loss: 0.364832; batch adversarial loss: 0.398665\n",
      "epoch 168; iter: 0; batch classifier loss: 0.302522; batch adversarial loss: 0.454883\n",
      "epoch 169; iter: 0; batch classifier loss: 0.291783; batch adversarial loss: 0.344152\n",
      "epoch 170; iter: 0; batch classifier loss: 0.295123; batch adversarial loss: 0.340394\n",
      "epoch 171; iter: 0; batch classifier loss: 0.410861; batch adversarial loss: 0.258148\n",
      "epoch 172; iter: 0; batch classifier loss: 0.286718; batch adversarial loss: 0.290499\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350663; batch adversarial loss: 0.330994\n",
      "epoch 174; iter: 0; batch classifier loss: 0.371913; batch adversarial loss: 0.432749\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308496; batch adversarial loss: 0.424832\n",
      "epoch 176; iter: 0; batch classifier loss: 0.347079; batch adversarial loss: 0.315785\n",
      "epoch 177; iter: 0; batch classifier loss: 0.312138; batch adversarial loss: 0.223677\n",
      "epoch 178; iter: 0; batch classifier loss: 0.307072; batch adversarial loss: 0.343647\n",
      "epoch 179; iter: 0; batch classifier loss: 0.268712; batch adversarial loss: 0.270326\n",
      "epoch 180; iter: 0; batch classifier loss: 0.307250; batch adversarial loss: 0.399565\n",
      "epoch 181; iter: 0; batch classifier loss: 0.263414; batch adversarial loss: 0.291869\n",
      "epoch 182; iter: 0; batch classifier loss: 0.317809; batch adversarial loss: 0.350982\n",
      "epoch 183; iter: 0; batch classifier loss: 0.244127; batch adversarial loss: 0.355989\n",
      "epoch 184; iter: 0; batch classifier loss: 0.366189; batch adversarial loss: 0.291495\n",
      "epoch 185; iter: 0; batch classifier loss: 0.369056; batch adversarial loss: 0.363694\n",
      "epoch 186; iter: 0; batch classifier loss: 0.322291; batch adversarial loss: 0.314877\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340380; batch adversarial loss: 0.379349\n",
      "epoch 188; iter: 0; batch classifier loss: 0.268554; batch adversarial loss: 0.237325\n",
      "epoch 189; iter: 0; batch classifier loss: 0.350818; batch adversarial loss: 0.366307\n",
      "epoch 190; iter: 0; batch classifier loss: 0.256385; batch adversarial loss: 0.361710\n",
      "epoch 191; iter: 0; batch classifier loss: 0.310715; batch adversarial loss: 0.295521\n",
      "epoch 192; iter: 0; batch classifier loss: 0.308900; batch adversarial loss: 0.313988\n",
      "epoch 193; iter: 0; batch classifier loss: 0.270860; batch adversarial loss: 0.306655\n",
      "epoch 194; iter: 0; batch classifier loss: 0.385468; batch adversarial loss: 0.391068\n",
      "epoch 195; iter: 0; batch classifier loss: 0.311596; batch adversarial loss: 0.222168\n",
      "epoch 196; iter: 0; batch classifier loss: 0.294240; batch adversarial loss: 0.288384\n",
      "epoch 197; iter: 0; batch classifier loss: 0.318490; batch adversarial loss: 0.240315\n",
      "epoch 198; iter: 0; batch classifier loss: 0.361484; batch adversarial loss: 0.367029\n",
      "epoch 199; iter: 0; batch classifier loss: 0.272589; batch adversarial loss: 0.418362\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.257897; batch adversarial loss: 0.926549\n",
      "epoch 2; iter: 0; batch classifier loss: 1.138939; batch adversarial loss: 0.800373\n",
      "epoch 3; iter: 0; batch classifier loss: 0.892240; batch adversarial loss: 0.819902\n",
      "epoch 4; iter: 0; batch classifier loss: 0.827580; batch adversarial loss: 0.725423\n",
      "epoch 5; iter: 0; batch classifier loss: 0.687645; batch adversarial loss: 0.664537\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585592; batch adversarial loss: 0.636129\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580395; batch adversarial loss: 0.612590\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551394; batch adversarial loss: 0.601471\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540312; batch adversarial loss: 0.572904\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540178; batch adversarial loss: 0.582160\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568659; batch adversarial loss: 0.541187\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528661; batch adversarial loss: 0.534907\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532293; batch adversarial loss: 0.528858\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511632; batch adversarial loss: 0.493847\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523607; batch adversarial loss: 0.474842\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591613; batch adversarial loss: 0.456862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.507657; batch adversarial loss: 0.464444\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542441; batch adversarial loss: 0.454489\n",
      "epoch 19; iter: 0; batch classifier loss: 0.560417; batch adversarial loss: 0.464744\n",
      "epoch 20; iter: 0; batch classifier loss: 0.526733; batch adversarial loss: 0.438452\n",
      "epoch 21; iter: 0; batch classifier loss: 0.550656; batch adversarial loss: 0.453327\n",
      "epoch 22; iter: 0; batch classifier loss: 0.585373; batch adversarial loss: 0.468358\n",
      "epoch 23; iter: 0; batch classifier loss: 0.536026; batch adversarial loss: 0.507451\n",
      "epoch 24; iter: 0; batch classifier loss: 0.587002; batch adversarial loss: 0.367249\n",
      "epoch 25; iter: 0; batch classifier loss: 0.563831; batch adversarial loss: 0.432710\n",
      "epoch 26; iter: 0; batch classifier loss: 0.650830; batch adversarial loss: 0.484962\n",
      "epoch 27; iter: 0; batch classifier loss: 0.704844; batch adversarial loss: 0.500410\n",
      "epoch 28; iter: 0; batch classifier loss: 0.614562; batch adversarial loss: 0.410734\n",
      "epoch 29; iter: 0; batch classifier loss: 0.531335; batch adversarial loss: 0.466185\n",
      "epoch 30; iter: 0; batch classifier loss: 0.551979; batch adversarial loss: 0.381850\n",
      "epoch 31; iter: 0; batch classifier loss: 0.605219; batch adversarial loss: 0.403403\n",
      "epoch 32; iter: 0; batch classifier loss: 0.632761; batch adversarial loss: 0.430837\n",
      "epoch 33; iter: 0; batch classifier loss: 0.594663; batch adversarial loss: 0.395185\n",
      "epoch 34; iter: 0; batch classifier loss: 0.546953; batch adversarial loss: 0.335856\n",
      "epoch 35; iter: 0; batch classifier loss: 0.668787; batch adversarial loss: 0.438194\n",
      "epoch 36; iter: 0; batch classifier loss: 0.548764; batch adversarial loss: 0.381832\n",
      "epoch 37; iter: 0; batch classifier loss: 0.593607; batch adversarial loss: 0.414009\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446636; batch adversarial loss: 0.343756\n",
      "epoch 39; iter: 0; batch classifier loss: 0.560181; batch adversarial loss: 0.320488\n",
      "epoch 40; iter: 0; batch classifier loss: 0.524960; batch adversarial loss: 0.387534\n",
      "epoch 41; iter: 0; batch classifier loss: 0.597714; batch adversarial loss: 0.406845\n",
      "epoch 42; iter: 0; batch classifier loss: 0.503002; batch adversarial loss: 0.337449\n",
      "epoch 43; iter: 0; batch classifier loss: 0.540929; batch adversarial loss: 0.351089\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462856; batch adversarial loss: 0.315218\n",
      "epoch 45; iter: 0; batch classifier loss: 0.510385; batch adversarial loss: 0.340287\n",
      "epoch 46; iter: 0; batch classifier loss: 0.530550; batch adversarial loss: 0.301009\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483405; batch adversarial loss: 0.268691\n",
      "epoch 48; iter: 0; batch classifier loss: 0.595744; batch adversarial loss: 0.383035\n",
      "epoch 49; iter: 0; batch classifier loss: 0.521758; batch adversarial loss: 0.368391\n",
      "epoch 50; iter: 0; batch classifier loss: 0.596323; batch adversarial loss: 0.314022\n",
      "epoch 51; iter: 0; batch classifier loss: 0.599709; batch adversarial loss: 0.364328\n",
      "epoch 52; iter: 0; batch classifier loss: 0.515749; batch adversarial loss: 0.282255\n",
      "epoch 53; iter: 0; batch classifier loss: 0.578040; batch adversarial loss: 0.398925\n",
      "epoch 54; iter: 0; batch classifier loss: 0.627014; batch adversarial loss: 0.278188\n",
      "epoch 55; iter: 0; batch classifier loss: 0.466941; batch adversarial loss: 0.249549\n",
      "epoch 56; iter: 0; batch classifier loss: 0.444558; batch adversarial loss: 0.352239\n",
      "epoch 57; iter: 0; batch classifier loss: 0.498596; batch adversarial loss: 0.352761\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426951; batch adversarial loss: 0.365665\n",
      "epoch 59; iter: 0; batch classifier loss: 0.461308; batch adversarial loss: 0.377485\n",
      "epoch 60; iter: 0; batch classifier loss: 0.480833; batch adversarial loss: 0.320042\n",
      "epoch 61; iter: 0; batch classifier loss: 0.462089; batch adversarial loss: 0.248839\n",
      "epoch 62; iter: 0; batch classifier loss: 0.483125; batch adversarial loss: 0.303448\n",
      "epoch 63; iter: 0; batch classifier loss: 0.468596; batch adversarial loss: 0.404591\n",
      "epoch 64; iter: 0; batch classifier loss: 0.364132; batch adversarial loss: 0.321157\n",
      "epoch 65; iter: 0; batch classifier loss: 0.451849; batch adversarial loss: 0.257529\n",
      "epoch 66; iter: 0; batch classifier loss: 0.317613; batch adversarial loss: 0.330464\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410416; batch adversarial loss: 0.344129\n",
      "epoch 68; iter: 0; batch classifier loss: 0.415587; batch adversarial loss: 0.343551\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426810; batch adversarial loss: 0.280767\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423924; batch adversarial loss: 0.343347\n",
      "epoch 71; iter: 0; batch classifier loss: 0.477273; batch adversarial loss: 0.279861\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411031; batch adversarial loss: 0.286686\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375922; batch adversarial loss: 0.286738\n",
      "epoch 74; iter: 0; batch classifier loss: 0.462826; batch adversarial loss: 0.363722\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352364; batch adversarial loss: 0.308308\n",
      "epoch 76; iter: 0; batch classifier loss: 0.367359; batch adversarial loss: 0.314796\n",
      "epoch 77; iter: 0; batch classifier loss: 0.415254; batch adversarial loss: 0.336530\n",
      "epoch 78; iter: 0; batch classifier loss: 0.355002; batch adversarial loss: 0.228252\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380577; batch adversarial loss: 0.367061\n",
      "epoch 80; iter: 0; batch classifier loss: 0.478089; batch adversarial loss: 0.418418\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419439; batch adversarial loss: 0.278317\n",
      "epoch 82; iter: 0; batch classifier loss: 0.454642; batch adversarial loss: 0.271614\n",
      "epoch 83; iter: 0; batch classifier loss: 0.377260; batch adversarial loss: 0.276814\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440171; batch adversarial loss: 0.268585\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387164; batch adversarial loss: 0.396420\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412658; batch adversarial loss: 0.297109\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377379; batch adversarial loss: 0.312751\n",
      "epoch 88; iter: 0; batch classifier loss: 0.415457; batch adversarial loss: 0.259374\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386349; batch adversarial loss: 0.269855\n",
      "epoch 90; iter: 0; batch classifier loss: 0.460167; batch adversarial loss: 0.260101\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410714; batch adversarial loss: 0.359422\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376266; batch adversarial loss: 0.241511\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347425; batch adversarial loss: 0.288360\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380420; batch adversarial loss: 0.285709\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417513; batch adversarial loss: 0.293482\n",
      "epoch 96; iter: 0; batch classifier loss: 0.367518; batch adversarial loss: 0.309016\n",
      "epoch 97; iter: 0; batch classifier loss: 0.371131; batch adversarial loss: 0.289772\n",
      "epoch 98; iter: 0; batch classifier loss: 0.381884; batch adversarial loss: 0.254238\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355614; batch adversarial loss: 0.227448\n",
      "epoch 100; iter: 0; batch classifier loss: 0.413350; batch adversarial loss: 0.299795\n",
      "epoch 101; iter: 0; batch classifier loss: 0.365119; batch adversarial loss: 0.259805\n",
      "epoch 102; iter: 0; batch classifier loss: 0.332836; batch adversarial loss: 0.273248\n",
      "epoch 103; iter: 0; batch classifier loss: 0.395931; batch adversarial loss: 0.362868\n",
      "epoch 104; iter: 0; batch classifier loss: 0.424993; batch adversarial loss: 0.290429\n",
      "epoch 105; iter: 0; batch classifier loss: 0.302392; batch adversarial loss: 0.337352\n",
      "epoch 106; iter: 0; batch classifier loss: 0.383135; batch adversarial loss: 0.270025\n",
      "epoch 107; iter: 0; batch classifier loss: 0.365443; batch adversarial loss: 0.281751\n",
      "epoch 108; iter: 0; batch classifier loss: 0.367932; batch adversarial loss: 0.316395\n",
      "epoch 109; iter: 0; batch classifier loss: 0.375253; batch adversarial loss: 0.289456\n",
      "epoch 110; iter: 0; batch classifier loss: 0.408175; batch adversarial loss: 0.308294\n",
      "epoch 111; iter: 0; batch classifier loss: 0.333752; batch adversarial loss: 0.363314\n",
      "epoch 112; iter: 0; batch classifier loss: 0.388205; batch adversarial loss: 0.371546\n",
      "epoch 113; iter: 0; batch classifier loss: 0.356584; batch adversarial loss: 0.321035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.369414; batch adversarial loss: 0.232929\n",
      "epoch 115; iter: 0; batch classifier loss: 0.335657; batch adversarial loss: 0.219089\n",
      "epoch 116; iter: 0; batch classifier loss: 0.347445; batch adversarial loss: 0.223645\n",
      "epoch 117; iter: 0; batch classifier loss: 0.318378; batch adversarial loss: 0.273812\n",
      "epoch 118; iter: 0; batch classifier loss: 0.303565; batch adversarial loss: 0.296761\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373597; batch adversarial loss: 0.324435\n",
      "epoch 120; iter: 0; batch classifier loss: 0.287332; batch adversarial loss: 0.219359\n",
      "epoch 121; iter: 0; batch classifier loss: 0.327941; batch adversarial loss: 0.284965\n",
      "epoch 122; iter: 0; batch classifier loss: 0.386062; batch adversarial loss: 0.253206\n",
      "epoch 123; iter: 0; batch classifier loss: 0.350112; batch adversarial loss: 0.344398\n",
      "epoch 124; iter: 0; batch classifier loss: 0.343642; batch adversarial loss: 0.361213\n",
      "epoch 125; iter: 0; batch classifier loss: 0.400368; batch adversarial loss: 0.370543\n",
      "epoch 126; iter: 0; batch classifier loss: 0.366789; batch adversarial loss: 0.377999\n",
      "epoch 127; iter: 0; batch classifier loss: 0.462043; batch adversarial loss: 0.288992\n",
      "epoch 128; iter: 0; batch classifier loss: 0.311444; batch adversarial loss: 0.220639\n",
      "epoch 129; iter: 0; batch classifier loss: 0.275730; batch adversarial loss: 0.339273\n",
      "epoch 130; iter: 0; batch classifier loss: 0.364977; batch adversarial loss: 0.167988\n",
      "epoch 131; iter: 0; batch classifier loss: 0.328993; batch adversarial loss: 0.325133\n",
      "epoch 132; iter: 0; batch classifier loss: 0.317056; batch adversarial loss: 0.346242\n",
      "epoch 133; iter: 0; batch classifier loss: 0.339092; batch adversarial loss: 0.317383\n",
      "epoch 134; iter: 0; batch classifier loss: 0.283198; batch adversarial loss: 0.221537\n",
      "epoch 135; iter: 0; batch classifier loss: 0.315825; batch adversarial loss: 0.356681\n",
      "epoch 136; iter: 0; batch classifier loss: 0.339499; batch adversarial loss: 0.270354\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368162; batch adversarial loss: 0.305857\n",
      "epoch 138; iter: 0; batch classifier loss: 0.321326; batch adversarial loss: 0.265022\n",
      "epoch 139; iter: 0; batch classifier loss: 0.367933; batch adversarial loss: 0.272539\n",
      "epoch 140; iter: 0; batch classifier loss: 0.364249; batch adversarial loss: 0.295312\n",
      "epoch 141; iter: 0; batch classifier loss: 0.345050; batch adversarial loss: 0.299376\n",
      "epoch 142; iter: 0; batch classifier loss: 0.304716; batch adversarial loss: 0.191088\n",
      "epoch 143; iter: 0; batch classifier loss: 0.296986; batch adversarial loss: 0.300719\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348048; batch adversarial loss: 0.254748\n",
      "epoch 145; iter: 0; batch classifier loss: 0.373208; batch adversarial loss: 0.343931\n",
      "epoch 146; iter: 0; batch classifier loss: 0.379078; batch adversarial loss: 0.227536\n",
      "epoch 147; iter: 0; batch classifier loss: 0.303792; batch adversarial loss: 0.167007\n",
      "epoch 148; iter: 0; batch classifier loss: 0.320857; batch adversarial loss: 0.347015\n",
      "epoch 149; iter: 0; batch classifier loss: 0.364256; batch adversarial loss: 0.244548\n",
      "epoch 150; iter: 0; batch classifier loss: 0.363791; batch adversarial loss: 0.323881\n",
      "epoch 151; iter: 0; batch classifier loss: 0.380318; batch adversarial loss: 0.275815\n",
      "epoch 152; iter: 0; batch classifier loss: 0.333218; batch adversarial loss: 0.294171\n",
      "epoch 153; iter: 0; batch classifier loss: 0.417002; batch adversarial loss: 0.322096\n",
      "epoch 154; iter: 0; batch classifier loss: 0.321460; batch adversarial loss: 0.328624\n",
      "epoch 155; iter: 0; batch classifier loss: 0.326893; batch adversarial loss: 0.167308\n",
      "epoch 156; iter: 0; batch classifier loss: 0.367565; batch adversarial loss: 0.278207\n",
      "epoch 157; iter: 0; batch classifier loss: 0.333935; batch adversarial loss: 0.330606\n",
      "epoch 158; iter: 0; batch classifier loss: 0.306718; batch adversarial loss: 0.339024\n",
      "epoch 159; iter: 0; batch classifier loss: 0.279858; batch adversarial loss: 0.315080\n",
      "epoch 160; iter: 0; batch classifier loss: 0.320848; batch adversarial loss: 0.290905\n",
      "epoch 161; iter: 0; batch classifier loss: 0.369721; batch adversarial loss: 0.219306\n",
      "epoch 162; iter: 0; batch classifier loss: 0.273323; batch adversarial loss: 0.208776\n",
      "epoch 163; iter: 0; batch classifier loss: 0.253183; batch adversarial loss: 0.306317\n",
      "epoch 164; iter: 0; batch classifier loss: 0.353792; batch adversarial loss: 0.314022\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379722; batch adversarial loss: 0.220176\n",
      "epoch 166; iter: 0; batch classifier loss: 0.353081; batch adversarial loss: 0.379443\n",
      "epoch 167; iter: 0; batch classifier loss: 0.400102; batch adversarial loss: 0.398655\n",
      "epoch 168; iter: 0; batch classifier loss: 0.337170; batch adversarial loss: 0.456240\n",
      "epoch 169; iter: 0; batch classifier loss: 0.313001; batch adversarial loss: 0.343282\n",
      "epoch 170; iter: 0; batch classifier loss: 0.304065; batch adversarial loss: 0.340331\n",
      "epoch 171; iter: 0; batch classifier loss: 0.386348; batch adversarial loss: 0.257386\n",
      "epoch 172; iter: 0; batch classifier loss: 0.276836; batch adversarial loss: 0.290333\n",
      "epoch 173; iter: 0; batch classifier loss: 0.333556; batch adversarial loss: 0.331046\n",
      "epoch 174; iter: 0; batch classifier loss: 0.366092; batch adversarial loss: 0.432443\n",
      "epoch 175; iter: 0; batch classifier loss: 0.297843; batch adversarial loss: 0.424851\n",
      "epoch 176; iter: 0; batch classifier loss: 0.365871; batch adversarial loss: 0.315612\n",
      "epoch 177; iter: 0; batch classifier loss: 0.303966; batch adversarial loss: 0.223875\n",
      "epoch 178; iter: 0; batch classifier loss: 0.312615; batch adversarial loss: 0.343335\n",
      "epoch 179; iter: 0; batch classifier loss: 0.282014; batch adversarial loss: 0.270200\n",
      "epoch 180; iter: 0; batch classifier loss: 0.299389; batch adversarial loss: 0.399725\n",
      "epoch 181; iter: 0; batch classifier loss: 0.271282; batch adversarial loss: 0.292275\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336256; batch adversarial loss: 0.350397\n",
      "epoch 183; iter: 0; batch classifier loss: 0.260159; batch adversarial loss: 0.355890\n",
      "epoch 184; iter: 0; batch classifier loss: 0.362414; batch adversarial loss: 0.291548\n",
      "epoch 185; iter: 0; batch classifier loss: 0.378231; batch adversarial loss: 0.363829\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315427; batch adversarial loss: 0.314946\n",
      "epoch 187; iter: 0; batch classifier loss: 0.340977; batch adversarial loss: 0.379424\n",
      "epoch 188; iter: 0; batch classifier loss: 0.266194; batch adversarial loss: 0.237339\n",
      "epoch 189; iter: 0; batch classifier loss: 0.346343; batch adversarial loss: 0.366333\n",
      "epoch 190; iter: 0; batch classifier loss: 0.262678; batch adversarial loss: 0.361702\n",
      "epoch 191; iter: 0; batch classifier loss: 0.306405; batch adversarial loss: 0.295004\n",
      "epoch 192; iter: 0; batch classifier loss: 0.287611; batch adversarial loss: 0.314299\n",
      "epoch 193; iter: 0; batch classifier loss: 0.247014; batch adversarial loss: 0.306292\n",
      "epoch 194; iter: 0; batch classifier loss: 0.362318; batch adversarial loss: 0.390988\n",
      "epoch 195; iter: 0; batch classifier loss: 0.303152; batch adversarial loss: 0.222328\n",
      "epoch 196; iter: 0; batch classifier loss: 0.299352; batch adversarial loss: 0.288446\n",
      "epoch 197; iter: 0; batch classifier loss: 0.324580; batch adversarial loss: 0.240011\n",
      "epoch 198; iter: 0; batch classifier loss: 0.334336; batch adversarial loss: 0.366923\n",
      "epoch 199; iter: 0; batch classifier loss: 0.276299; batch adversarial loss: 0.419056\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.178583; batch adversarial loss: 0.923443\n",
      "epoch 2; iter: 0; batch classifier loss: 1.079674; batch adversarial loss: 0.797508\n",
      "epoch 3; iter: 0; batch classifier loss: 0.842399; batch adversarial loss: 0.815293\n",
      "epoch 4; iter: 0; batch classifier loss: 0.769543; batch adversarial loss: 0.719707\n",
      "epoch 5; iter: 0; batch classifier loss: 0.644686; batch adversarial loss: 0.659075\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577350; batch adversarial loss: 0.636238\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583355; batch adversarial loss: 0.612066\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552387; batch adversarial loss: 0.601714\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538301; batch adversarial loss: 0.574064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.546091; batch adversarial loss: 0.582694\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570775; batch adversarial loss: 0.542239\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533256; batch adversarial loss: 0.535601\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537267; batch adversarial loss: 0.529168\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521426; batch adversarial loss: 0.491776\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529842; batch adversarial loss: 0.471754\n",
      "epoch 16; iter: 0; batch classifier loss: 0.593632; batch adversarial loss: 0.454386\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506429; batch adversarial loss: 0.460689\n",
      "epoch 18; iter: 0; batch classifier loss: 0.546516; batch adversarial loss: 0.451978\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535661; batch adversarial loss: 0.454513\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510034; batch adversarial loss: 0.425363\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515692; batch adversarial loss: 0.439697\n",
      "epoch 22; iter: 0; batch classifier loss: 0.548887; batch adversarial loss: 0.454646\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505880; batch adversarial loss: 0.501265\n",
      "epoch 24; iter: 0; batch classifier loss: 0.567730; batch adversarial loss: 0.363200\n",
      "epoch 25; iter: 0; batch classifier loss: 0.533857; batch adversarial loss: 0.426495\n",
      "epoch 26; iter: 0; batch classifier loss: 0.607515; batch adversarial loss: 0.478397\n",
      "epoch 27; iter: 0; batch classifier loss: 0.668988; batch adversarial loss: 0.498233\n",
      "epoch 28; iter: 0; batch classifier loss: 0.598865; batch adversarial loss: 0.408788\n",
      "epoch 29; iter: 0; batch classifier loss: 0.511924; batch adversarial loss: 0.466489\n",
      "epoch 30; iter: 0; batch classifier loss: 0.538718; batch adversarial loss: 0.381533\n",
      "epoch 31; iter: 0; batch classifier loss: 0.584355; batch adversarial loss: 0.403453\n",
      "epoch 32; iter: 0; batch classifier loss: 0.625927; batch adversarial loss: 0.432970\n",
      "epoch 33; iter: 0; batch classifier loss: 0.583789; batch adversarial loss: 0.395779\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544577; batch adversarial loss: 0.336309\n",
      "epoch 35; iter: 0; batch classifier loss: 0.650505; batch adversarial loss: 0.441660\n",
      "epoch 36; iter: 0; batch classifier loss: 0.551543; batch adversarial loss: 0.384248\n",
      "epoch 37; iter: 0; batch classifier loss: 0.586869; batch adversarial loss: 0.417338\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446391; batch adversarial loss: 0.345381\n",
      "epoch 39; iter: 0; batch classifier loss: 0.555159; batch adversarial loss: 0.321736\n",
      "epoch 40; iter: 0; batch classifier loss: 0.515209; batch adversarial loss: 0.389828\n",
      "epoch 41; iter: 0; batch classifier loss: 0.598402; batch adversarial loss: 0.410770\n",
      "epoch 42; iter: 0; batch classifier loss: 0.492928; batch adversarial loss: 0.339365\n",
      "epoch 43; iter: 0; batch classifier loss: 0.532727; batch adversarial loss: 0.353479\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461236; batch adversarial loss: 0.316018\n",
      "epoch 45; iter: 0; batch classifier loss: 0.529292; batch adversarial loss: 0.342686\n",
      "epoch 46; iter: 0; batch classifier loss: 0.539519; batch adversarial loss: 0.302401\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487180; batch adversarial loss: 0.269537\n",
      "epoch 48; iter: 0; batch classifier loss: 0.603922; batch adversarial loss: 0.386055\n",
      "epoch 49; iter: 0; batch classifier loss: 0.519983; batch adversarial loss: 0.370994\n",
      "epoch 50; iter: 0; batch classifier loss: 0.591149; batch adversarial loss: 0.315411\n",
      "epoch 51; iter: 0; batch classifier loss: 0.602201; batch adversarial loss: 0.366636\n",
      "epoch 52; iter: 0; batch classifier loss: 0.513010; batch adversarial loss: 0.283148\n",
      "epoch 53; iter: 0; batch classifier loss: 0.561739; batch adversarial loss: 0.401740\n",
      "epoch 54; iter: 0; batch classifier loss: 0.592487; batch adversarial loss: 0.279380\n",
      "epoch 55; iter: 0; batch classifier loss: 0.585539; batch adversarial loss: 0.251062\n",
      "epoch 56; iter: 0; batch classifier loss: 0.446868; batch adversarial loss: 0.352883\n",
      "epoch 57; iter: 0; batch classifier loss: 0.497843; batch adversarial loss: 0.352934\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424784; batch adversarial loss: 0.366093\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458968; batch adversarial loss: 0.377569\n",
      "epoch 60; iter: 0; batch classifier loss: 0.479621; batch adversarial loss: 0.320205\n",
      "epoch 61; iter: 0; batch classifier loss: 0.453278; batch adversarial loss: 0.249336\n",
      "epoch 62; iter: 0; batch classifier loss: 0.486798; batch adversarial loss: 0.303788\n",
      "epoch 63; iter: 0; batch classifier loss: 0.462759; batch adversarial loss: 0.404406\n",
      "epoch 64; iter: 0; batch classifier loss: 0.364754; batch adversarial loss: 0.321453\n",
      "epoch 65; iter: 0; batch classifier loss: 0.442381; batch adversarial loss: 0.257920\n",
      "epoch 66; iter: 0; batch classifier loss: 0.320016; batch adversarial loss: 0.330588\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403056; batch adversarial loss: 0.344376\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408458; batch adversarial loss: 0.343261\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419140; batch adversarial loss: 0.280775\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422296; batch adversarial loss: 0.343334\n",
      "epoch 71; iter: 0; batch classifier loss: 0.477909; batch adversarial loss: 0.280028\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412806; batch adversarial loss: 0.286856\n",
      "epoch 73; iter: 0; batch classifier loss: 0.376537; batch adversarial loss: 0.287260\n",
      "epoch 74; iter: 0; batch classifier loss: 0.443776; batch adversarial loss: 0.364359\n",
      "epoch 75; iter: 0; batch classifier loss: 0.355638; batch adversarial loss: 0.308474\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373039; batch adversarial loss: 0.314882\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419507; batch adversarial loss: 0.336722\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362051; batch adversarial loss: 0.228392\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369830; batch adversarial loss: 0.367232\n",
      "epoch 80; iter: 0; batch classifier loss: 0.479283; batch adversarial loss: 0.418508\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410520; batch adversarial loss: 0.278045\n",
      "epoch 82; iter: 0; batch classifier loss: 0.457472; batch adversarial loss: 0.271653\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383477; batch adversarial loss: 0.276666\n",
      "epoch 84; iter: 0; batch classifier loss: 0.427478; batch adversarial loss: 0.269090\n",
      "epoch 85; iter: 0; batch classifier loss: 0.394507; batch adversarial loss: 0.397117\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406661; batch adversarial loss: 0.297204\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378476; batch adversarial loss: 0.312538\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422548; batch adversarial loss: 0.259501\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381113; batch adversarial loss: 0.269777\n",
      "epoch 90; iter: 0; batch classifier loss: 0.452879; batch adversarial loss: 0.260042\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410623; batch adversarial loss: 0.360337\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376262; batch adversarial loss: 0.241876\n",
      "epoch 93; iter: 0; batch classifier loss: 0.345837; batch adversarial loss: 0.288218\n",
      "epoch 94; iter: 0; batch classifier loss: 0.368801; batch adversarial loss: 0.285729\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401078; batch adversarial loss: 0.293735\n",
      "epoch 96; iter: 0; batch classifier loss: 0.369302; batch adversarial loss: 0.309320\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359276; batch adversarial loss: 0.289586\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383601; batch adversarial loss: 0.254273\n",
      "epoch 99; iter: 0; batch classifier loss: 0.368509; batch adversarial loss: 0.228271\n",
      "epoch 100; iter: 0; batch classifier loss: 0.425934; batch adversarial loss: 0.300050\n",
      "epoch 101; iter: 0; batch classifier loss: 0.372238; batch adversarial loss: 0.260029\n",
      "epoch 102; iter: 0; batch classifier loss: 0.321368; batch adversarial loss: 0.273157\n",
      "epoch 103; iter: 0; batch classifier loss: 0.395344; batch adversarial loss: 0.363360\n",
      "epoch 104; iter: 0; batch classifier loss: 0.433250; batch adversarial loss: 0.291310\n",
      "epoch 105; iter: 0; batch classifier loss: 0.294630; batch adversarial loss: 0.337203\n",
      "epoch 106; iter: 0; batch classifier loss: 0.378817; batch adversarial loss: 0.269877\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355618; batch adversarial loss: 0.281628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.382817; batch adversarial loss: 0.315353\n",
      "epoch 109; iter: 0; batch classifier loss: 0.359833; batch adversarial loss: 0.289674\n",
      "epoch 110; iter: 0; batch classifier loss: 0.411021; batch adversarial loss: 0.308429\n",
      "epoch 111; iter: 0; batch classifier loss: 0.311824; batch adversarial loss: 0.364130\n",
      "epoch 112; iter: 0; batch classifier loss: 0.379518; batch adversarial loss: 0.371432\n",
      "epoch 113; iter: 0; batch classifier loss: 0.356108; batch adversarial loss: 0.321177\n",
      "epoch 114; iter: 0; batch classifier loss: 0.358427; batch adversarial loss: 0.232775\n",
      "epoch 115; iter: 0; batch classifier loss: 0.315146; batch adversarial loss: 0.219165\n",
      "epoch 116; iter: 0; batch classifier loss: 0.336105; batch adversarial loss: 0.223713\n",
      "epoch 117; iter: 0; batch classifier loss: 0.325743; batch adversarial loss: 0.273070\n",
      "epoch 118; iter: 0; batch classifier loss: 0.294740; batch adversarial loss: 0.296788\n",
      "epoch 119; iter: 0; batch classifier loss: 0.372880; batch adversarial loss: 0.325116\n",
      "epoch 120; iter: 0; batch classifier loss: 0.291951; batch adversarial loss: 0.219437\n",
      "epoch 121; iter: 0; batch classifier loss: 0.312459; batch adversarial loss: 0.284950\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385826; batch adversarial loss: 0.253448\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359036; batch adversarial loss: 0.345148\n",
      "epoch 124; iter: 0; batch classifier loss: 0.333318; batch adversarial loss: 0.360205\n",
      "epoch 125; iter: 0; batch classifier loss: 0.401404; batch adversarial loss: 0.370585\n",
      "epoch 126; iter: 0; batch classifier loss: 0.371747; batch adversarial loss: 0.378334\n",
      "epoch 127; iter: 0; batch classifier loss: 0.427550; batch adversarial loss: 0.289189\n",
      "epoch 128; iter: 0; batch classifier loss: 0.299893; batch adversarial loss: 0.220608\n",
      "epoch 129; iter: 0; batch classifier loss: 0.293634; batch adversarial loss: 0.338677\n",
      "epoch 130; iter: 0; batch classifier loss: 0.366019; batch adversarial loss: 0.168027\n",
      "epoch 131; iter: 0; batch classifier loss: 0.333071; batch adversarial loss: 0.324760\n",
      "epoch 132; iter: 0; batch classifier loss: 0.326073; batch adversarial loss: 0.346500\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341029; batch adversarial loss: 0.317040\n",
      "epoch 134; iter: 0; batch classifier loss: 0.278392; batch adversarial loss: 0.221235\n",
      "epoch 135; iter: 0; batch classifier loss: 0.312241; batch adversarial loss: 0.356943\n",
      "epoch 136; iter: 0; batch classifier loss: 0.340257; batch adversarial loss: 0.270377\n",
      "epoch 137; iter: 0; batch classifier loss: 0.357977; batch adversarial loss: 0.306188\n",
      "epoch 138; iter: 0; batch classifier loss: 0.307018; batch adversarial loss: 0.264860\n",
      "epoch 139; iter: 0; batch classifier loss: 0.361489; batch adversarial loss: 0.272618\n",
      "epoch 140; iter: 0; batch classifier loss: 0.387609; batch adversarial loss: 0.295681\n",
      "epoch 141; iter: 0; batch classifier loss: 0.349515; batch adversarial loss: 0.300110\n",
      "epoch 142; iter: 0; batch classifier loss: 0.321059; batch adversarial loss: 0.190690\n",
      "epoch 143; iter: 0; batch classifier loss: 0.306199; batch adversarial loss: 0.300209\n",
      "epoch 144; iter: 0; batch classifier loss: 0.344181; batch adversarial loss: 0.254983\n",
      "epoch 145; iter: 0; batch classifier loss: 0.370226; batch adversarial loss: 0.344101\n",
      "epoch 146; iter: 0; batch classifier loss: 0.371966; batch adversarial loss: 0.227998\n",
      "epoch 147; iter: 0; batch classifier loss: 0.307426; batch adversarial loss: 0.167014\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330891; batch adversarial loss: 0.347351\n",
      "epoch 149; iter: 0; batch classifier loss: 0.374771; batch adversarial loss: 0.244359\n",
      "epoch 150; iter: 0; batch classifier loss: 0.347079; batch adversarial loss: 0.324007\n",
      "epoch 151; iter: 0; batch classifier loss: 0.382826; batch adversarial loss: 0.275546\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330717; batch adversarial loss: 0.294107\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381270; batch adversarial loss: 0.321915\n",
      "epoch 154; iter: 0; batch classifier loss: 0.316471; batch adversarial loss: 0.328711\n",
      "epoch 155; iter: 0; batch classifier loss: 0.329630; batch adversarial loss: 0.167624\n",
      "epoch 156; iter: 0; batch classifier loss: 0.374597; batch adversarial loss: 0.277784\n",
      "epoch 157; iter: 0; batch classifier loss: 0.308584; batch adversarial loss: 0.331861\n",
      "epoch 158; iter: 0; batch classifier loss: 0.317852; batch adversarial loss: 0.339379\n",
      "epoch 159; iter: 0; batch classifier loss: 0.290020; batch adversarial loss: 0.314296\n",
      "epoch 160; iter: 0; batch classifier loss: 0.310612; batch adversarial loss: 0.291438\n",
      "epoch 161; iter: 0; batch classifier loss: 0.350970; batch adversarial loss: 0.218613\n",
      "epoch 162; iter: 0; batch classifier loss: 0.260945; batch adversarial loss: 0.208000\n",
      "epoch 163; iter: 0; batch classifier loss: 0.253721; batch adversarial loss: 0.306122\n",
      "epoch 164; iter: 0; batch classifier loss: 0.317071; batch adversarial loss: 0.314136\n",
      "epoch 165; iter: 0; batch classifier loss: 0.379664; batch adversarial loss: 0.220345\n",
      "epoch 166; iter: 0; batch classifier loss: 0.375203; batch adversarial loss: 0.378843\n",
      "epoch 167; iter: 0; batch classifier loss: 0.366905; batch adversarial loss: 0.398487\n",
      "epoch 168; iter: 0; batch classifier loss: 0.296696; batch adversarial loss: 0.455458\n",
      "epoch 169; iter: 0; batch classifier loss: 0.299338; batch adversarial loss: 0.344371\n",
      "epoch 170; iter: 0; batch classifier loss: 0.297623; batch adversarial loss: 0.340180\n",
      "epoch 171; iter: 0; batch classifier loss: 0.385260; batch adversarial loss: 0.257707\n",
      "epoch 172; iter: 0; batch classifier loss: 0.275022; batch adversarial loss: 0.290011\n",
      "epoch 173; iter: 0; batch classifier loss: 0.348385; batch adversarial loss: 0.331779\n",
      "epoch 174; iter: 0; batch classifier loss: 0.363505; batch adversarial loss: 0.432824\n",
      "epoch 175; iter: 0; batch classifier loss: 0.298857; batch adversarial loss: 0.425389\n",
      "epoch 176; iter: 0; batch classifier loss: 0.372382; batch adversarial loss: 0.316506\n",
      "epoch 177; iter: 0; batch classifier loss: 0.294787; batch adversarial loss: 0.223925\n",
      "epoch 178; iter: 0; batch classifier loss: 0.315989; batch adversarial loss: 0.342938\n",
      "epoch 179; iter: 0; batch classifier loss: 0.284671; batch adversarial loss: 0.270004\n",
      "epoch 180; iter: 0; batch classifier loss: 0.289296; batch adversarial loss: 0.399496\n",
      "epoch 181; iter: 0; batch classifier loss: 0.281096; batch adversarial loss: 0.292858\n",
      "epoch 182; iter: 0; batch classifier loss: 0.339931; batch adversarial loss: 0.351089\n",
      "epoch 183; iter: 0; batch classifier loss: 0.234071; batch adversarial loss: 0.355895\n",
      "epoch 184; iter: 0; batch classifier loss: 0.363320; batch adversarial loss: 0.291239\n",
      "epoch 185; iter: 0; batch classifier loss: 0.354964; batch adversarial loss: 0.364016\n",
      "epoch 186; iter: 0; batch classifier loss: 0.306041; batch adversarial loss: 0.314798\n",
      "epoch 187; iter: 0; batch classifier loss: 0.350518; batch adversarial loss: 0.379227\n",
      "epoch 188; iter: 0; batch classifier loss: 0.278314; batch adversarial loss: 0.237377\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357828; batch adversarial loss: 0.366362\n",
      "epoch 190; iter: 0; batch classifier loss: 0.238267; batch adversarial loss: 0.361822\n",
      "epoch 191; iter: 0; batch classifier loss: 0.303586; batch adversarial loss: 0.295755\n",
      "epoch 192; iter: 0; batch classifier loss: 0.316474; batch adversarial loss: 0.313788\n",
      "epoch 193; iter: 0; batch classifier loss: 0.259355; batch adversarial loss: 0.306289\n",
      "epoch 194; iter: 0; batch classifier loss: 0.377575; batch adversarial loss: 0.390515\n",
      "epoch 195; iter: 0; batch classifier loss: 0.319460; batch adversarial loss: 0.222051\n",
      "epoch 196; iter: 0; batch classifier loss: 0.322404; batch adversarial loss: 0.288655\n",
      "epoch 197; iter: 0; batch classifier loss: 0.332492; batch adversarial loss: 0.240074\n",
      "epoch 198; iter: 0; batch classifier loss: 0.355708; batch adversarial loss: 0.367109\n",
      "epoch 199; iter: 0; batch classifier loss: 0.252471; batch adversarial loss: 0.418801\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.236864; batch adversarial loss: 0.925816\n",
      "epoch 2; iter: 0; batch classifier loss: 1.123508; batch adversarial loss: 0.799675\n",
      "epoch 3; iter: 0; batch classifier loss: 0.878184; batch adversarial loss: 0.818765\n",
      "epoch 4; iter: 0; batch classifier loss: 0.811701; batch adversarial loss: 0.723998\n",
      "epoch 5; iter: 0; batch classifier loss: 0.674960; batch adversarial loss: 0.663034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.583794; batch adversarial loss: 0.636045\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580512; batch adversarial loss: 0.612481\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551705; batch adversarial loss: 0.601478\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539684; batch adversarial loss: 0.573169\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541463; batch adversarial loss: 0.582453\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568271; batch adversarial loss: 0.541578\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530695; batch adversarial loss: 0.535013\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533796; batch adversarial loss: 0.528764\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514134; batch adversarial loss: 0.493164\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524685; batch adversarial loss: 0.474055\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591478; batch adversarial loss: 0.456431\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506914; batch adversarial loss: 0.463175\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541756; batch adversarial loss: 0.453856\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550971; batch adversarial loss: 0.461395\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519533; batch adversarial loss: 0.433570\n",
      "epoch 21; iter: 0; batch classifier loss: 0.540512; batch adversarial loss: 0.449685\n",
      "epoch 22; iter: 0; batch classifier loss: 0.574210; batch adversarial loss: 0.464757\n",
      "epoch 23; iter: 0; batch classifier loss: 0.529224; batch adversarial loss: 0.506281\n",
      "epoch 24; iter: 0; batch classifier loss: 0.584202; batch adversarial loss: 0.366328\n",
      "epoch 25; iter: 0; batch classifier loss: 0.555043; batch adversarial loss: 0.431384\n",
      "epoch 26; iter: 0; batch classifier loss: 0.640989; batch adversarial loss: 0.484163\n",
      "epoch 27; iter: 0; batch classifier loss: 0.695601; batch adversarial loss: 0.500291\n",
      "epoch 28; iter: 0; batch classifier loss: 0.610487; batch adversarial loss: 0.410531\n",
      "epoch 29; iter: 0; batch classifier loss: 0.527454; batch adversarial loss: 0.466509\n",
      "epoch 30; iter: 0; batch classifier loss: 0.547687; batch adversarial loss: 0.381778\n",
      "epoch 31; iter: 0; batch classifier loss: 0.601285; batch adversarial loss: 0.403471\n",
      "epoch 32; iter: 0; batch classifier loss: 0.630435; batch adversarial loss: 0.431180\n",
      "epoch 33; iter: 0; batch classifier loss: 0.592206; batch adversarial loss: 0.395303\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544552; batch adversarial loss: 0.335905\n",
      "epoch 35; iter: 0; batch classifier loss: 0.665078; batch adversarial loss: 0.439111\n",
      "epoch 36; iter: 0; batch classifier loss: 0.552723; batch adversarial loss: 0.382608\n",
      "epoch 37; iter: 0; batch classifier loss: 0.594762; batch adversarial loss: 0.414891\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444537; batch adversarial loss: 0.344309\n",
      "epoch 39; iter: 0; batch classifier loss: 0.560429; batch adversarial loss: 0.320757\n",
      "epoch 40; iter: 0; batch classifier loss: 0.523117; batch adversarial loss: 0.388105\n",
      "epoch 41; iter: 0; batch classifier loss: 0.599084; batch adversarial loss: 0.408122\n",
      "epoch 42; iter: 0; batch classifier loss: 0.499854; batch adversarial loss: 0.337995\n",
      "epoch 43; iter: 0; batch classifier loss: 0.547513; batch adversarial loss: 0.352094\n",
      "epoch 44; iter: 0; batch classifier loss: 0.465898; batch adversarial loss: 0.315350\n",
      "epoch 45; iter: 0; batch classifier loss: 0.518421; batch adversarial loss: 0.341058\n",
      "epoch 46; iter: 0; batch classifier loss: 0.540873; batch adversarial loss: 0.301326\n",
      "epoch 47; iter: 0; batch classifier loss: 0.488764; batch adversarial loss: 0.268824\n",
      "epoch 48; iter: 0; batch classifier loss: 0.598526; batch adversarial loss: 0.383821\n",
      "epoch 49; iter: 0; batch classifier loss: 0.523390; batch adversarial loss: 0.369085\n",
      "epoch 50; iter: 0; batch classifier loss: 0.595914; batch adversarial loss: 0.314252\n",
      "epoch 51; iter: 0; batch classifier loss: 0.593950; batch adversarial loss: 0.364904\n",
      "epoch 52; iter: 0; batch classifier loss: 0.516992; batch adversarial loss: 0.282461\n",
      "epoch 53; iter: 0; batch classifier loss: 0.575185; batch adversarial loss: 0.399779\n",
      "epoch 54; iter: 0; batch classifier loss: 0.617498; batch adversarial loss: 0.278546\n",
      "epoch 55; iter: 0; batch classifier loss: 0.476082; batch adversarial loss: 0.249883\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449196; batch adversarial loss: 0.352454\n",
      "epoch 57; iter: 0; batch classifier loss: 0.493510; batch adversarial loss: 0.352778\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421690; batch adversarial loss: 0.365683\n",
      "epoch 59; iter: 0; batch classifier loss: 0.473833; batch adversarial loss: 0.377583\n",
      "epoch 60; iter: 0; batch classifier loss: 0.485756; batch adversarial loss: 0.320113\n",
      "epoch 61; iter: 0; batch classifier loss: 0.457279; batch adversarial loss: 0.248990\n",
      "epoch 62; iter: 0; batch classifier loss: 0.478471; batch adversarial loss: 0.303447\n",
      "epoch 63; iter: 0; batch classifier loss: 0.468321; batch adversarial loss: 0.404444\n",
      "epoch 64; iter: 0; batch classifier loss: 0.365614; batch adversarial loss: 0.321263\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448072; batch adversarial loss: 0.257680\n",
      "epoch 66; iter: 0; batch classifier loss: 0.323453; batch adversarial loss: 0.330487\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407345; batch adversarial loss: 0.344057\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408005; batch adversarial loss: 0.343338\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430195; batch adversarial loss: 0.280835\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424587; batch adversarial loss: 0.343358\n",
      "epoch 71; iter: 0; batch classifier loss: 0.478259; batch adversarial loss: 0.280033\n",
      "epoch 72; iter: 0; batch classifier loss: 0.410252; batch adversarial loss: 0.286542\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371183; batch adversarial loss: 0.287135\n",
      "epoch 74; iter: 0; batch classifier loss: 0.457186; batch adversarial loss: 0.363825\n",
      "epoch 75; iter: 0; batch classifier loss: 0.356392; batch adversarial loss: 0.308593\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373329; batch adversarial loss: 0.314791\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425259; batch adversarial loss: 0.336629\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359336; batch adversarial loss: 0.228362\n",
      "epoch 79; iter: 0; batch classifier loss: 0.387867; batch adversarial loss: 0.367322\n",
      "epoch 80; iter: 0; batch classifier loss: 0.486677; batch adversarial loss: 0.418703\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419296; batch adversarial loss: 0.277942\n",
      "epoch 82; iter: 0; batch classifier loss: 0.454380; batch adversarial loss: 0.271538\n",
      "epoch 83; iter: 0; batch classifier loss: 0.384990; batch adversarial loss: 0.276719\n",
      "epoch 84; iter: 0; batch classifier loss: 0.444981; batch adversarial loss: 0.268619\n",
      "epoch 85; iter: 0; batch classifier loss: 0.391197; batch adversarial loss: 0.396585\n",
      "epoch 86; iter: 0; batch classifier loss: 0.410991; batch adversarial loss: 0.297075\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377475; batch adversarial loss: 0.312587\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420674; batch adversarial loss: 0.259168\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383716; batch adversarial loss: 0.269867\n",
      "epoch 90; iter: 0; batch classifier loss: 0.464054; batch adversarial loss: 0.260312\n",
      "epoch 91; iter: 0; batch classifier loss: 0.399103; batch adversarial loss: 0.359862\n",
      "epoch 92; iter: 0; batch classifier loss: 0.383739; batch adversarial loss: 0.241386\n",
      "epoch 93; iter: 0; batch classifier loss: 0.352989; batch adversarial loss: 0.288419\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378836; batch adversarial loss: 0.285274\n",
      "epoch 95; iter: 0; batch classifier loss: 0.410257; batch adversarial loss: 0.293424\n",
      "epoch 96; iter: 0; batch classifier loss: 0.376394; batch adversarial loss: 0.308879\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378347; batch adversarial loss: 0.290080\n",
      "epoch 98; iter: 0; batch classifier loss: 0.379655; batch adversarial loss: 0.254710\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364958; batch adversarial loss: 0.227611\n",
      "epoch 100; iter: 0; batch classifier loss: 0.421130; batch adversarial loss: 0.300179\n",
      "epoch 101; iter: 0; batch classifier loss: 0.363857; batch adversarial loss: 0.259671\n",
      "epoch 102; iter: 0; batch classifier loss: 0.328507; batch adversarial loss: 0.273192\n",
      "epoch 103; iter: 0; batch classifier loss: 0.402759; batch adversarial loss: 0.363271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.424477; batch adversarial loss: 0.291040\n",
      "epoch 105; iter: 0; batch classifier loss: 0.289009; batch adversarial loss: 0.337061\n",
      "epoch 106; iter: 0; batch classifier loss: 0.397845; batch adversarial loss: 0.270629\n",
      "epoch 107; iter: 0; batch classifier loss: 0.374098; batch adversarial loss: 0.281104\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379102; batch adversarial loss: 0.315894\n",
      "epoch 109; iter: 0; batch classifier loss: 0.381492; batch adversarial loss: 0.289185\n",
      "epoch 110; iter: 0; batch classifier loss: 0.405708; batch adversarial loss: 0.307953\n",
      "epoch 111; iter: 0; batch classifier loss: 0.321033; batch adversarial loss: 0.363713\n",
      "epoch 112; iter: 0; batch classifier loss: 0.370226; batch adversarial loss: 0.371052\n",
      "epoch 113; iter: 0; batch classifier loss: 0.348946; batch adversarial loss: 0.320690\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362598; batch adversarial loss: 0.233086\n",
      "epoch 115; iter: 0; batch classifier loss: 0.339422; batch adversarial loss: 0.219082\n",
      "epoch 116; iter: 0; batch classifier loss: 0.367296; batch adversarial loss: 0.223567\n",
      "epoch 117; iter: 0; batch classifier loss: 0.339087; batch adversarial loss: 0.272777\n",
      "epoch 118; iter: 0; batch classifier loss: 0.294682; batch adversarial loss: 0.297158\n",
      "epoch 119; iter: 0; batch classifier loss: 0.383969; batch adversarial loss: 0.324922\n",
      "epoch 120; iter: 0; batch classifier loss: 0.293341; batch adversarial loss: 0.219346\n",
      "epoch 121; iter: 0; batch classifier loss: 0.319400; batch adversarial loss: 0.285021\n",
      "epoch 122; iter: 0; batch classifier loss: 0.402772; batch adversarial loss: 0.253013\n",
      "epoch 123; iter: 0; batch classifier loss: 0.365865; batch adversarial loss: 0.344423\n",
      "epoch 124; iter: 0; batch classifier loss: 0.337210; batch adversarial loss: 0.360886\n",
      "epoch 125; iter: 0; batch classifier loss: 0.408567; batch adversarial loss: 0.370142\n",
      "epoch 126; iter: 0; batch classifier loss: 0.358521; batch adversarial loss: 0.377986\n",
      "epoch 127; iter: 0; batch classifier loss: 0.445814; batch adversarial loss: 0.288958\n",
      "epoch 128; iter: 0; batch classifier loss: 0.307286; batch adversarial loss: 0.220580\n",
      "epoch 129; iter: 0; batch classifier loss: 0.292427; batch adversarial loss: 0.339161\n",
      "epoch 130; iter: 0; batch classifier loss: 0.377503; batch adversarial loss: 0.168174\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339693; batch adversarial loss: 0.324555\n",
      "epoch 132; iter: 0; batch classifier loss: 0.310044; batch adversarial loss: 0.347504\n",
      "epoch 133; iter: 0; batch classifier loss: 0.342505; batch adversarial loss: 0.317502\n",
      "epoch 134; iter: 0; batch classifier loss: 0.283805; batch adversarial loss: 0.222257\n",
      "epoch 135; iter: 0; batch classifier loss: 0.314954; batch adversarial loss: 0.357094\n",
      "epoch 136; iter: 0; batch classifier loss: 0.358694; batch adversarial loss: 0.270908\n",
      "epoch 137; iter: 0; batch classifier loss: 0.369723; batch adversarial loss: 0.306034\n",
      "epoch 138; iter: 0; batch classifier loss: 0.317408; batch adversarial loss: 0.264807\n",
      "epoch 139; iter: 0; batch classifier loss: 0.346941; batch adversarial loss: 0.272059\n",
      "epoch 140; iter: 0; batch classifier loss: 0.358167; batch adversarial loss: 0.294745\n",
      "epoch 141; iter: 0; batch classifier loss: 0.352252; batch adversarial loss: 0.299517\n",
      "epoch 142; iter: 0; batch classifier loss: 0.321405; batch adversarial loss: 0.190612\n",
      "epoch 143; iter: 0; batch classifier loss: 0.306450; batch adversarial loss: 0.300716\n",
      "epoch 144; iter: 0; batch classifier loss: 0.341294; batch adversarial loss: 0.255095\n",
      "epoch 145; iter: 0; batch classifier loss: 0.382729; batch adversarial loss: 0.344659\n",
      "epoch 146; iter: 0; batch classifier loss: 0.384330; batch adversarial loss: 0.227582\n",
      "epoch 147; iter: 0; batch classifier loss: 0.295100; batch adversarial loss: 0.167011\n",
      "epoch 148; iter: 0; batch classifier loss: 0.329579; batch adversarial loss: 0.347691\n",
      "epoch 149; iter: 0; batch classifier loss: 0.391065; batch adversarial loss: 0.244903\n",
      "epoch 150; iter: 0; batch classifier loss: 0.360284; batch adversarial loss: 0.323570\n",
      "epoch 151; iter: 0; batch classifier loss: 0.392351; batch adversarial loss: 0.275712\n",
      "epoch 152; iter: 0; batch classifier loss: 0.335546; batch adversarial loss: 0.294264\n",
      "epoch 153; iter: 0; batch classifier loss: 0.390735; batch adversarial loss: 0.321964\n",
      "epoch 154; iter: 0; batch classifier loss: 0.340930; batch adversarial loss: 0.329539\n",
      "epoch 155; iter: 0; batch classifier loss: 0.344714; batch adversarial loss: 0.167509\n",
      "epoch 156; iter: 0; batch classifier loss: 0.371271; batch adversarial loss: 0.278204\n",
      "epoch 157; iter: 0; batch classifier loss: 0.325581; batch adversarial loss: 0.331222\n",
      "epoch 158; iter: 0; batch classifier loss: 0.303369; batch adversarial loss: 0.339164\n",
      "epoch 159; iter: 0; batch classifier loss: 0.291874; batch adversarial loss: 0.314896\n",
      "epoch 160; iter: 0; batch classifier loss: 0.311558; batch adversarial loss: 0.291018\n",
      "epoch 161; iter: 0; batch classifier loss: 0.366658; batch adversarial loss: 0.218884\n",
      "epoch 162; iter: 0; batch classifier loss: 0.262150; batch adversarial loss: 0.207938\n",
      "epoch 163; iter: 0; batch classifier loss: 0.246472; batch adversarial loss: 0.306026\n",
      "epoch 164; iter: 0; batch classifier loss: 0.362790; batch adversarial loss: 0.314405\n",
      "epoch 165; iter: 0; batch classifier loss: 0.381920; batch adversarial loss: 0.220157\n",
      "epoch 166; iter: 0; batch classifier loss: 0.369767; batch adversarial loss: 0.378745\n",
      "epoch 167; iter: 0; batch classifier loss: 0.371385; batch adversarial loss: 0.397980\n",
      "epoch 168; iter: 0; batch classifier loss: 0.316445; batch adversarial loss: 0.455548\n",
      "epoch 169; iter: 0; batch classifier loss: 0.313425; batch adversarial loss: 0.344288\n",
      "epoch 170; iter: 0; batch classifier loss: 0.308131; batch adversarial loss: 0.340477\n",
      "epoch 171; iter: 0; batch classifier loss: 0.399125; batch adversarial loss: 0.258004\n",
      "epoch 172; iter: 0; batch classifier loss: 0.283118; batch adversarial loss: 0.290859\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357301; batch adversarial loss: 0.331254\n",
      "epoch 174; iter: 0; batch classifier loss: 0.364866; batch adversarial loss: 0.432196\n",
      "epoch 175; iter: 0; batch classifier loss: 0.309047; batch adversarial loss: 0.424550\n",
      "epoch 176; iter: 0; batch classifier loss: 0.336108; batch adversarial loss: 0.316156\n",
      "epoch 177; iter: 0; batch classifier loss: 0.297425; batch adversarial loss: 0.223891\n",
      "epoch 178; iter: 0; batch classifier loss: 0.312435; batch adversarial loss: 0.342957\n",
      "epoch 179; iter: 0; batch classifier loss: 0.280632; batch adversarial loss: 0.270092\n",
      "epoch 180; iter: 0; batch classifier loss: 0.291864; batch adversarial loss: 0.399773\n",
      "epoch 181; iter: 0; batch classifier loss: 0.264588; batch adversarial loss: 0.292141\n",
      "epoch 182; iter: 0; batch classifier loss: 0.345586; batch adversarial loss: 0.350976\n",
      "epoch 183; iter: 0; batch classifier loss: 0.257348; batch adversarial loss: 0.356236\n",
      "epoch 184; iter: 0; batch classifier loss: 0.368381; batch adversarial loss: 0.291586\n",
      "epoch 185; iter: 0; batch classifier loss: 0.384962; batch adversarial loss: 0.363638\n",
      "epoch 186; iter: 0; batch classifier loss: 0.315469; batch adversarial loss: 0.315310\n",
      "epoch 187; iter: 0; batch classifier loss: 0.332302; batch adversarial loss: 0.379701\n",
      "epoch 188; iter: 0; batch classifier loss: 0.256159; batch adversarial loss: 0.237299\n",
      "epoch 189; iter: 0; batch classifier loss: 0.347190; batch adversarial loss: 0.366543\n",
      "epoch 190; iter: 0; batch classifier loss: 0.249423; batch adversarial loss: 0.361845\n",
      "epoch 191; iter: 0; batch classifier loss: 0.323190; batch adversarial loss: 0.295008\n",
      "epoch 192; iter: 0; batch classifier loss: 0.297093; batch adversarial loss: 0.314527\n",
      "epoch 193; iter: 0; batch classifier loss: 0.256056; batch adversarial loss: 0.306362\n",
      "epoch 194; iter: 0; batch classifier loss: 0.353276; batch adversarial loss: 0.390167\n",
      "epoch 195; iter: 0; batch classifier loss: 0.304996; batch adversarial loss: 0.222432\n",
      "epoch 196; iter: 0; batch classifier loss: 0.308938; batch adversarial loss: 0.288554\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329672; batch adversarial loss: 0.240145\n",
      "epoch 198; iter: 0; batch classifier loss: 0.353867; batch adversarial loss: 0.366322\n",
      "epoch 199; iter: 0; batch classifier loss: 0.290288; batch adversarial loss: 0.418720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.130336; batch adversarial loss: 0.920935\n",
      "epoch 2; iter: 0; batch classifier loss: 1.041325; batch adversarial loss: 0.795320\n",
      "epoch 3; iter: 0; batch classifier loss: 0.812371; batch adversarial loss: 0.811544\n",
      "epoch 4; iter: 0; batch classifier loss: 0.735617; batch adversarial loss: 0.714632\n",
      "epoch 5; iter: 0; batch classifier loss: 0.623965; batch adversarial loss: 0.655238\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574457; batch adversarial loss: 0.636219\n",
      "epoch 7; iter: 0; batch classifier loss: 0.585919; batch adversarial loss: 0.611543\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554587; batch adversarial loss: 0.601709\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538449; batch adversarial loss: 0.574664\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550876; batch adversarial loss: 0.582777\n",
      "epoch 11; iter: 0; batch classifier loss: 0.574802; batch adversarial loss: 0.542557\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537851; batch adversarial loss: 0.535791\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540948; batch adversarial loss: 0.529904\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528363; batch adversarial loss: 0.491034\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533064; batch adversarial loss: 0.470610\n",
      "epoch 16; iter: 0; batch classifier loss: 0.597618; batch adversarial loss: 0.452466\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505465; batch adversarial loss: 0.458695\n",
      "epoch 18; iter: 0; batch classifier loss: 0.549813; batch adversarial loss: 0.449589\n",
      "epoch 19; iter: 0; batch classifier loss: 0.531516; batch adversarial loss: 0.450573\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504066; batch adversarial loss: 0.420888\n",
      "epoch 21; iter: 0; batch classifier loss: 0.510165; batch adversarial loss: 0.432794\n",
      "epoch 22; iter: 0; batch classifier loss: 0.529917; batch adversarial loss: 0.448428\n",
      "epoch 23; iter: 0; batch classifier loss: 0.490438; batch adversarial loss: 0.493992\n",
      "epoch 24; iter: 0; batch classifier loss: 0.553970; batch adversarial loss: 0.358880\n",
      "epoch 25; iter: 0; batch classifier loss: 0.522475; batch adversarial loss: 0.420353\n",
      "epoch 26; iter: 0; batch classifier loss: 0.580582; batch adversarial loss: 0.470549\n",
      "epoch 27; iter: 0; batch classifier loss: 0.646607; batch adversarial loss: 0.494577\n",
      "epoch 28; iter: 0; batch classifier loss: 0.574972; batch adversarial loss: 0.405227\n",
      "epoch 29; iter: 0; batch classifier loss: 0.502645; batch adversarial loss: 0.463980\n",
      "epoch 30; iter: 0; batch classifier loss: 0.525886; batch adversarial loss: 0.379867\n",
      "epoch 31; iter: 0; batch classifier loss: 0.562465; batch adversarial loss: 0.401496\n",
      "epoch 32; iter: 0; batch classifier loss: 0.604917; batch adversarial loss: 0.433260\n",
      "epoch 33; iter: 0; batch classifier loss: 0.573279; batch adversarial loss: 0.394763\n",
      "epoch 34; iter: 0; batch classifier loss: 0.539086; batch adversarial loss: 0.336237\n",
      "epoch 35; iter: 0; batch classifier loss: 0.645761; batch adversarial loss: 0.444403\n",
      "epoch 36; iter: 0; batch classifier loss: 0.547540; batch adversarial loss: 0.386153\n",
      "epoch 37; iter: 0; batch classifier loss: 0.594330; batch adversarial loss: 0.420180\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445107; batch adversarial loss: 0.346656\n",
      "epoch 39; iter: 0; batch classifier loss: 0.559096; batch adversarial loss: 0.322068\n",
      "epoch 40; iter: 0; batch classifier loss: 0.516602; batch adversarial loss: 0.392408\n",
      "epoch 41; iter: 0; batch classifier loss: 0.597683; batch adversarial loss: 0.414286\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496375; batch adversarial loss: 0.340704\n",
      "epoch 43; iter: 0; batch classifier loss: 0.533543; batch adversarial loss: 0.356035\n",
      "epoch 44; iter: 0; batch classifier loss: 0.473565; batch adversarial loss: 0.317569\n",
      "epoch 45; iter: 0; batch classifier loss: 0.531145; batch adversarial loss: 0.344629\n",
      "epoch 46; iter: 0; batch classifier loss: 0.555332; batch adversarial loss: 0.304010\n",
      "epoch 47; iter: 0; batch classifier loss: 0.492484; batch adversarial loss: 0.270629\n",
      "epoch 48; iter: 0; batch classifier loss: 0.609831; batch adversarial loss: 0.388682\n",
      "epoch 49; iter: 0; batch classifier loss: 0.530001; batch adversarial loss: 0.372978\n",
      "epoch 50; iter: 0; batch classifier loss: 0.586861; batch adversarial loss: 0.316949\n",
      "epoch 51; iter: 0; batch classifier loss: 0.595028; batch adversarial loss: 0.368492\n",
      "epoch 52; iter: 0; batch classifier loss: 0.516015; batch adversarial loss: 0.283788\n",
      "epoch 53; iter: 0; batch classifier loss: 0.553932; batch adversarial loss: 0.404219\n",
      "epoch 54; iter: 0; batch classifier loss: 0.566489; batch adversarial loss: 0.280102\n",
      "epoch 55; iter: 0; batch classifier loss: 0.561864; batch adversarial loss: 0.251900\n",
      "epoch 56; iter: 0; batch classifier loss: 0.552867; batch adversarial loss: 0.353809\n",
      "epoch 57; iter: 0; batch classifier loss: 0.512658; batch adversarial loss: 0.353300\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429708; batch adversarial loss: 0.365994\n",
      "epoch 59; iter: 0; batch classifier loss: 0.452835; batch adversarial loss: 0.377553\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481206; batch adversarial loss: 0.320762\n",
      "epoch 61; iter: 0; batch classifier loss: 0.455173; batch adversarial loss: 0.249844\n",
      "epoch 62; iter: 0; batch classifier loss: 0.486740; batch adversarial loss: 0.304130\n",
      "epoch 63; iter: 0; batch classifier loss: 0.454999; batch adversarial loss: 0.404346\n",
      "epoch 64; iter: 0; batch classifier loss: 0.362315; batch adversarial loss: 0.321580\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441763; batch adversarial loss: 0.258184\n",
      "epoch 66; iter: 0; batch classifier loss: 0.322994; batch adversarial loss: 0.330823\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407047; batch adversarial loss: 0.344621\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403284; batch adversarial loss: 0.343366\n",
      "epoch 69; iter: 0; batch classifier loss: 0.410675; batch adversarial loss: 0.280670\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419524; batch adversarial loss: 0.343724\n",
      "epoch 71; iter: 0; batch classifier loss: 0.471915; batch adversarial loss: 0.279964\n",
      "epoch 72; iter: 0; batch classifier loss: 0.418713; batch adversarial loss: 0.286774\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372006; batch adversarial loss: 0.287765\n",
      "epoch 74; iter: 0; batch classifier loss: 0.443884; batch adversarial loss: 0.364474\n",
      "epoch 75; iter: 0; batch classifier loss: 0.353076; batch adversarial loss: 0.308434\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376618; batch adversarial loss: 0.315043\n",
      "epoch 77; iter: 0; batch classifier loss: 0.415475; batch adversarial loss: 0.336538\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347646; batch adversarial loss: 0.228082\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374035; batch adversarial loss: 0.367468\n",
      "epoch 80; iter: 0; batch classifier loss: 0.468411; batch adversarial loss: 0.419123\n",
      "epoch 81; iter: 0; batch classifier loss: 0.402971; batch adversarial loss: 0.277472\n",
      "epoch 82; iter: 0; batch classifier loss: 0.457299; batch adversarial loss: 0.271272\n",
      "epoch 83; iter: 0; batch classifier loss: 0.380868; batch adversarial loss: 0.276416\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443019; batch adversarial loss: 0.268863\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383803; batch adversarial loss: 0.397081\n",
      "epoch 86; iter: 0; batch classifier loss: 0.390828; batch adversarial loss: 0.296954\n",
      "epoch 87; iter: 0; batch classifier loss: 0.369665; batch adversarial loss: 0.312777\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423871; batch adversarial loss: 0.258932\n",
      "epoch 89; iter: 0; batch classifier loss: 0.395432; batch adversarial loss: 0.269767\n",
      "epoch 90; iter: 0; batch classifier loss: 0.441658; batch adversarial loss: 0.260354\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403639; batch adversarial loss: 0.360344\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370645; batch adversarial loss: 0.241552\n",
      "epoch 93; iter: 0; batch classifier loss: 0.342185; batch adversarial loss: 0.288557\n",
      "epoch 94; iter: 0; batch classifier loss: 0.367338; batch adversarial loss: 0.285647\n",
      "epoch 95; iter: 0; batch classifier loss: 0.428753; batch adversarial loss: 0.293724\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370761; batch adversarial loss: 0.309620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.357549; batch adversarial loss: 0.289427\n",
      "epoch 98; iter: 0; batch classifier loss: 0.376117; batch adversarial loss: 0.253371\n",
      "epoch 99; iter: 0; batch classifier loss: 0.356692; batch adversarial loss: 0.227995\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417690; batch adversarial loss: 0.299764\n",
      "epoch 101; iter: 0; batch classifier loss: 0.391054; batch adversarial loss: 0.260325\n",
      "epoch 102; iter: 0; batch classifier loss: 0.332223; batch adversarial loss: 0.273008\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399146; batch adversarial loss: 0.364032\n",
      "epoch 104; iter: 0; batch classifier loss: 0.448458; batch adversarial loss: 0.291113\n",
      "epoch 105; iter: 0; batch classifier loss: 0.290133; batch adversarial loss: 0.336590\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379744; batch adversarial loss: 0.269759\n",
      "epoch 107; iter: 0; batch classifier loss: 0.366203; batch adversarial loss: 0.281594\n",
      "epoch 108; iter: 0; batch classifier loss: 0.379944; batch adversarial loss: 0.316632\n",
      "epoch 109; iter: 0; batch classifier loss: 0.376567; batch adversarial loss: 0.288822\n",
      "epoch 110; iter: 0; batch classifier loss: 0.415965; batch adversarial loss: 0.307770\n",
      "epoch 111; iter: 0; batch classifier loss: 0.311414; batch adversarial loss: 0.363212\n",
      "epoch 112; iter: 0; batch classifier loss: 0.389106; batch adversarial loss: 0.371850\n",
      "epoch 113; iter: 0; batch classifier loss: 0.347799; batch adversarial loss: 0.320626\n",
      "epoch 114; iter: 0; batch classifier loss: 0.352371; batch adversarial loss: 0.232486\n",
      "epoch 115; iter: 0; batch classifier loss: 0.329074; batch adversarial loss: 0.218970\n",
      "epoch 116; iter: 0; batch classifier loss: 0.350205; batch adversarial loss: 0.223458\n",
      "epoch 117; iter: 0; batch classifier loss: 0.314045; batch adversarial loss: 0.271590\n",
      "epoch 118; iter: 0; batch classifier loss: 0.302341; batch adversarial loss: 0.297188\n",
      "epoch 119; iter: 0; batch classifier loss: 0.363696; batch adversarial loss: 0.323830\n",
      "epoch 120; iter: 0; batch classifier loss: 0.303876; batch adversarial loss: 0.219282\n",
      "epoch 121; iter: 0; batch classifier loss: 0.319052; batch adversarial loss: 0.284458\n",
      "epoch 122; iter: 0; batch classifier loss: 0.377708; batch adversarial loss: 0.253178\n",
      "epoch 123; iter: 0; batch classifier loss: 0.348570; batch adversarial loss: 0.344629\n",
      "epoch 124; iter: 0; batch classifier loss: 0.353642; batch adversarial loss: 0.359083\n",
      "epoch 125; iter: 0; batch classifier loss: 0.398500; batch adversarial loss: 0.369273\n",
      "epoch 126; iter: 0; batch classifier loss: 0.367986; batch adversarial loss: 0.377702\n",
      "epoch 127; iter: 0; batch classifier loss: 0.421883; batch adversarial loss: 0.288797\n",
      "epoch 128; iter: 0; batch classifier loss: 0.320446; batch adversarial loss: 0.220691\n",
      "epoch 129; iter: 0; batch classifier loss: 0.283872; batch adversarial loss: 0.337613\n",
      "epoch 130; iter: 0; batch classifier loss: 0.360184; batch adversarial loss: 0.167748\n",
      "epoch 131; iter: 0; batch classifier loss: 0.328742; batch adversarial loss: 0.324945\n",
      "epoch 132; iter: 0; batch classifier loss: 0.324602; batch adversarial loss: 0.346550\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349091; batch adversarial loss: 0.317275\n",
      "epoch 134; iter: 0; batch classifier loss: 0.288933; batch adversarial loss: 0.221116\n",
      "epoch 135; iter: 0; batch classifier loss: 0.311624; batch adversarial loss: 0.357259\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328082; batch adversarial loss: 0.270207\n",
      "epoch 137; iter: 0; batch classifier loss: 0.374282; batch adversarial loss: 0.305904\n",
      "epoch 138; iter: 0; batch classifier loss: 0.313129; batch adversarial loss: 0.264851\n",
      "epoch 139; iter: 0; batch classifier loss: 0.372000; batch adversarial loss: 0.272908\n",
      "epoch 140; iter: 0; batch classifier loss: 0.391689; batch adversarial loss: 0.295721\n",
      "epoch 141; iter: 0; batch classifier loss: 0.343045; batch adversarial loss: 0.300105\n",
      "epoch 142; iter: 0; batch classifier loss: 0.339835; batch adversarial loss: 0.191407\n",
      "epoch 143; iter: 0; batch classifier loss: 0.301819; batch adversarial loss: 0.301273\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356024; batch adversarial loss: 0.253928\n",
      "epoch 145; iter: 0; batch classifier loss: 0.399604; batch adversarial loss: 0.343864\n",
      "epoch 146; iter: 0; batch classifier loss: 0.374780; batch adversarial loss: 0.227356\n",
      "epoch 147; iter: 0; batch classifier loss: 0.310352; batch adversarial loss: 0.166933\n",
      "epoch 148; iter: 0; batch classifier loss: 0.325488; batch adversarial loss: 0.347477\n",
      "epoch 149; iter: 0; batch classifier loss: 0.345931; batch adversarial loss: 0.244741\n",
      "epoch 150; iter: 0; batch classifier loss: 0.352278; batch adversarial loss: 0.323576\n",
      "epoch 151; iter: 0; batch classifier loss: 0.405116; batch adversarial loss: 0.274944\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338339; batch adversarial loss: 0.293679\n",
      "epoch 153; iter: 0; batch classifier loss: 0.388223; batch adversarial loss: 0.321315\n",
      "epoch 154; iter: 0; batch classifier loss: 0.305170; batch adversarial loss: 0.328819\n",
      "epoch 155; iter: 0; batch classifier loss: 0.322866; batch adversarial loss: 0.167321\n",
      "epoch 156; iter: 0; batch classifier loss: 0.361744; batch adversarial loss: 0.278684\n",
      "epoch 157; iter: 0; batch classifier loss: 0.324126; batch adversarial loss: 0.332631\n",
      "epoch 158; iter: 0; batch classifier loss: 0.319929; batch adversarial loss: 0.338832\n",
      "epoch 159; iter: 0; batch classifier loss: 0.292625; batch adversarial loss: 0.315046\n",
      "epoch 160; iter: 0; batch classifier loss: 0.311246; batch adversarial loss: 0.290970\n",
      "epoch 161; iter: 0; batch classifier loss: 0.368023; batch adversarial loss: 0.217950\n",
      "epoch 162; iter: 0; batch classifier loss: 0.265751; batch adversarial loss: 0.207471\n",
      "epoch 163; iter: 0; batch classifier loss: 0.244954; batch adversarial loss: 0.305535\n",
      "epoch 164; iter: 0; batch classifier loss: 0.327807; batch adversarial loss: 0.314143\n",
      "epoch 165; iter: 0; batch classifier loss: 0.374779; batch adversarial loss: 0.220868\n",
      "epoch 166; iter: 0; batch classifier loss: 0.367284; batch adversarial loss: 0.378755\n",
      "epoch 167; iter: 0; batch classifier loss: 0.364467; batch adversarial loss: 0.398765\n",
      "epoch 168; iter: 0; batch classifier loss: 0.313709; batch adversarial loss: 0.455622\n",
      "epoch 169; iter: 0; batch classifier loss: 0.285857; batch adversarial loss: 0.344827\n",
      "epoch 170; iter: 0; batch classifier loss: 0.290159; batch adversarial loss: 0.339541\n",
      "epoch 171; iter: 0; batch classifier loss: 0.378729; batch adversarial loss: 0.257525\n",
      "epoch 172; iter: 0; batch classifier loss: 0.295428; batch adversarial loss: 0.288877\n",
      "epoch 173; iter: 0; batch classifier loss: 0.349916; batch adversarial loss: 0.332091\n",
      "epoch 174; iter: 0; batch classifier loss: 0.370029; batch adversarial loss: 0.432287\n",
      "epoch 175; iter: 0; batch classifier loss: 0.295982; batch adversarial loss: 0.425279\n",
      "epoch 176; iter: 0; batch classifier loss: 0.347878; batch adversarial loss: 0.315913\n",
      "epoch 177; iter: 0; batch classifier loss: 0.304797; batch adversarial loss: 0.223685\n",
      "epoch 178; iter: 0; batch classifier loss: 0.334498; batch adversarial loss: 0.341458\n",
      "epoch 179; iter: 0; batch classifier loss: 0.290735; batch adversarial loss: 0.269856\n",
      "epoch 180; iter: 0; batch classifier loss: 0.300439; batch adversarial loss: 0.399750\n",
      "epoch 181; iter: 0; batch classifier loss: 0.276666; batch adversarial loss: 0.291590\n",
      "epoch 182; iter: 0; batch classifier loss: 0.345806; batch adversarial loss: 0.350858\n",
      "epoch 183; iter: 0; batch classifier loss: 0.260746; batch adversarial loss: 0.355178\n",
      "epoch 184; iter: 0; batch classifier loss: 0.390007; batch adversarial loss: 0.290983\n",
      "epoch 185; iter: 0; batch classifier loss: 0.381109; batch adversarial loss: 0.363338\n",
      "epoch 186; iter: 0; batch classifier loss: 0.309088; batch adversarial loss: 0.315811\n",
      "epoch 187; iter: 0; batch classifier loss: 0.324149; batch adversarial loss: 0.377794\n",
      "epoch 188; iter: 0; batch classifier loss: 0.272814; batch adversarial loss: 0.236901\n",
      "epoch 189; iter: 0; batch classifier loss: 0.338643; batch adversarial loss: 0.365184\n",
      "epoch 190; iter: 0; batch classifier loss: 0.254806; batch adversarial loss: 0.361850\n",
      "epoch 191; iter: 0; batch classifier loss: 0.331805; batch adversarial loss: 0.295701\n",
      "epoch 192; iter: 0; batch classifier loss: 0.327515; batch adversarial loss: 0.314115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 193; iter: 0; batch classifier loss: 0.266170; batch adversarial loss: 0.305242\n",
      "epoch 194; iter: 0; batch classifier loss: 0.400849; batch adversarial loss: 0.392954\n",
      "epoch 195; iter: 0; batch classifier loss: 0.302331; batch adversarial loss: 0.221965\n",
      "epoch 196; iter: 0; batch classifier loss: 0.330287; batch adversarial loss: 0.288092\n",
      "epoch 197; iter: 0; batch classifier loss: 0.312735; batch adversarial loss: 0.240256\n",
      "epoch 198; iter: 0; batch classifier loss: 0.346233; batch adversarial loss: 0.367049\n",
      "epoch 199; iter: 0; batch classifier loss: 0.259637; batch adversarial loss: 0.417866\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.227900; batch adversarial loss: 0.925473\n",
      "epoch 2; iter: 0; batch classifier loss: 1.116354; batch adversarial loss: 0.799366\n",
      "epoch 3; iter: 0; batch classifier loss: 0.872472; batch adversarial loss: 0.818269\n",
      "epoch 4; iter: 0; batch classifier loss: 0.804623; batch adversarial loss: 0.723426\n",
      "epoch 5; iter: 0; batch classifier loss: 0.670072; batch adversarial loss: 0.662560\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582822; batch adversarial loss: 0.635978\n",
      "epoch 7; iter: 0; batch classifier loss: 0.581451; batch adversarial loss: 0.612274\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551961; batch adversarial loss: 0.601471\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539384; batch adversarial loss: 0.573332\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542408; batch adversarial loss: 0.582471\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568670; batch adversarial loss: 0.541669\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530796; batch adversarial loss: 0.535116\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533677; batch adversarial loss: 0.528913\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515447; batch adversarial loss: 0.492865\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526511; batch adversarial loss: 0.473544\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591345; batch adversarial loss: 0.456208\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506577; batch adversarial loss: 0.462785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543207; batch adversarial loss: 0.453583\n",
      "epoch 19; iter: 0; batch classifier loss: 0.547230; batch adversarial loss: 0.459910\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517350; batch adversarial loss: 0.431893\n",
      "epoch 21; iter: 0; batch classifier loss: 0.535564; batch adversarial loss: 0.447846\n",
      "epoch 22; iter: 0; batch classifier loss: 0.571577; batch adversarial loss: 0.463206\n",
      "epoch 23; iter: 0; batch classifier loss: 0.524580; batch adversarial loss: 0.505830\n",
      "epoch 24; iter: 0; batch classifier loss: 0.580562; batch adversarial loss: 0.366034\n",
      "epoch 25; iter: 0; batch classifier loss: 0.553768; batch adversarial loss: 0.430832\n",
      "epoch 26; iter: 0; batch classifier loss: 0.640300; batch adversarial loss: 0.484074\n",
      "epoch 27; iter: 0; batch classifier loss: 0.693532; batch adversarial loss: 0.500382\n",
      "epoch 28; iter: 0; batch classifier loss: 0.608204; batch adversarial loss: 0.410099\n",
      "epoch 29; iter: 0; batch classifier loss: 0.523122; batch adversarial loss: 0.466576\n",
      "epoch 30; iter: 0; batch classifier loss: 0.548805; batch adversarial loss: 0.382041\n",
      "epoch 31; iter: 0; batch classifier loss: 0.600766; batch adversarial loss: 0.403950\n",
      "epoch 32; iter: 0; batch classifier loss: 0.629031; batch adversarial loss: 0.431841\n",
      "epoch 33; iter: 0; batch classifier loss: 0.589201; batch adversarial loss: 0.395857\n",
      "epoch 34; iter: 0; batch classifier loss: 0.546560; batch adversarial loss: 0.335896\n",
      "epoch 35; iter: 0; batch classifier loss: 0.664607; batch adversarial loss: 0.439316\n",
      "epoch 36; iter: 0; batch classifier loss: 0.548695; batch adversarial loss: 0.382930\n",
      "epoch 37; iter: 0; batch classifier loss: 0.591263; batch adversarial loss: 0.415312\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443403; batch adversarial loss: 0.344220\n",
      "epoch 39; iter: 0; batch classifier loss: 0.557945; batch adversarial loss: 0.320892\n",
      "epoch 40; iter: 0; batch classifier loss: 0.517097; batch adversarial loss: 0.388270\n",
      "epoch 41; iter: 0; batch classifier loss: 0.592394; batch adversarial loss: 0.408047\n",
      "epoch 42; iter: 0; batch classifier loss: 0.492514; batch adversarial loss: 0.338172\n",
      "epoch 43; iter: 0; batch classifier loss: 0.543696; batch adversarial loss: 0.352136\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462334; batch adversarial loss: 0.315215\n",
      "epoch 45; iter: 0; batch classifier loss: 0.514730; batch adversarial loss: 0.341170\n",
      "epoch 46; iter: 0; batch classifier loss: 0.538266; batch adversarial loss: 0.301418\n",
      "epoch 47; iter: 0; batch classifier loss: 0.489397; batch adversarial loss: 0.269052\n",
      "epoch 48; iter: 0; batch classifier loss: 0.597563; batch adversarial loss: 0.384110\n",
      "epoch 49; iter: 0; batch classifier loss: 0.520609; batch adversarial loss: 0.369254\n",
      "epoch 50; iter: 0; batch classifier loss: 0.586733; batch adversarial loss: 0.314423\n",
      "epoch 51; iter: 0; batch classifier loss: 0.592295; batch adversarial loss: 0.365193\n",
      "epoch 52; iter: 0; batch classifier loss: 0.519465; batch adversarial loss: 0.282538\n",
      "epoch 53; iter: 0; batch classifier loss: 0.570068; batch adversarial loss: 0.400131\n",
      "epoch 54; iter: 0; batch classifier loss: 0.617143; batch adversarial loss: 0.278686\n",
      "epoch 55; iter: 0; batch classifier loss: 0.503946; batch adversarial loss: 0.250070\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445463; batch adversarial loss: 0.352540\n",
      "epoch 57; iter: 0; batch classifier loss: 0.494022; batch adversarial loss: 0.352748\n",
      "epoch 58; iter: 0; batch classifier loss: 0.422757; batch adversarial loss: 0.365743\n",
      "epoch 59; iter: 0; batch classifier loss: 0.460585; batch adversarial loss: 0.377503\n",
      "epoch 60; iter: 0; batch classifier loss: 0.475890; batch adversarial loss: 0.320199\n",
      "epoch 61; iter: 0; batch classifier loss: 0.460099; batch adversarial loss: 0.249036\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479927; batch adversarial loss: 0.303598\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465530; batch adversarial loss: 0.404470\n",
      "epoch 64; iter: 0; batch classifier loss: 0.359414; batch adversarial loss: 0.321397\n",
      "epoch 65; iter: 0; batch classifier loss: 0.453810; batch adversarial loss: 0.257719\n",
      "epoch 66; iter: 0; batch classifier loss: 0.318011; batch adversarial loss: 0.330422\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407685; batch adversarial loss: 0.344311\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408309; batch adversarial loss: 0.343330\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428570; batch adversarial loss: 0.280720\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418790; batch adversarial loss: 0.343464\n",
      "epoch 71; iter: 0; batch classifier loss: 0.479928; batch adversarial loss: 0.280035\n",
      "epoch 72; iter: 0; batch classifier loss: 0.410261; batch adversarial loss: 0.286369\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372143; batch adversarial loss: 0.287311\n",
      "epoch 74; iter: 0; batch classifier loss: 0.451766; batch adversarial loss: 0.364423\n",
      "epoch 75; iter: 0; batch classifier loss: 0.356903; batch adversarial loss: 0.308536\n",
      "epoch 76; iter: 0; batch classifier loss: 0.367002; batch adversarial loss: 0.314955\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423075; batch adversarial loss: 0.336671\n",
      "epoch 78; iter: 0; batch classifier loss: 0.357748; batch adversarial loss: 0.228390\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374973; batch adversarial loss: 0.367214\n",
      "epoch 80; iter: 0; batch classifier loss: 0.478207; batch adversarial loss: 0.418422\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424651; batch adversarial loss: 0.278032\n",
      "epoch 82; iter: 0; batch classifier loss: 0.464285; batch adversarial loss: 0.271474\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386850; batch adversarial loss: 0.276779\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443732; batch adversarial loss: 0.269003\n",
      "epoch 85; iter: 0; batch classifier loss: 0.391551; batch adversarial loss: 0.396877\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418074; batch adversarial loss: 0.297141\n",
      "epoch 87; iter: 0; batch classifier loss: 0.384026; batch adversarial loss: 0.312665\n",
      "epoch 88; iter: 0; batch classifier loss: 0.428063; batch adversarial loss: 0.259179\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383735; batch adversarial loss: 0.269907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.451389; batch adversarial loss: 0.260310\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409020; batch adversarial loss: 0.360398\n",
      "epoch 92; iter: 0; batch classifier loss: 0.372183; batch adversarial loss: 0.241800\n",
      "epoch 93; iter: 0; batch classifier loss: 0.351781; batch adversarial loss: 0.288736\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375760; batch adversarial loss: 0.285158\n",
      "epoch 95; iter: 0; batch classifier loss: 0.412701; batch adversarial loss: 0.294084\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370886; batch adversarial loss: 0.309181\n",
      "epoch 97; iter: 0; batch classifier loss: 0.374924; batch adversarial loss: 0.290008\n",
      "epoch 98; iter: 0; batch classifier loss: 0.378620; batch adversarial loss: 0.254523\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355844; batch adversarial loss: 0.227630\n",
      "epoch 100; iter: 0; batch classifier loss: 0.424626; batch adversarial loss: 0.300083\n",
      "epoch 101; iter: 0; batch classifier loss: 0.374860; batch adversarial loss: 0.259982\n",
      "epoch 102; iter: 0; batch classifier loss: 0.333521; batch adversarial loss: 0.273318\n",
      "epoch 103; iter: 0; batch classifier loss: 0.398590; batch adversarial loss: 0.363586\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428006; batch adversarial loss: 0.291041\n",
      "epoch 105; iter: 0; batch classifier loss: 0.297740; batch adversarial loss: 0.337123\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388515; batch adversarial loss: 0.270281\n",
      "epoch 107; iter: 0; batch classifier loss: 0.367365; batch adversarial loss: 0.282005\n",
      "epoch 108; iter: 0; batch classifier loss: 0.373970; batch adversarial loss: 0.316040\n",
      "epoch 109; iter: 0; batch classifier loss: 0.384354; batch adversarial loss: 0.289683\n",
      "epoch 110; iter: 0; batch classifier loss: 0.409978; batch adversarial loss: 0.307733\n",
      "epoch 111; iter: 0; batch classifier loss: 0.321819; batch adversarial loss: 0.364247\n",
      "epoch 112; iter: 0; batch classifier loss: 0.382834; batch adversarial loss: 0.371720\n",
      "epoch 113; iter: 0; batch classifier loss: 0.346088; batch adversarial loss: 0.321007\n",
      "epoch 114; iter: 0; batch classifier loss: 0.365812; batch adversarial loss: 0.233043\n",
      "epoch 115; iter: 0; batch classifier loss: 0.329776; batch adversarial loss: 0.219179\n",
      "epoch 116; iter: 0; batch classifier loss: 0.351164; batch adversarial loss: 0.223632\n",
      "epoch 117; iter: 0; batch classifier loss: 0.336296; batch adversarial loss: 0.273147\n",
      "epoch 118; iter: 0; batch classifier loss: 0.306276; batch adversarial loss: 0.297089\n",
      "epoch 119; iter: 0; batch classifier loss: 0.376645; batch adversarial loss: 0.324220\n",
      "epoch 120; iter: 0; batch classifier loss: 0.295365; batch adversarial loss: 0.219538\n",
      "epoch 121; iter: 0; batch classifier loss: 0.316824; batch adversarial loss: 0.285170\n",
      "epoch 122; iter: 0; batch classifier loss: 0.371718; batch adversarial loss: 0.253208\n",
      "epoch 123; iter: 0; batch classifier loss: 0.348438; batch adversarial loss: 0.344944\n",
      "epoch 124; iter: 0; batch classifier loss: 0.332277; batch adversarial loss: 0.361287\n",
      "epoch 125; iter: 0; batch classifier loss: 0.414112; batch adversarial loss: 0.369613\n",
      "epoch 126; iter: 0; batch classifier loss: 0.377931; batch adversarial loss: 0.378138\n",
      "epoch 127; iter: 0; batch classifier loss: 0.442180; batch adversarial loss: 0.288946\n",
      "epoch 128; iter: 0; batch classifier loss: 0.311699; batch adversarial loss: 0.220931\n",
      "epoch 129; iter: 0; batch classifier loss: 0.291942; batch adversarial loss: 0.338309\n",
      "epoch 130; iter: 0; batch classifier loss: 0.349125; batch adversarial loss: 0.167918\n",
      "epoch 131; iter: 0; batch classifier loss: 0.339081; batch adversarial loss: 0.325553\n",
      "epoch 132; iter: 0; batch classifier loss: 0.305143; batch adversarial loss: 0.346568\n",
      "epoch 133; iter: 0; batch classifier loss: 0.349879; batch adversarial loss: 0.317237\n",
      "epoch 134; iter: 0; batch classifier loss: 0.280290; batch adversarial loss: 0.222992\n",
      "epoch 135; iter: 0; batch classifier loss: 0.308634; batch adversarial loss: 0.357230\n",
      "epoch 136; iter: 0; batch classifier loss: 0.338107; batch adversarial loss: 0.270637\n",
      "epoch 137; iter: 0; batch classifier loss: 0.358065; batch adversarial loss: 0.306204\n",
      "epoch 138; iter: 0; batch classifier loss: 0.317412; batch adversarial loss: 0.264436\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368406; batch adversarial loss: 0.272780\n",
      "epoch 140; iter: 0; batch classifier loss: 0.375110; batch adversarial loss: 0.295471\n",
      "epoch 141; iter: 0; batch classifier loss: 0.359394; batch adversarial loss: 0.299702\n",
      "epoch 142; iter: 0; batch classifier loss: 0.325643; batch adversarial loss: 0.190803\n",
      "epoch 143; iter: 0; batch classifier loss: 0.296511; batch adversarial loss: 0.300480\n",
      "epoch 144; iter: 0; batch classifier loss: 0.336437; batch adversarial loss: 0.254825\n",
      "epoch 145; iter: 0; batch classifier loss: 0.371234; batch adversarial loss: 0.344584\n",
      "epoch 146; iter: 0; batch classifier loss: 0.378248; batch adversarial loss: 0.227596\n",
      "epoch 147; iter: 0; batch classifier loss: 0.306640; batch adversarial loss: 0.167102\n",
      "epoch 148; iter: 0; batch classifier loss: 0.315173; batch adversarial loss: 0.347250\n",
      "epoch 149; iter: 0; batch classifier loss: 0.377008; batch adversarial loss: 0.244532\n",
      "epoch 150; iter: 0; batch classifier loss: 0.346823; batch adversarial loss: 0.323663\n",
      "epoch 151; iter: 0; batch classifier loss: 0.373153; batch adversarial loss: 0.275760\n",
      "epoch 152; iter: 0; batch classifier loss: 0.324249; batch adversarial loss: 0.294272\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391797; batch adversarial loss: 0.322289\n",
      "epoch 154; iter: 0; batch classifier loss: 0.313797; batch adversarial loss: 0.329473\n",
      "epoch 155; iter: 0; batch classifier loss: 0.344660; batch adversarial loss: 0.167532\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373504; batch adversarial loss: 0.278354\n",
      "epoch 157; iter: 0; batch classifier loss: 0.318868; batch adversarial loss: 0.331603\n",
      "epoch 158; iter: 0; batch classifier loss: 0.318591; batch adversarial loss: 0.339628\n",
      "epoch 159; iter: 0; batch classifier loss: 0.279667; batch adversarial loss: 0.314826\n",
      "epoch 160; iter: 0; batch classifier loss: 0.325987; batch adversarial loss: 0.291336\n",
      "epoch 161; iter: 0; batch classifier loss: 0.373542; batch adversarial loss: 0.219427\n",
      "epoch 162; iter: 0; batch classifier loss: 0.254422; batch adversarial loss: 0.207253\n",
      "epoch 163; iter: 0; batch classifier loss: 0.247812; batch adversarial loss: 0.306288\n",
      "epoch 164; iter: 0; batch classifier loss: 0.347965; batch adversarial loss: 0.313860\n",
      "epoch 165; iter: 0; batch classifier loss: 0.386996; batch adversarial loss: 0.220750\n",
      "epoch 166; iter: 0; batch classifier loss: 0.382595; batch adversarial loss: 0.378841\n",
      "epoch 167; iter: 0; batch classifier loss: 0.365764; batch adversarial loss: 0.399546\n",
      "epoch 168; iter: 0; batch classifier loss: 0.329953; batch adversarial loss: 0.455436\n",
      "epoch 169; iter: 0; batch classifier loss: 0.302250; batch adversarial loss: 0.344737\n",
      "epoch 170; iter: 0; batch classifier loss: 0.305971; batch adversarial loss: 0.340506\n",
      "epoch 171; iter: 0; batch classifier loss: 0.384687; batch adversarial loss: 0.257916\n",
      "epoch 172; iter: 0; batch classifier loss: 0.278510; batch adversarial loss: 0.289478\n",
      "epoch 173; iter: 0; batch classifier loss: 0.357663; batch adversarial loss: 0.331600\n",
      "epoch 174; iter: 0; batch classifier loss: 0.376711; batch adversarial loss: 0.433246\n",
      "epoch 175; iter: 0; batch classifier loss: 0.286333; batch adversarial loss: 0.424769\n",
      "epoch 176; iter: 0; batch classifier loss: 0.358445; batch adversarial loss: 0.316023\n",
      "epoch 177; iter: 0; batch classifier loss: 0.299136; batch adversarial loss: 0.223790\n",
      "epoch 178; iter: 0; batch classifier loss: 0.309796; batch adversarial loss: 0.342830\n",
      "epoch 179; iter: 0; batch classifier loss: 0.279527; batch adversarial loss: 0.270416\n",
      "epoch 180; iter: 0; batch classifier loss: 0.291636; batch adversarial loss: 0.399878\n",
      "epoch 181; iter: 0; batch classifier loss: 0.253851; batch adversarial loss: 0.292470\n",
      "epoch 182; iter: 0; batch classifier loss: 0.333327; batch adversarial loss: 0.351162\n",
      "epoch 183; iter: 0; batch classifier loss: 0.260611; batch adversarial loss: 0.356339\n",
      "epoch 184; iter: 0; batch classifier loss: 0.383247; batch adversarial loss: 0.291549\n",
      "epoch 185; iter: 0; batch classifier loss: 0.383077; batch adversarial loss: 0.363837\n",
      "epoch 186; iter: 0; batch classifier loss: 0.310828; batch adversarial loss: 0.314794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 187; iter: 0; batch classifier loss: 0.330787; batch adversarial loss: 0.379191\n",
      "epoch 188; iter: 0; batch classifier loss: 0.277069; batch adversarial loss: 0.237233\n",
      "epoch 189; iter: 0; batch classifier loss: 0.343209; batch adversarial loss: 0.366439\n",
      "epoch 190; iter: 0; batch classifier loss: 0.234609; batch adversarial loss: 0.361578\n",
      "epoch 191; iter: 0; batch classifier loss: 0.306904; batch adversarial loss: 0.294950\n",
      "epoch 192; iter: 0; batch classifier loss: 0.320961; batch adversarial loss: 0.314604\n",
      "epoch 193; iter: 0; batch classifier loss: 0.254329; batch adversarial loss: 0.306476\n",
      "epoch 194; iter: 0; batch classifier loss: 0.398215; batch adversarial loss: 0.391168\n",
      "epoch 195; iter: 0; batch classifier loss: 0.317734; batch adversarial loss: 0.222574\n",
      "epoch 196; iter: 0; batch classifier loss: 0.326123; batch adversarial loss: 0.288666\n",
      "epoch 197; iter: 0; batch classifier loss: 0.321887; batch adversarial loss: 0.240269\n",
      "epoch 198; iter: 0; batch classifier loss: 0.331995; batch adversarial loss: 0.366609\n",
      "epoch 199; iter: 0; batch classifier loss: 0.265728; batch adversarial loss: 0.418700\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.104867; batch adversarial loss: 0.919317\n",
      "epoch 2; iter: 0; batch classifier loss: 1.019671; batch adversarial loss: 0.793939\n",
      "epoch 3; iter: 0; batch classifier loss: 0.795870; batch adversarial loss: 0.809409\n",
      "epoch 4; iter: 0; batch classifier loss: 0.717682; batch adversarial loss: 0.711764\n",
      "epoch 5; iter: 0; batch classifier loss: 0.615224; batch adversarial loss: 0.652652\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572716; batch adversarial loss: 0.636214\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586929; batch adversarial loss: 0.611346\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554290; batch adversarial loss: 0.601702\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538164; batch adversarial loss: 0.575059\n",
      "epoch 10; iter: 0; batch classifier loss: 0.553580; batch adversarial loss: 0.582716\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576182; batch adversarial loss: 0.542741\n",
      "epoch 12; iter: 0; batch classifier loss: 0.541476; batch adversarial loss: 0.535686\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541990; batch adversarial loss: 0.530517\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530205; batch adversarial loss: 0.491119\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538575; batch adversarial loss: 0.469747\n",
      "epoch 16; iter: 0; batch classifier loss: 0.599764; batch adversarial loss: 0.451655\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506596; batch adversarial loss: 0.457258\n",
      "epoch 18; iter: 0; batch classifier loss: 0.553956; batch adversarial loss: 0.448178\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527583; batch adversarial loss: 0.448854\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505082; batch adversarial loss: 0.419368\n",
      "epoch 21; iter: 0; batch classifier loss: 0.505338; batch adversarial loss: 0.429596\n",
      "epoch 22; iter: 0; batch classifier loss: 0.523072; batch adversarial loss: 0.444980\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479564; batch adversarial loss: 0.488036\n",
      "epoch 24; iter: 0; batch classifier loss: 0.548983; batch adversarial loss: 0.356189\n",
      "epoch 25; iter: 0; batch classifier loss: 0.512730; batch adversarial loss: 0.417814\n",
      "epoch 26; iter: 0; batch classifier loss: 0.569350; batch adversarial loss: 0.467402\n",
      "epoch 27; iter: 0; batch classifier loss: 0.633593; batch adversarial loss: 0.491927\n",
      "epoch 28; iter: 0; batch classifier loss: 0.560485; batch adversarial loss: 0.401908\n",
      "epoch 29; iter: 0; batch classifier loss: 0.492012; batch adversarial loss: 0.461789\n",
      "epoch 30; iter: 0; batch classifier loss: 0.516114; batch adversarial loss: 0.378641\n",
      "epoch 31; iter: 0; batch classifier loss: 0.553987; batch adversarial loss: 0.399435\n",
      "epoch 32; iter: 0; batch classifier loss: 0.593287; batch adversarial loss: 0.432696\n",
      "epoch 33; iter: 0; batch classifier loss: 0.563913; batch adversarial loss: 0.393855\n",
      "epoch 34; iter: 0; batch classifier loss: 0.533045; batch adversarial loss: 0.335837\n",
      "epoch 35; iter: 0; batch classifier loss: 0.638208; batch adversarial loss: 0.445105\n",
      "epoch 36; iter: 0; batch classifier loss: 0.543898; batch adversarial loss: 0.386318\n",
      "epoch 37; iter: 0; batch classifier loss: 0.585424; batch adversarial loss: 0.421039\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445224; batch adversarial loss: 0.347407\n",
      "epoch 39; iter: 0; batch classifier loss: 0.554401; batch adversarial loss: 0.322142\n",
      "epoch 40; iter: 0; batch classifier loss: 0.513679; batch adversarial loss: 0.393044\n",
      "epoch 41; iter: 0; batch classifier loss: 0.596735; batch adversarial loss: 0.415950\n",
      "epoch 42; iter: 0; batch classifier loss: 0.493012; batch adversarial loss: 0.341469\n",
      "epoch 43; iter: 0; batch classifier loss: 0.537884; batch adversarial loss: 0.357357\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474018; batch adversarial loss: 0.318101\n",
      "epoch 45; iter: 0; batch classifier loss: 0.537035; batch adversarial loss: 0.345768\n",
      "epoch 46; iter: 0; batch classifier loss: 0.554618; batch adversarial loss: 0.304778\n",
      "epoch 47; iter: 0; batch classifier loss: 0.502499; batch adversarial loss: 0.271160\n",
      "epoch 48; iter: 0; batch classifier loss: 0.608625; batch adversarial loss: 0.390380\n",
      "epoch 49; iter: 0; batch classifier loss: 0.528305; batch adversarial loss: 0.374670\n",
      "epoch 50; iter: 0; batch classifier loss: 0.588758; batch adversarial loss: 0.317978\n",
      "epoch 51; iter: 0; batch classifier loss: 0.606888; batch adversarial loss: 0.369915\n",
      "epoch 52; iter: 0; batch classifier loss: 0.510500; batch adversarial loss: 0.284160\n",
      "epoch 53; iter: 0; batch classifier loss: 0.551550; batch adversarial loss: 0.405873\n",
      "epoch 54; iter: 0; batch classifier loss: 0.560488; batch adversarial loss: 0.280648\n",
      "epoch 55; iter: 0; batch classifier loss: 0.553999; batch adversarial loss: 0.252339\n",
      "epoch 56; iter: 0; batch classifier loss: 0.626754; batch adversarial loss: 0.355362\n",
      "epoch 57; iter: 0; batch classifier loss: 0.509330; batch adversarial loss: 0.353573\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426175; batch adversarial loss: 0.366279\n",
      "epoch 59; iter: 0; batch classifier loss: 0.451686; batch adversarial loss: 0.377653\n",
      "epoch 60; iter: 0; batch classifier loss: 0.478895; batch adversarial loss: 0.320877\n",
      "epoch 61; iter: 0; batch classifier loss: 0.458028; batch adversarial loss: 0.250048\n",
      "epoch 62; iter: 0; batch classifier loss: 0.482225; batch adversarial loss: 0.304235\n",
      "epoch 63; iter: 0; batch classifier loss: 0.452080; batch adversarial loss: 0.404140\n",
      "epoch 64; iter: 0; batch classifier loss: 0.363413; batch adversarial loss: 0.321617\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441248; batch adversarial loss: 0.258253\n",
      "epoch 66; iter: 0; batch classifier loss: 0.312000; batch adversarial loss: 0.330654\n",
      "epoch 67; iter: 0; batch classifier loss: 0.403964; batch adversarial loss: 0.344530\n",
      "epoch 68; iter: 0; batch classifier loss: 0.401404; batch adversarial loss: 0.343494\n",
      "epoch 69; iter: 0; batch classifier loss: 0.414037; batch adversarial loss: 0.280674\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423048; batch adversarial loss: 0.343728\n",
      "epoch 71; iter: 0; batch classifier loss: 0.471757; batch adversarial loss: 0.280042\n",
      "epoch 72; iter: 0; batch classifier loss: 0.432070; batch adversarial loss: 0.286613\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373836; batch adversarial loss: 0.287815\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432468; batch adversarial loss: 0.364972\n",
      "epoch 75; iter: 0; batch classifier loss: 0.346960; batch adversarial loss: 0.308334\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371520; batch adversarial loss: 0.315113\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421963; batch adversarial loss: 0.336540\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347909; batch adversarial loss: 0.228073\n",
      "epoch 79; iter: 0; batch classifier loss: 0.371582; batch adversarial loss: 0.367490\n",
      "epoch 80; iter: 0; batch classifier loss: 0.470379; batch adversarial loss: 0.418317\n",
      "epoch 81; iter: 0; batch classifier loss: 0.394807; batch adversarial loss: 0.277540\n",
      "epoch 82; iter: 0; batch classifier loss: 0.463479; batch adversarial loss: 0.271047\n",
      "epoch 83; iter: 0; batch classifier loss: 0.380602; batch adversarial loss: 0.276539\n",
      "epoch 84; iter: 0; batch classifier loss: 0.449350; batch adversarial loss: 0.267944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85; iter: 0; batch classifier loss: 0.385366; batch adversarial loss: 0.396742\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412977; batch adversarial loss: 0.297095\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377998; batch adversarial loss: 0.312315\n",
      "epoch 88; iter: 0; batch classifier loss: 0.429302; batch adversarial loss: 0.258556\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385767; batch adversarial loss: 0.269513\n",
      "epoch 90; iter: 0; batch classifier loss: 0.440452; batch adversarial loss: 0.260643\n",
      "epoch 91; iter: 0; batch classifier loss: 0.403021; batch adversarial loss: 0.360327\n",
      "epoch 92; iter: 0; batch classifier loss: 0.365546; batch adversarial loss: 0.241584\n",
      "epoch 93; iter: 0; batch classifier loss: 0.337942; batch adversarial loss: 0.288189\n",
      "epoch 94; iter: 0; batch classifier loss: 0.376732; batch adversarial loss: 0.285895\n",
      "epoch 95; iter: 0; batch classifier loss: 0.429499; batch adversarial loss: 0.293405\n",
      "epoch 96; iter: 0; batch classifier loss: 0.364015; batch adversarial loss: 0.309310\n",
      "epoch 97; iter: 0; batch classifier loss: 0.353874; batch adversarial loss: 0.289248\n",
      "epoch 98; iter: 0; batch classifier loss: 0.365286; batch adversarial loss: 0.253359\n",
      "epoch 99; iter: 0; batch classifier loss: 0.344966; batch adversarial loss: 0.227692\n",
      "epoch 100; iter: 0; batch classifier loss: 0.417482; batch adversarial loss: 0.299639\n",
      "epoch 101; iter: 0; batch classifier loss: 0.389795; batch adversarial loss: 0.260478\n",
      "epoch 102; iter: 0; batch classifier loss: 0.334619; batch adversarial loss: 0.272976\n",
      "epoch 103; iter: 0; batch classifier loss: 0.414939; batch adversarial loss: 0.363505\n",
      "epoch 104; iter: 0; batch classifier loss: 0.452884; batch adversarial loss: 0.290516\n",
      "epoch 105; iter: 0; batch classifier loss: 0.300448; batch adversarial loss: 0.336469\n",
      "epoch 106; iter: 0; batch classifier loss: 0.379633; batch adversarial loss: 0.269461\n",
      "epoch 107; iter: 0; batch classifier loss: 0.361737; batch adversarial loss: 0.281284\n",
      "epoch 108; iter: 0; batch classifier loss: 0.371355; batch adversarial loss: 0.316392\n",
      "epoch 109; iter: 0; batch classifier loss: 0.367642; batch adversarial loss: 0.288716\n",
      "epoch 110; iter: 0; batch classifier loss: 0.402254; batch adversarial loss: 0.307979\n",
      "epoch 111; iter: 0; batch classifier loss: 0.302029; batch adversarial loss: 0.363287\n",
      "epoch 112; iter: 0; batch classifier loss: 0.378545; batch adversarial loss: 0.371671\n",
      "epoch 113; iter: 0; batch classifier loss: 0.353202; batch adversarial loss: 0.320779\n",
      "epoch 114; iter: 0; batch classifier loss: 0.347821; batch adversarial loss: 0.232199\n",
      "epoch 115; iter: 0; batch classifier loss: 0.329505; batch adversarial loss: 0.218944\n",
      "epoch 116; iter: 0; batch classifier loss: 0.346421; batch adversarial loss: 0.223660\n",
      "epoch 117; iter: 0; batch classifier loss: 0.310302; batch adversarial loss: 0.271501\n",
      "epoch 118; iter: 0; batch classifier loss: 0.297069; batch adversarial loss: 0.297390\n",
      "epoch 119; iter: 0; batch classifier loss: 0.359396; batch adversarial loss: 0.323448\n",
      "epoch 120; iter: 0; batch classifier loss: 0.309788; batch adversarial loss: 0.219194\n",
      "epoch 121; iter: 0; batch classifier loss: 0.311069; batch adversarial loss: 0.284212\n",
      "epoch 122; iter: 0; batch classifier loss: 0.385711; batch adversarial loss: 0.253278\n",
      "epoch 123; iter: 0; batch classifier loss: 0.360798; batch adversarial loss: 0.345130\n",
      "epoch 124; iter: 0; batch classifier loss: 0.329567; batch adversarial loss: 0.359329\n",
      "epoch 125; iter: 0; batch classifier loss: 0.387005; batch adversarial loss: 0.369326\n",
      "epoch 126; iter: 0; batch classifier loss: 0.385136; batch adversarial loss: 0.377438\n",
      "epoch 127; iter: 0; batch classifier loss: 0.418595; batch adversarial loss: 0.287981\n",
      "epoch 128; iter: 0; batch classifier loss: 0.313578; batch adversarial loss: 0.220679\n",
      "epoch 129; iter: 0; batch classifier loss: 0.278758; batch adversarial loss: 0.338368\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361122; batch adversarial loss: 0.167661\n",
      "epoch 131; iter: 0; batch classifier loss: 0.326842; batch adversarial loss: 0.324791\n",
      "epoch 132; iter: 0; batch classifier loss: 0.325032; batch adversarial loss: 0.346743\n",
      "epoch 133; iter: 0; batch classifier loss: 0.360123; batch adversarial loss: 0.317506\n",
      "epoch 134; iter: 0; batch classifier loss: 0.293960; batch adversarial loss: 0.222299\n",
      "epoch 135; iter: 0; batch classifier loss: 0.322210; batch adversarial loss: 0.356922\n",
      "epoch 136; iter: 0; batch classifier loss: 0.329541; batch adversarial loss: 0.269721\n",
      "epoch 137; iter: 0; batch classifier loss: 0.368925; batch adversarial loss: 0.305764\n",
      "epoch 138; iter: 0; batch classifier loss: 0.320750; batch adversarial loss: 0.265132\n",
      "epoch 139; iter: 0; batch classifier loss: 0.358777; batch adversarial loss: 0.272621\n",
      "epoch 140; iter: 0; batch classifier loss: 0.374695; batch adversarial loss: 0.295566\n",
      "epoch 141; iter: 0; batch classifier loss: 0.322716; batch adversarial loss: 0.300257\n",
      "epoch 142; iter: 0; batch classifier loss: 0.323397; batch adversarial loss: 0.191143\n",
      "epoch 143; iter: 0; batch classifier loss: 0.289200; batch adversarial loss: 0.300638\n",
      "epoch 144; iter: 0; batch classifier loss: 0.356905; batch adversarial loss: 0.253970\n",
      "epoch 145; iter: 0; batch classifier loss: 0.380000; batch adversarial loss: 0.343741\n",
      "epoch 146; iter: 0; batch classifier loss: 0.380297; batch adversarial loss: 0.228278\n",
      "epoch 147; iter: 0; batch classifier loss: 0.315628; batch adversarial loss: 0.167016\n",
      "epoch 148; iter: 0; batch classifier loss: 0.333978; batch adversarial loss: 0.347127\n",
      "epoch 149; iter: 0; batch classifier loss: 0.353951; batch adversarial loss: 0.244962\n",
      "epoch 150; iter: 0; batch classifier loss: 0.337743; batch adversarial loss: 0.323116\n",
      "epoch 151; iter: 0; batch classifier loss: 0.399076; batch adversarial loss: 0.274792\n",
      "epoch 152; iter: 0; batch classifier loss: 0.324265; batch adversarial loss: 0.293807\n",
      "epoch 153; iter: 0; batch classifier loss: 0.408191; batch adversarial loss: 0.321355\n",
      "epoch 154; iter: 0; batch classifier loss: 0.306620; batch adversarial loss: 0.329046\n",
      "epoch 155; iter: 0; batch classifier loss: 0.327020; batch adversarial loss: 0.167341\n",
      "epoch 156; iter: 0; batch classifier loss: 0.350106; batch adversarial loss: 0.278865\n",
      "epoch 157; iter: 0; batch classifier loss: 0.314869; batch adversarial loss: 0.332423\n",
      "epoch 158; iter: 0; batch classifier loss: 0.315308; batch adversarial loss: 0.338685\n",
      "epoch 159; iter: 0; batch classifier loss: 0.292806; batch adversarial loss: 0.313808\n",
      "epoch 160; iter: 0; batch classifier loss: 0.316300; batch adversarial loss: 0.291183\n",
      "epoch 161; iter: 0; batch classifier loss: 0.369867; batch adversarial loss: 0.218000\n",
      "epoch 162; iter: 0; batch classifier loss: 0.281113; batch adversarial loss: 0.208246\n",
      "epoch 163; iter: 0; batch classifier loss: 0.258631; batch adversarial loss: 0.306005\n",
      "epoch 164; iter: 0; batch classifier loss: 0.339523; batch adversarial loss: 0.313653\n",
      "epoch 165; iter: 0; batch classifier loss: 0.361007; batch adversarial loss: 0.220619\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366541; batch adversarial loss: 0.378514\n",
      "epoch 167; iter: 0; batch classifier loss: 0.369922; batch adversarial loss: 0.398097\n",
      "epoch 168; iter: 0; batch classifier loss: 0.320285; batch adversarial loss: 0.455221\n",
      "epoch 169; iter: 0; batch classifier loss: 0.267075; batch adversarial loss: 0.344029\n",
      "epoch 170; iter: 0; batch classifier loss: 0.296882; batch adversarial loss: 0.339309\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392066; batch adversarial loss: 0.257147\n",
      "epoch 172; iter: 0; batch classifier loss: 0.295369; batch adversarial loss: 0.289446\n",
      "epoch 173; iter: 0; batch classifier loss: 0.337254; batch adversarial loss: 0.331224\n",
      "epoch 174; iter: 0; batch classifier loss: 0.368187; batch adversarial loss: 0.431638\n",
      "epoch 175; iter: 0; batch classifier loss: 0.308089; batch adversarial loss: 0.426126\n",
      "epoch 176; iter: 0; batch classifier loss: 0.361314; batch adversarial loss: 0.316465\n",
      "epoch 177; iter: 0; batch classifier loss: 0.290717; batch adversarial loss: 0.223654\n",
      "epoch 178; iter: 0; batch classifier loss: 0.308606; batch adversarial loss: 0.342490\n",
      "epoch 179; iter: 0; batch classifier loss: 0.280516; batch adversarial loss: 0.269839\n",
      "epoch 180; iter: 0; batch classifier loss: 0.288954; batch adversarial loss: 0.399031\n",
      "epoch 181; iter: 0; batch classifier loss: 0.290661; batch adversarial loss: 0.292056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.338024; batch adversarial loss: 0.350525\n",
      "epoch 183; iter: 0; batch classifier loss: 0.281112; batch adversarial loss: 0.355036\n",
      "epoch 184; iter: 0; batch classifier loss: 0.382930; batch adversarial loss: 0.290941\n",
      "epoch 185; iter: 0; batch classifier loss: 0.357967; batch adversarial loss: 0.363309\n",
      "epoch 186; iter: 0; batch classifier loss: 0.301034; batch adversarial loss: 0.315776\n",
      "epoch 187; iter: 0; batch classifier loss: 0.319703; batch adversarial loss: 0.378776\n",
      "epoch 188; iter: 0; batch classifier loss: 0.269160; batch adversarial loss: 0.236817\n",
      "epoch 189; iter: 0; batch classifier loss: 0.340459; batch adversarial loss: 0.364522\n",
      "epoch 190; iter: 0; batch classifier loss: 0.251135; batch adversarial loss: 0.361302\n",
      "epoch 191; iter: 0; batch classifier loss: 0.322935; batch adversarial loss: 0.294550\n",
      "epoch 192; iter: 0; batch classifier loss: 0.317519; batch adversarial loss: 0.313175\n",
      "epoch 193; iter: 0; batch classifier loss: 0.263862; batch adversarial loss: 0.305237\n",
      "epoch 194; iter: 0; batch classifier loss: 0.382326; batch adversarial loss: 0.392616\n",
      "epoch 195; iter: 0; batch classifier loss: 0.308518; batch adversarial loss: 0.222512\n",
      "epoch 196; iter: 0; batch classifier loss: 0.298294; batch adversarial loss: 0.287544\n",
      "epoch 197; iter: 0; batch classifier loss: 0.329724; batch adversarial loss: 0.240027\n",
      "epoch 198; iter: 0; batch classifier loss: 0.350500; batch adversarial loss: 0.366683\n",
      "epoch 199; iter: 0; batch classifier loss: 0.260865; batch adversarial loss: 0.417634\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.236574; batch adversarial loss: 0.925804\n",
      "epoch 2; iter: 0; batch classifier loss: 1.123316; batch adversarial loss: 0.799686\n",
      "epoch 3; iter: 0; batch classifier loss: 0.878269; batch adversarial loss: 0.818746\n",
      "epoch 4; iter: 0; batch classifier loss: 0.810963; batch adversarial loss: 0.723993\n",
      "epoch 5; iter: 0; batch classifier loss: 0.674673; batch adversarial loss: 0.662995\n",
      "epoch 6; iter: 0; batch classifier loss: 0.583145; batch adversarial loss: 0.636015\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580690; batch adversarial loss: 0.612421\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551900; batch adversarial loss: 0.601488\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539854; batch adversarial loss: 0.573180\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541401; batch adversarial loss: 0.582541\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568504; batch adversarial loss: 0.541540\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530178; batch adversarial loss: 0.535102\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533331; batch adversarial loss: 0.528867\n",
      "epoch 14; iter: 0; batch classifier loss: 0.514215; batch adversarial loss: 0.493248\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525041; batch adversarial loss: 0.474055\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592156; batch adversarial loss: 0.456271\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507300; batch adversarial loss: 0.463245\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542074; batch adversarial loss: 0.453901\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550334; batch adversarial loss: 0.461426\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518924; batch adversarial loss: 0.433696\n",
      "epoch 21; iter: 0; batch classifier loss: 0.540917; batch adversarial loss: 0.449549\n",
      "epoch 22; iter: 0; batch classifier loss: 0.574041; batch adversarial loss: 0.464663\n",
      "epoch 23; iter: 0; batch classifier loss: 0.529743; batch adversarial loss: 0.506621\n",
      "epoch 24; iter: 0; batch classifier loss: 0.582828; batch adversarial loss: 0.366290\n",
      "epoch 25; iter: 0; batch classifier loss: 0.555061; batch adversarial loss: 0.431553\n",
      "epoch 26; iter: 0; batch classifier loss: 0.644151; batch adversarial loss: 0.484627\n",
      "epoch 27; iter: 0; batch classifier loss: 0.696913; batch adversarial loss: 0.500430\n",
      "epoch 28; iter: 0; batch classifier loss: 0.610434; batch adversarial loss: 0.410412\n",
      "epoch 29; iter: 0; batch classifier loss: 0.525867; batch adversarial loss: 0.466558\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550459; batch adversarial loss: 0.382084\n",
      "epoch 31; iter: 0; batch classifier loss: 0.600997; batch adversarial loss: 0.403590\n",
      "epoch 32; iter: 0; batch classifier loss: 0.628199; batch adversarial loss: 0.431227\n",
      "epoch 33; iter: 0; batch classifier loss: 0.589793; batch adversarial loss: 0.395277\n",
      "epoch 34; iter: 0; batch classifier loss: 0.543273; batch adversarial loss: 0.335834\n",
      "epoch 35; iter: 0; batch classifier loss: 0.659133; batch adversarial loss: 0.438898\n",
      "epoch 36; iter: 0; batch classifier loss: 0.551862; batch adversarial loss: 0.382653\n",
      "epoch 37; iter: 0; batch classifier loss: 0.592831; batch adversarial loss: 0.414789\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444452; batch adversarial loss: 0.343980\n",
      "epoch 39; iter: 0; batch classifier loss: 0.560545; batch adversarial loss: 0.320972\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522422; batch adversarial loss: 0.388250\n",
      "epoch 41; iter: 0; batch classifier loss: 0.597956; batch adversarial loss: 0.407984\n",
      "epoch 42; iter: 0; batch classifier loss: 0.500486; batch adversarial loss: 0.338153\n",
      "epoch 43; iter: 0; batch classifier loss: 0.541308; batch adversarial loss: 0.351624\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468295; batch adversarial loss: 0.315429\n",
      "epoch 45; iter: 0; batch classifier loss: 0.517982; batch adversarial loss: 0.341077\n",
      "epoch 46; iter: 0; batch classifier loss: 0.541801; batch adversarial loss: 0.301323\n",
      "epoch 47; iter: 0; batch classifier loss: 0.490905; batch adversarial loss: 0.269039\n",
      "epoch 48; iter: 0; batch classifier loss: 0.593526; batch adversarial loss: 0.383633\n",
      "epoch 49; iter: 0; batch classifier loss: 0.522947; batch adversarial loss: 0.369141\n",
      "epoch 50; iter: 0; batch classifier loss: 0.597389; batch adversarial loss: 0.314309\n",
      "epoch 51; iter: 0; batch classifier loss: 0.598485; batch adversarial loss: 0.364880\n",
      "epoch 52; iter: 0; batch classifier loss: 0.516504; batch adversarial loss: 0.282438\n",
      "epoch 53; iter: 0; batch classifier loss: 0.568797; batch adversarial loss: 0.399699\n",
      "epoch 54; iter: 0; batch classifier loss: 0.617936; batch adversarial loss: 0.278525\n",
      "epoch 55; iter: 0; batch classifier loss: 0.484312; batch adversarial loss: 0.249895\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448554; batch adversarial loss: 0.352456\n",
      "epoch 57; iter: 0; batch classifier loss: 0.492107; batch adversarial loss: 0.352733\n",
      "epoch 58; iter: 0; batch classifier loss: 0.429835; batch adversarial loss: 0.365761\n",
      "epoch 59; iter: 0; batch classifier loss: 0.463337; batch adversarial loss: 0.377576\n",
      "epoch 60; iter: 0; batch classifier loss: 0.482566; batch adversarial loss: 0.320109\n",
      "epoch 61; iter: 0; batch classifier loss: 0.456461; batch adversarial loss: 0.248943\n",
      "epoch 62; iter: 0; batch classifier loss: 0.473611; batch adversarial loss: 0.303442\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463580; batch adversarial loss: 0.404502\n",
      "epoch 64; iter: 0; batch classifier loss: 0.360703; batch adversarial loss: 0.321184\n",
      "epoch 65; iter: 0; batch classifier loss: 0.450838; batch adversarial loss: 0.257672\n",
      "epoch 66; iter: 0; batch classifier loss: 0.320134; batch adversarial loss: 0.330540\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410963; batch adversarial loss: 0.344148\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408518; batch adversarial loss: 0.343325\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430415; batch adversarial loss: 0.280760\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420903; batch adversarial loss: 0.343284\n",
      "epoch 71; iter: 0; batch classifier loss: 0.479838; batch adversarial loss: 0.279778\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416178; batch adversarial loss: 0.286407\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373162; batch adversarial loss: 0.287141\n",
      "epoch 74; iter: 0; batch classifier loss: 0.452502; batch adversarial loss: 0.363759\n",
      "epoch 75; iter: 0; batch classifier loss: 0.356622; batch adversarial loss: 0.308498\n",
      "epoch 76; iter: 0; batch classifier loss: 0.373016; batch adversarial loss: 0.314766\n",
      "epoch 77; iter: 0; batch classifier loss: 0.429228; batch adversarial loss: 0.336602\n",
      "epoch 78; iter: 0; batch classifier loss: 0.356512; batch adversarial loss: 0.228392\n",
      "epoch 79; iter: 0; batch classifier loss: 0.386427; batch adversarial loss: 0.367366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.480408; batch adversarial loss: 0.418386\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421930; batch adversarial loss: 0.278247\n",
      "epoch 82; iter: 0; batch classifier loss: 0.462435; batch adversarial loss: 0.271727\n",
      "epoch 83; iter: 0; batch classifier loss: 0.380334; batch adversarial loss: 0.276967\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435410; batch adversarial loss: 0.268914\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387730; batch adversarial loss: 0.396658\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412547; batch adversarial loss: 0.297216\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377429; batch adversarial loss: 0.312333\n",
      "epoch 88; iter: 0; batch classifier loss: 0.419879; batch adversarial loss: 0.259115\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389488; batch adversarial loss: 0.269937\n",
      "epoch 90; iter: 0; batch classifier loss: 0.463108; batch adversarial loss: 0.260118\n",
      "epoch 91; iter: 0; batch classifier loss: 0.407840; batch adversarial loss: 0.359553\n",
      "epoch 92; iter: 0; batch classifier loss: 0.377284; batch adversarial loss: 0.241369\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347294; batch adversarial loss: 0.288423\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372910; batch adversarial loss: 0.285577\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407797; batch adversarial loss: 0.294190\n",
      "epoch 96; iter: 0; batch classifier loss: 0.361872; batch adversarial loss: 0.308835\n",
      "epoch 97; iter: 0; batch classifier loss: 0.375883; batch adversarial loss: 0.289864\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373967; batch adversarial loss: 0.254467\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363744; batch adversarial loss: 0.227470\n",
      "epoch 100; iter: 0; batch classifier loss: 0.433087; batch adversarial loss: 0.300221\n",
      "epoch 101; iter: 0; batch classifier loss: 0.371521; batch adversarial loss: 0.259857\n",
      "epoch 102; iter: 0; batch classifier loss: 0.331300; batch adversarial loss: 0.273281\n",
      "epoch 103; iter: 0; batch classifier loss: 0.396752; batch adversarial loss: 0.363023\n",
      "epoch 104; iter: 0; batch classifier loss: 0.424801; batch adversarial loss: 0.290953\n",
      "epoch 105; iter: 0; batch classifier loss: 0.295931; batch adversarial loss: 0.337307\n",
      "epoch 106; iter: 0; batch classifier loss: 0.388927; batch adversarial loss: 0.270275\n",
      "epoch 107; iter: 0; batch classifier loss: 0.372622; batch adversarial loss: 0.282015\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380961; batch adversarial loss: 0.315626\n",
      "epoch 109; iter: 0; batch classifier loss: 0.372767; batch adversarial loss: 0.289687\n",
      "epoch 110; iter: 0; batch classifier loss: 0.403747; batch adversarial loss: 0.308104\n",
      "epoch 111; iter: 0; batch classifier loss: 0.331610; batch adversarial loss: 0.364242\n",
      "epoch 112; iter: 0; batch classifier loss: 0.393691; batch adversarial loss: 0.371475\n",
      "epoch 113; iter: 0; batch classifier loss: 0.349213; batch adversarial loss: 0.320976\n",
      "epoch 114; iter: 0; batch classifier loss: 0.351623; batch adversarial loss: 0.232828\n",
      "epoch 115; iter: 0; batch classifier loss: 0.325106; batch adversarial loss: 0.219207\n",
      "epoch 116; iter: 0; batch classifier loss: 0.356516; batch adversarial loss: 0.223529\n",
      "epoch 117; iter: 0; batch classifier loss: 0.323019; batch adversarial loss: 0.273174\n",
      "epoch 118; iter: 0; batch classifier loss: 0.298210; batch adversarial loss: 0.296962\n",
      "epoch 119; iter: 0; batch classifier loss: 0.373200; batch adversarial loss: 0.324844\n",
      "epoch 120; iter: 0; batch classifier loss: 0.288825; batch adversarial loss: 0.219443\n",
      "epoch 121; iter: 0; batch classifier loss: 0.318623; batch adversarial loss: 0.284904\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388013; batch adversarial loss: 0.253477\n",
      "epoch 123; iter: 0; batch classifier loss: 0.357796; batch adversarial loss: 0.344367\n",
      "epoch 124; iter: 0; batch classifier loss: 0.340547; batch adversarial loss: 0.360597\n",
      "epoch 125; iter: 0; batch classifier loss: 0.408068; batch adversarial loss: 0.369818\n",
      "epoch 126; iter: 0; batch classifier loss: 0.375319; batch adversarial loss: 0.377860\n",
      "epoch 127; iter: 0; batch classifier loss: 0.448942; batch adversarial loss: 0.288407\n",
      "epoch 128; iter: 0; batch classifier loss: 0.308587; batch adversarial loss: 0.220682\n",
      "epoch 129; iter: 0; batch classifier loss: 0.290868; batch adversarial loss: 0.338880\n",
      "epoch 130; iter: 0; batch classifier loss: 0.371858; batch adversarial loss: 0.168048\n",
      "epoch 131; iter: 0; batch classifier loss: 0.343168; batch adversarial loss: 0.325171\n",
      "epoch 132; iter: 0; batch classifier loss: 0.307307; batch adversarial loss: 0.346481\n",
      "epoch 133; iter: 0; batch classifier loss: 0.342390; batch adversarial loss: 0.317169\n",
      "epoch 134; iter: 0; batch classifier loss: 0.284095; batch adversarial loss: 0.221541\n",
      "epoch 135; iter: 0; batch classifier loss: 0.319526; batch adversarial loss: 0.356901\n",
      "epoch 136; iter: 0; batch classifier loss: 0.346215; batch adversarial loss: 0.270692\n",
      "epoch 137; iter: 0; batch classifier loss: 0.353599; batch adversarial loss: 0.306011\n",
      "epoch 138; iter: 0; batch classifier loss: 0.305588; batch adversarial loss: 0.264602\n",
      "epoch 139; iter: 0; batch classifier loss: 0.368597; batch adversarial loss: 0.272648\n",
      "epoch 140; iter: 0; batch classifier loss: 0.366099; batch adversarial loss: 0.295018\n",
      "epoch 141; iter: 0; batch classifier loss: 0.354194; batch adversarial loss: 0.299688\n",
      "epoch 142; iter: 0; batch classifier loss: 0.321845; batch adversarial loss: 0.190837\n",
      "epoch 143; iter: 0; batch classifier loss: 0.295609; batch adversarial loss: 0.300810\n",
      "epoch 144; iter: 0; batch classifier loss: 0.351299; batch adversarial loss: 0.255080\n",
      "epoch 145; iter: 0; batch classifier loss: 0.369177; batch adversarial loss: 0.344264\n",
      "epoch 146; iter: 0; batch classifier loss: 0.365731; batch adversarial loss: 0.227755\n",
      "epoch 147; iter: 0; batch classifier loss: 0.303226; batch adversarial loss: 0.167112\n",
      "epoch 148; iter: 0; batch classifier loss: 0.336999; batch adversarial loss: 0.347462\n",
      "epoch 149; iter: 0; batch classifier loss: 0.361296; batch adversarial loss: 0.243980\n",
      "epoch 150; iter: 0; batch classifier loss: 0.361310; batch adversarial loss: 0.323842\n",
      "epoch 151; iter: 0; batch classifier loss: 0.382644; batch adversarial loss: 0.276143\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330396; batch adversarial loss: 0.293887\n",
      "epoch 153; iter: 0; batch classifier loss: 0.400455; batch adversarial loss: 0.322161\n",
      "epoch 154; iter: 0; batch classifier loss: 0.302994; batch adversarial loss: 0.329236\n",
      "epoch 155; iter: 0; batch classifier loss: 0.335316; batch adversarial loss: 0.167324\n",
      "epoch 156; iter: 0; batch classifier loss: 0.374886; batch adversarial loss: 0.278107\n",
      "epoch 157; iter: 0; batch classifier loss: 0.334967; batch adversarial loss: 0.331539\n",
      "epoch 158; iter: 0; batch classifier loss: 0.306174; batch adversarial loss: 0.339153\n",
      "epoch 159; iter: 0; batch classifier loss: 0.277693; batch adversarial loss: 0.314692\n",
      "epoch 160; iter: 0; batch classifier loss: 0.308757; batch adversarial loss: 0.291041\n",
      "epoch 161; iter: 0; batch classifier loss: 0.369807; batch adversarial loss: 0.219378\n",
      "epoch 162; iter: 0; batch classifier loss: 0.267729; batch adversarial loss: 0.208355\n",
      "epoch 163; iter: 0; batch classifier loss: 0.238764; batch adversarial loss: 0.306173\n",
      "epoch 164; iter: 0; batch classifier loss: 0.345330; batch adversarial loss: 0.313999\n",
      "epoch 165; iter: 0; batch classifier loss: 0.393499; batch adversarial loss: 0.219743\n",
      "epoch 166; iter: 0; batch classifier loss: 0.365041; batch adversarial loss: 0.378841\n",
      "epoch 167; iter: 0; batch classifier loss: 0.383435; batch adversarial loss: 0.398744\n",
      "epoch 168; iter: 0; batch classifier loss: 0.321200; batch adversarial loss: 0.455990\n",
      "epoch 169; iter: 0; batch classifier loss: 0.319027; batch adversarial loss: 0.344146\n",
      "epoch 170; iter: 0; batch classifier loss: 0.296584; batch adversarial loss: 0.340557\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392045; batch adversarial loss: 0.257675\n",
      "epoch 172; iter: 0; batch classifier loss: 0.286121; batch adversarial loss: 0.290416\n",
      "epoch 173; iter: 0; batch classifier loss: 0.354142; batch adversarial loss: 0.331204\n",
      "epoch 174; iter: 0; batch classifier loss: 0.377379; batch adversarial loss: 0.432056\n",
      "epoch 175; iter: 0; batch classifier loss: 0.307884; batch adversarial loss: 0.425086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.340947; batch adversarial loss: 0.315539\n",
      "epoch 177; iter: 0; batch classifier loss: 0.300317; batch adversarial loss: 0.223804\n",
      "epoch 178; iter: 0; batch classifier loss: 0.303105; batch adversarial loss: 0.343053\n",
      "epoch 179; iter: 0; batch classifier loss: 0.288826; batch adversarial loss: 0.270506\n",
      "epoch 180; iter: 0; batch classifier loss: 0.297111; batch adversarial loss: 0.399817\n",
      "epoch 181; iter: 0; batch classifier loss: 0.268868; batch adversarial loss: 0.292442\n",
      "epoch 182; iter: 0; batch classifier loss: 0.313800; batch adversarial loss: 0.350502\n",
      "epoch 183; iter: 0; batch classifier loss: 0.252827; batch adversarial loss: 0.356049\n",
      "epoch 184; iter: 0; batch classifier loss: 0.371980; batch adversarial loss: 0.291496\n",
      "epoch 185; iter: 0; batch classifier loss: 0.395421; batch adversarial loss: 0.364342\n",
      "epoch 186; iter: 0; batch classifier loss: 0.309811; batch adversarial loss: 0.315150\n",
      "epoch 187; iter: 0; batch classifier loss: 0.342886; batch adversarial loss: 0.379897\n",
      "epoch 188; iter: 0; batch classifier loss: 0.266276; batch adversarial loss: 0.237113\n",
      "epoch 189; iter: 0; batch classifier loss: 0.346106; batch adversarial loss: 0.366404\n",
      "epoch 190; iter: 0; batch classifier loss: 0.248483; batch adversarial loss: 0.361649\n",
      "epoch 191; iter: 0; batch classifier loss: 0.327425; batch adversarial loss: 0.295238\n",
      "epoch 192; iter: 0; batch classifier loss: 0.323475; batch adversarial loss: 0.314382\n",
      "epoch 193; iter: 0; batch classifier loss: 0.264279; batch adversarial loss: 0.306314\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379396; batch adversarial loss: 0.391381\n",
      "epoch 195; iter: 0; batch classifier loss: 0.306474; batch adversarial loss: 0.222831\n",
      "epoch 196; iter: 0; batch classifier loss: 0.308290; batch adversarial loss: 0.288498\n",
      "epoch 197; iter: 0; batch classifier loss: 0.339236; batch adversarial loss: 0.239422\n",
      "epoch 198; iter: 0; batch classifier loss: 0.340446; batch adversarial loss: 0.366918\n",
      "epoch 199; iter: 0; batch classifier loss: 0.259039; batch adversarial loss: 0.419442\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.237920; batch adversarial loss: 0.925851\n",
      "epoch 2; iter: 0; batch classifier loss: 1.124605; batch adversarial loss: 0.799712\n",
      "epoch 3; iter: 0; batch classifier loss: 0.879260; batch adversarial loss: 0.818880\n",
      "epoch 4; iter: 0; batch classifier loss: 0.812160; batch adversarial loss: 0.724080\n",
      "epoch 5; iter: 0; batch classifier loss: 0.675809; batch adversarial loss: 0.663052\n",
      "epoch 6; iter: 0; batch classifier loss: 0.583564; batch adversarial loss: 0.635972\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580738; batch adversarial loss: 0.612453\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552364; batch adversarial loss: 0.601417\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539756; batch adversarial loss: 0.573195\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541040; batch adversarial loss: 0.582532\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568496; batch adversarial loss: 0.541514\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529742; batch adversarial loss: 0.535096\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533511; batch adversarial loss: 0.528848\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513863; batch adversarial loss: 0.493263\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525481; batch adversarial loss: 0.473973\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591792; batch adversarial loss: 0.456223\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507675; batch adversarial loss: 0.463248\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541974; batch adversarial loss: 0.453943\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550093; batch adversarial loss: 0.461500\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522498; batch adversarial loss: 0.434166\n",
      "epoch 21; iter: 0; batch classifier loss: 0.541576; batch adversarial loss: 0.450069\n",
      "epoch 22; iter: 0; batch classifier loss: 0.574846; batch adversarial loss: 0.465142\n",
      "epoch 23; iter: 0; batch classifier loss: 0.529319; batch adversarial loss: 0.506130\n",
      "epoch 24; iter: 0; batch classifier loss: 0.583109; batch adversarial loss: 0.366334\n",
      "epoch 25; iter: 0; batch classifier loss: 0.555654; batch adversarial loss: 0.431335\n",
      "epoch 26; iter: 0; batch classifier loss: 0.642899; batch adversarial loss: 0.484275\n",
      "epoch 27; iter: 0; batch classifier loss: 0.697475; batch adversarial loss: 0.500367\n",
      "epoch 28; iter: 0; batch classifier loss: 0.609550; batch adversarial loss: 0.410444\n",
      "epoch 29; iter: 0; batch classifier loss: 0.527360; batch adversarial loss: 0.466441\n",
      "epoch 30; iter: 0; batch classifier loss: 0.546156; batch adversarial loss: 0.382010\n",
      "epoch 31; iter: 0; batch classifier loss: 0.600999; batch adversarial loss: 0.403762\n",
      "epoch 32; iter: 0; batch classifier loss: 0.629611; batch adversarial loss: 0.431500\n",
      "epoch 33; iter: 0; batch classifier loss: 0.588259; batch adversarial loss: 0.395354\n",
      "epoch 34; iter: 0; batch classifier loss: 0.543361; batch adversarial loss: 0.335819\n",
      "epoch 35; iter: 0; batch classifier loss: 0.664538; batch adversarial loss: 0.438702\n",
      "epoch 36; iter: 0; batch classifier loss: 0.549295; batch adversarial loss: 0.382450\n",
      "epoch 37; iter: 0; batch classifier loss: 0.590538; batch adversarial loss: 0.415023\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444769; batch adversarial loss: 0.343998\n",
      "epoch 39; iter: 0; batch classifier loss: 0.554159; batch adversarial loss: 0.320701\n",
      "epoch 40; iter: 0; batch classifier loss: 0.518262; batch adversarial loss: 0.387951\n",
      "epoch 41; iter: 0; batch classifier loss: 0.589819; batch adversarial loss: 0.407928\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496736; batch adversarial loss: 0.337861\n",
      "epoch 43; iter: 0; batch classifier loss: 0.543350; batch adversarial loss: 0.351866\n",
      "epoch 44; iter: 0; batch classifier loss: 0.465943; batch adversarial loss: 0.315171\n",
      "epoch 45; iter: 0; batch classifier loss: 0.513549; batch adversarial loss: 0.341022\n",
      "epoch 46; iter: 0; batch classifier loss: 0.539764; batch adversarial loss: 0.301325\n",
      "epoch 47; iter: 0; batch classifier loss: 0.490410; batch adversarial loss: 0.269038\n",
      "epoch 48; iter: 0; batch classifier loss: 0.596038; batch adversarial loss: 0.383651\n",
      "epoch 49; iter: 0; batch classifier loss: 0.519002; batch adversarial loss: 0.369028\n",
      "epoch 50; iter: 0; batch classifier loss: 0.589427; batch adversarial loss: 0.314140\n",
      "epoch 51; iter: 0; batch classifier loss: 0.602208; batch adversarial loss: 0.364962\n",
      "epoch 52; iter: 0; batch classifier loss: 0.516339; batch adversarial loss: 0.282497\n",
      "epoch 53; iter: 0; batch classifier loss: 0.575036; batch adversarial loss: 0.399774\n",
      "epoch 54; iter: 0; batch classifier loss: 0.619646; batch adversarial loss: 0.278534\n",
      "epoch 55; iter: 0; batch classifier loss: 0.473445; batch adversarial loss: 0.249821\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445844; batch adversarial loss: 0.352467\n",
      "epoch 57; iter: 0; batch classifier loss: 0.487822; batch adversarial loss: 0.352792\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426354; batch adversarial loss: 0.365704\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464707; batch adversarial loss: 0.377561\n",
      "epoch 60; iter: 0; batch classifier loss: 0.479933; batch adversarial loss: 0.320148\n",
      "epoch 61; iter: 0; batch classifier loss: 0.466091; batch adversarial loss: 0.249031\n",
      "epoch 62; iter: 0; batch classifier loss: 0.472509; batch adversarial loss: 0.303516\n",
      "epoch 63; iter: 0; batch classifier loss: 0.461711; batch adversarial loss: 0.404455\n",
      "epoch 64; iter: 0; batch classifier loss: 0.365762; batch adversarial loss: 0.321271\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447917; batch adversarial loss: 0.257646\n",
      "epoch 66; iter: 0; batch classifier loss: 0.320653; batch adversarial loss: 0.330585\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411587; batch adversarial loss: 0.344143\n",
      "epoch 68; iter: 0; batch classifier loss: 0.409539; batch adversarial loss: 0.343446\n",
      "epoch 69; iter: 0; batch classifier loss: 0.427404; batch adversarial loss: 0.280782\n",
      "epoch 70; iter: 0; batch classifier loss: 0.428972; batch adversarial loss: 0.343406\n",
      "epoch 71; iter: 0; batch classifier loss: 0.481809; batch adversarial loss: 0.280060\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419768; batch adversarial loss: 0.286641\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371977; batch adversarial loss: 0.287129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.467128; batch adversarial loss: 0.364016\n",
      "epoch 75; iter: 0; batch classifier loss: 0.358549; batch adversarial loss: 0.308623\n",
      "epoch 76; iter: 0; batch classifier loss: 0.372195; batch adversarial loss: 0.314920\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425173; batch adversarial loss: 0.336728\n",
      "epoch 78; iter: 0; batch classifier loss: 0.350597; batch adversarial loss: 0.228306\n",
      "epoch 79; iter: 0; batch classifier loss: 0.383779; batch adversarial loss: 0.367023\n",
      "epoch 80; iter: 0; batch classifier loss: 0.480451; batch adversarial loss: 0.417854\n",
      "epoch 81; iter: 0; batch classifier loss: 0.418628; batch adversarial loss: 0.278598\n",
      "epoch 82; iter: 0; batch classifier loss: 0.468580; batch adversarial loss: 0.271627\n",
      "epoch 83; iter: 0; batch classifier loss: 0.383336; batch adversarial loss: 0.276745\n",
      "epoch 84; iter: 0; batch classifier loss: 0.445612; batch adversarial loss: 0.268488\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390781; batch adversarial loss: 0.396724\n",
      "epoch 86; iter: 0; batch classifier loss: 0.414123; batch adversarial loss: 0.296999\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375422; batch adversarial loss: 0.312414\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420927; batch adversarial loss: 0.259195\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391406; batch adversarial loss: 0.270129\n",
      "epoch 90; iter: 0; batch classifier loss: 0.464467; batch adversarial loss: 0.260390\n",
      "epoch 91; iter: 0; batch classifier loss: 0.417864; batch adversarial loss: 0.359722\n",
      "epoch 92; iter: 0; batch classifier loss: 0.378508; batch adversarial loss: 0.241921\n",
      "epoch 93; iter: 0; batch classifier loss: 0.341172; batch adversarial loss: 0.288259\n",
      "epoch 94; iter: 0; batch classifier loss: 0.385584; batch adversarial loss: 0.285378\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417019; batch adversarial loss: 0.294262\n",
      "epoch 96; iter: 0; batch classifier loss: 0.369795; batch adversarial loss: 0.308922\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369253; batch adversarial loss: 0.290423\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386174; batch adversarial loss: 0.254734\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363662; batch adversarial loss: 0.227910\n",
      "epoch 100; iter: 0; batch classifier loss: 0.420001; batch adversarial loss: 0.300170\n",
      "epoch 101; iter: 0; batch classifier loss: 0.371561; batch adversarial loss: 0.259836\n",
      "epoch 102; iter: 0; batch classifier loss: 0.333694; batch adversarial loss: 0.273080\n",
      "epoch 103; iter: 0; batch classifier loss: 0.394286; batch adversarial loss: 0.363206\n",
      "epoch 104; iter: 0; batch classifier loss: 0.424440; batch adversarial loss: 0.290957\n",
      "epoch 105; iter: 0; batch classifier loss: 0.290779; batch adversarial loss: 0.337702\n",
      "epoch 106; iter: 0; batch classifier loss: 0.393889; batch adversarial loss: 0.270551\n",
      "epoch 107; iter: 0; batch classifier loss: 0.367572; batch adversarial loss: 0.281942\n",
      "epoch 108; iter: 0; batch classifier loss: 0.375926; batch adversarial loss: 0.316441\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386678; batch adversarial loss: 0.289576\n",
      "epoch 110; iter: 0; batch classifier loss: 0.412630; batch adversarial loss: 0.308225\n",
      "epoch 111; iter: 0; batch classifier loss: 0.324556; batch adversarial loss: 0.363239\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383145; batch adversarial loss: 0.371595\n",
      "epoch 113; iter: 0; batch classifier loss: 0.362622; batch adversarial loss: 0.321268\n",
      "epoch 114; iter: 0; batch classifier loss: 0.365128; batch adversarial loss: 0.233074\n",
      "epoch 115; iter: 0; batch classifier loss: 0.334356; batch adversarial loss: 0.219205\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355799; batch adversarial loss: 0.223526\n",
      "epoch 117; iter: 0; batch classifier loss: 0.325235; batch adversarial loss: 0.272690\n",
      "epoch 118; iter: 0; batch classifier loss: 0.304163; batch adversarial loss: 0.297316\n",
      "epoch 119; iter: 0; batch classifier loss: 0.376541; batch adversarial loss: 0.324653\n",
      "epoch 120; iter: 0; batch classifier loss: 0.299778; batch adversarial loss: 0.219456\n",
      "epoch 121; iter: 0; batch classifier loss: 0.321616; batch adversarial loss: 0.285136\n",
      "epoch 122; iter: 0; batch classifier loss: 0.398570; batch adversarial loss: 0.253474\n",
      "epoch 123; iter: 0; batch classifier loss: 0.366467; batch adversarial loss: 0.345403\n",
      "epoch 124; iter: 0; batch classifier loss: 0.337178; batch adversarial loss: 0.360704\n",
      "epoch 125; iter: 0; batch classifier loss: 0.410201; batch adversarial loss: 0.369831\n",
      "epoch 126; iter: 0; batch classifier loss: 0.376112; batch adversarial loss: 0.377421\n",
      "epoch 127; iter: 0; batch classifier loss: 0.459977; batch adversarial loss: 0.288987\n",
      "epoch 128; iter: 0; batch classifier loss: 0.330579; batch adversarial loss: 0.220885\n",
      "epoch 129; iter: 0; batch classifier loss: 0.293438; batch adversarial loss: 0.339136\n",
      "epoch 130; iter: 0; batch classifier loss: 0.385540; batch adversarial loss: 0.168234\n",
      "epoch 131; iter: 0; batch classifier loss: 0.336334; batch adversarial loss: 0.324700\n",
      "epoch 132; iter: 0; batch classifier loss: 0.318556; batch adversarial loss: 0.346482\n",
      "epoch 133; iter: 0; batch classifier loss: 0.334803; batch adversarial loss: 0.317326\n",
      "epoch 134; iter: 0; batch classifier loss: 0.295613; batch adversarial loss: 0.222153\n",
      "epoch 135; iter: 0; batch classifier loss: 0.320868; batch adversarial loss: 0.357429\n",
      "epoch 136; iter: 0; batch classifier loss: 0.347402; batch adversarial loss: 0.270622\n",
      "epoch 137; iter: 0; batch classifier loss: 0.349138; batch adversarial loss: 0.306140\n",
      "epoch 138; iter: 0; batch classifier loss: 0.327686; batch adversarial loss: 0.264568\n",
      "epoch 139; iter: 0; batch classifier loss: 0.377798; batch adversarial loss: 0.272797\n",
      "epoch 140; iter: 0; batch classifier loss: 0.380578; batch adversarial loss: 0.295449\n",
      "epoch 141; iter: 0; batch classifier loss: 0.350567; batch adversarial loss: 0.299532\n",
      "epoch 142; iter: 0; batch classifier loss: 0.320760; batch adversarial loss: 0.190693\n",
      "epoch 143; iter: 0; batch classifier loss: 0.284375; batch adversarial loss: 0.300051\n",
      "epoch 144; iter: 0; batch classifier loss: 0.337107; batch adversarial loss: 0.254659\n",
      "epoch 145; iter: 0; batch classifier loss: 0.380045; batch adversarial loss: 0.344547\n",
      "epoch 146; iter: 0; batch classifier loss: 0.365331; batch adversarial loss: 0.227258\n",
      "epoch 147; iter: 0; batch classifier loss: 0.297939; batch adversarial loss: 0.167092\n",
      "epoch 148; iter: 0; batch classifier loss: 0.316806; batch adversarial loss: 0.347540\n",
      "epoch 149; iter: 0; batch classifier loss: 0.387652; batch adversarial loss: 0.244768\n",
      "epoch 150; iter: 0; batch classifier loss: 0.349414; batch adversarial loss: 0.323614\n",
      "epoch 151; iter: 0; batch classifier loss: 0.383682; batch adversarial loss: 0.276201\n",
      "epoch 152; iter: 0; batch classifier loss: 0.338161; batch adversarial loss: 0.293881\n",
      "epoch 153; iter: 0; batch classifier loss: 0.397748; batch adversarial loss: 0.322216\n",
      "epoch 154; iter: 0; batch classifier loss: 0.329832; batch adversarial loss: 0.329022\n",
      "epoch 155; iter: 0; batch classifier loss: 0.357498; batch adversarial loss: 0.167544\n",
      "epoch 156; iter: 0; batch classifier loss: 0.383289; batch adversarial loss: 0.278073\n",
      "epoch 157; iter: 0; batch classifier loss: 0.319931; batch adversarial loss: 0.331140\n",
      "epoch 158; iter: 0; batch classifier loss: 0.311863; batch adversarial loss: 0.339184\n",
      "epoch 159; iter: 0; batch classifier loss: 0.288397; batch adversarial loss: 0.314660\n",
      "epoch 160; iter: 0; batch classifier loss: 0.317515; batch adversarial loss: 0.291061\n",
      "epoch 161; iter: 0; batch classifier loss: 0.380649; batch adversarial loss: 0.219974\n",
      "epoch 162; iter: 0; batch classifier loss: 0.277741; batch adversarial loss: 0.207984\n",
      "epoch 163; iter: 0; batch classifier loss: 0.237245; batch adversarial loss: 0.306244\n",
      "epoch 164; iter: 0; batch classifier loss: 0.373639; batch adversarial loss: 0.314121\n",
      "epoch 165; iter: 0; batch classifier loss: 0.362868; batch adversarial loss: 0.220426\n",
      "epoch 166; iter: 0; batch classifier loss: 0.354214; batch adversarial loss: 0.379057\n",
      "epoch 167; iter: 0; batch classifier loss: 0.382483; batch adversarial loss: 0.398433\n",
      "epoch 168; iter: 0; batch classifier loss: 0.307794; batch adversarial loss: 0.455215\n",
      "epoch 169; iter: 0; batch classifier loss: 0.297312; batch adversarial loss: 0.343991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.288228; batch adversarial loss: 0.340645\n",
      "epoch 171; iter: 0; batch classifier loss: 0.409485; batch adversarial loss: 0.258314\n",
      "epoch 172; iter: 0; batch classifier loss: 0.294938; batch adversarial loss: 0.290374\n",
      "epoch 173; iter: 0; batch classifier loss: 0.350362; batch adversarial loss: 0.331178\n",
      "epoch 174; iter: 0; batch classifier loss: 0.384314; batch adversarial loss: 0.433008\n",
      "epoch 175; iter: 0; batch classifier loss: 0.298795; batch adversarial loss: 0.424740\n",
      "epoch 176; iter: 0; batch classifier loss: 0.349917; batch adversarial loss: 0.315735\n",
      "epoch 177; iter: 0; batch classifier loss: 0.303592; batch adversarial loss: 0.223758\n",
      "epoch 178; iter: 0; batch classifier loss: 0.303546; batch adversarial loss: 0.343280\n",
      "epoch 179; iter: 0; batch classifier loss: 0.288724; batch adversarial loss: 0.270303\n",
      "epoch 180; iter: 0; batch classifier loss: 0.286299; batch adversarial loss: 0.399936\n",
      "epoch 181; iter: 0; batch classifier loss: 0.265100; batch adversarial loss: 0.292426\n",
      "epoch 182; iter: 0; batch classifier loss: 0.336787; batch adversarial loss: 0.351065\n",
      "epoch 183; iter: 0; batch classifier loss: 0.252036; batch adversarial loss: 0.356139\n",
      "epoch 184; iter: 0; batch classifier loss: 0.358697; batch adversarial loss: 0.291354\n",
      "epoch 185; iter: 0; batch classifier loss: 0.397016; batch adversarial loss: 0.363703\n",
      "epoch 186; iter: 0; batch classifier loss: 0.325959; batch adversarial loss: 0.314843\n",
      "epoch 187; iter: 0; batch classifier loss: 0.335419; batch adversarial loss: 0.379240\n",
      "epoch 188; iter: 0; batch classifier loss: 0.267443; batch adversarial loss: 0.237292\n",
      "epoch 189; iter: 0; batch classifier loss: 0.351893; batch adversarial loss: 0.366381\n",
      "epoch 190; iter: 0; batch classifier loss: 0.230400; batch adversarial loss: 0.361789\n",
      "epoch 191; iter: 0; batch classifier loss: 0.331446; batch adversarial loss: 0.295045\n",
      "epoch 192; iter: 0; batch classifier loss: 0.303607; batch adversarial loss: 0.314325\n",
      "epoch 193; iter: 0; batch classifier loss: 0.251623; batch adversarial loss: 0.306381\n",
      "epoch 194; iter: 0; batch classifier loss: 0.366292; batch adversarial loss: 0.391715\n",
      "epoch 195; iter: 0; batch classifier loss: 0.307194; batch adversarial loss: 0.222256\n",
      "epoch 196; iter: 0; batch classifier loss: 0.316274; batch adversarial loss: 0.288548\n",
      "epoch 197; iter: 0; batch classifier loss: 0.320385; batch adversarial loss: 0.240315\n",
      "epoch 198; iter: 0; batch classifier loss: 0.348327; batch adversarial loss: 0.366725\n",
      "epoch 199; iter: 0; batch classifier loss: 0.275027; batch adversarial loss: 0.418870\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.202090; batch adversarial loss: 0.924485\n",
      "epoch 2; iter: 0; batch classifier loss: 1.098245; batch adversarial loss: 0.798512\n",
      "epoch 3; iter: 0; batch classifier loss: 0.857450; batch adversarial loss: 0.817046\n",
      "epoch 4; iter: 0; batch classifier loss: 0.787283; batch adversarial loss: 0.721777\n",
      "epoch 5; iter: 0; batch classifier loss: 0.656194; batch adversarial loss: 0.660840\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579944; batch adversarial loss: 0.636194\n",
      "epoch 7; iter: 0; batch classifier loss: 0.581815; batch adversarial loss: 0.612236\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551902; batch adversarial loss: 0.601641\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538853; batch adversarial loss: 0.573717\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543447; batch adversarial loss: 0.582736\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569862; batch adversarial loss: 0.541968\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532398; batch adversarial loss: 0.535322\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535172; batch adversarial loss: 0.528991\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518690; batch adversarial loss: 0.492184\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527777; batch adversarial loss: 0.472614\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592320; batch adversarial loss: 0.455176\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505205; batch adversarial loss: 0.461657\n",
      "epoch 18; iter: 0; batch classifier loss: 0.544610; batch adversarial loss: 0.452735\n",
      "epoch 19; iter: 0; batch classifier loss: 0.541290; batch adversarial loss: 0.457185\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512253; batch adversarial loss: 0.428214\n",
      "epoch 21; iter: 0; batch classifier loss: 0.524980; batch adversarial loss: 0.443421\n",
      "epoch 22; iter: 0; batch classifier loss: 0.556944; batch adversarial loss: 0.458346\n",
      "epoch 23; iter: 0; batch classifier loss: 0.513945; batch adversarial loss: 0.503170\n",
      "epoch 24; iter: 0; batch classifier loss: 0.573566; batch adversarial loss: 0.364419\n",
      "epoch 25; iter: 0; batch classifier loss: 0.545183; batch adversarial loss: 0.428859\n",
      "epoch 26; iter: 0; batch classifier loss: 0.620694; batch adversarial loss: 0.481243\n",
      "epoch 27; iter: 0; batch classifier loss: 0.683414; batch adversarial loss: 0.499442\n",
      "epoch 28; iter: 0; batch classifier loss: 0.605437; batch adversarial loss: 0.409915\n",
      "epoch 29; iter: 0; batch classifier loss: 0.519091; batch adversarial loss: 0.466486\n",
      "epoch 30; iter: 0; batch classifier loss: 0.544320; batch adversarial loss: 0.381756\n",
      "epoch 31; iter: 0; batch classifier loss: 0.592809; batch adversarial loss: 0.403761\n",
      "epoch 32; iter: 0; batch classifier loss: 0.630796; batch adversarial loss: 0.432415\n",
      "epoch 33; iter: 0; batch classifier loss: 0.583680; batch adversarial loss: 0.395441\n",
      "epoch 34; iter: 0; batch classifier loss: 0.547797; batch adversarial loss: 0.335988\n",
      "epoch 35; iter: 0; batch classifier loss: 0.654119; batch adversarial loss: 0.440743\n",
      "epoch 36; iter: 0; batch classifier loss: 0.550488; batch adversarial loss: 0.383953\n",
      "epoch 37; iter: 0; batch classifier loss: 0.592243; batch adversarial loss: 0.416417\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446472; batch adversarial loss: 0.344885\n",
      "epoch 39; iter: 0; batch classifier loss: 0.559431; batch adversarial loss: 0.321335\n",
      "epoch 40; iter: 0; batch classifier loss: 0.521782; batch adversarial loss: 0.389149\n",
      "epoch 41; iter: 0; batch classifier loss: 0.601342; batch adversarial loss: 0.409913\n",
      "epoch 42; iter: 0; batch classifier loss: 0.500386; batch adversarial loss: 0.338674\n",
      "epoch 43; iter: 0; batch classifier loss: 0.540478; batch adversarial loss: 0.352861\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463660; batch adversarial loss: 0.315664\n",
      "epoch 45; iter: 0; batch classifier loss: 0.524085; batch adversarial loss: 0.341668\n",
      "epoch 46; iter: 0; batch classifier loss: 0.541053; batch adversarial loss: 0.301965\n",
      "epoch 47; iter: 0; batch classifier loss: 0.489789; batch adversarial loss: 0.269360\n",
      "epoch 48; iter: 0; batch classifier loss: 0.598338; batch adversarial loss: 0.385019\n",
      "epoch 49; iter: 0; batch classifier loss: 0.519645; batch adversarial loss: 0.370036\n",
      "epoch 50; iter: 0; batch classifier loss: 0.598767; batch adversarial loss: 0.314927\n",
      "epoch 51; iter: 0; batch classifier loss: 0.601257; batch adversarial loss: 0.366023\n",
      "epoch 52; iter: 0; batch classifier loss: 0.512342; batch adversarial loss: 0.282725\n",
      "epoch 53; iter: 0; batch classifier loss: 0.562585; batch adversarial loss: 0.400980\n",
      "epoch 54; iter: 0; batch classifier loss: 0.602191; batch adversarial loss: 0.279073\n",
      "epoch 55; iter: 0; batch classifier loss: 0.556393; batch adversarial loss: 0.250603\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445327; batch adversarial loss: 0.352711\n",
      "epoch 57; iter: 0; batch classifier loss: 0.490480; batch adversarial loss: 0.352869\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423235; batch adversarial loss: 0.365906\n",
      "epoch 59; iter: 0; batch classifier loss: 0.461664; batch adversarial loss: 0.377594\n",
      "epoch 60; iter: 0; batch classifier loss: 0.484900; batch adversarial loss: 0.320157\n",
      "epoch 61; iter: 0; batch classifier loss: 0.455736; batch adversarial loss: 0.249211\n",
      "epoch 62; iter: 0; batch classifier loss: 0.483359; batch adversarial loss: 0.303718\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465979; batch adversarial loss: 0.404558\n",
      "epoch 64; iter: 0; batch classifier loss: 0.361536; batch adversarial loss: 0.321302\n",
      "epoch 65; iter: 0; batch classifier loss: 0.451187; batch adversarial loss: 0.257841\n",
      "epoch 66; iter: 0; batch classifier loss: 0.323784; batch adversarial loss: 0.330604\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408774; batch adversarial loss: 0.344258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.405724; batch adversarial loss: 0.343307\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426547; batch adversarial loss: 0.280927\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418635; batch adversarial loss: 0.343430\n",
      "epoch 71; iter: 0; batch classifier loss: 0.480076; batch adversarial loss: 0.280063\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414353; batch adversarial loss: 0.286637\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375424; batch adversarial loss: 0.287301\n",
      "epoch 74; iter: 0; batch classifier loss: 0.439640; batch adversarial loss: 0.364124\n",
      "epoch 75; iter: 0; batch classifier loss: 0.356839; batch adversarial loss: 0.308453\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364304; batch adversarial loss: 0.314734\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416181; batch adversarial loss: 0.336760\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362072; batch adversarial loss: 0.228405\n",
      "epoch 79; iter: 0; batch classifier loss: 0.373247; batch adversarial loss: 0.367507\n",
      "epoch 80; iter: 0; batch classifier loss: 0.471415; batch adversarial loss: 0.418377\n",
      "epoch 81; iter: 0; batch classifier loss: 0.422804; batch adversarial loss: 0.277661\n",
      "epoch 82; iter: 0; batch classifier loss: 0.459896; batch adversarial loss: 0.271454\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381172; batch adversarial loss: 0.276575\n",
      "epoch 84; iter: 0; batch classifier loss: 0.441175; batch adversarial loss: 0.268540\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392193; batch adversarial loss: 0.396764\n",
      "epoch 86; iter: 0; batch classifier loss: 0.405656; batch adversarial loss: 0.297016\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376629; batch adversarial loss: 0.312106\n",
      "epoch 88; iter: 0; batch classifier loss: 0.418793; batch adversarial loss: 0.259392\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382266; batch adversarial loss: 0.269821\n",
      "epoch 90; iter: 0; batch classifier loss: 0.464596; batch adversarial loss: 0.260171\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413013; batch adversarial loss: 0.360431\n",
      "epoch 92; iter: 0; batch classifier loss: 0.371458; batch adversarial loss: 0.241644\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349219; batch adversarial loss: 0.288138\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374229; batch adversarial loss: 0.285783\n",
      "epoch 95; iter: 0; batch classifier loss: 0.401355; batch adversarial loss: 0.294106\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372601; batch adversarial loss: 0.309513\n",
      "epoch 97; iter: 0; batch classifier loss: 0.358801; batch adversarial loss: 0.289907\n",
      "epoch 98; iter: 0; batch classifier loss: 0.391641; batch adversarial loss: 0.254382\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355294; batch adversarial loss: 0.228220\n",
      "epoch 100; iter: 0; batch classifier loss: 0.428101; batch adversarial loss: 0.300221\n",
      "epoch 101; iter: 0; batch classifier loss: 0.370516; batch adversarial loss: 0.260069\n",
      "epoch 102; iter: 0; batch classifier loss: 0.323410; batch adversarial loss: 0.273193\n",
      "epoch 103; iter: 0; batch classifier loss: 0.399505; batch adversarial loss: 0.363535\n",
      "epoch 104; iter: 0; batch classifier loss: 0.428179; batch adversarial loss: 0.290928\n",
      "epoch 105; iter: 0; batch classifier loss: 0.297590; batch adversarial loss: 0.337590\n",
      "epoch 106; iter: 0; batch classifier loss: 0.384009; batch adversarial loss: 0.270014\n",
      "epoch 107; iter: 0; batch classifier loss: 0.355540; batch adversarial loss: 0.281395\n",
      "epoch 108; iter: 0; batch classifier loss: 0.380782; batch adversarial loss: 0.315549\n",
      "epoch 109; iter: 0; batch classifier loss: 0.386093; batch adversarial loss: 0.289345\n",
      "epoch 110; iter: 0; batch classifier loss: 0.402743; batch adversarial loss: 0.308251\n",
      "epoch 111; iter: 0; batch classifier loss: 0.320569; batch adversarial loss: 0.363265\n",
      "epoch 112; iter: 0; batch classifier loss: 0.384298; batch adversarial loss: 0.371765\n",
      "epoch 113; iter: 0; batch classifier loss: 0.350720; batch adversarial loss: 0.321019\n",
      "epoch 114; iter: 0; batch classifier loss: 0.362391; batch adversarial loss: 0.232892\n",
      "epoch 115; iter: 0; batch classifier loss: 0.328170; batch adversarial loss: 0.219263\n",
      "epoch 116; iter: 0; batch classifier loss: 0.355844; batch adversarial loss: 0.223552\n",
      "epoch 117; iter: 0; batch classifier loss: 0.331797; batch adversarial loss: 0.273545\n",
      "epoch 118; iter: 0; batch classifier loss: 0.301295; batch adversarial loss: 0.297036\n",
      "epoch 119; iter: 0; batch classifier loss: 0.372765; batch adversarial loss: 0.325075\n",
      "epoch 120; iter: 0; batch classifier loss: 0.301434; batch adversarial loss: 0.219459\n",
      "epoch 121; iter: 0; batch classifier loss: 0.304087; batch adversarial loss: 0.284951\n",
      "epoch 122; iter: 0; batch classifier loss: 0.388966; batch adversarial loss: 0.253015\n",
      "epoch 123; iter: 0; batch classifier loss: 0.346117; batch adversarial loss: 0.343948\n",
      "epoch 124; iter: 0; batch classifier loss: 0.342348; batch adversarial loss: 0.360275\n",
      "epoch 125; iter: 0; batch classifier loss: 0.412455; batch adversarial loss: 0.370629\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369480; batch adversarial loss: 0.378506\n",
      "epoch 127; iter: 0; batch classifier loss: 0.446649; batch adversarial loss: 0.289660\n",
      "epoch 128; iter: 0; batch classifier loss: 0.301251; batch adversarial loss: 0.220819\n",
      "epoch 129; iter: 0; batch classifier loss: 0.291499; batch adversarial loss: 0.339370\n",
      "epoch 130; iter: 0; batch classifier loss: 0.373979; batch adversarial loss: 0.168194\n",
      "epoch 131; iter: 0; batch classifier loss: 0.328558; batch adversarial loss: 0.325209\n",
      "epoch 132; iter: 0; batch classifier loss: 0.303323; batch adversarial loss: 0.346840\n",
      "epoch 133; iter: 0; batch classifier loss: 0.339157; batch adversarial loss: 0.317033\n",
      "epoch 134; iter: 0; batch classifier loss: 0.293196; batch adversarial loss: 0.221969\n",
      "epoch 135; iter: 0; batch classifier loss: 0.294704; batch adversarial loss: 0.357239\n",
      "epoch 136; iter: 0; batch classifier loss: 0.328469; batch adversarial loss: 0.270485\n",
      "epoch 137; iter: 0; batch classifier loss: 0.344908; batch adversarial loss: 0.305968\n",
      "epoch 138; iter: 0; batch classifier loss: 0.321820; batch adversarial loss: 0.264803\n",
      "epoch 139; iter: 0; batch classifier loss: 0.360914; batch adversarial loss: 0.272483\n",
      "epoch 140; iter: 0; batch classifier loss: 0.378265; batch adversarial loss: 0.295420\n",
      "epoch 141; iter: 0; batch classifier loss: 0.353178; batch adversarial loss: 0.299683\n",
      "epoch 142; iter: 0; batch classifier loss: 0.329122; batch adversarial loss: 0.191004\n",
      "epoch 143; iter: 0; batch classifier loss: 0.302275; batch adversarial loss: 0.299844\n",
      "epoch 144; iter: 0; batch classifier loss: 0.334672; batch adversarial loss: 0.255052\n",
      "epoch 145; iter: 0; batch classifier loss: 0.355337; batch adversarial loss: 0.343938\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366043; batch adversarial loss: 0.227353\n",
      "epoch 147; iter: 0; batch classifier loss: 0.303862; batch adversarial loss: 0.167167\n",
      "epoch 148; iter: 0; batch classifier loss: 0.334335; batch adversarial loss: 0.347886\n",
      "epoch 149; iter: 0; batch classifier loss: 0.379100; batch adversarial loss: 0.244434\n",
      "epoch 150; iter: 0; batch classifier loss: 0.359643; batch adversarial loss: 0.323743\n",
      "epoch 151; iter: 0; batch classifier loss: 0.384265; batch adversarial loss: 0.275915\n",
      "epoch 152; iter: 0; batch classifier loss: 0.331514; batch adversarial loss: 0.294577\n",
      "epoch 153; iter: 0; batch classifier loss: 0.381689; batch adversarial loss: 0.322041\n",
      "epoch 154; iter: 0; batch classifier loss: 0.306732; batch adversarial loss: 0.328956\n",
      "epoch 155; iter: 0; batch classifier loss: 0.339196; batch adversarial loss: 0.167519\n",
      "epoch 156; iter: 0; batch classifier loss: 0.373787; batch adversarial loss: 0.278117\n",
      "epoch 157; iter: 0; batch classifier loss: 0.316900; batch adversarial loss: 0.331627\n",
      "epoch 158; iter: 0; batch classifier loss: 0.304087; batch adversarial loss: 0.339371\n",
      "epoch 159; iter: 0; batch classifier loss: 0.289188; batch adversarial loss: 0.314607\n",
      "epoch 160; iter: 0; batch classifier loss: 0.304960; batch adversarial loss: 0.290713\n",
      "epoch 161; iter: 0; batch classifier loss: 0.359124; batch adversarial loss: 0.219094\n",
      "epoch 162; iter: 0; batch classifier loss: 0.253485; batch adversarial loss: 0.207981\n",
      "epoch 163; iter: 0; batch classifier loss: 0.247792; batch adversarial loss: 0.306115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.341345; batch adversarial loss: 0.314005\n",
      "epoch 165; iter: 0; batch classifier loss: 0.392598; batch adversarial loss: 0.220594\n",
      "epoch 166; iter: 0; batch classifier loss: 0.379028; batch adversarial loss: 0.378702\n",
      "epoch 167; iter: 0; batch classifier loss: 0.356327; batch adversarial loss: 0.398623\n",
      "epoch 168; iter: 0; batch classifier loss: 0.300309; batch adversarial loss: 0.454958\n",
      "epoch 169; iter: 0; batch classifier loss: 0.288334; batch adversarial loss: 0.344425\n",
      "epoch 170; iter: 0; batch classifier loss: 0.299481; batch adversarial loss: 0.340362\n",
      "epoch 171; iter: 0; batch classifier loss: 0.389080; batch adversarial loss: 0.257979\n",
      "epoch 172; iter: 0; batch classifier loss: 0.281228; batch adversarial loss: 0.290465\n",
      "epoch 173; iter: 0; batch classifier loss: 0.353851; batch adversarial loss: 0.331377\n",
      "epoch 174; iter: 0; batch classifier loss: 0.361292; batch adversarial loss: 0.432324\n",
      "epoch 175; iter: 0; batch classifier loss: 0.287259; batch adversarial loss: 0.424823\n",
      "epoch 176; iter: 0; batch classifier loss: 0.359595; batch adversarial loss: 0.316399\n",
      "epoch 177; iter: 0; batch classifier loss: 0.296213; batch adversarial loss: 0.223660\n",
      "epoch 178; iter: 0; batch classifier loss: 0.302961; batch adversarial loss: 0.342676\n",
      "epoch 179; iter: 0; batch classifier loss: 0.295342; batch adversarial loss: 0.270271\n",
      "epoch 180; iter: 0; batch classifier loss: 0.302327; batch adversarial loss: 0.399610\n",
      "epoch 181; iter: 0; batch classifier loss: 0.258895; batch adversarial loss: 0.292359\n",
      "epoch 182; iter: 0; batch classifier loss: 0.331418; batch adversarial loss: 0.350778\n",
      "epoch 183; iter: 0; batch classifier loss: 0.256884; batch adversarial loss: 0.356020\n",
      "epoch 184; iter: 0; batch classifier loss: 0.380482; batch adversarial loss: 0.291438\n",
      "epoch 185; iter: 0; batch classifier loss: 0.369353; batch adversarial loss: 0.363634\n",
      "epoch 186; iter: 0; batch classifier loss: 0.309602; batch adversarial loss: 0.314877\n",
      "epoch 187; iter: 0; batch classifier loss: 0.328044; batch adversarial loss: 0.379142\n",
      "epoch 188; iter: 0; batch classifier loss: 0.285428; batch adversarial loss: 0.237502\n",
      "epoch 189; iter: 0; batch classifier loss: 0.356699; batch adversarial loss: 0.366307\n",
      "epoch 190; iter: 0; batch classifier loss: 0.245361; batch adversarial loss: 0.362008\n",
      "epoch 191; iter: 0; batch classifier loss: 0.312104; batch adversarial loss: 0.295276\n",
      "epoch 192; iter: 0; batch classifier loss: 0.303606; batch adversarial loss: 0.314027\n",
      "epoch 193; iter: 0; batch classifier loss: 0.253015; batch adversarial loss: 0.306433\n",
      "epoch 194; iter: 0; batch classifier loss: 0.369666; batch adversarial loss: 0.390835\n",
      "epoch 195; iter: 0; batch classifier loss: 0.309408; batch adversarial loss: 0.222181\n",
      "epoch 196; iter: 0; batch classifier loss: 0.316216; batch adversarial loss: 0.288555\n",
      "epoch 197; iter: 0; batch classifier loss: 0.304639; batch adversarial loss: 0.239793\n",
      "epoch 198; iter: 0; batch classifier loss: 0.340740; batch adversarial loss: 0.367048\n",
      "epoch 199; iter: 0; batch classifier loss: 0.265568; batch adversarial loss: 0.418319\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.215420; batch adversarial loss: 0.925003\n",
      "epoch 2; iter: 0; batch classifier loss: 1.107628; batch adversarial loss: 0.798983\n",
      "epoch 3; iter: 0; batch classifier loss: 0.864209; batch adversarial loss: 0.817584\n",
      "epoch 4; iter: 0; batch classifier loss: 0.796284; batch adversarial loss: 0.722735\n",
      "epoch 5; iter: 0; batch classifier loss: 0.662892; batch adversarial loss: 0.661677\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580593; batch adversarial loss: 0.636321\n",
      "epoch 7; iter: 0; batch classifier loss: 0.581749; batch adversarial loss: 0.612226\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552183; batch adversarial loss: 0.601536\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539713; batch adversarial loss: 0.573437\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543377; batch adversarial loss: 0.582477\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568726; batch adversarial loss: 0.541879\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532223; batch adversarial loss: 0.535051\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534828; batch adversarial loss: 0.528778\n",
      "epoch 14; iter: 0; batch classifier loss: 0.517438; batch adversarial loss: 0.492459\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527311; batch adversarial loss: 0.473051\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591595; batch adversarial loss: 0.455696\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505133; batch adversarial loss: 0.462354\n",
      "epoch 18; iter: 0; batch classifier loss: 0.544841; batch adversarial loss: 0.453147\n",
      "epoch 19; iter: 0; batch classifier loss: 0.544201; batch adversarial loss: 0.458329\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513727; batch adversarial loss: 0.429751\n",
      "epoch 21; iter: 0; batch classifier loss: 0.528993; batch adversarial loss: 0.445500\n",
      "epoch 22; iter: 0; batch classifier loss: 0.565134; batch adversarial loss: 0.460478\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518611; batch adversarial loss: 0.504688\n",
      "epoch 24; iter: 0; batch classifier loss: 0.575354; batch adversarial loss: 0.365164\n",
      "epoch 25; iter: 0; batch classifier loss: 0.548045; batch adversarial loss: 0.429805\n",
      "epoch 26; iter: 0; batch classifier loss: 0.631704; batch adversarial loss: 0.483053\n",
      "epoch 27; iter: 0; batch classifier loss: 0.689268; batch adversarial loss: 0.500289\n",
      "epoch 28; iter: 0; batch classifier loss: 0.607893; batch adversarial loss: 0.409983\n",
      "epoch 29; iter: 0; batch classifier loss: 0.520310; batch adversarial loss: 0.467047\n",
      "epoch 30; iter: 0; batch classifier loss: 0.548733; batch adversarial loss: 0.382060\n",
      "epoch 31; iter: 0; batch classifier loss: 0.597868; batch adversarial loss: 0.403849\n",
      "epoch 32; iter: 0; batch classifier loss: 0.629218; batch adversarial loss: 0.432160\n",
      "epoch 33; iter: 0; batch classifier loss: 0.590270; batch adversarial loss: 0.395692\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544390; batch adversarial loss: 0.336021\n",
      "epoch 35; iter: 0; batch classifier loss: 0.661714; batch adversarial loss: 0.439916\n",
      "epoch 36; iter: 0; batch classifier loss: 0.551612; batch adversarial loss: 0.383305\n",
      "epoch 37; iter: 0; batch classifier loss: 0.592385; batch adversarial loss: 0.415664\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442898; batch adversarial loss: 0.344385\n",
      "epoch 39; iter: 0; batch classifier loss: 0.559077; batch adversarial loss: 0.321193\n",
      "epoch 40; iter: 0; batch classifier loss: 0.523069; batch adversarial loss: 0.388651\n",
      "epoch 41; iter: 0; batch classifier loss: 0.597489; batch adversarial loss: 0.408917\n",
      "epoch 42; iter: 0; batch classifier loss: 0.499212; batch adversarial loss: 0.338370\n",
      "epoch 43; iter: 0; batch classifier loss: 0.541911; batch adversarial loss: 0.352578\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464044; batch adversarial loss: 0.315532\n",
      "epoch 45; iter: 0; batch classifier loss: 0.516058; batch adversarial loss: 0.341389\n",
      "epoch 46; iter: 0; batch classifier loss: 0.540836; batch adversarial loss: 0.301740\n",
      "epoch 47; iter: 0; batch classifier loss: 0.489937; batch adversarial loss: 0.269036\n",
      "epoch 48; iter: 0; batch classifier loss: 0.607884; batch adversarial loss: 0.384541\n",
      "epoch 49; iter: 0; batch classifier loss: 0.520999; batch adversarial loss: 0.369818\n",
      "epoch 50; iter: 0; batch classifier loss: 0.587371; batch adversarial loss: 0.314649\n",
      "epoch 51; iter: 0; batch classifier loss: 0.589273; batch adversarial loss: 0.365494\n",
      "epoch 52; iter: 0; batch classifier loss: 0.520241; batch adversarial loss: 0.282672\n",
      "epoch 53; iter: 0; batch classifier loss: 0.567666; batch adversarial loss: 0.400523\n",
      "epoch 54; iter: 0; batch classifier loss: 0.607983; batch adversarial loss: 0.278862\n",
      "epoch 55; iter: 0; batch classifier loss: 0.540530; batch adversarial loss: 0.250351\n",
      "epoch 56; iter: 0; batch classifier loss: 0.441719; batch adversarial loss: 0.352663\n",
      "epoch 57; iter: 0; batch classifier loss: 0.496930; batch adversarial loss: 0.352838\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424115; batch adversarial loss: 0.365801\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458037; batch adversarial loss: 0.377480\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481202; batch adversarial loss: 0.320145\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459015; batch adversarial loss: 0.249156\n",
      "epoch 62; iter: 0; batch classifier loss: 0.489037; batch adversarial loss: 0.303671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63; iter: 0; batch classifier loss: 0.463149; batch adversarial loss: 0.404428\n",
      "epoch 64; iter: 0; batch classifier loss: 0.359524; batch adversarial loss: 0.321202\n",
      "epoch 65; iter: 0; batch classifier loss: 0.444223; batch adversarial loss: 0.257718\n",
      "epoch 66; iter: 0; batch classifier loss: 0.323944; batch adversarial loss: 0.330597\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406465; batch adversarial loss: 0.344352\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408505; batch adversarial loss: 0.343365\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430331; batch adversarial loss: 0.280910\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419351; batch adversarial loss: 0.343367\n",
      "epoch 71; iter: 0; batch classifier loss: 0.476727; batch adversarial loss: 0.279873\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412730; batch adversarial loss: 0.286582\n",
      "epoch 73; iter: 0; batch classifier loss: 0.368424; batch adversarial loss: 0.287257\n",
      "epoch 74; iter: 0; batch classifier loss: 0.456764; batch adversarial loss: 0.364163\n",
      "epoch 75; iter: 0; batch classifier loss: 0.353051; batch adversarial loss: 0.308389\n",
      "epoch 76; iter: 0; batch classifier loss: 0.361373; batch adversarial loss: 0.314807\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408511; batch adversarial loss: 0.336502\n",
      "epoch 78; iter: 0; batch classifier loss: 0.362071; batch adversarial loss: 0.228405\n",
      "epoch 79; iter: 0; batch classifier loss: 0.385804; batch adversarial loss: 0.367057\n",
      "epoch 80; iter: 0; batch classifier loss: 0.480376; batch adversarial loss: 0.418410\n",
      "epoch 81; iter: 0; batch classifier loss: 0.415110; batch adversarial loss: 0.277967\n",
      "epoch 82; iter: 0; batch classifier loss: 0.456076; batch adversarial loss: 0.271657\n",
      "epoch 83; iter: 0; batch classifier loss: 0.374780; batch adversarial loss: 0.276300\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435768; batch adversarial loss: 0.268572\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389737; batch adversarial loss: 0.396803\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415558; batch adversarial loss: 0.297079\n",
      "epoch 87; iter: 0; batch classifier loss: 0.376874; batch adversarial loss: 0.312427\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426798; batch adversarial loss: 0.259195\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387694; batch adversarial loss: 0.269884\n",
      "epoch 90; iter: 0; batch classifier loss: 0.456406; batch adversarial loss: 0.260236\n",
      "epoch 91; iter: 0; batch classifier loss: 0.422653; batch adversarial loss: 0.359953\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376688; batch adversarial loss: 0.241776\n",
      "epoch 93; iter: 0; batch classifier loss: 0.343022; batch adversarial loss: 0.288258\n",
      "epoch 94; iter: 0; batch classifier loss: 0.374383; batch adversarial loss: 0.285281\n",
      "epoch 95; iter: 0; batch classifier loss: 0.400076; batch adversarial loss: 0.294132\n",
      "epoch 96; iter: 0; batch classifier loss: 0.367862; batch adversarial loss: 0.309254\n",
      "epoch 97; iter: 0; batch classifier loss: 0.359582; batch adversarial loss: 0.289698\n",
      "epoch 98; iter: 0; batch classifier loss: 0.389933; batch adversarial loss: 0.254381\n",
      "epoch 99; iter: 0; batch classifier loss: 0.360999; batch adversarial loss: 0.227548\n",
      "epoch 100; iter: 0; batch classifier loss: 0.419325; batch adversarial loss: 0.299990\n",
      "epoch 101; iter: 0; batch classifier loss: 0.373259; batch adversarial loss: 0.260011\n",
      "epoch 102; iter: 0; batch classifier loss: 0.323006; batch adversarial loss: 0.273046\n",
      "epoch 103; iter: 0; batch classifier loss: 0.397664; batch adversarial loss: 0.363082\n",
      "epoch 104; iter: 0; batch classifier loss: 0.417704; batch adversarial loss: 0.290690\n",
      "epoch 105; iter: 0; batch classifier loss: 0.290052; batch adversarial loss: 0.337567\n",
      "epoch 106; iter: 0; batch classifier loss: 0.400865; batch adversarial loss: 0.270272\n",
      "epoch 107; iter: 0; batch classifier loss: 0.367339; batch adversarial loss: 0.281599\n",
      "epoch 108; iter: 0; batch classifier loss: 0.377338; batch adversarial loss: 0.316115\n",
      "epoch 109; iter: 0; batch classifier loss: 0.383365; batch adversarial loss: 0.289250\n",
      "epoch 110; iter: 0; batch classifier loss: 0.412929; batch adversarial loss: 0.307978\n",
      "epoch 111; iter: 0; batch classifier loss: 0.319759; batch adversarial loss: 0.363755\n",
      "epoch 112; iter: 0; batch classifier loss: 0.383425; batch adversarial loss: 0.371339\n",
      "epoch 113; iter: 0; batch classifier loss: 0.354193; batch adversarial loss: 0.321010\n",
      "epoch 114; iter: 0; batch classifier loss: 0.370611; batch adversarial loss: 0.233046\n",
      "epoch 115; iter: 0; batch classifier loss: 0.321302; batch adversarial loss: 0.219140\n",
      "epoch 116; iter: 0; batch classifier loss: 0.347851; batch adversarial loss: 0.223608\n",
      "epoch 117; iter: 0; batch classifier loss: 0.333059; batch adversarial loss: 0.273822\n",
      "epoch 118; iter: 0; batch classifier loss: 0.300735; batch adversarial loss: 0.296970\n",
      "epoch 119; iter: 0; batch classifier loss: 0.378948; batch adversarial loss: 0.325141\n",
      "epoch 120; iter: 0; batch classifier loss: 0.288547; batch adversarial loss: 0.219298\n",
      "epoch 121; iter: 0; batch classifier loss: 0.313285; batch adversarial loss: 0.284911\n",
      "epoch 122; iter: 0; batch classifier loss: 0.392763; batch adversarial loss: 0.253105\n",
      "epoch 123; iter: 0; batch classifier loss: 0.345384; batch adversarial loss: 0.344456\n",
      "epoch 124; iter: 0; batch classifier loss: 0.341200; batch adversarial loss: 0.360391\n",
      "epoch 125; iter: 0; batch classifier loss: 0.402658; batch adversarial loss: 0.370246\n",
      "epoch 126; iter: 0; batch classifier loss: 0.369963; batch adversarial loss: 0.378689\n",
      "epoch 127; iter: 0; batch classifier loss: 0.437631; batch adversarial loss: 0.289246\n",
      "epoch 128; iter: 0; batch classifier loss: 0.315376; batch adversarial loss: 0.220823\n",
      "epoch 129; iter: 0; batch classifier loss: 0.286362; batch adversarial loss: 0.338578\n",
      "epoch 130; iter: 0; batch classifier loss: 0.359779; batch adversarial loss: 0.167980\n",
      "epoch 131; iter: 0; batch classifier loss: 0.337185; batch adversarial loss: 0.324348\n",
      "epoch 132; iter: 0; batch classifier loss: 0.303642; batch adversarial loss: 0.346468\n",
      "epoch 133; iter: 0; batch classifier loss: 0.341670; batch adversarial loss: 0.317153\n",
      "epoch 134; iter: 0; batch classifier loss: 0.288816; batch adversarial loss: 0.222308\n",
      "epoch 135; iter: 0; batch classifier loss: 0.306404; batch adversarial loss: 0.356862\n",
      "epoch 136; iter: 0; batch classifier loss: 0.352606; batch adversarial loss: 0.270598\n",
      "epoch 137; iter: 0; batch classifier loss: 0.367671; batch adversarial loss: 0.306283\n",
      "epoch 138; iter: 0; batch classifier loss: 0.312714; batch adversarial loss: 0.263964\n",
      "epoch 139; iter: 0; batch classifier loss: 0.364957; batch adversarial loss: 0.272471\n",
      "epoch 140; iter: 0; batch classifier loss: 0.383113; batch adversarial loss: 0.295491\n",
      "epoch 141; iter: 0; batch classifier loss: 0.368083; batch adversarial loss: 0.299790\n",
      "epoch 142; iter: 0; batch classifier loss: 0.326545; batch adversarial loss: 0.190599\n",
      "epoch 143; iter: 0; batch classifier loss: 0.298282; batch adversarial loss: 0.300325\n",
      "epoch 144; iter: 0; batch classifier loss: 0.340452; batch adversarial loss: 0.254553\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374327; batch adversarial loss: 0.344745\n",
      "epoch 146; iter: 0; batch classifier loss: 0.378161; batch adversarial loss: 0.227554\n",
      "epoch 147; iter: 0; batch classifier loss: 0.303359; batch adversarial loss: 0.166973\n",
      "epoch 148; iter: 0; batch classifier loss: 0.330909; batch adversarial loss: 0.347304\n",
      "epoch 149; iter: 0; batch classifier loss: 0.376170; batch adversarial loss: 0.244064\n",
      "epoch 150; iter: 0; batch classifier loss: 0.338863; batch adversarial loss: 0.323875\n",
      "epoch 151; iter: 0; batch classifier loss: 0.400399; batch adversarial loss: 0.275465\n",
      "epoch 152; iter: 0; batch classifier loss: 0.333263; batch adversarial loss: 0.294302\n",
      "epoch 153; iter: 0; batch classifier loss: 0.391648; batch adversarial loss: 0.322023\n",
      "epoch 154; iter: 0; batch classifier loss: 0.311506; batch adversarial loss: 0.329038\n",
      "epoch 155; iter: 0; batch classifier loss: 0.331867; batch adversarial loss: 0.167597\n",
      "epoch 156; iter: 0; batch classifier loss: 0.364157; batch adversarial loss: 0.277901\n",
      "epoch 157; iter: 0; batch classifier loss: 0.314966; batch adversarial loss: 0.331526\n",
      "epoch 158; iter: 0; batch classifier loss: 0.312619; batch adversarial loss: 0.339465\n",
      "epoch 159; iter: 0; batch classifier loss: 0.298114; batch adversarial loss: 0.314179\n",
      "epoch 160; iter: 0; batch classifier loss: 0.322252; batch adversarial loss: 0.291528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.364595; batch adversarial loss: 0.219200\n",
      "epoch 162; iter: 0; batch classifier loss: 0.258288; batch adversarial loss: 0.208099\n",
      "epoch 163; iter: 0; batch classifier loss: 0.251476; batch adversarial loss: 0.306444\n",
      "epoch 164; iter: 0; batch classifier loss: 0.346530; batch adversarial loss: 0.314012\n",
      "epoch 165; iter: 0; batch classifier loss: 0.394704; batch adversarial loss: 0.221215\n",
      "epoch 166; iter: 0; batch classifier loss: 0.366292; batch adversarial loss: 0.378788\n",
      "epoch 167; iter: 0; batch classifier loss: 0.362059; batch adversarial loss: 0.398691\n",
      "epoch 168; iter: 0; batch classifier loss: 0.309927; batch adversarial loss: 0.456003\n",
      "epoch 169; iter: 0; batch classifier loss: 0.292020; batch adversarial loss: 0.344427\n",
      "epoch 170; iter: 0; batch classifier loss: 0.299973; batch adversarial loss: 0.340484\n",
      "epoch 171; iter: 0; batch classifier loss: 0.400106; batch adversarial loss: 0.257978\n",
      "epoch 172; iter: 0; batch classifier loss: 0.282267; batch adversarial loss: 0.290164\n",
      "epoch 173; iter: 0; batch classifier loss: 0.365102; batch adversarial loss: 0.330988\n",
      "epoch 174; iter: 0; batch classifier loss: 0.368636; batch adversarial loss: 0.432782\n",
      "epoch 175; iter: 0; batch classifier loss: 0.294891; batch adversarial loss: 0.425368\n",
      "epoch 176; iter: 0; batch classifier loss: 0.360786; batch adversarial loss: 0.316541\n",
      "epoch 177; iter: 0; batch classifier loss: 0.300840; batch adversarial loss: 0.223789\n",
      "epoch 178; iter: 0; batch classifier loss: 0.316390; batch adversarial loss: 0.342800\n",
      "epoch 179; iter: 0; batch classifier loss: 0.279194; batch adversarial loss: 0.270346\n",
      "epoch 180; iter: 0; batch classifier loss: 0.307229; batch adversarial loss: 0.399421\n",
      "epoch 181; iter: 0; batch classifier loss: 0.260882; batch adversarial loss: 0.292347\n",
      "epoch 182; iter: 0; batch classifier loss: 0.329658; batch adversarial loss: 0.350893\n",
      "epoch 183; iter: 0; batch classifier loss: 0.246457; batch adversarial loss: 0.356207\n",
      "epoch 184; iter: 0; batch classifier loss: 0.380136; batch adversarial loss: 0.291536\n",
      "epoch 185; iter: 0; batch classifier loss: 0.374942; batch adversarial loss: 0.364015\n",
      "epoch 186; iter: 0; batch classifier loss: 0.339839; batch adversarial loss: 0.315001\n",
      "epoch 187; iter: 0; batch classifier loss: 0.350094; batch adversarial loss: 0.379707\n",
      "epoch 188; iter: 0; batch classifier loss: 0.268496; batch adversarial loss: 0.237224\n",
      "epoch 189; iter: 0; batch classifier loss: 0.357390; batch adversarial loss: 0.366718\n",
      "epoch 190; iter: 0; batch classifier loss: 0.260042; batch adversarial loss: 0.361969\n",
      "epoch 191; iter: 0; batch classifier loss: 0.312674; batch adversarial loss: 0.295754\n",
      "epoch 192; iter: 0; batch classifier loss: 0.299142; batch adversarial loss: 0.314517\n",
      "epoch 193; iter: 0; batch classifier loss: 0.256891; batch adversarial loss: 0.306505\n",
      "epoch 194; iter: 0; batch classifier loss: 0.379874; batch adversarial loss: 0.391127\n",
      "epoch 195; iter: 0; batch classifier loss: 0.322350; batch adversarial loss: 0.222281\n",
      "epoch 196; iter: 0; batch classifier loss: 0.313750; batch adversarial loss: 0.288408\n",
      "epoch 197; iter: 0; batch classifier loss: 0.322682; batch adversarial loss: 0.240384\n",
      "epoch 198; iter: 0; batch classifier loss: 0.358502; batch adversarial loss: 0.366791\n",
      "epoch 199; iter: 0; batch classifier loss: 0.280252; batch adversarial loss: 0.418036\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.174006; batch adversarial loss: 0.923225\n",
      "epoch 2; iter: 0; batch classifier loss: 1.077063; batch adversarial loss: 0.797309\n",
      "epoch 3; iter: 0; batch classifier loss: 0.840073; batch adversarial loss: 0.815160\n",
      "epoch 4; iter: 0; batch classifier loss: 0.766774; batch adversarial loss: 0.719189\n",
      "epoch 5; iter: 0; batch classifier loss: 0.643621; batch adversarial loss: 0.658518\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577074; batch adversarial loss: 0.636249\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583965; batch adversarial loss: 0.611949\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552118; batch adversarial loss: 0.601768\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539065; batch adversarial loss: 0.574045\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546104; batch adversarial loss: 0.582782\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570916; batch adversarial loss: 0.542276\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532925; batch adversarial loss: 0.535792\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537173; batch adversarial loss: 0.529350\n",
      "epoch 14; iter: 0; batch classifier loss: 0.522577; batch adversarial loss: 0.491551\n",
      "epoch 15; iter: 0; batch classifier loss: 0.528462; batch adversarial loss: 0.471937\n",
      "epoch 16; iter: 0; batch classifier loss: 0.593744; batch adversarial loss: 0.454338\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505155; batch adversarial loss: 0.460563\n",
      "epoch 18; iter: 0; batch classifier loss: 0.546935; batch adversarial loss: 0.451805\n",
      "epoch 19; iter: 0; batch classifier loss: 0.535854; batch adversarial loss: 0.454508\n",
      "epoch 20; iter: 0; batch classifier loss: 0.509382; batch adversarial loss: 0.424902\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517206; batch adversarial loss: 0.438859\n",
      "epoch 22; iter: 0; batch classifier loss: 0.548703; batch adversarial loss: 0.453973\n",
      "epoch 23; iter: 0; batch classifier loss: 0.507006; batch adversarial loss: 0.500663\n",
      "epoch 24; iter: 0; batch classifier loss: 0.567302; batch adversarial loss: 0.362668\n",
      "epoch 25; iter: 0; batch classifier loss: 0.532138; batch adversarial loss: 0.426091\n",
      "epoch 26; iter: 0; batch classifier loss: 0.607062; batch adversarial loss: 0.477911\n",
      "epoch 27; iter: 0; batch classifier loss: 0.669664; batch adversarial loss: 0.498198\n",
      "epoch 28; iter: 0; batch classifier loss: 0.592886; batch adversarial loss: 0.408426\n",
      "epoch 29; iter: 0; batch classifier loss: 0.511279; batch adversarial loss: 0.466296\n",
      "epoch 30; iter: 0; batch classifier loss: 0.538422; batch adversarial loss: 0.381590\n",
      "epoch 31; iter: 0; batch classifier loss: 0.582012; batch adversarial loss: 0.403205\n",
      "epoch 32; iter: 0; batch classifier loss: 0.617194; batch adversarial loss: 0.432719\n",
      "epoch 33; iter: 0; batch classifier loss: 0.582000; batch adversarial loss: 0.395728\n",
      "epoch 34; iter: 0; batch classifier loss: 0.548136; batch adversarial loss: 0.335949\n",
      "epoch 35; iter: 0; batch classifier loss: 0.647121; batch adversarial loss: 0.441618\n",
      "epoch 36; iter: 0; batch classifier loss: 0.555128; batch adversarial loss: 0.384752\n",
      "epoch 37; iter: 0; batch classifier loss: 0.588505; batch adversarial loss: 0.417611\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445662; batch adversarial loss: 0.345580\n",
      "epoch 39; iter: 0; batch classifier loss: 0.560931; batch adversarial loss: 0.321634\n",
      "epoch 40; iter: 0; batch classifier loss: 0.517362; batch adversarial loss: 0.390022\n",
      "epoch 41; iter: 0; batch classifier loss: 0.602003; batch adversarial loss: 0.411045\n",
      "epoch 42; iter: 0; batch classifier loss: 0.492402; batch adversarial loss: 0.339310\n",
      "epoch 43; iter: 0; batch classifier loss: 0.532606; batch adversarial loss: 0.353538\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459959; batch adversarial loss: 0.316027\n",
      "epoch 45; iter: 0; batch classifier loss: 0.520596; batch adversarial loss: 0.342656\n",
      "epoch 46; iter: 0; batch classifier loss: 0.541289; batch adversarial loss: 0.302429\n",
      "epoch 47; iter: 0; batch classifier loss: 0.486406; batch adversarial loss: 0.269546\n",
      "epoch 48; iter: 0; batch classifier loss: 0.598734; batch adversarial loss: 0.386251\n",
      "epoch 49; iter: 0; batch classifier loss: 0.523448; batch adversarial loss: 0.370994\n",
      "epoch 50; iter: 0; batch classifier loss: 0.598018; batch adversarial loss: 0.315710\n",
      "epoch 51; iter: 0; batch classifier loss: 0.598656; batch adversarial loss: 0.366894\n",
      "epoch 52; iter: 0; batch classifier loss: 0.516525; batch adversarial loss: 0.283201\n",
      "epoch 53; iter: 0; batch classifier loss: 0.568541; batch adversarial loss: 0.402157\n",
      "epoch 54; iter: 0; batch classifier loss: 0.593728; batch adversarial loss: 0.279495\n",
      "epoch 55; iter: 0; batch classifier loss: 0.585977; batch adversarial loss: 0.251158\n",
      "epoch 56; iter: 0; batch classifier loss: 0.444487; batch adversarial loss: 0.352883\n",
      "epoch 57; iter: 0; batch classifier loss: 0.500329; batch adversarial loss: 0.352947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.424686; batch adversarial loss: 0.365980\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458644; batch adversarial loss: 0.377565\n",
      "epoch 60; iter: 0; batch classifier loss: 0.477127; batch adversarial loss: 0.320152\n",
      "epoch 61; iter: 0; batch classifier loss: 0.457136; batch adversarial loss: 0.249354\n",
      "epoch 62; iter: 0; batch classifier loss: 0.483904; batch adversarial loss: 0.303777\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465015; batch adversarial loss: 0.404352\n",
      "epoch 64; iter: 0; batch classifier loss: 0.361897; batch adversarial loss: 0.321557\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447111; batch adversarial loss: 0.257920\n",
      "epoch 66; iter: 0; batch classifier loss: 0.312052; batch adversarial loss: 0.330521\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410208; batch adversarial loss: 0.344454\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410520; batch adversarial loss: 0.343275\n",
      "epoch 69; iter: 0; batch classifier loss: 0.419620; batch adversarial loss: 0.280755\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424812; batch adversarial loss: 0.343657\n",
      "epoch 71; iter: 0; batch classifier loss: 0.475638; batch adversarial loss: 0.279948\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415780; batch adversarial loss: 0.286823\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373764; batch adversarial loss: 0.287393\n",
      "epoch 74; iter: 0; batch classifier loss: 0.446613; batch adversarial loss: 0.364094\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354531; batch adversarial loss: 0.308419\n",
      "epoch 76; iter: 0; batch classifier loss: 0.372221; batch adversarial loss: 0.314707\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418588; batch adversarial loss: 0.336658\n",
      "epoch 78; iter: 0; batch classifier loss: 0.356441; batch adversarial loss: 0.228258\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369591; batch adversarial loss: 0.367035\n",
      "epoch 80; iter: 0; batch classifier loss: 0.476867; batch adversarial loss: 0.418327\n",
      "epoch 81; iter: 0; batch classifier loss: 0.412585; batch adversarial loss: 0.277972\n",
      "epoch 82; iter: 0; batch classifier loss: 0.451531; batch adversarial loss: 0.271892\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376887; batch adversarial loss: 0.276335\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437967; batch adversarial loss: 0.269370\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387163; batch adversarial loss: 0.396881\n",
      "epoch 86; iter: 0; batch classifier loss: 0.404502; batch adversarial loss: 0.297061\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378993; batch adversarial loss: 0.312322\n",
      "epoch 88; iter: 0; batch classifier loss: 0.411814; batch adversarial loss: 0.259603\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385327; batch adversarial loss: 0.269800\n",
      "epoch 90; iter: 0; batch classifier loss: 0.454233; batch adversarial loss: 0.260164\n",
      "epoch 91; iter: 0; batch classifier loss: 0.414858; batch adversarial loss: 0.360474\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375257; batch adversarial loss: 0.241627\n",
      "epoch 93; iter: 0; batch classifier loss: 0.339403; batch adversarial loss: 0.287824\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372597; batch adversarial loss: 0.285387\n",
      "epoch 95; iter: 0; batch classifier loss: 0.406635; batch adversarial loss: 0.293859\n",
      "epoch 96; iter: 0; batch classifier loss: 0.371026; batch adversarial loss: 0.309075\n",
      "epoch 97; iter: 0; batch classifier loss: 0.372912; batch adversarial loss: 0.289496\n",
      "epoch 98; iter: 0; batch classifier loss: 0.401592; batch adversarial loss: 0.254060\n",
      "epoch 99; iter: 0; batch classifier loss: 0.357944; batch adversarial loss: 0.228066\n",
      "epoch 100; iter: 0; batch classifier loss: 0.415614; batch adversarial loss: 0.299702\n",
      "epoch 101; iter: 0; batch classifier loss: 0.392179; batch adversarial loss: 0.260312\n",
      "epoch 102; iter: 0; batch classifier loss: 0.332088; batch adversarial loss: 0.273123\n",
      "epoch 103; iter: 0; batch classifier loss: 0.391648; batch adversarial loss: 0.362723\n",
      "epoch 104; iter: 0; batch classifier loss: 0.426781; batch adversarial loss: 0.291149\n",
      "epoch 105; iter: 0; batch classifier loss: 0.293351; batch adversarial loss: 0.337319\n",
      "epoch 106; iter: 0; batch classifier loss: 0.384316; batch adversarial loss: 0.270418\n",
      "epoch 107; iter: 0; batch classifier loss: 0.364112; batch adversarial loss: 0.281717\n",
      "epoch 108; iter: 0; batch classifier loss: 0.370985; batch adversarial loss: 0.315871\n",
      "epoch 109; iter: 0; batch classifier loss: 0.381731; batch adversarial loss: 0.289467\n",
      "epoch 110; iter: 0; batch classifier loss: 0.407356; batch adversarial loss: 0.307976\n",
      "epoch 111; iter: 0; batch classifier loss: 0.318014; batch adversarial loss: 0.363763\n",
      "epoch 112; iter: 0; batch classifier loss: 0.369504; batch adversarial loss: 0.371340\n",
      "epoch 113; iter: 0; batch classifier loss: 0.346075; batch adversarial loss: 0.320703\n",
      "epoch 114; iter: 0; batch classifier loss: 0.366056; batch adversarial loss: 0.232647\n",
      "epoch 115; iter: 0; batch classifier loss: 0.327789; batch adversarial loss: 0.219081\n",
      "epoch 116; iter: 0; batch classifier loss: 0.336359; batch adversarial loss: 0.223734\n",
      "epoch 117; iter: 0; batch classifier loss: 0.325553; batch adversarial loss: 0.272559\n",
      "epoch 118; iter: 0; batch classifier loss: 0.295544; batch adversarial loss: 0.296851\n",
      "epoch 119; iter: 0; batch classifier loss: 0.367979; batch adversarial loss: 0.324135\n",
      "epoch 120; iter: 0; batch classifier loss: 0.294998; batch adversarial loss: 0.219188\n",
      "epoch 121; iter: 0; batch classifier loss: 0.326011; batch adversarial loss: 0.284893\n",
      "epoch 122; iter: 0; batch classifier loss: 0.387023; batch adversarial loss: 0.253389\n",
      "epoch 123; iter: 0; batch classifier loss: 0.359528; batch adversarial loss: 0.344903\n",
      "epoch 124; iter: 0; batch classifier loss: 0.334833; batch adversarial loss: 0.361026\n",
      "epoch 125; iter: 0; batch classifier loss: 0.387697; batch adversarial loss: 0.369916\n",
      "epoch 126; iter: 0; batch classifier loss: 0.370820; batch adversarial loss: 0.377747\n",
      "epoch 127; iter: 0; batch classifier loss: 0.443854; batch adversarial loss: 0.288717\n",
      "epoch 128; iter: 0; batch classifier loss: 0.313416; batch adversarial loss: 0.220588\n",
      "epoch 129; iter: 0; batch classifier loss: 0.293323; batch adversarial loss: 0.338644\n",
      "epoch 130; iter: 0; batch classifier loss: 0.361933; batch adversarial loss: 0.167953\n",
      "epoch 131; iter: 0; batch classifier loss: 0.327587; batch adversarial loss: 0.324665\n",
      "epoch 132; iter: 0; batch classifier loss: 0.308757; batch adversarial loss: 0.346817\n",
      "epoch 133; iter: 0; batch classifier loss: 0.337895; batch adversarial loss: 0.316899\n",
      "epoch 134; iter: 0; batch classifier loss: 0.279410; batch adversarial loss: 0.221387\n",
      "epoch 135; iter: 0; batch classifier loss: 0.318634; batch adversarial loss: 0.357174\n",
      "epoch 136; iter: 0; batch classifier loss: 0.349031; batch adversarial loss: 0.270557\n",
      "epoch 137; iter: 0; batch classifier loss: 0.345258; batch adversarial loss: 0.305709\n",
      "epoch 138; iter: 0; batch classifier loss: 0.309640; batch adversarial loss: 0.264672\n",
      "epoch 139; iter: 0; batch classifier loss: 0.369686; batch adversarial loss: 0.272832\n",
      "epoch 140; iter: 0; batch classifier loss: 0.385055; batch adversarial loss: 0.295613\n",
      "epoch 141; iter: 0; batch classifier loss: 0.347680; batch adversarial loss: 0.300026\n",
      "epoch 142; iter: 0; batch classifier loss: 0.331375; batch adversarial loss: 0.191172\n",
      "epoch 143; iter: 0; batch classifier loss: 0.289828; batch adversarial loss: 0.300904\n",
      "epoch 144; iter: 0; batch classifier loss: 0.348794; batch adversarial loss: 0.254754\n",
      "epoch 145; iter: 0; batch classifier loss: 0.374068; batch adversarial loss: 0.343728\n",
      "epoch 146; iter: 0; batch classifier loss: 0.366744; batch adversarial loss: 0.227900\n",
      "epoch 147; iter: 0; batch classifier loss: 0.302236; batch adversarial loss: 0.166978\n",
      "epoch 148; iter: 0; batch classifier loss: 0.335929; batch adversarial loss: 0.346685\n",
      "epoch 149; iter: 0; batch classifier loss: 0.370137; batch adversarial loss: 0.244596\n",
      "epoch 150; iter: 0; batch classifier loss: 0.350130; batch adversarial loss: 0.323587\n",
      "epoch 151; iter: 0; batch classifier loss: 0.407730; batch adversarial loss: 0.275564\n",
      "epoch 152; iter: 0; batch classifier loss: 0.330893; batch adversarial loss: 0.293556\n",
      "epoch 153; iter: 0; batch classifier loss: 0.374456; batch adversarial loss: 0.321398\n",
      "epoch 154; iter: 0; batch classifier loss: 0.326009; batch adversarial loss: 0.329022\n",
      "epoch 155; iter: 0; batch classifier loss: 0.337273; batch adversarial loss: 0.167547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.369723; batch adversarial loss: 0.277988\n",
      "epoch 157; iter: 0; batch classifier loss: 0.313944; batch adversarial loss: 0.331808\n",
      "epoch 158; iter: 0; batch classifier loss: 0.304052; batch adversarial loss: 0.339123\n",
      "epoch 159; iter: 0; batch classifier loss: 0.278956; batch adversarial loss: 0.314262\n",
      "epoch 160; iter: 0; batch classifier loss: 0.320396; batch adversarial loss: 0.290735\n",
      "epoch 161; iter: 0; batch classifier loss: 0.361238; batch adversarial loss: 0.218671\n",
      "epoch 162; iter: 0; batch classifier loss: 0.255604; batch adversarial loss: 0.208180\n",
      "epoch 163; iter: 0; batch classifier loss: 0.258309; batch adversarial loss: 0.305965\n",
      "epoch 164; iter: 0; batch classifier loss: 0.336365; batch adversarial loss: 0.314227\n",
      "epoch 165; iter: 0; batch classifier loss: 0.375409; batch adversarial loss: 0.220847\n",
      "epoch 166; iter: 0; batch classifier loss: 0.361706; batch adversarial loss: 0.378131\n",
      "epoch 167; iter: 0; batch classifier loss: 0.332095; batch adversarial loss: 0.399385\n",
      "epoch 168; iter: 0; batch classifier loss: 0.313935; batch adversarial loss: 0.455464\n",
      "epoch 169; iter: 0; batch classifier loss: 0.292480; batch adversarial loss: 0.344397\n",
      "epoch 170; iter: 0; batch classifier loss: 0.315411; batch adversarial loss: 0.339895\n",
      "epoch 171; iter: 0; batch classifier loss: 0.392656; batch adversarial loss: 0.257534\n",
      "epoch 172; iter: 0; batch classifier loss: 0.286684; batch adversarial loss: 0.289863\n",
      "epoch 173; iter: 0; batch classifier loss: 0.334193; batch adversarial loss: 0.331322\n",
      "epoch 174; iter: 0; batch classifier loss: 0.355139; batch adversarial loss: 0.431963\n",
      "epoch 175; iter: 0; batch classifier loss: 0.302178; batch adversarial loss: 0.425470\n",
      "epoch 176; iter: 0; batch classifier loss: 0.363797; batch adversarial loss: 0.316273\n",
      "epoch 177; iter: 0; batch classifier loss: 0.306143; batch adversarial loss: 0.224023\n",
      "epoch 178; iter: 0; batch classifier loss: 0.317405; batch adversarial loss: 0.342072\n",
      "epoch 179; iter: 0; batch classifier loss: 0.282579; batch adversarial loss: 0.269983\n",
      "epoch 180; iter: 0; batch classifier loss: 0.287494; batch adversarial loss: 0.399905\n",
      "epoch 181; iter: 0; batch classifier loss: 0.274945; batch adversarial loss: 0.292541\n",
      "epoch 182; iter: 0; batch classifier loss: 0.339975; batch adversarial loss: 0.350308\n",
      "epoch 183; iter: 0; batch classifier loss: 0.243066; batch adversarial loss: 0.355523\n",
      "epoch 184; iter: 0; batch classifier loss: 0.364229; batch adversarial loss: 0.291115\n",
      "epoch 185; iter: 0; batch classifier loss: 0.377330; batch adversarial loss: 0.363377\n",
      "epoch 186; iter: 0; batch classifier loss: 0.314252; batch adversarial loss: 0.315333\n",
      "epoch 187; iter: 0; batch classifier loss: 0.346855; batch adversarial loss: 0.379191\n",
      "epoch 188; iter: 0; batch classifier loss: 0.273944; batch adversarial loss: 0.237324\n",
      "epoch 189; iter: 0; batch classifier loss: 0.348756; batch adversarial loss: 0.366430\n",
      "epoch 190; iter: 0; batch classifier loss: 0.238413; batch adversarial loss: 0.361672\n",
      "epoch 191; iter: 0; batch classifier loss: 0.311682; batch adversarial loss: 0.295324\n",
      "epoch 192; iter: 0; batch classifier loss: 0.295322; batch adversarial loss: 0.314345\n",
      "epoch 193; iter: 0; batch classifier loss: 0.259386; batch adversarial loss: 0.306144\n",
      "epoch 194; iter: 0; batch classifier loss: 0.371058; batch adversarial loss: 0.391493\n",
      "epoch 195; iter: 0; batch classifier loss: 0.310860; batch adversarial loss: 0.222044\n",
      "epoch 196; iter: 0; batch classifier loss: 0.300338; batch adversarial loss: 0.288179\n",
      "epoch 197; iter: 0; batch classifier loss: 0.331955; batch adversarial loss: 0.239903\n",
      "epoch 198; iter: 0; batch classifier loss: 0.334182; batch adversarial loss: 0.367032\n",
      "epoch 199; iter: 0; batch classifier loss: 0.258650; batch adversarial loss: 0.419329\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.246540; batch adversarial loss: 0.926150\n",
      "epoch 2; iter: 0; batch classifier loss: 1.130175; batch adversarial loss: 0.800001\n",
      "epoch 3; iter: 0; batch classifier loss: 0.883954; batch adversarial loss: 0.819219\n",
      "epoch 4; iter: 0; batch classifier loss: 0.817969; batch adversarial loss: 0.724629\n",
      "epoch 5; iter: 0; batch classifier loss: 0.679731; batch adversarial loss: 0.663907\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584621; batch adversarial loss: 0.636095\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580644; batch adversarial loss: 0.612476\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551275; batch adversarial loss: 0.601519\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540065; batch adversarial loss: 0.572989\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540307; batch adversarial loss: 0.582414\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568535; batch adversarial loss: 0.541355\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529495; batch adversarial loss: 0.534950\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532873; batch adversarial loss: 0.528838\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513062; batch adversarial loss: 0.493471\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525365; batch adversarial loss: 0.474384\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592357; batch adversarial loss: 0.456499\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506526; batch adversarial loss: 0.463716\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542694; batch adversarial loss: 0.454242\n",
      "epoch 19; iter: 0; batch classifier loss: 0.555755; batch adversarial loss: 0.462469\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523137; batch adversarial loss: 0.435214\n",
      "epoch 21; iter: 0; batch classifier loss: 0.546249; batch adversarial loss: 0.451249\n",
      "epoch 22; iter: 0; batch classifier loss: 0.581525; batch adversarial loss: 0.466843\n",
      "epoch 23; iter: 0; batch classifier loss: 0.532945; batch adversarial loss: 0.507020\n",
      "epoch 24; iter: 0; batch classifier loss: 0.584404; batch adversarial loss: 0.366783\n",
      "epoch 25; iter: 0; batch classifier loss: 0.558535; batch adversarial loss: 0.432389\n",
      "epoch 26; iter: 0; batch classifier loss: 0.650044; batch adversarial loss: 0.485350\n",
      "epoch 27; iter: 0; batch classifier loss: 0.699940; batch adversarial loss: 0.500628\n",
      "epoch 28; iter: 0; batch classifier loss: 0.612819; batch adversarial loss: 0.410472\n",
      "epoch 29; iter: 0; batch classifier loss: 0.530007; batch adversarial loss: 0.466556\n",
      "epoch 30; iter: 0; batch classifier loss: 0.551755; batch adversarial loss: 0.382188\n",
      "epoch 31; iter: 0; batch classifier loss: 0.602534; batch adversarial loss: 0.403534\n",
      "epoch 32; iter: 0; batch classifier loss: 0.631618; batch adversarial loss: 0.431089\n",
      "epoch 33; iter: 0; batch classifier loss: 0.593518; batch adversarial loss: 0.395616\n",
      "epoch 34; iter: 0; batch classifier loss: 0.543565; batch adversarial loss: 0.335756\n",
      "epoch 35; iter: 0; batch classifier loss: 0.664047; batch adversarial loss: 0.438423\n",
      "epoch 36; iter: 0; batch classifier loss: 0.551644; batch adversarial loss: 0.382099\n",
      "epoch 37; iter: 0; batch classifier loss: 0.591978; batch adversarial loss: 0.414457\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444361; batch adversarial loss: 0.343962\n",
      "epoch 39; iter: 0; batch classifier loss: 0.558278; batch adversarial loss: 0.320593\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522173; batch adversarial loss: 0.387648\n",
      "epoch 41; iter: 0; batch classifier loss: 0.592318; batch adversarial loss: 0.407196\n",
      "epoch 42; iter: 0; batch classifier loss: 0.497771; batch adversarial loss: 0.337711\n",
      "epoch 43; iter: 0; batch classifier loss: 0.539554; batch adversarial loss: 0.351624\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462608; batch adversarial loss: 0.315171\n",
      "epoch 45; iter: 0; batch classifier loss: 0.512199; batch adversarial loss: 0.340823\n",
      "epoch 46; iter: 0; batch classifier loss: 0.536217; batch adversarial loss: 0.301131\n",
      "epoch 47; iter: 0; batch classifier loss: 0.486817; batch adversarial loss: 0.268881\n",
      "epoch 48; iter: 0; batch classifier loss: 0.596368; batch adversarial loss: 0.383399\n",
      "epoch 49; iter: 0; batch classifier loss: 0.517218; batch adversarial loss: 0.368602\n",
      "epoch 50; iter: 0; batch classifier loss: 0.592483; batch adversarial loss: 0.313883\n",
      "epoch 51; iter: 0; batch classifier loss: 0.594297; batch adversarial loss: 0.364605\n",
      "epoch 52; iter: 0; batch classifier loss: 0.517621; batch adversarial loss: 0.282355\n",
      "epoch 53; iter: 0; batch classifier loss: 0.574129; batch adversarial loss: 0.399435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54; iter: 0; batch classifier loss: 0.613099; batch adversarial loss: 0.278373\n",
      "epoch 55; iter: 0; batch classifier loss: 0.465086; batch adversarial loss: 0.249704\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449950; batch adversarial loss: 0.352422\n",
      "epoch 57; iter: 0; batch classifier loss: 0.496943; batch adversarial loss: 0.352816\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425818; batch adversarial loss: 0.365704\n",
      "epoch 59; iter: 0; batch classifier loss: 0.466561; batch adversarial loss: 0.377541\n",
      "epoch 60; iter: 0; batch classifier loss: 0.472277; batch adversarial loss: 0.320040\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463788; batch adversarial loss: 0.248925\n",
      "epoch 62; iter: 0; batch classifier loss: 0.477686; batch adversarial loss: 0.303505\n",
      "epoch 63; iter: 0; batch classifier loss: 0.466812; batch adversarial loss: 0.404542\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358105; batch adversarial loss: 0.321206\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448005; batch adversarial loss: 0.257600\n",
      "epoch 66; iter: 0; batch classifier loss: 0.324545; batch adversarial loss: 0.330420\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409036; batch adversarial loss: 0.344092\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405352; batch adversarial loss: 0.343413\n",
      "epoch 69; iter: 0; batch classifier loss: 0.426952; batch adversarial loss: 0.280706\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422302; batch adversarial loss: 0.343265\n",
      "epoch 71; iter: 0; batch classifier loss: 0.485350; batch adversarial loss: 0.280087\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408163; batch adversarial loss: 0.286450\n",
      "epoch 73; iter: 0; batch classifier loss: 0.371186; batch adversarial loss: 0.287067\n",
      "epoch 74; iter: 0; batch classifier loss: 0.461139; batch adversarial loss: 0.364444\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352359; batch adversarial loss: 0.308400\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369988; batch adversarial loss: 0.314887\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423864; batch adversarial loss: 0.336685\n",
      "epoch 78; iter: 0; batch classifier loss: 0.351367; batch adversarial loss: 0.228283\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380396; batch adversarial loss: 0.367101\n",
      "epoch 80; iter: 0; batch classifier loss: 0.492146; batch adversarial loss: 0.418477\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421166; batch adversarial loss: 0.278216\n",
      "epoch 82; iter: 0; batch classifier loss: 0.467542; batch adversarial loss: 0.271739\n",
      "epoch 83; iter: 0; batch classifier loss: 0.387095; batch adversarial loss: 0.276681\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440924; batch adversarial loss: 0.268578\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393800; batch adversarial loss: 0.396858\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406571; batch adversarial loss: 0.297164\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371219; batch adversarial loss: 0.313138\n",
      "epoch 88; iter: 0; batch classifier loss: 0.428390; batch adversarial loss: 0.259476\n",
      "epoch 89; iter: 0; batch classifier loss: 0.381020; batch adversarial loss: 0.269905\n",
      "epoch 90; iter: 0; batch classifier loss: 0.459139; batch adversarial loss: 0.260163\n",
      "epoch 91; iter: 0; batch classifier loss: 0.413048; batch adversarial loss: 0.360093\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375057; batch adversarial loss: 0.242022\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347214; batch adversarial loss: 0.288215\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380154; batch adversarial loss: 0.285643\n",
      "epoch 95; iter: 0; batch classifier loss: 0.410940; batch adversarial loss: 0.294196\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377082; batch adversarial loss: 0.309272\n",
      "epoch 97; iter: 0; batch classifier loss: 0.370421; batch adversarial loss: 0.290252\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384239; batch adversarial loss: 0.254577\n",
      "epoch 99; iter: 0; batch classifier loss: 0.370436; batch adversarial loss: 0.227954\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.246396; batch adversarial loss: 0.926144\n",
      "epoch 2; iter: 0; batch classifier loss: 1.130200; batch adversarial loss: 0.799991\n",
      "epoch 3; iter: 0; batch classifier loss: 0.883969; batch adversarial loss: 0.819221\n",
      "epoch 4; iter: 0; batch classifier loss: 0.817921; batch adversarial loss: 0.724591\n",
      "epoch 5; iter: 0; batch classifier loss: 0.680059; batch adversarial loss: 0.663856\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584567; batch adversarial loss: 0.636168\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580751; batch adversarial loss: 0.612465\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551056; batch adversarial loss: 0.601563\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539945; batch adversarial loss: 0.573058\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540105; batch adversarial loss: 0.582469\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568665; batch adversarial loss: 0.541325\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529251; batch adversarial loss: 0.535007\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533036; batch adversarial loss: 0.528834\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513165; batch adversarial loss: 0.493438\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525301; batch adversarial loss: 0.474274\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592183; batch adversarial loss: 0.456566\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507383; batch adversarial loss: 0.463785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543812; batch adversarial loss: 0.454156\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554489; batch adversarial loss: 0.462696\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523793; batch adversarial loss: 0.435509\n",
      "epoch 21; iter: 0; batch classifier loss: 0.544241; batch adversarial loss: 0.451381\n",
      "epoch 22; iter: 0; batch classifier loss: 0.578534; batch adversarial loss: 0.466600\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531312; batch adversarial loss: 0.506495\n",
      "epoch 24; iter: 0; batch classifier loss: 0.584076; batch adversarial loss: 0.366470\n",
      "epoch 25; iter: 0; batch classifier loss: 0.557420; batch adversarial loss: 0.432205\n",
      "epoch 26; iter: 0; batch classifier loss: 0.645232; batch adversarial loss: 0.484696\n",
      "epoch 27; iter: 0; batch classifier loss: 0.701726; batch adversarial loss: 0.500444\n",
      "epoch 28; iter: 0; batch classifier loss: 0.614102; batch adversarial loss: 0.410726\n",
      "epoch 29; iter: 0; batch classifier loss: 0.529555; batch adversarial loss: 0.466368\n",
      "epoch 30; iter: 0; batch classifier loss: 0.551030; batch adversarial loss: 0.382095\n",
      "epoch 31; iter: 0; batch classifier loss: 0.602901; batch adversarial loss: 0.403506\n",
      "epoch 32; iter: 0; batch classifier loss: 0.633221; batch adversarial loss: 0.431133\n",
      "epoch 33; iter: 0; batch classifier loss: 0.590771; batch adversarial loss: 0.395682\n",
      "epoch 34; iter: 0; batch classifier loss: 0.543398; batch adversarial loss: 0.335687\n",
      "epoch 35; iter: 0; batch classifier loss: 0.668171; batch adversarial loss: 0.438544\n",
      "epoch 36; iter: 0; batch classifier loss: 0.549943; batch adversarial loss: 0.382168\n",
      "epoch 37; iter: 0; batch classifier loss: 0.592278; batch adversarial loss: 0.414565\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444465; batch adversarial loss: 0.344060\n",
      "epoch 39; iter: 0; batch classifier loss: 0.562020; batch adversarial loss: 0.320532\n",
      "epoch 40; iter: 0; batch classifier loss: 0.519115; batch adversarial loss: 0.387787\n",
      "epoch 41; iter: 0; batch classifier loss: 0.597539; batch adversarial loss: 0.407445\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496712; batch adversarial loss: 0.337696\n",
      "epoch 43; iter: 0; batch classifier loss: 0.542853; batch adversarial loss: 0.351545\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463737; batch adversarial loss: 0.315238\n",
      "epoch 45; iter: 0; batch classifier loss: 0.512963; batch adversarial loss: 0.340819\n",
      "epoch 46; iter: 0; batch classifier loss: 0.538596; batch adversarial loss: 0.301230\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487315; batch adversarial loss: 0.268908\n",
      "epoch 48; iter: 0; batch classifier loss: 0.594735; batch adversarial loss: 0.383324\n",
      "epoch 49; iter: 0; batch classifier loss: 0.523590; batch adversarial loss: 0.368638\n",
      "epoch 50; iter: 0; batch classifier loss: 0.590509; batch adversarial loss: 0.313953\n",
      "epoch 51; iter: 0; batch classifier loss: 0.593961; batch adversarial loss: 0.364658\n",
      "epoch 52; iter: 0; batch classifier loss: 0.517658; batch adversarial loss: 0.282343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.579863; batch adversarial loss: 0.399489\n",
      "epoch 54; iter: 0; batch classifier loss: 0.620212; batch adversarial loss: 0.278410\n",
      "epoch 55; iter: 0; batch classifier loss: 0.471171; batch adversarial loss: 0.249717\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448911; batch adversarial loss: 0.352391\n",
      "epoch 57; iter: 0; batch classifier loss: 0.494522; batch adversarial loss: 0.352778\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424606; batch adversarial loss: 0.365668\n",
      "epoch 59; iter: 0; batch classifier loss: 0.465940; batch adversarial loss: 0.377466\n",
      "epoch 60; iter: 0; batch classifier loss: 0.478266; batch adversarial loss: 0.320130\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459924; batch adversarial loss: 0.248962\n",
      "epoch 62; iter: 0; batch classifier loss: 0.478491; batch adversarial loss: 0.303543\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463993; batch adversarial loss: 0.404525\n",
      "epoch 64; iter: 0; batch classifier loss: 0.360951; batch adversarial loss: 0.321308\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448464; batch adversarial loss: 0.257580\n",
      "epoch 66; iter: 0; batch classifier loss: 0.319352; batch adversarial loss: 0.330513\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407577; batch adversarial loss: 0.344142\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404013; batch adversarial loss: 0.343526\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425149; batch adversarial loss: 0.280696\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421419; batch adversarial loss: 0.343273\n",
      "epoch 71; iter: 0; batch classifier loss: 0.484021; batch adversarial loss: 0.280023\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411703; batch adversarial loss: 0.286364\n",
      "epoch 73; iter: 0; batch classifier loss: 0.367775; batch adversarial loss: 0.287026\n",
      "epoch 74; iter: 0; batch classifier loss: 0.464954; batch adversarial loss: 0.364032\n",
      "epoch 75; iter: 0; batch classifier loss: 0.357059; batch adversarial loss: 0.308516\n",
      "epoch 76; iter: 0; batch classifier loss: 0.368192; batch adversarial loss: 0.314902\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425127; batch adversarial loss: 0.336638\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352134; batch adversarial loss: 0.228301\n",
      "epoch 79; iter: 0; batch classifier loss: 0.383410; batch adversarial loss: 0.366864\n",
      "epoch 80; iter: 0; batch classifier loss: 0.482259; batch adversarial loss: 0.418365\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414650; batch adversarial loss: 0.278411\n",
      "epoch 82; iter: 0; batch classifier loss: 0.466889; batch adversarial loss: 0.271566\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385594; batch adversarial loss: 0.276495\n",
      "epoch 84; iter: 0; batch classifier loss: 0.445684; batch adversarial loss: 0.268601\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389103; batch adversarial loss: 0.396956\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412285; batch adversarial loss: 0.297019\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377096; batch adversarial loss: 0.312654\n",
      "epoch 88; iter: 0; batch classifier loss: 0.416462; batch adversarial loss: 0.259606\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379414; batch adversarial loss: 0.269951\n",
      "epoch 90; iter: 0; batch classifier loss: 0.458037; batch adversarial loss: 0.260039\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410752; batch adversarial loss: 0.359773\n",
      "epoch 92; iter: 0; batch classifier loss: 0.372284; batch adversarial loss: 0.241835\n",
      "epoch 93; iter: 0; batch classifier loss: 0.336933; batch adversarial loss: 0.287995\n",
      "epoch 94; iter: 0; batch classifier loss: 0.376365; batch adversarial loss: 0.285284\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417349; batch adversarial loss: 0.294180\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380747; batch adversarial loss: 0.308953\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369505; batch adversarial loss: 0.289935\n",
      "epoch 98; iter: 0; batch classifier loss: 0.381620; batch adversarial loss: 0.254585\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367181; batch adversarial loss: 0.227574\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.249751; batch adversarial loss: 0.926236\n",
      "epoch 2; iter: 0; batch classifier loss: 1.131906; batch adversarial loss: 0.800067\n",
      "epoch 3; iter: 0; batch classifier loss: 0.885616; batch adversarial loss: 0.819376\n",
      "epoch 4; iter: 0; batch classifier loss: 0.820904; batch adversarial loss: 0.724652\n",
      "epoch 5; iter: 0; batch classifier loss: 0.681101; batch adversarial loss: 0.663841\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585956; batch adversarial loss: 0.635840\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580929; batch adversarial loss: 0.612406\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551441; batch adversarial loss: 0.601537\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540304; batch adversarial loss: 0.572966\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540386; batch adversarial loss: 0.582394\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569160; batch adversarial loss: 0.541250\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528839; batch adversarial loss: 0.535036\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532880; batch adversarial loss: 0.528841\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513229; batch adversarial loss: 0.493506\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524714; batch adversarial loss: 0.474475\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592039; batch adversarial loss: 0.456578\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507891; batch adversarial loss: 0.463739\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542285; batch adversarial loss: 0.454315\n",
      "epoch 19; iter: 0; batch classifier loss: 0.555569; batch adversarial loss: 0.463017\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523972; batch adversarial loss: 0.436040\n",
      "epoch 21; iter: 0; batch classifier loss: 0.547118; batch adversarial loss: 0.451929\n",
      "epoch 22; iter: 0; batch classifier loss: 0.582063; batch adversarial loss: 0.467400\n",
      "epoch 23; iter: 0; batch classifier loss: 0.534460; batch adversarial loss: 0.507270\n",
      "epoch 24; iter: 0; batch classifier loss: 0.585341; batch adversarial loss: 0.366856\n",
      "epoch 25; iter: 0; batch classifier loss: 0.560494; batch adversarial loss: 0.432339\n",
      "epoch 26; iter: 0; batch classifier loss: 0.648416; batch adversarial loss: 0.485158\n",
      "epoch 27; iter: 0; batch classifier loss: 0.703449; batch adversarial loss: 0.500606\n",
      "epoch 28; iter: 0; batch classifier loss: 0.614757; batch adversarial loss: 0.410833\n",
      "epoch 29; iter: 0; batch classifier loss: 0.532460; batch adversarial loss: 0.466587\n",
      "epoch 30; iter: 0; batch classifier loss: 0.551993; batch adversarial loss: 0.382323\n",
      "epoch 31; iter: 0; batch classifier loss: 0.601769; batch adversarial loss: 0.403651\n",
      "epoch 32; iter: 0; batch classifier loss: 0.633136; batch adversarial loss: 0.431077\n",
      "epoch 33; iter: 0; batch classifier loss: 0.589921; batch adversarial loss: 0.395189\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544078; batch adversarial loss: 0.335671\n",
      "epoch 35; iter: 0; batch classifier loss: 0.670066; batch adversarial loss: 0.438201\n",
      "epoch 36; iter: 0; batch classifier loss: 0.549364; batch adversarial loss: 0.382056\n",
      "epoch 37; iter: 0; batch classifier loss: 0.594674; batch adversarial loss: 0.414458\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442736; batch adversarial loss: 0.343851\n",
      "epoch 39; iter: 0; batch classifier loss: 0.556034; batch adversarial loss: 0.320584\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522466; batch adversarial loss: 0.387639\n",
      "epoch 41; iter: 0; batch classifier loss: 0.592789; batch adversarial loss: 0.407354\n",
      "epoch 42; iter: 0; batch classifier loss: 0.499071; batch adversarial loss: 0.337661\n",
      "epoch 43; iter: 0; batch classifier loss: 0.541461; batch adversarial loss: 0.351635\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464983; batch adversarial loss: 0.315007\n",
      "epoch 45; iter: 0; batch classifier loss: 0.511293; batch adversarial loss: 0.340662\n",
      "epoch 46; iter: 0; batch classifier loss: 0.536735; batch adversarial loss: 0.301103\n",
      "epoch 47; iter: 0; batch classifier loss: 0.488893; batch adversarial loss: 0.268764\n",
      "epoch 48; iter: 0; batch classifier loss: 0.593840; batch adversarial loss: 0.383347\n",
      "epoch 49; iter: 0; batch classifier loss: 0.520154; batch adversarial loss: 0.368768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.588002; batch adversarial loss: 0.313930\n",
      "epoch 51; iter: 0; batch classifier loss: 0.593314; batch adversarial loss: 0.364542\n",
      "epoch 52; iter: 0; batch classifier loss: 0.521913; batch adversarial loss: 0.282335\n",
      "epoch 53; iter: 0; batch classifier loss: 0.580558; batch adversarial loss: 0.399286\n",
      "epoch 54; iter: 0; batch classifier loss: 0.621734; batch adversarial loss: 0.278318\n",
      "epoch 55; iter: 0; batch classifier loss: 0.464082; batch adversarial loss: 0.249651\n",
      "epoch 56; iter: 0; batch classifier loss: 0.446569; batch adversarial loss: 0.352355\n",
      "epoch 57; iter: 0; batch classifier loss: 0.495511; batch adversarial loss: 0.352797\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424789; batch adversarial loss: 0.365647\n",
      "epoch 59; iter: 0; batch classifier loss: 0.464005; batch adversarial loss: 0.377488\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481804; batch adversarial loss: 0.320072\n",
      "epoch 61; iter: 0; batch classifier loss: 0.467952; batch adversarial loss: 0.248969\n",
      "epoch 62; iter: 0; batch classifier loss: 0.475337; batch adversarial loss: 0.303466\n",
      "epoch 63; iter: 0; batch classifier loss: 0.461738; batch adversarial loss: 0.404516\n",
      "epoch 64; iter: 0; batch classifier loss: 0.361769; batch adversarial loss: 0.321238\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443840; batch adversarial loss: 0.257559\n",
      "epoch 66; iter: 0; batch classifier loss: 0.318406; batch adversarial loss: 0.330434\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409079; batch adversarial loss: 0.344253\n",
      "epoch 68; iter: 0; batch classifier loss: 0.409445; batch adversarial loss: 0.343472\n",
      "epoch 69; iter: 0; batch classifier loss: 0.424081; batch adversarial loss: 0.280729\n",
      "epoch 70; iter: 0; batch classifier loss: 0.424438; batch adversarial loss: 0.343309\n",
      "epoch 71; iter: 0; batch classifier loss: 0.480527; batch adversarial loss: 0.279887\n",
      "epoch 72; iter: 0; batch classifier loss: 0.410932; batch adversarial loss: 0.286612\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369620; batch adversarial loss: 0.287003\n",
      "epoch 74; iter: 0; batch classifier loss: 0.466445; batch adversarial loss: 0.364202\n",
      "epoch 75; iter: 0; batch classifier loss: 0.355467; batch adversarial loss: 0.308463\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369110; batch adversarial loss: 0.314869\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416714; batch adversarial loss: 0.336568\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358411; batch adversarial loss: 0.228328\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381455; batch adversarial loss: 0.366894\n",
      "epoch 80; iter: 0; batch classifier loss: 0.490830; batch adversarial loss: 0.418141\n",
      "epoch 81; iter: 0; batch classifier loss: 0.418249; batch adversarial loss: 0.278343\n",
      "epoch 82; iter: 0; batch classifier loss: 0.464916; batch adversarial loss: 0.271703\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381177; batch adversarial loss: 0.276335\n",
      "epoch 84; iter: 0; batch classifier loss: 0.448109; batch adversarial loss: 0.268563\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396313; batch adversarial loss: 0.396574\n",
      "epoch 86; iter: 0; batch classifier loss: 0.411327; batch adversarial loss: 0.297027\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372978; batch adversarial loss: 0.312857\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425257; batch adversarial loss: 0.259361\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389642; batch adversarial loss: 0.270021\n",
      "epoch 90; iter: 0; batch classifier loss: 0.456524; batch adversarial loss: 0.260180\n",
      "epoch 91; iter: 0; batch classifier loss: 0.417383; batch adversarial loss: 0.359912\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376450; batch adversarial loss: 0.241749\n",
      "epoch 93; iter: 0; batch classifier loss: 0.343021; batch adversarial loss: 0.288403\n",
      "epoch 94; iter: 0; batch classifier loss: 0.377975; batch adversarial loss: 0.285456\n",
      "epoch 95; iter: 0; batch classifier loss: 0.412460; batch adversarial loss: 0.293879\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377544; batch adversarial loss: 0.309015\n",
      "epoch 97; iter: 0; batch classifier loss: 0.368389; batch adversarial loss: 0.290326\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382874; batch adversarial loss: 0.254568\n",
      "epoch 99; iter: 0; batch classifier loss: 0.365026; batch adversarial loss: 0.227891\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.254010; batch adversarial loss: 0.926402\n",
      "epoch 2; iter: 0; batch classifier loss: 1.135485; batch adversarial loss: 0.800229\n",
      "epoch 3; iter: 0; batch classifier loss: 0.888880; batch adversarial loss: 0.819678\n",
      "epoch 4; iter: 0; batch classifier loss: 0.825098; batch adversarial loss: 0.724971\n",
      "epoch 5; iter: 0; batch classifier loss: 0.684956; batch adversarial loss: 0.664400\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585832; batch adversarial loss: 0.635956\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580630; batch adversarial loss: 0.612453\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551754; batch adversarial loss: 0.601441\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540194; batch adversarial loss: 0.572890\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540430; batch adversarial loss: 0.582266\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568471; batch adversarial loss: 0.541227\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528162; batch adversarial loss: 0.535026\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532374; batch adversarial loss: 0.528888\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512218; batch adversarial loss: 0.493683\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524839; batch adversarial loss: 0.474546\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591744; batch adversarial loss: 0.456771\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508061; batch adversarial loss: 0.463978\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542282; batch adversarial loss: 0.454412\n",
      "epoch 19; iter: 0; batch classifier loss: 0.559408; batch adversarial loss: 0.464083\n",
      "epoch 20; iter: 0; batch classifier loss: 0.526528; batch adversarial loss: 0.437115\n",
      "epoch 21; iter: 0; batch classifier loss: 0.548688; batch adversarial loss: 0.452574\n",
      "epoch 22; iter: 0; batch classifier loss: 0.584071; batch adversarial loss: 0.468034\n",
      "epoch 23; iter: 0; batch classifier loss: 0.535086; batch adversarial loss: 0.507175\n",
      "epoch 24; iter: 0; batch classifier loss: 0.585994; batch adversarial loss: 0.366833\n",
      "epoch 25; iter: 0; batch classifier loss: 0.561972; batch adversarial loss: 0.432765\n",
      "epoch 26; iter: 0; batch classifier loss: 0.654194; batch adversarial loss: 0.485457\n",
      "epoch 27; iter: 0; batch classifier loss: 0.707919; batch adversarial loss: 0.500645\n",
      "epoch 28; iter: 0; batch classifier loss: 0.615136; batch adversarial loss: 0.410498\n",
      "epoch 29; iter: 0; batch classifier loss: 0.531545; batch adversarial loss: 0.466357\n",
      "epoch 30; iter: 0; batch classifier loss: 0.551173; batch adversarial loss: 0.382206\n",
      "epoch 31; iter: 0; batch classifier loss: 0.604173; batch adversarial loss: 0.403605\n",
      "epoch 32; iter: 0; batch classifier loss: 0.631680; batch adversarial loss: 0.430679\n",
      "epoch 33; iter: 0; batch classifier loss: 0.589676; batch adversarial loss: 0.395187\n",
      "epoch 34; iter: 0; batch classifier loss: 0.542677; batch adversarial loss: 0.335456\n",
      "epoch 35; iter: 0; batch classifier loss: 0.669186; batch adversarial loss: 0.438452\n",
      "epoch 36; iter: 0; batch classifier loss: 0.547797; batch adversarial loss: 0.381916\n",
      "epoch 37; iter: 0; batch classifier loss: 0.591496; batch adversarial loss: 0.414344\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446548; batch adversarial loss: 0.343949\n",
      "epoch 39; iter: 0; batch classifier loss: 0.561748; batch adversarial loss: 0.320250\n",
      "epoch 40; iter: 0; batch classifier loss: 0.520214; batch adversarial loss: 0.387129\n",
      "epoch 41; iter: 0; batch classifier loss: 0.593214; batch adversarial loss: 0.406931\n",
      "epoch 42; iter: 0; batch classifier loss: 0.495727; batch adversarial loss: 0.337492\n",
      "epoch 43; iter: 0; batch classifier loss: 0.539886; batch adversarial loss: 0.351224\n",
      "epoch 44; iter: 0; batch classifier loss: 0.465247; batch adversarial loss: 0.314960\n",
      "epoch 45; iter: 0; batch classifier loss: 0.513396; batch adversarial loss: 0.340657\n",
      "epoch 46; iter: 0; batch classifier loss: 0.536307; batch adversarial loss: 0.301147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.486898; batch adversarial loss: 0.268708\n",
      "epoch 48; iter: 0; batch classifier loss: 0.597550; batch adversarial loss: 0.383167\n",
      "epoch 49; iter: 0; batch classifier loss: 0.519904; batch adversarial loss: 0.368588\n",
      "epoch 50; iter: 0; batch classifier loss: 0.591582; batch adversarial loss: 0.314020\n",
      "epoch 51; iter: 0; batch classifier loss: 0.599522; batch adversarial loss: 0.364545\n",
      "epoch 52; iter: 0; batch classifier loss: 0.518604; batch adversarial loss: 0.282315\n",
      "epoch 53; iter: 0; batch classifier loss: 0.577339; batch adversarial loss: 0.399232\n",
      "epoch 54; iter: 0; batch classifier loss: 0.632437; batch adversarial loss: 0.278314\n",
      "epoch 55; iter: 0; batch classifier loss: 0.465726; batch adversarial loss: 0.249624\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451460; batch adversarial loss: 0.352324\n",
      "epoch 57; iter: 0; batch classifier loss: 0.494019; batch adversarial loss: 0.352749\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426806; batch adversarial loss: 0.365750\n",
      "epoch 59; iter: 0; batch classifier loss: 0.468437; batch adversarial loss: 0.377486\n",
      "epoch 60; iter: 0; batch classifier loss: 0.487628; batch adversarial loss: 0.320162\n",
      "epoch 61; iter: 0; batch classifier loss: 0.463869; batch adversarial loss: 0.248914\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479994; batch adversarial loss: 0.303489\n",
      "epoch 63; iter: 0; batch classifier loss: 0.468033; batch adversarial loss: 0.404551\n",
      "epoch 64; iter: 0; batch classifier loss: 0.359974; batch adversarial loss: 0.321221\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447908; batch adversarial loss: 0.257571\n",
      "epoch 66; iter: 0; batch classifier loss: 0.322698; batch adversarial loss: 0.330517\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410870; batch adversarial loss: 0.344188\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406627; batch adversarial loss: 0.343328\n",
      "epoch 69; iter: 0; batch classifier loss: 0.428047; batch adversarial loss: 0.280785\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422818; batch adversarial loss: 0.343361\n",
      "epoch 71; iter: 0; batch classifier loss: 0.488773; batch adversarial loss: 0.279996\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413428; batch adversarial loss: 0.286333\n",
      "epoch 73; iter: 0; batch classifier loss: 0.370173; batch adversarial loss: 0.287260\n",
      "epoch 74; iter: 0; batch classifier loss: 0.468317; batch adversarial loss: 0.363841\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352199; batch adversarial loss: 0.308457\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364890; batch adversarial loss: 0.314807\n",
      "epoch 77; iter: 0; batch classifier loss: 0.420276; batch adversarial loss: 0.336593\n",
      "epoch 78; iter: 0; batch classifier loss: 0.357210; batch adversarial loss: 0.228522\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384840; batch adversarial loss: 0.366809\n",
      "epoch 80; iter: 0; batch classifier loss: 0.487688; batch adversarial loss: 0.418524\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424651; batch adversarial loss: 0.278120\n",
      "epoch 82; iter: 0; batch classifier loss: 0.460663; batch adversarial loss: 0.271495\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385539; batch adversarial loss: 0.276574\n",
      "epoch 84; iter: 0; batch classifier loss: 0.448120; batch adversarial loss: 0.268503\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393425; batch adversarial loss: 0.396515\n",
      "epoch 86; iter: 0; batch classifier loss: 0.404394; batch adversarial loss: 0.297020\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373755; batch adversarial loss: 0.312953\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417669; batch adversarial loss: 0.259117\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387852; batch adversarial loss: 0.270059\n",
      "epoch 90; iter: 0; batch classifier loss: 0.451884; batch adversarial loss: 0.260004\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409655; batch adversarial loss: 0.359746\n",
      "epoch 92; iter: 0; batch classifier loss: 0.378500; batch adversarial loss: 0.241713\n",
      "epoch 93; iter: 0; batch classifier loss: 0.336101; batch adversarial loss: 0.288402\n",
      "epoch 94; iter: 0; batch classifier loss: 0.380653; batch adversarial loss: 0.285164\n",
      "epoch 95; iter: 0; batch classifier loss: 0.418827; batch adversarial loss: 0.294023\n",
      "epoch 96; iter: 0; batch classifier loss: 0.383252; batch adversarial loss: 0.308986\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369844; batch adversarial loss: 0.290290\n",
      "epoch 98; iter: 0; batch classifier loss: 0.373147; batch adversarial loss: 0.254317\n",
      "epoch 99; iter: 0; batch classifier loss: 0.368028; batch adversarial loss: 0.227626\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.185751; batch adversarial loss: 0.923775\n",
      "epoch 2; iter: 0; batch classifier loss: 1.085981; batch adversarial loss: 0.797887\n",
      "epoch 3; iter: 0; batch classifier loss: 0.846852; batch adversarial loss: 0.815799\n",
      "epoch 4; iter: 0; batch classifier loss: 0.775439; batch adversarial loss: 0.720420\n",
      "epoch 5; iter: 0; batch classifier loss: 0.648157; batch adversarial loss: 0.659463\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577810; batch adversarial loss: 0.636350\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582439; batch adversarial loss: 0.612120\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551857; batch adversarial loss: 0.601781\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538807; batch adversarial loss: 0.573923\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544900; batch adversarial loss: 0.582772\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570860; batch adversarial loss: 0.542170\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532122; batch adversarial loss: 0.535709\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537491; batch adversarial loss: 0.529051\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521196; batch adversarial loss: 0.491780\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527552; batch adversarial loss: 0.472307\n",
      "epoch 16; iter: 0; batch classifier loss: 0.593137; batch adversarial loss: 0.454685\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505485; batch adversarial loss: 0.461094\n",
      "epoch 18; iter: 0; batch classifier loss: 0.547911; batch adversarial loss: 0.451875\n",
      "epoch 19; iter: 0; batch classifier loss: 0.538363; batch adversarial loss: 0.455511\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511310; batch adversarial loss: 0.426150\n",
      "epoch 21; iter: 0; batch classifier loss: 0.518378; batch adversarial loss: 0.440980\n",
      "epoch 22; iter: 0; batch classifier loss: 0.550238; batch adversarial loss: 0.455767\n",
      "epoch 23; iter: 0; batch classifier loss: 0.509968; batch adversarial loss: 0.501235\n",
      "epoch 24; iter: 0; batch classifier loss: 0.569708; batch adversarial loss: 0.363204\n",
      "epoch 25; iter: 0; batch classifier loss: 0.535763; batch adversarial loss: 0.426994\n",
      "epoch 26; iter: 0; batch classifier loss: 0.611201; batch adversarial loss: 0.479111\n",
      "epoch 27; iter: 0; batch classifier loss: 0.671672; batch adversarial loss: 0.498722\n",
      "epoch 28; iter: 0; batch classifier loss: 0.596543; batch adversarial loss: 0.409135\n",
      "epoch 29; iter: 0; batch classifier loss: 0.512232; batch adversarial loss: 0.466384\n",
      "epoch 30; iter: 0; batch classifier loss: 0.539429; batch adversarial loss: 0.381476\n",
      "epoch 31; iter: 0; batch classifier loss: 0.585858; batch adversarial loss: 0.403658\n",
      "epoch 32; iter: 0; batch classifier loss: 0.625668; batch adversarial loss: 0.432883\n",
      "epoch 33; iter: 0; batch classifier loss: 0.585189; batch adversarial loss: 0.395891\n",
      "epoch 34; iter: 0; batch classifier loss: 0.549612; batch adversarial loss: 0.335907\n",
      "epoch 35; iter: 0; batch classifier loss: 0.652098; batch adversarial loss: 0.441217\n",
      "epoch 36; iter: 0; batch classifier loss: 0.555651; batch adversarial loss: 0.384271\n",
      "epoch 37; iter: 0; batch classifier loss: 0.594257; batch adversarial loss: 0.417276\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444144; batch adversarial loss: 0.345090\n",
      "epoch 39; iter: 0; batch classifier loss: 0.560165; batch adversarial loss: 0.321533\n",
      "epoch 40; iter: 0; batch classifier loss: 0.516015; batch adversarial loss: 0.389457\n",
      "epoch 41; iter: 0; batch classifier loss: 0.594873; batch adversarial loss: 0.410299\n",
      "epoch 42; iter: 0; batch classifier loss: 0.499130; batch adversarial loss: 0.339364\n",
      "epoch 43; iter: 0; batch classifier loss: 0.535747; batch adversarial loss: 0.353360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.464110; batch adversarial loss: 0.316010\n",
      "epoch 45; iter: 0; batch classifier loss: 0.528891; batch adversarial loss: 0.342378\n",
      "epoch 46; iter: 0; batch classifier loss: 0.540142; batch adversarial loss: 0.302304\n",
      "epoch 47; iter: 0; batch classifier loss: 0.488503; batch adversarial loss: 0.269650\n",
      "epoch 48; iter: 0; batch classifier loss: 0.597594; batch adversarial loss: 0.385572\n",
      "epoch 49; iter: 0; batch classifier loss: 0.518995; batch adversarial loss: 0.370601\n",
      "epoch 50; iter: 0; batch classifier loss: 0.596675; batch adversarial loss: 0.315268\n",
      "epoch 51; iter: 0; batch classifier loss: 0.594268; batch adversarial loss: 0.366434\n",
      "epoch 52; iter: 0; batch classifier loss: 0.516516; batch adversarial loss: 0.282924\n",
      "epoch 53; iter: 0; batch classifier loss: 0.564306; batch adversarial loss: 0.401667\n",
      "epoch 54; iter: 0; batch classifier loss: 0.594839; batch adversarial loss: 0.279332\n",
      "epoch 55; iter: 0; batch classifier loss: 0.580086; batch adversarial loss: 0.251006\n",
      "epoch 56; iter: 0; batch classifier loss: 0.443799; batch adversarial loss: 0.352867\n",
      "epoch 57; iter: 0; batch classifier loss: 0.494457; batch adversarial loss: 0.352957\n",
      "epoch 58; iter: 0; batch classifier loss: 0.418676; batch adversarial loss: 0.366033\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462884; batch adversarial loss: 0.377689\n",
      "epoch 60; iter: 0; batch classifier loss: 0.474872; batch adversarial loss: 0.320147\n",
      "epoch 61; iter: 0; batch classifier loss: 0.455811; batch adversarial loss: 0.249355\n",
      "epoch 62; iter: 0; batch classifier loss: 0.485675; batch adversarial loss: 0.303736\n",
      "epoch 63; iter: 0; batch classifier loss: 0.461670; batch adversarial loss: 0.404436\n",
      "epoch 64; iter: 0; batch classifier loss: 0.360354; batch adversarial loss: 0.321414\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448863; batch adversarial loss: 0.257947\n",
      "epoch 66; iter: 0; batch classifier loss: 0.318241; batch adversarial loss: 0.330598\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406213; batch adversarial loss: 0.344346\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412366; batch adversarial loss: 0.343322\n",
      "epoch 69; iter: 0; batch classifier loss: 0.422330; batch adversarial loss: 0.280822\n",
      "epoch 70; iter: 0; batch classifier loss: 0.420519; batch adversarial loss: 0.343572\n",
      "epoch 71; iter: 0; batch classifier loss: 0.482871; batch adversarial loss: 0.279858\n",
      "epoch 72; iter: 0; batch classifier loss: 0.414598; batch adversarial loss: 0.286647\n",
      "epoch 73; iter: 0; batch classifier loss: 0.373075; batch adversarial loss: 0.287446\n",
      "epoch 74; iter: 0; batch classifier loss: 0.447392; batch adversarial loss: 0.364023\n",
      "epoch 75; iter: 0; batch classifier loss: 0.350528; batch adversarial loss: 0.308399\n",
      "epoch 76; iter: 0; batch classifier loss: 0.365945; batch adversarial loss: 0.314855\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419031; batch adversarial loss: 0.336638\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352792; batch adversarial loss: 0.228232\n",
      "epoch 79; iter: 0; batch classifier loss: 0.377677; batch adversarial loss: 0.367168\n",
      "epoch 80; iter: 0; batch classifier loss: 0.469836; batch adversarial loss: 0.418322\n",
      "epoch 81; iter: 0; batch classifier loss: 0.421785; batch adversarial loss: 0.277695\n",
      "epoch 82; iter: 0; batch classifier loss: 0.451560; batch adversarial loss: 0.271874\n",
      "epoch 83; iter: 0; batch classifier loss: 0.388170; batch adversarial loss: 0.276647\n",
      "epoch 84; iter: 0; batch classifier loss: 0.439677; batch adversarial loss: 0.268662\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383589; batch adversarial loss: 0.396849\n",
      "epoch 86; iter: 0; batch classifier loss: 0.405811; batch adversarial loss: 0.297009\n",
      "epoch 87; iter: 0; batch classifier loss: 0.374399; batch adversarial loss: 0.312512\n",
      "epoch 88; iter: 0; batch classifier loss: 0.417837; batch adversarial loss: 0.259466\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385366; batch adversarial loss: 0.269799\n",
      "epoch 90; iter: 0; batch classifier loss: 0.451582; batch adversarial loss: 0.260057\n",
      "epoch 91; iter: 0; batch classifier loss: 0.401895; batch adversarial loss: 0.360118\n",
      "epoch 92; iter: 0; batch classifier loss: 0.375051; batch adversarial loss: 0.241401\n",
      "epoch 93; iter: 0; batch classifier loss: 0.354552; batch adversarial loss: 0.288230\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378095; batch adversarial loss: 0.285226\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402264; batch adversarial loss: 0.294405\n",
      "epoch 96; iter: 0; batch classifier loss: 0.369339; batch adversarial loss: 0.309349\n",
      "epoch 97; iter: 0; batch classifier loss: 0.364342; batch adversarial loss: 0.289241\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382677; batch adversarial loss: 0.254304\n",
      "epoch 99; iter: 0; batch classifier loss: 0.351279; batch adversarial loss: 0.227468\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.206482; batch adversarial loss: 0.924671\n",
      "epoch 2; iter: 0; batch classifier loss: 1.101243; batch adversarial loss: 0.798661\n",
      "epoch 3; iter: 0; batch classifier loss: 0.860046; batch adversarial loss: 0.817209\n",
      "epoch 4; iter: 0; batch classifier loss: 0.789759; batch adversarial loss: 0.722009\n",
      "epoch 5; iter: 0; batch classifier loss: 0.658236; batch adversarial loss: 0.661263\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579828; batch adversarial loss: 0.636184\n",
      "epoch 7; iter: 0; batch classifier loss: 0.581944; batch adversarial loss: 0.612216\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551813; batch adversarial loss: 0.601674\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539279; batch adversarial loss: 0.573624\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543441; batch adversarial loss: 0.582665\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569687; batch adversarial loss: 0.541935\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532511; batch adversarial loss: 0.535272\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534803; batch adversarial loss: 0.528913\n",
      "epoch 14; iter: 0; batch classifier loss: 0.517465; batch adversarial loss: 0.492369\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527523; batch adversarial loss: 0.472738\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592072; batch adversarial loss: 0.455488\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505166; batch adversarial loss: 0.462001\n",
      "epoch 18; iter: 0; batch classifier loss: 0.544973; batch adversarial loss: 0.453003\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542366; batch adversarial loss: 0.457695\n",
      "epoch 20; iter: 0; batch classifier loss: 0.514123; batch adversarial loss: 0.429181\n",
      "epoch 21; iter: 0; batch classifier loss: 0.527604; batch adversarial loss: 0.444377\n",
      "epoch 22; iter: 0; batch classifier loss: 0.560692; batch adversarial loss: 0.459332\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518186; batch adversarial loss: 0.504174\n",
      "epoch 24; iter: 0; batch classifier loss: 0.576749; batch adversarial loss: 0.364707\n",
      "epoch 25; iter: 0; batch classifier loss: 0.545149; batch adversarial loss: 0.429259\n",
      "epoch 26; iter: 0; batch classifier loss: 0.623051; batch adversarial loss: 0.481687\n",
      "epoch 27; iter: 0; batch classifier loss: 0.682342; batch adversarial loss: 0.499162\n",
      "epoch 28; iter: 0; batch classifier loss: 0.606600; batch adversarial loss: 0.410009\n",
      "epoch 29; iter: 0; batch classifier loss: 0.519812; batch adversarial loss: 0.466702\n",
      "epoch 30; iter: 0; batch classifier loss: 0.544279; batch adversarial loss: 0.381965\n",
      "epoch 31; iter: 0; batch classifier loss: 0.590898; batch adversarial loss: 0.403630\n",
      "epoch 32; iter: 0; batch classifier loss: 0.630976; batch adversarial loss: 0.432476\n",
      "epoch 33; iter: 0; batch classifier loss: 0.584489; batch adversarial loss: 0.395462\n",
      "epoch 34; iter: 0; batch classifier loss: 0.545249; batch adversarial loss: 0.336112\n",
      "epoch 35; iter: 0; batch classifier loss: 0.655201; batch adversarial loss: 0.440143\n",
      "epoch 36; iter: 0; batch classifier loss: 0.554071; batch adversarial loss: 0.383520\n",
      "epoch 37; iter: 0; batch classifier loss: 0.597707; batch adversarial loss: 0.416450\n",
      "epoch 38; iter: 0; batch classifier loss: 0.449600; batch adversarial loss: 0.344643\n",
      "epoch 39; iter: 0; batch classifier loss: 0.560948; batch adversarial loss: 0.321123\n",
      "epoch 40; iter: 0; batch classifier loss: 0.518714; batch adversarial loss: 0.388763\n",
      "epoch 41; iter: 0; batch classifier loss: 0.597281; batch adversarial loss: 0.409224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.496292; batch adversarial loss: 0.338458\n",
      "epoch 43; iter: 0; batch classifier loss: 0.533841; batch adversarial loss: 0.352574\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464455; batch adversarial loss: 0.315560\n",
      "epoch 45; iter: 0; batch classifier loss: 0.520219; batch adversarial loss: 0.341578\n",
      "epoch 46; iter: 0; batch classifier loss: 0.541694; batch adversarial loss: 0.301951\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484322; batch adversarial loss: 0.269324\n",
      "epoch 48; iter: 0; batch classifier loss: 0.602936; batch adversarial loss: 0.384817\n",
      "epoch 49; iter: 0; batch classifier loss: 0.519102; batch adversarial loss: 0.369963\n",
      "epoch 50; iter: 0; batch classifier loss: 0.593204; batch adversarial loss: 0.314852\n",
      "epoch 51; iter: 0; batch classifier loss: 0.594734; batch adversarial loss: 0.365725\n",
      "epoch 52; iter: 0; batch classifier loss: 0.520053; batch adversarial loss: 0.282772\n",
      "epoch 53; iter: 0; batch classifier loss: 0.562879; batch adversarial loss: 0.400703\n",
      "epoch 54; iter: 0; batch classifier loss: 0.602845; batch adversarial loss: 0.278973\n",
      "epoch 55; iter: 0; batch classifier loss: 0.558984; batch adversarial loss: 0.250537\n",
      "epoch 56; iter: 0; batch classifier loss: 0.443582; batch adversarial loss: 0.352700\n",
      "epoch 57; iter: 0; batch classifier loss: 0.495512; batch adversarial loss: 0.352915\n",
      "epoch 58; iter: 0; batch classifier loss: 0.421376; batch adversarial loss: 0.365888\n",
      "epoch 59; iter: 0; batch classifier loss: 0.465251; batch adversarial loss: 0.377524\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481400; batch adversarial loss: 0.320175\n",
      "epoch 61; iter: 0; batch classifier loss: 0.460812; batch adversarial loss: 0.249231\n",
      "epoch 62; iter: 0; batch classifier loss: 0.487440; batch adversarial loss: 0.303706\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465348; batch adversarial loss: 0.404401\n",
      "epoch 64; iter: 0; batch classifier loss: 0.361069; batch adversarial loss: 0.321323\n",
      "epoch 65; iter: 0; batch classifier loss: 0.443009; batch adversarial loss: 0.257760\n",
      "epoch 66; iter: 0; batch classifier loss: 0.317164; batch adversarial loss: 0.330622\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410196; batch adversarial loss: 0.344357\n",
      "epoch 68; iter: 0; batch classifier loss: 0.413088; batch adversarial loss: 0.343368\n",
      "epoch 69; iter: 0; batch classifier loss: 0.433282; batch adversarial loss: 0.280904\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418749; batch adversarial loss: 0.343346\n",
      "epoch 71; iter: 0; batch classifier loss: 0.481234; batch adversarial loss: 0.279984\n",
      "epoch 72; iter: 0; batch classifier loss: 0.413363; batch adversarial loss: 0.286507\n",
      "epoch 73; iter: 0; batch classifier loss: 0.369919; batch adversarial loss: 0.287435\n",
      "epoch 74; iter: 0; batch classifier loss: 0.447387; batch adversarial loss: 0.364428\n",
      "epoch 75; iter: 0; batch classifier loss: 0.353918; batch adversarial loss: 0.308419\n",
      "epoch 76; iter: 0; batch classifier loss: 0.363220; batch adversarial loss: 0.314928\n",
      "epoch 77; iter: 0; batch classifier loss: 0.408297; batch adversarial loss: 0.336628\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358536; batch adversarial loss: 0.228440\n",
      "epoch 79; iter: 0; batch classifier loss: 0.379162; batch adversarial loss: 0.367281\n",
      "epoch 80; iter: 0; batch classifier loss: 0.475746; batch adversarial loss: 0.418021\n",
      "epoch 81; iter: 0; batch classifier loss: 0.412009; batch adversarial loss: 0.277793\n",
      "epoch 82; iter: 0; batch classifier loss: 0.451876; batch adversarial loss: 0.271813\n",
      "epoch 83; iter: 0; batch classifier loss: 0.378935; batch adversarial loss: 0.276477\n",
      "epoch 84; iter: 0; batch classifier loss: 0.437581; batch adversarial loss: 0.268471\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385403; batch adversarial loss: 0.396720\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416332; batch adversarial loss: 0.296992\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380553; batch adversarial loss: 0.312440\n",
      "epoch 88; iter: 0; batch classifier loss: 0.418587; batch adversarial loss: 0.259160\n",
      "epoch 89; iter: 0; batch classifier loss: 0.384929; batch adversarial loss: 0.269945\n",
      "epoch 90; iter: 0; batch classifier loss: 0.459677; batch adversarial loss: 0.260224\n",
      "epoch 91; iter: 0; batch classifier loss: 0.412115; batch adversarial loss: 0.359739\n",
      "epoch 92; iter: 0; batch classifier loss: 0.374851; batch adversarial loss: 0.241690\n",
      "epoch 93; iter: 0; batch classifier loss: 0.341663; batch adversarial loss: 0.288312\n",
      "epoch 94; iter: 0; batch classifier loss: 0.372148; batch adversarial loss: 0.285402\n",
      "epoch 95; iter: 0; batch classifier loss: 0.402655; batch adversarial loss: 0.294057\n",
      "epoch 96; iter: 0; batch classifier loss: 0.377847; batch adversarial loss: 0.309288\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363026; batch adversarial loss: 0.290208\n",
      "epoch 98; iter: 0; batch classifier loss: 0.383056; batch adversarial loss: 0.254407\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361367; batch adversarial loss: 0.227739\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.244830; batch adversarial loss: 0.926088\n",
      "epoch 2; iter: 0; batch classifier loss: 1.129081; batch adversarial loss: 0.799925\n",
      "epoch 3; iter: 0; batch classifier loss: 0.882566; batch adversarial loss: 0.819083\n",
      "epoch 4; iter: 0; batch classifier loss: 0.816790; batch adversarial loss: 0.724527\n",
      "epoch 5; iter: 0; batch classifier loss: 0.678341; batch adversarial loss: 0.663637\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584411; batch adversarial loss: 0.636136\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580968; batch adversarial loss: 0.612449\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550972; batch adversarial loss: 0.601558\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539630; batch adversarial loss: 0.573091\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540079; batch adversarial loss: 0.582534\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568306; batch adversarial loss: 0.541411\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529733; batch adversarial loss: 0.534971\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533088; batch adversarial loss: 0.528793\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513197; batch adversarial loss: 0.493424\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525090; batch adversarial loss: 0.474189\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592007; batch adversarial loss: 0.456455\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507044; batch adversarial loss: 0.463740\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542453; batch adversarial loss: 0.454214\n",
      "epoch 19; iter: 0; batch classifier loss: 0.552962; batch adversarial loss: 0.462394\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523223; batch adversarial loss: 0.435002\n",
      "epoch 21; iter: 0; batch classifier loss: 0.542871; batch adversarial loss: 0.451063\n",
      "epoch 22; iter: 0; batch classifier loss: 0.579372; batch adversarial loss: 0.466191\n",
      "epoch 23; iter: 0; batch classifier loss: 0.530764; batch adversarial loss: 0.506580\n",
      "epoch 24; iter: 0; batch classifier loss: 0.584928; batch adversarial loss: 0.366562\n",
      "epoch 25; iter: 0; batch classifier loss: 0.556705; batch adversarial loss: 0.431829\n",
      "epoch 26; iter: 0; batch classifier loss: 0.647226; batch adversarial loss: 0.484929\n",
      "epoch 27; iter: 0; batch classifier loss: 0.697886; batch adversarial loss: 0.500338\n",
      "epoch 28; iter: 0; batch classifier loss: 0.611712; batch adversarial loss: 0.410377\n",
      "epoch 29; iter: 0; batch classifier loss: 0.529713; batch adversarial loss: 0.466302\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550024; batch adversarial loss: 0.382088\n",
      "epoch 31; iter: 0; batch classifier loss: 0.601335; batch adversarial loss: 0.403613\n",
      "epoch 32; iter: 0; batch classifier loss: 0.636113; batch adversarial loss: 0.431426\n",
      "epoch 33; iter: 0; batch classifier loss: 0.593822; batch adversarial loss: 0.395614\n",
      "epoch 34; iter: 0; batch classifier loss: 0.541590; batch adversarial loss: 0.335704\n",
      "epoch 35; iter: 0; batch classifier loss: 0.664210; batch adversarial loss: 0.438585\n",
      "epoch 36; iter: 0; batch classifier loss: 0.547843; batch adversarial loss: 0.382251\n",
      "epoch 37; iter: 0; batch classifier loss: 0.595055; batch adversarial loss: 0.414505\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443201; batch adversarial loss: 0.344037\n",
      "epoch 39; iter: 0; batch classifier loss: 0.559119; batch adversarial loss: 0.320643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.518072; batch adversarial loss: 0.387635\n",
      "epoch 41; iter: 0; batch classifier loss: 0.595384; batch adversarial loss: 0.407420\n",
      "epoch 42; iter: 0; batch classifier loss: 0.497245; batch adversarial loss: 0.337653\n",
      "epoch 43; iter: 0; batch classifier loss: 0.544975; batch adversarial loss: 0.351623\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462907; batch adversarial loss: 0.315212\n",
      "epoch 45; iter: 0; batch classifier loss: 0.512771; batch adversarial loss: 0.340835\n",
      "epoch 46; iter: 0; batch classifier loss: 0.537060; batch adversarial loss: 0.301181\n",
      "epoch 47; iter: 0; batch classifier loss: 0.493275; batch adversarial loss: 0.269047\n",
      "epoch 48; iter: 0; batch classifier loss: 0.600531; batch adversarial loss: 0.383566\n",
      "epoch 49; iter: 0; batch classifier loss: 0.520386; batch adversarial loss: 0.368835\n",
      "epoch 50; iter: 0; batch classifier loss: 0.587355; batch adversarial loss: 0.313965\n",
      "epoch 51; iter: 0; batch classifier loss: 0.595398; batch adversarial loss: 0.364677\n",
      "epoch 52; iter: 0; batch classifier loss: 0.519754; batch adversarial loss: 0.282410\n",
      "epoch 53; iter: 0; batch classifier loss: 0.570512; batch adversarial loss: 0.399388\n",
      "epoch 54; iter: 0; batch classifier loss: 0.620746; batch adversarial loss: 0.278413\n",
      "epoch 55; iter: 0; batch classifier loss: 0.466686; batch adversarial loss: 0.249739\n",
      "epoch 56; iter: 0; batch classifier loss: 0.456337; batch adversarial loss: 0.352413\n",
      "epoch 57; iter: 0; batch classifier loss: 0.495788; batch adversarial loss: 0.352723\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425331; batch adversarial loss: 0.365688\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467904; batch adversarial loss: 0.377489\n",
      "epoch 60; iter: 0; batch classifier loss: 0.484136; batch adversarial loss: 0.320104\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459396; batch adversarial loss: 0.248934\n",
      "epoch 62; iter: 0; batch classifier loss: 0.482002; batch adversarial loss: 0.303519\n",
      "epoch 63; iter: 0; batch classifier loss: 0.467330; batch adversarial loss: 0.404454\n",
      "epoch 64; iter: 0; batch classifier loss: 0.363559; batch adversarial loss: 0.321288\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447767; batch adversarial loss: 0.257601\n",
      "epoch 66; iter: 0; batch classifier loss: 0.320434; batch adversarial loss: 0.330426\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411566; batch adversarial loss: 0.344182\n",
      "epoch 68; iter: 0; batch classifier loss: 0.407234; batch adversarial loss: 0.343497\n",
      "epoch 69; iter: 0; batch classifier loss: 0.427497; batch adversarial loss: 0.280719\n",
      "epoch 70; iter: 0; batch classifier loss: 0.427534; batch adversarial loss: 0.343381\n",
      "epoch 71; iter: 0; batch classifier loss: 0.480737; batch adversarial loss: 0.279920\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408936; batch adversarial loss: 0.286427\n",
      "epoch 73; iter: 0; batch classifier loss: 0.370050; batch adversarial loss: 0.287128\n",
      "epoch 74; iter: 0; batch classifier loss: 0.461720; batch adversarial loss: 0.363953\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354821; batch adversarial loss: 0.308494\n",
      "epoch 76; iter: 0; batch classifier loss: 0.367223; batch adversarial loss: 0.314814\n",
      "epoch 77; iter: 0; batch classifier loss: 0.419727; batch adversarial loss: 0.336593\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352222; batch adversarial loss: 0.228239\n",
      "epoch 79; iter: 0; batch classifier loss: 0.385175; batch adversarial loss: 0.366958\n",
      "epoch 80; iter: 0; batch classifier loss: 0.489846; batch adversarial loss: 0.418089\n",
      "epoch 81; iter: 0; batch classifier loss: 0.408889; batch adversarial loss: 0.278358\n",
      "epoch 82; iter: 0; batch classifier loss: 0.462637; batch adversarial loss: 0.271640\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385862; batch adversarial loss: 0.276598\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440984; batch adversarial loss: 0.268557\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389073; batch adversarial loss: 0.396731\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412443; batch adversarial loss: 0.297053\n",
      "epoch 87; iter: 0; batch classifier loss: 0.374833; batch adversarial loss: 0.312610\n",
      "epoch 88; iter: 0; batch classifier loss: 0.413326; batch adversarial loss: 0.259235\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391726; batch adversarial loss: 0.269981\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443963; batch adversarial loss: 0.260031\n",
      "epoch 91; iter: 0; batch classifier loss: 0.408949; batch adversarial loss: 0.359987\n",
      "epoch 92; iter: 0; batch classifier loss: 0.371941; batch adversarial loss: 0.241613\n",
      "epoch 93; iter: 0; batch classifier loss: 0.343855; batch adversarial loss: 0.288193\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375733; batch adversarial loss: 0.285416\n",
      "epoch 95; iter: 0; batch classifier loss: 0.410778; batch adversarial loss: 0.294020\n",
      "epoch 96; iter: 0; batch classifier loss: 0.369649; batch adversarial loss: 0.309071\n",
      "epoch 97; iter: 0; batch classifier loss: 0.364861; batch adversarial loss: 0.290083\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382728; batch adversarial loss: 0.254484\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366200; batch adversarial loss: 0.228096\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.183951; batch adversarial loss: 0.923695\n",
      "epoch 2; iter: 0; batch classifier loss: 1.085073; batch adversarial loss: 0.797858\n",
      "epoch 3; iter: 0; batch classifier loss: 0.846106; batch adversarial loss: 0.815674\n",
      "epoch 4; iter: 0; batch classifier loss: 0.773880; batch adversarial loss: 0.720318\n",
      "epoch 5; iter: 0; batch classifier loss: 0.646869; batch adversarial loss: 0.659353\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577340; batch adversarial loss: 0.636468\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582619; batch adversarial loss: 0.612044\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551662; batch adversarial loss: 0.601819\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538591; batch adversarial loss: 0.573946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546003; batch adversarial loss: 0.582634\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571099; batch adversarial loss: 0.542156\n",
      "epoch 12; iter: 0; batch classifier loss: 0.533113; batch adversarial loss: 0.535565\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536775; batch adversarial loss: 0.529148\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521209; batch adversarial loss: 0.491778\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527965; batch adversarial loss: 0.472208\n",
      "epoch 16; iter: 0; batch classifier loss: 0.594126; batch adversarial loss: 0.454591\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506001; batch adversarial loss: 0.460819\n",
      "epoch 18; iter: 0; batch classifier loss: 0.546218; batch adversarial loss: 0.452225\n",
      "epoch 19; iter: 0; batch classifier loss: 0.538600; batch adversarial loss: 0.455207\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510155; batch adversarial loss: 0.425942\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520564; batch adversarial loss: 0.440678\n",
      "epoch 22; iter: 0; batch classifier loss: 0.552656; batch adversarial loss: 0.455293\n",
      "epoch 23; iter: 0; batch classifier loss: 0.509141; batch adversarial loss: 0.501683\n",
      "epoch 24; iter: 0; batch classifier loss: 0.568795; batch adversarial loss: 0.363394\n",
      "epoch 25; iter: 0; batch classifier loss: 0.536307; batch adversarial loss: 0.427236\n",
      "epoch 26; iter: 0; batch classifier loss: 0.608888; batch adversarial loss: 0.479118\n",
      "epoch 27; iter: 0; batch classifier loss: 0.670012; batch adversarial loss: 0.498291\n",
      "epoch 28; iter: 0; batch classifier loss: 0.601175; batch adversarial loss: 0.409068\n",
      "epoch 29; iter: 0; batch classifier loss: 0.514539; batch adversarial loss: 0.466693\n",
      "epoch 30; iter: 0; batch classifier loss: 0.540503; batch adversarial loss: 0.381360\n",
      "epoch 31; iter: 0; batch classifier loss: 0.584852; batch adversarial loss: 0.403580\n",
      "epoch 32; iter: 0; batch classifier loss: 0.627048; batch adversarial loss: 0.433045\n",
      "epoch 33; iter: 0; batch classifier loss: 0.584982; batch adversarial loss: 0.395445\n",
      "epoch 34; iter: 0; batch classifier loss: 0.546961; batch adversarial loss: 0.335979\n",
      "epoch 35; iter: 0; batch classifier loss: 0.650368; batch adversarial loss: 0.441070\n",
      "epoch 36; iter: 0; batch classifier loss: 0.552077; batch adversarial loss: 0.384201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37; iter: 0; batch classifier loss: 0.589217; batch adversarial loss: 0.416968\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447504; batch adversarial loss: 0.345220\n",
      "epoch 39; iter: 0; batch classifier loss: 0.558680; batch adversarial loss: 0.321600\n",
      "epoch 40; iter: 0; batch classifier loss: 0.516067; batch adversarial loss: 0.389722\n",
      "epoch 41; iter: 0; batch classifier loss: 0.599614; batch adversarial loss: 0.410428\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496509; batch adversarial loss: 0.339248\n",
      "epoch 43; iter: 0; batch classifier loss: 0.535870; batch adversarial loss: 0.353463\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468478; batch adversarial loss: 0.316169\n",
      "epoch 45; iter: 0; batch classifier loss: 0.524460; batch adversarial loss: 0.342377\n",
      "epoch 46; iter: 0; batch classifier loss: 0.542110; batch adversarial loss: 0.302198\n",
      "epoch 47; iter: 0; batch classifier loss: 0.486314; batch adversarial loss: 0.269527\n",
      "epoch 48; iter: 0; batch classifier loss: 0.605321; batch adversarial loss: 0.385894\n",
      "epoch 49; iter: 0; batch classifier loss: 0.522094; batch adversarial loss: 0.370793\n",
      "epoch 50; iter: 0; batch classifier loss: 0.592564; batch adversarial loss: 0.315335\n",
      "epoch 51; iter: 0; batch classifier loss: 0.592617; batch adversarial loss: 0.366474\n",
      "epoch 52; iter: 0; batch classifier loss: 0.516319; batch adversarial loss: 0.283020\n",
      "epoch 53; iter: 0; batch classifier loss: 0.562970; batch adversarial loss: 0.401625\n",
      "epoch 54; iter: 0; batch classifier loss: 0.595653; batch adversarial loss: 0.279309\n",
      "epoch 55; iter: 0; batch classifier loss: 0.583411; batch adversarial loss: 0.250988\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445415; batch adversarial loss: 0.352843\n",
      "epoch 57; iter: 0; batch classifier loss: 0.493843; batch adversarial loss: 0.352976\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426726; batch adversarial loss: 0.366008\n",
      "epoch 59; iter: 0; batch classifier loss: 0.463738; batch adversarial loss: 0.377593\n",
      "epoch 60; iter: 0; batch classifier loss: 0.481234; batch adversarial loss: 0.320220\n",
      "epoch 61; iter: 0; batch classifier loss: 0.454915; batch adversarial loss: 0.249324\n",
      "epoch 62; iter: 0; batch classifier loss: 0.491856; batch adversarial loss: 0.303772\n",
      "epoch 63; iter: 0; batch classifier loss: 0.460089; batch adversarial loss: 0.404393\n",
      "epoch 64; iter: 0; batch classifier loss: 0.362666; batch adversarial loss: 0.321447\n",
      "epoch 65; iter: 0; batch classifier loss: 0.444305; batch adversarial loss: 0.257873\n",
      "epoch 66; iter: 0; batch classifier loss: 0.321457; batch adversarial loss: 0.330586\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406046; batch adversarial loss: 0.344444\n",
      "epoch 68; iter: 0; batch classifier loss: 0.408153; batch adversarial loss: 0.343377\n",
      "epoch 69; iter: 0; batch classifier loss: 0.420459; batch adversarial loss: 0.280783\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419658; batch adversarial loss: 0.343427\n",
      "epoch 71; iter: 0; batch classifier loss: 0.477320; batch adversarial loss: 0.279982\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416038; batch adversarial loss: 0.286564\n",
      "epoch 73; iter: 0; batch classifier loss: 0.376074; batch adversarial loss: 0.287313\n",
      "epoch 74; iter: 0; batch classifier loss: 0.447099; batch adversarial loss: 0.364049\n",
      "epoch 75; iter: 0; batch classifier loss: 0.353059; batch adversarial loss: 0.308355\n",
      "epoch 76; iter: 0; batch classifier loss: 0.371706; batch adversarial loss: 0.314796\n",
      "epoch 77; iter: 0; batch classifier loss: 0.414239; batch adversarial loss: 0.336570\n",
      "epoch 78; iter: 0; batch classifier loss: 0.359810; batch adversarial loss: 0.228303\n",
      "epoch 79; iter: 0; batch classifier loss: 0.377856; batch adversarial loss: 0.367297\n",
      "epoch 80; iter: 0; batch classifier loss: 0.472657; batch adversarial loss: 0.418082\n",
      "epoch 81; iter: 0; batch classifier loss: 0.410444; batch adversarial loss: 0.277469\n",
      "epoch 82; iter: 0; batch classifier loss: 0.457843; batch adversarial loss: 0.271541\n",
      "epoch 83; iter: 0; batch classifier loss: 0.389014; batch adversarial loss: 0.276450\n",
      "epoch 84; iter: 0; batch classifier loss: 0.440265; batch adversarial loss: 0.268584\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389894; batch adversarial loss: 0.396638\n",
      "epoch 86; iter: 0; batch classifier loss: 0.409404; batch adversarial loss: 0.296964\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373921; batch adversarial loss: 0.312702\n",
      "epoch 88; iter: 0; batch classifier loss: 0.431531; batch adversarial loss: 0.259711\n",
      "epoch 89; iter: 0; batch classifier loss: 0.391713; batch adversarial loss: 0.269856\n",
      "epoch 90; iter: 0; batch classifier loss: 0.452287; batch adversarial loss: 0.260016\n",
      "epoch 91; iter: 0; batch classifier loss: 0.419394; batch adversarial loss: 0.360152\n",
      "epoch 92; iter: 0; batch classifier loss: 0.378879; batch adversarial loss: 0.241661\n",
      "epoch 93; iter: 0; batch classifier loss: 0.341027; batch adversarial loss: 0.288094\n",
      "epoch 94; iter: 0; batch classifier loss: 0.370043; batch adversarial loss: 0.285811\n",
      "epoch 95; iter: 0; batch classifier loss: 0.408483; batch adversarial loss: 0.294101\n",
      "epoch 96; iter: 0; batch classifier loss: 0.367594; batch adversarial loss: 0.309231\n",
      "epoch 97; iter: 0; batch classifier loss: 0.364130; batch adversarial loss: 0.289830\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387968; batch adversarial loss: 0.254358\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366989; batch adversarial loss: 0.227443\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697777; batch adversarial loss: 0.845058\n",
      "epoch 1; iter: 0; batch classifier loss: 0.928762; batch adversarial loss: 0.899783\n",
      "epoch 2; iter: 0; batch classifier loss: 0.887400; batch adversarial loss: 0.787687\n",
      "epoch 3; iter: 0; batch classifier loss: 0.693877; batch adversarial loss: 0.784969\n",
      "epoch 4; iter: 0; batch classifier loss: 0.611414; batch adversarial loss: 0.697889\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550390; batch adversarial loss: 0.648629\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552218; batch adversarial loss: 0.640304\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584265; batch adversarial loss: 0.612625\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560412; batch adversarial loss: 0.603120\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522898; batch adversarial loss: 0.580577\n",
      "epoch 10; iter: 0; batch classifier loss: 0.534601; batch adversarial loss: 0.585837\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560318; batch adversarial loss: 0.549302\n",
      "epoch 12; iter: 0; batch classifier loss: 0.515249; batch adversarial loss: 0.543666\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522790; batch adversarial loss: 0.538419\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478409; batch adversarial loss: 0.501133\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500834; batch adversarial loss: 0.477686\n",
      "epoch 16; iter: 0; batch classifier loss: 0.623859; batch adversarial loss: 0.447919\n",
      "epoch 17; iter: 0; batch classifier loss: 0.482179; batch adversarial loss: 0.454466\n",
      "epoch 18; iter: 0; batch classifier loss: 0.528968; batch adversarial loss: 0.447573\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492995; batch adversarial loss: 0.438581\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475672; batch adversarial loss: 0.414446\n",
      "epoch 21; iter: 0; batch classifier loss: 0.494871; batch adversarial loss: 0.423655\n",
      "epoch 22; iter: 0; batch classifier loss: 0.493100; batch adversarial loss: 0.429688\n",
      "epoch 23; iter: 0; batch classifier loss: 0.426743; batch adversarial loss: 0.458586\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465687; batch adversarial loss: 0.339734\n",
      "epoch 25; iter: 0; batch classifier loss: 0.480901; batch adversarial loss: 0.401321\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472920; batch adversarial loss: 0.444341\n",
      "epoch 27; iter: 0; batch classifier loss: 0.507281; batch adversarial loss: 0.478554\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483593; batch adversarial loss: 0.387748\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425371; batch adversarial loss: 0.444714\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455699; batch adversarial loss: 0.363956\n",
      "epoch 31; iter: 0; batch classifier loss: 0.465091; batch adversarial loss: 0.380890\n",
      "epoch 32; iter: 0; batch classifier loss: 0.476982; batch adversarial loss: 0.410204\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461463; batch adversarial loss: 0.370777\n",
      "epoch 34; iter: 0; batch classifier loss: 0.497637; batch adversarial loss: 0.325331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.499350; batch adversarial loss: 0.430766\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440004; batch adversarial loss: 0.371995\n",
      "epoch 37; iter: 0; batch classifier loss: 0.494954; batch adversarial loss: 0.407843\n",
      "epoch 38; iter: 0; batch classifier loss: 0.407271; batch adversarial loss: 0.343260\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460840; batch adversarial loss: 0.325402\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443486; batch adversarial loss: 0.394678\n",
      "epoch 41; iter: 0; batch classifier loss: 0.482512; batch adversarial loss: 0.415853\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433084; batch adversarial loss: 0.338543\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447627; batch adversarial loss: 0.365708\n",
      "epoch 44; iter: 0; batch classifier loss: 0.403770; batch adversarial loss: 0.317793\n",
      "epoch 45; iter: 0; batch classifier loss: 0.464916; batch adversarial loss: 0.351157\n",
      "epoch 46; iter: 0; batch classifier loss: 0.495227; batch adversarial loss: 0.307888\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439302; batch adversarial loss: 0.270585\n",
      "epoch 48; iter: 0; batch classifier loss: 0.571150; batch adversarial loss: 0.404114\n",
      "epoch 49; iter: 0; batch classifier loss: 0.467466; batch adversarial loss: 0.383178\n",
      "epoch 50; iter: 0; batch classifier loss: 0.503771; batch adversarial loss: 0.322236\n",
      "epoch 51; iter: 0; batch classifier loss: 0.486624; batch adversarial loss: 0.380246\n",
      "epoch 52; iter: 0; batch classifier loss: 0.388247; batch adversarial loss: 0.286802\n",
      "epoch 53; iter: 0; batch classifier loss: 0.507838; batch adversarial loss: 0.419604\n",
      "epoch 54; iter: 0; batch classifier loss: 0.474334; batch adversarial loss: 0.283933\n",
      "epoch 55; iter: 0; batch classifier loss: 0.445916; batch adversarial loss: 0.254867\n",
      "epoch 56; iter: 0; batch classifier loss: 0.503443; batch adversarial loss: 0.363628\n",
      "epoch 57; iter: 0; batch classifier loss: 0.552883; batch adversarial loss: 0.364330\n",
      "epoch 58; iter: 0; batch classifier loss: 0.493419; batch adversarial loss: 0.374912\n",
      "epoch 59; iter: 0; batch classifier loss: 0.494186; batch adversarial loss: 0.379970\n",
      "epoch 60; iter: 0; batch classifier loss: 0.356037; batch adversarial loss: 0.320756\n",
      "epoch 61; iter: 0; batch classifier loss: 0.371784; batch adversarial loss: 0.251706\n",
      "epoch 62; iter: 0; batch classifier loss: 0.397537; batch adversarial loss: 0.304812\n",
      "epoch 63; iter: 0; batch classifier loss: 0.338307; batch adversarial loss: 0.402964\n",
      "epoch 64; iter: 0; batch classifier loss: 0.330270; batch adversarial loss: 0.324053\n",
      "epoch 65; iter: 0; batch classifier loss: 0.330213; batch adversarial loss: 0.258278\n",
      "epoch 66; iter: 0; batch classifier loss: 0.283115; batch adversarial loss: 0.331105\n",
      "epoch 67; iter: 0; batch classifier loss: 0.332061; batch adversarial loss: 0.344137\n",
      "epoch 68; iter: 0; batch classifier loss: 0.339196; batch adversarial loss: 0.342067\n",
      "epoch 69; iter: 0; batch classifier loss: 0.367489; batch adversarial loss: 0.280446\n",
      "epoch 70; iter: 0; batch classifier loss: 0.327495; batch adversarial loss: 0.344201\n",
      "epoch 71; iter: 0; batch classifier loss: 0.357715; batch adversarial loss: 0.279743\n",
      "epoch 72; iter: 0; batch classifier loss: 0.362869; batch adversarial loss: 0.287885\n",
      "epoch 73; iter: 0; batch classifier loss: 0.280784; batch adversarial loss: 0.289550\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364426; batch adversarial loss: 0.366202\n",
      "epoch 75; iter: 0; batch classifier loss: 0.288805; batch adversarial loss: 0.307387\n",
      "epoch 76; iter: 0; batch classifier loss: 0.277518; batch adversarial loss: 0.315157\n",
      "epoch 77; iter: 0; batch classifier loss: 0.345597; batch adversarial loss: 0.333778\n",
      "epoch 78; iter: 0; batch classifier loss: 0.283581; batch adversarial loss: 0.228342\n",
      "epoch 79; iter: 0; batch classifier loss: 0.280721; batch adversarial loss: 0.369701\n",
      "epoch 80; iter: 0; batch classifier loss: 0.346937; batch adversarial loss: 0.418465\n",
      "epoch 81; iter: 0; batch classifier loss: 0.335779; batch adversarial loss: 0.279586\n",
      "epoch 82; iter: 0; batch classifier loss: 0.355643; batch adversarial loss: 0.270494\n",
      "epoch 83; iter: 0; batch classifier loss: 0.263206; batch adversarial loss: 0.277505\n",
      "epoch 84; iter: 0; batch classifier loss: 0.358825; batch adversarial loss: 0.271559\n",
      "epoch 85; iter: 0; batch classifier loss: 0.332671; batch adversarial loss: 0.397578\n",
      "epoch 86; iter: 0; batch classifier loss: 0.295447; batch adversarial loss: 0.295347\n",
      "epoch 87; iter: 0; batch classifier loss: 0.311298; batch adversarial loss: 0.315534\n",
      "epoch 88; iter: 0; batch classifier loss: 0.369915; batch adversarial loss: 0.262035\n",
      "epoch 89; iter: 0; batch classifier loss: 0.291638; batch adversarial loss: 0.267858\n",
      "epoch 90; iter: 0; batch classifier loss: 0.388333; batch adversarial loss: 0.257187\n",
      "epoch 91; iter: 0; batch classifier loss: 0.334176; batch adversarial loss: 0.358408\n",
      "epoch 92; iter: 0; batch classifier loss: 0.331812; batch adversarial loss: 0.241994\n",
      "epoch 93; iter: 0; batch classifier loss: 0.261526; batch adversarial loss: 0.289244\n",
      "epoch 94; iter: 0; batch classifier loss: 0.305331; batch adversarial loss: 0.287156\n",
      "epoch 95; iter: 0; batch classifier loss: 0.311023; batch adversarial loss: 0.295430\n",
      "epoch 96; iter: 0; batch classifier loss: 0.307150; batch adversarial loss: 0.308959\n",
      "epoch 97; iter: 0; batch classifier loss: 0.258823; batch adversarial loss: 0.290775\n",
      "epoch 98; iter: 0; batch classifier loss: 0.292918; batch adversarial loss: 0.254339\n",
      "epoch 99; iter: 0; batch classifier loss: 0.313548; batch adversarial loss: 0.228266\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.151523; batch adversarial loss: 0.922112\n",
      "epoch 2; iter: 0; batch classifier loss: 1.058616; batch adversarial loss: 0.796332\n",
      "epoch 3; iter: 0; batch classifier loss: 0.825135; batch adversarial loss: 0.813276\n",
      "epoch 4; iter: 0; batch classifier loss: 0.750417; batch adversarial loss: 0.717057\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633161; batch adversarial loss: 0.656778\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575751; batch adversarial loss: 0.636331\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584976; batch adversarial loss: 0.611780\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553853; batch adversarial loss: 0.601651\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538093; batch adversarial loss: 0.574492\n",
      "epoch 10; iter: 0; batch classifier loss: 0.548542; batch adversarial loss: 0.582795\n",
      "epoch 11; iter: 0; batch classifier loss: 0.572341; batch adversarial loss: 0.542619\n",
      "epoch 12; iter: 0; batch classifier loss: 0.534828; batch adversarial loss: 0.535986\n",
      "epoch 13; iter: 0; batch classifier loss: 0.538202; batch adversarial loss: 0.529748\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524918; batch adversarial loss: 0.491374\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531093; batch adversarial loss: 0.471106\n",
      "epoch 16; iter: 0; batch classifier loss: 0.595016; batch adversarial loss: 0.453514\n",
      "epoch 17; iter: 0; batch classifier loss: 0.504718; batch adversarial loss: 0.459731\n",
      "epoch 18; iter: 0; batch classifier loss: 0.548219; batch adversarial loss: 0.450769\n",
      "epoch 19; iter: 0; batch classifier loss: 0.533333; batch adversarial loss: 0.452435\n",
      "epoch 20; iter: 0; batch classifier loss: 0.508087; batch adversarial loss: 0.422684\n",
      "epoch 21; iter: 0; batch classifier loss: 0.513068; batch adversarial loss: 0.435620\n",
      "epoch 22; iter: 0; batch classifier loss: 0.541439; batch adversarial loss: 0.450983\n",
      "epoch 23; iter: 0; batch classifier loss: 0.498340; batch adversarial loss: 0.497296\n",
      "epoch 24; iter: 0; batch classifier loss: 0.563648; batch adversarial loss: 0.361135\n",
      "epoch 25; iter: 0; batch classifier loss: 0.524347; batch adversarial loss: 0.423647\n",
      "epoch 26; iter: 0; batch classifier loss: 0.591142; batch adversarial loss: 0.474306\n",
      "epoch 27; iter: 0; batch classifier loss: 0.657370; batch adversarial loss: 0.496520\n",
      "epoch 28; iter: 0; batch classifier loss: 0.589921; batch adversarial loss: 0.407155\n",
      "epoch 29; iter: 0; batch classifier loss: 0.505351; batch adversarial loss: 0.465461\n",
      "epoch 30; iter: 0; batch classifier loss: 0.533268; batch adversarial loss: 0.380544\n",
      "epoch 31; iter: 0; batch classifier loss: 0.571499; batch adversarial loss: 0.402372\n",
      "epoch 32; iter: 0; batch classifier loss: 0.613620; batch adversarial loss: 0.432900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.573413; batch adversarial loss: 0.394939\n",
      "epoch 34; iter: 0; batch classifier loss: 0.546626; batch adversarial loss: 0.336071\n",
      "epoch 35; iter: 0; batch classifier loss: 0.646876; batch adversarial loss: 0.442930\n",
      "epoch 36; iter: 0; batch classifier loss: 0.553368; batch adversarial loss: 0.385546\n",
      "epoch 37; iter: 0; batch classifier loss: 0.590598; batch adversarial loss: 0.418470\n",
      "epoch 38; iter: 0; batch classifier loss: 0.450011; batch adversarial loss: 0.346422\n",
      "epoch 39; iter: 0; batch classifier loss: 0.558748; batch adversarial loss: 0.321973\n",
      "epoch 40; iter: 0; batch classifier loss: 0.514622; batch adversarial loss: 0.390996\n",
      "epoch 41; iter: 0; batch classifier loss: 0.598908; batch adversarial loss: 0.412124\n",
      "epoch 42; iter: 0; batch classifier loss: 0.493474; batch adversarial loss: 0.339854\n",
      "epoch 43; iter: 0; batch classifier loss: 0.532608; batch adversarial loss: 0.354420\n",
      "epoch 44; iter: 0; batch classifier loss: 0.465739; batch adversarial loss: 0.316539\n",
      "epoch 45; iter: 0; batch classifier loss: 0.524450; batch adversarial loss: 0.343397\n",
      "epoch 46; iter: 0; batch classifier loss: 0.543872; batch adversarial loss: 0.303127\n",
      "epoch 47; iter: 0; batch classifier loss: 0.490221; batch adversarial loss: 0.269769\n",
      "epoch 48; iter: 0; batch classifier loss: 0.601952; batch adversarial loss: 0.387338\n",
      "epoch 49; iter: 0; batch classifier loss: 0.524930; batch adversarial loss: 0.372090\n",
      "epoch 50; iter: 0; batch classifier loss: 0.587083; batch adversarial loss: 0.316199\n",
      "epoch 51; iter: 0; batch classifier loss: 0.600982; batch adversarial loss: 0.367773\n",
      "epoch 52; iter: 0; batch classifier loss: 0.518822; batch adversarial loss: 0.283505\n",
      "epoch 53; iter: 0; batch classifier loss: 0.559798; batch adversarial loss: 0.403122\n",
      "epoch 54; iter: 0; batch classifier loss: 0.580523; batch adversarial loss: 0.279878\n",
      "epoch 55; iter: 0; batch classifier loss: 0.581624; batch adversarial loss: 0.251602\n",
      "epoch 56; iter: 0; batch classifier loss: 0.451338; batch adversarial loss: 0.352984\n",
      "epoch 57; iter: 0; batch classifier loss: 0.505723; batch adversarial loss: 0.353133\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427212; batch adversarial loss: 0.366108\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458012; batch adversarial loss: 0.377618\n",
      "epoch 60; iter: 0; batch classifier loss: 0.477278; batch adversarial loss: 0.320378\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459158; batch adversarial loss: 0.249614\n",
      "epoch 62; iter: 0; batch classifier loss: 0.480942; batch adversarial loss: 0.303921\n",
      "epoch 63; iter: 0; batch classifier loss: 0.459610; batch adversarial loss: 0.404468\n",
      "epoch 64; iter: 0; batch classifier loss: 0.360117; batch adversarial loss: 0.321649\n",
      "epoch 65; iter: 0; batch classifier loss: 0.445574; batch adversarial loss: 0.258059\n",
      "epoch 66; iter: 0; batch classifier loss: 0.317942; batch adversarial loss: 0.330709\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409576; batch adversarial loss: 0.344464\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400342; batch adversarial loss: 0.343149\n",
      "epoch 69; iter: 0; batch classifier loss: 0.418855; batch adversarial loss: 0.280837\n",
      "epoch 70; iter: 0; batch classifier loss: 0.417976; batch adversarial loss: 0.343624\n",
      "epoch 71; iter: 0; batch classifier loss: 0.473754; batch adversarial loss: 0.279977\n",
      "epoch 72; iter: 0; batch classifier loss: 0.424879; batch adversarial loss: 0.286546\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378988; batch adversarial loss: 0.287859\n",
      "epoch 74; iter: 0; batch classifier loss: 0.448852; batch adversarial loss: 0.364554\n",
      "epoch 75; iter: 0; batch classifier loss: 0.350536; batch adversarial loss: 0.308402\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366259; batch adversarial loss: 0.314960\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411501; batch adversarial loss: 0.336545\n",
      "epoch 78; iter: 0; batch classifier loss: 0.350244; batch adversarial loss: 0.228224\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369833; batch adversarial loss: 0.367588\n",
      "epoch 80; iter: 0; batch classifier loss: 0.476587; batch adversarial loss: 0.418790\n",
      "epoch 81; iter: 0; batch classifier loss: 0.401030; batch adversarial loss: 0.277900\n",
      "epoch 82; iter: 0; batch classifier loss: 0.451376; batch adversarial loss: 0.271393\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385469; batch adversarial loss: 0.276416\n",
      "epoch 84; iter: 0; batch classifier loss: 0.444488; batch adversarial loss: 0.268913\n",
      "epoch 85; iter: 0; batch classifier loss: 0.385605; batch adversarial loss: 0.396894\n",
      "epoch 86; iter: 0; batch classifier loss: 0.406581; batch adversarial loss: 0.297012\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377359; batch adversarial loss: 0.312645\n",
      "epoch 88; iter: 0; batch classifier loss: 0.428540; batch adversarial loss: 0.259272\n",
      "epoch 89; iter: 0; batch classifier loss: 0.387376; batch adversarial loss: 0.269754\n",
      "epoch 90; iter: 0; batch classifier loss: 0.447152; batch adversarial loss: 0.260272\n",
      "epoch 91; iter: 0; batch classifier loss: 0.414324; batch adversarial loss: 0.360710\n",
      "epoch 92; iter: 0; batch classifier loss: 0.370060; batch adversarial loss: 0.241799\n",
      "epoch 93; iter: 0; batch classifier loss: 0.344887; batch adversarial loss: 0.288214\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378058; batch adversarial loss: 0.285688\n",
      "epoch 95; iter: 0; batch classifier loss: 0.407306; batch adversarial loss: 0.294200\n",
      "epoch 96; iter: 0; batch classifier loss: 0.368395; batch adversarial loss: 0.309511\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376464; batch adversarial loss: 0.289858\n",
      "epoch 98; iter: 0; batch classifier loss: 0.385798; batch adversarial loss: 0.254018\n",
      "epoch 99; iter: 0; batch classifier loss: 0.355631; batch adversarial loss: 0.227798\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697777; batch adversarial loss: 0.845058\n",
      "epoch 1; iter: 0; batch classifier loss: 0.753894; batch adversarial loss: 0.852287\n",
      "epoch 2; iter: 0; batch classifier loss: 0.690117; batch adversarial loss: 0.752714\n",
      "epoch 3; iter: 0; batch classifier loss: 0.632248; batch adversarial loss: 0.725708\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607113; batch adversarial loss: 0.657948\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568173; batch adversarial loss: 0.636416\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564979; batch adversarial loss: 0.631818\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604357; batch adversarial loss: 0.604723\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583145; batch adversarial loss: 0.593015\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532456; batch adversarial loss: 0.576307\n",
      "epoch 10; iter: 0; batch classifier loss: 0.577191; batch adversarial loss: 0.574415\n",
      "epoch 11; iter: 0; batch classifier loss: 0.599743; batch adversarial loss: 0.539537\n",
      "epoch 12; iter: 0; batch classifier loss: 0.548193; batch adversarial loss: 0.537765\n",
      "epoch 13; iter: 0; batch classifier loss: 0.565013; batch adversarial loss: 0.531254\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483758; batch adversarial loss: 0.501203\n",
      "epoch 15; iter: 0; batch classifier loss: 0.533106; batch adversarial loss: 0.475940\n",
      "epoch 16; iter: 0; batch classifier loss: 0.626849; batch adversarial loss: 0.449210\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494368; batch adversarial loss: 0.451683\n",
      "epoch 18; iter: 0; batch classifier loss: 0.558514; batch adversarial loss: 0.433765\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497685; batch adversarial loss: 0.422915\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500420; batch adversarial loss: 0.391937\n",
      "epoch 21; iter: 0; batch classifier loss: 0.508755; batch adversarial loss: 0.400798\n",
      "epoch 22; iter: 0; batch classifier loss: 0.508245; batch adversarial loss: 0.402457\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443259; batch adversarial loss: 0.428698\n",
      "epoch 24; iter: 0; batch classifier loss: 0.461439; batch adversarial loss: 0.315252\n",
      "epoch 25; iter: 0; batch classifier loss: 0.485516; batch adversarial loss: 0.378074\n",
      "epoch 26; iter: 0; batch classifier loss: 0.457485; batch adversarial loss: 0.420751\n",
      "epoch 27; iter: 0; batch classifier loss: 0.455648; batch adversarial loss: 0.437542\n",
      "epoch 28; iter: 0; batch classifier loss: 0.465677; batch adversarial loss: 0.361837\n",
      "epoch 29; iter: 0; batch classifier loss: 0.387393; batch adversarial loss: 0.425511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.423401; batch adversarial loss: 0.347096\n",
      "epoch 31; iter: 0; batch classifier loss: 0.448096; batch adversarial loss: 0.360141\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442069; batch adversarial loss: 0.395705\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435766; batch adversarial loss: 0.352826\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471533; batch adversarial loss: 0.317064\n",
      "epoch 35; iter: 0; batch classifier loss: 0.459220; batch adversarial loss: 0.409153\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406140; batch adversarial loss: 0.358191\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461077; batch adversarial loss: 0.396210\n",
      "epoch 38; iter: 0; batch classifier loss: 0.380295; batch adversarial loss: 0.329909\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431784; batch adversarial loss: 0.321747\n",
      "epoch 40; iter: 0; batch classifier loss: 0.393428; batch adversarial loss: 0.388726\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410907; batch adversarial loss: 0.394429\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406824; batch adversarial loss: 0.333262\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413769; batch adversarial loss: 0.368153\n",
      "epoch 44; iter: 0; batch classifier loss: 0.359300; batch adversarial loss: 0.308070\n",
      "epoch 45; iter: 0; batch classifier loss: 0.401504; batch adversarial loss: 0.344289\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430494; batch adversarial loss: 0.299704\n",
      "epoch 47; iter: 0; batch classifier loss: 0.416665; batch adversarial loss: 0.258186\n",
      "epoch 48; iter: 0; batch classifier loss: 0.540144; batch adversarial loss: 0.421585\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417707; batch adversarial loss: 0.391779\n",
      "epoch 50; iter: 0; batch classifier loss: 0.467141; batch adversarial loss: 0.326878\n",
      "epoch 51; iter: 0; batch classifier loss: 0.429366; batch adversarial loss: 0.394310\n",
      "epoch 52; iter: 0; batch classifier loss: 0.383647; batch adversarial loss: 0.286704\n",
      "epoch 53; iter: 0; batch classifier loss: 0.441479; batch adversarial loss: 0.437901\n",
      "epoch 54; iter: 0; batch classifier loss: 0.423699; batch adversarial loss: 0.284084\n",
      "epoch 55; iter: 0; batch classifier loss: 0.394286; batch adversarial loss: 0.256013\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394538; batch adversarial loss: 0.367233\n",
      "epoch 57; iter: 0; batch classifier loss: 0.441218; batch adversarial loss: 0.379632\n",
      "epoch 58; iter: 0; batch classifier loss: 0.348999; batch adversarial loss: 0.397055\n",
      "epoch 59; iter: 0; batch classifier loss: 0.443388; batch adversarial loss: 0.400149\n",
      "epoch 60; iter: 0; batch classifier loss: 0.453670; batch adversarial loss: 0.336962\n",
      "epoch 61; iter: 0; batch classifier loss: 0.456070; batch adversarial loss: 0.262757\n",
      "epoch 62; iter: 0; batch classifier loss: 0.474282; batch adversarial loss: 0.317549\n",
      "epoch 63; iter: 0; batch classifier loss: 0.457049; batch adversarial loss: 0.422503\n",
      "epoch 64; iter: 0; batch classifier loss: 0.401889; batch adversarial loss: 0.338470\n",
      "epoch 65; iter: 0; batch classifier loss: 0.497892; batch adversarial loss: 0.268092\n",
      "epoch 66; iter: 0; batch classifier loss: 0.342645; batch adversarial loss: 0.334899\n",
      "epoch 67; iter: 0; batch classifier loss: 0.337126; batch adversarial loss: 0.345624\n",
      "epoch 68; iter: 0; batch classifier loss: 0.336931; batch adversarial loss: 0.343053\n",
      "epoch 69; iter: 0; batch classifier loss: 0.344788; batch adversarial loss: 0.282399\n",
      "epoch 70; iter: 0; batch classifier loss: 0.305667; batch adversarial loss: 0.344105\n",
      "epoch 71; iter: 0; batch classifier loss: 0.347211; batch adversarial loss: 0.280597\n",
      "epoch 72; iter: 0; batch classifier loss: 0.344853; batch adversarial loss: 0.289399\n",
      "epoch 73; iter: 0; batch classifier loss: 0.273507; batch adversarial loss: 0.291721\n",
      "epoch 74; iter: 0; batch classifier loss: 0.338594; batch adversarial loss: 0.366196\n",
      "epoch 75; iter: 0; batch classifier loss: 0.273742; batch adversarial loss: 0.305955\n",
      "epoch 76; iter: 0; batch classifier loss: 0.269249; batch adversarial loss: 0.316351\n",
      "epoch 77; iter: 0; batch classifier loss: 0.321927; batch adversarial loss: 0.332747\n",
      "epoch 78; iter: 0; batch classifier loss: 0.277539; batch adversarial loss: 0.228243\n",
      "epoch 79; iter: 0; batch classifier loss: 0.279560; batch adversarial loss: 0.370672\n",
      "epoch 80; iter: 0; batch classifier loss: 0.313293; batch adversarial loss: 0.419241\n",
      "epoch 81; iter: 0; batch classifier loss: 0.333347; batch adversarial loss: 0.279374\n",
      "epoch 82; iter: 0; batch classifier loss: 0.350561; batch adversarial loss: 0.269199\n",
      "epoch 83; iter: 0; batch classifier loss: 0.237696; batch adversarial loss: 0.277456\n",
      "epoch 84; iter: 0; batch classifier loss: 0.319766; batch adversarial loss: 0.274731\n",
      "epoch 85; iter: 0; batch classifier loss: 0.326085; batch adversarial loss: 0.398904\n",
      "epoch 86; iter: 0; batch classifier loss: 0.284003; batch adversarial loss: 0.293885\n",
      "epoch 87; iter: 0; batch classifier loss: 0.292336; batch adversarial loss: 0.317191\n",
      "epoch 88; iter: 0; batch classifier loss: 0.372977; batch adversarial loss: 0.262312\n",
      "epoch 89; iter: 0; batch classifier loss: 0.290318; batch adversarial loss: 0.267280\n",
      "epoch 90; iter: 0; batch classifier loss: 0.344732; batch adversarial loss: 0.257615\n",
      "epoch 91; iter: 0; batch classifier loss: 0.319732; batch adversarial loss: 0.356465\n",
      "epoch 92; iter: 0; batch classifier loss: 0.306666; batch adversarial loss: 0.242291\n",
      "epoch 93; iter: 0; batch classifier loss: 0.231308; batch adversarial loss: 0.288729\n",
      "epoch 94; iter: 0; batch classifier loss: 0.305664; batch adversarial loss: 0.288692\n",
      "epoch 95; iter: 0; batch classifier loss: 0.271167; batch adversarial loss: 0.295658\n",
      "epoch 96; iter: 0; batch classifier loss: 0.282607; batch adversarial loss: 0.308659\n",
      "epoch 97; iter: 0; batch classifier loss: 0.218258; batch adversarial loss: 0.290316\n",
      "epoch 98; iter: 0; batch classifier loss: 0.279487; batch adversarial loss: 0.251193\n",
      "epoch 99; iter: 0; batch classifier loss: 0.283213; batch adversarial loss: 0.228442\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.215696; batch adversarial loss: 0.925015\n",
      "epoch 2; iter: 0; batch classifier loss: 1.107993; batch adversarial loss: 0.798999\n",
      "epoch 3; iter: 0; batch classifier loss: 0.864966; batch adversarial loss: 0.817630\n",
      "epoch 4; iter: 0; batch classifier loss: 0.796652; batch adversarial loss: 0.722692\n",
      "epoch 5; iter: 0; batch classifier loss: 0.664011; batch adversarial loss: 0.661758\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581236; batch adversarial loss: 0.636067\n",
      "epoch 7; iter: 0; batch classifier loss: 0.581773; batch adversarial loss: 0.612256\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552015; batch adversarial loss: 0.601575\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539604; batch adversarial loss: 0.573411\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542570; batch adversarial loss: 0.582606\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569051; batch adversarial loss: 0.541804\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531425; batch adversarial loss: 0.535168\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534789; batch adversarial loss: 0.528794\n",
      "epoch 14; iter: 0; batch classifier loss: 0.517217; batch adversarial loss: 0.492512\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526678; batch adversarial loss: 0.473153\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591203; batch adversarial loss: 0.455687\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505002; batch adversarial loss: 0.462328\n",
      "epoch 18; iter: 0; batch classifier loss: 0.545514; batch adversarial loss: 0.453085\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543158; batch adversarial loss: 0.458675\n",
      "epoch 20; iter: 0; batch classifier loss: 0.515532; batch adversarial loss: 0.430199\n",
      "epoch 21; iter: 0; batch classifier loss: 0.528895; batch adversarial loss: 0.445501\n",
      "epoch 22; iter: 0; batch classifier loss: 0.564373; batch adversarial loss: 0.460823\n",
      "epoch 23; iter: 0; batch classifier loss: 0.520987; batch adversarial loss: 0.504938\n",
      "epoch 24; iter: 0; batch classifier loss: 0.575288; batch adversarial loss: 0.365211\n",
      "epoch 25; iter: 0; batch classifier loss: 0.549697; batch adversarial loss: 0.429784\n",
      "epoch 26; iter: 0; batch classifier loss: 0.630423; batch adversarial loss: 0.482653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.685774; batch adversarial loss: 0.499921\n",
      "epoch 28; iter: 0; batch classifier loss: 0.607891; batch adversarial loss: 0.410249\n",
      "epoch 29; iter: 0; batch classifier loss: 0.520451; batch adversarial loss: 0.467015\n",
      "epoch 30; iter: 0; batch classifier loss: 0.545395; batch adversarial loss: 0.382121\n",
      "epoch 31; iter: 0; batch classifier loss: 0.592051; batch adversarial loss: 0.403684\n",
      "epoch 32; iter: 0; batch classifier loss: 0.631641; batch adversarial loss: 0.432266\n",
      "epoch 33; iter: 0; batch classifier loss: 0.585392; batch adversarial loss: 0.395464\n",
      "epoch 34; iter: 0; batch classifier loss: 0.543351; batch adversarial loss: 0.336084\n",
      "epoch 35; iter: 0; batch classifier loss: 0.654101; batch adversarial loss: 0.439894\n",
      "epoch 36; iter: 0; batch classifier loss: 0.551145; batch adversarial loss: 0.383385\n",
      "epoch 37; iter: 0; batch classifier loss: 0.593781; batch adversarial loss: 0.416009\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443493; batch adversarial loss: 0.344378\n",
      "epoch 39; iter: 0; batch classifier loss: 0.559730; batch adversarial loss: 0.321263\n",
      "epoch 40; iter: 0; batch classifier loss: 0.520686; batch adversarial loss: 0.388454\n",
      "epoch 41; iter: 0; batch classifier loss: 0.593744; batch adversarial loss: 0.408635\n",
      "epoch 42; iter: 0; batch classifier loss: 0.499252; batch adversarial loss: 0.338417\n",
      "epoch 43; iter: 0; batch classifier loss: 0.535776; batch adversarial loss: 0.352305\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464584; batch adversarial loss: 0.315376\n",
      "epoch 45; iter: 0; batch classifier loss: 0.515601; batch adversarial loss: 0.341379\n",
      "epoch 46; iter: 0; batch classifier loss: 0.540469; batch adversarial loss: 0.301667\n",
      "epoch 47; iter: 0; batch classifier loss: 0.488589; batch adversarial loss: 0.269072\n",
      "epoch 48; iter: 0; batch classifier loss: 0.598486; batch adversarial loss: 0.384519\n",
      "epoch 49; iter: 0; batch classifier loss: 0.524061; batch adversarial loss: 0.369766\n",
      "epoch 50; iter: 0; batch classifier loss: 0.592908; batch adversarial loss: 0.314704\n",
      "epoch 51; iter: 0; batch classifier loss: 0.591528; batch adversarial loss: 0.365424\n",
      "epoch 52; iter: 0; batch classifier loss: 0.518796; batch adversarial loss: 0.282739\n",
      "epoch 53; iter: 0; batch classifier loss: 0.568511; batch adversarial loss: 0.400359\n",
      "epoch 54; iter: 0; batch classifier loss: 0.614558; batch adversarial loss: 0.278828\n",
      "epoch 55; iter: 0; batch classifier loss: 0.520282; batch adversarial loss: 0.250249\n",
      "epoch 56; iter: 0; batch classifier loss: 0.440901; batch adversarial loss: 0.352609\n",
      "epoch 57; iter: 0; batch classifier loss: 0.493103; batch adversarial loss: 0.352855\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424254; batch adversarial loss: 0.365888\n",
      "epoch 59; iter: 0; batch classifier loss: 0.458828; batch adversarial loss: 0.377558\n",
      "epoch 60; iter: 0; batch classifier loss: 0.477192; batch adversarial loss: 0.320163\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459189; batch adversarial loss: 0.249144\n",
      "epoch 62; iter: 0; batch classifier loss: 0.484278; batch adversarial loss: 0.303654\n",
      "epoch 63; iter: 0; batch classifier loss: 0.467090; batch adversarial loss: 0.404509\n",
      "epoch 64; iter: 0; batch classifier loss: 0.359997; batch adversarial loss: 0.321246\n",
      "epoch 65; iter: 0; batch classifier loss: 0.441687; batch adversarial loss: 0.257739\n",
      "epoch 66; iter: 0; batch classifier loss: 0.318025; batch adversarial loss: 0.330545\n",
      "epoch 67; iter: 0; batch classifier loss: 0.410441; batch adversarial loss: 0.344159\n",
      "epoch 68; iter: 0; batch classifier loss: 0.403912; batch adversarial loss: 0.343171\n",
      "epoch 69; iter: 0; batch classifier loss: 0.433312; batch adversarial loss: 0.280932\n",
      "epoch 70; iter: 0; batch classifier loss: 0.423367; batch adversarial loss: 0.343415\n",
      "epoch 71; iter: 0; batch classifier loss: 0.482325; batch adversarial loss: 0.280110\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416650; batch adversarial loss: 0.286713\n",
      "epoch 73; iter: 0; batch classifier loss: 0.374326; batch adversarial loss: 0.287199\n",
      "epoch 74; iter: 0; batch classifier loss: 0.453296; batch adversarial loss: 0.364422\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352161; batch adversarial loss: 0.308408\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366879; batch adversarial loss: 0.314895\n",
      "epoch 77; iter: 0; batch classifier loss: 0.416151; batch adversarial loss: 0.336693\n",
      "epoch 78; iter: 0; batch classifier loss: 0.361092; batch adversarial loss: 0.228376\n",
      "epoch 79; iter: 0; batch classifier loss: 0.376497; batch adversarial loss: 0.367293\n",
      "epoch 80; iter: 0; batch classifier loss: 0.474411; batch adversarial loss: 0.418107\n",
      "epoch 81; iter: 0; batch classifier loss: 0.417778; batch adversarial loss: 0.277987\n",
      "epoch 82; iter: 0; batch classifier loss: 0.456096; batch adversarial loss: 0.271763\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376287; batch adversarial loss: 0.276333\n",
      "epoch 84; iter: 0; batch classifier loss: 0.435393; batch adversarial loss: 0.268565\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392674; batch adversarial loss: 0.396785\n",
      "epoch 86; iter: 0; batch classifier loss: 0.415215; batch adversarial loss: 0.297016\n",
      "epoch 87; iter: 0; batch classifier loss: 0.372040; batch adversarial loss: 0.312486\n",
      "epoch 88; iter: 0; batch classifier loss: 0.421149; batch adversarial loss: 0.259072\n",
      "epoch 89; iter: 0; batch classifier loss: 0.384519; batch adversarial loss: 0.269909\n",
      "epoch 90; iter: 0; batch classifier loss: 0.450881; batch adversarial loss: 0.260070\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410571; batch adversarial loss: 0.360108\n",
      "epoch 92; iter: 0; batch classifier loss: 0.371280; batch adversarial loss: 0.241794\n",
      "epoch 93; iter: 0; batch classifier loss: 0.347793; batch adversarial loss: 0.288397\n",
      "epoch 94; iter: 0; batch classifier loss: 0.378987; batch adversarial loss: 0.285664\n",
      "epoch 95; iter: 0; batch classifier loss: 0.404674; batch adversarial loss: 0.293783\n",
      "epoch 96; iter: 0; batch classifier loss: 0.358901; batch adversarial loss: 0.309336\n",
      "epoch 97; iter: 0; batch classifier loss: 0.372144; batch adversarial loss: 0.290326\n",
      "epoch 98; iter: 0; batch classifier loss: 0.382460; batch adversarial loss: 0.254504\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361966; batch adversarial loss: 0.227423\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 0.871387; batch adversarial loss: 0.890301\n",
      "epoch 2; iter: 0; batch classifier loss: 0.816291; batch adversarial loss: 0.770080\n",
      "epoch 3; iter: 0; batch classifier loss: 0.659153; batch adversarial loss: 0.771467\n",
      "epoch 4; iter: 0; batch classifier loss: 0.610982; batch adversarial loss: 0.672184\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593940; batch adversarial loss: 0.635317\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569775; batch adversarial loss: 0.633790\n",
      "epoch 7; iter: 0; batch classifier loss: 0.609387; batch adversarial loss: 0.605916\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568234; batch adversarial loss: 0.597016\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543267; batch adversarial loss: 0.574801\n",
      "epoch 10; iter: 0; batch classifier loss: 0.589291; batch adversarial loss: 0.575686\n",
      "epoch 11; iter: 0; batch classifier loss: 0.605349; batch adversarial loss: 0.538846\n",
      "epoch 12; iter: 0; batch classifier loss: 0.561874; batch adversarial loss: 0.535372\n",
      "epoch 13; iter: 0; batch classifier loss: 0.566083; batch adversarial loss: 0.530952\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527903; batch adversarial loss: 0.495940\n",
      "epoch 15; iter: 0; batch classifier loss: 0.557518; batch adversarial loss: 0.472138\n",
      "epoch 16; iter: 0; batch classifier loss: 0.613665; batch adversarial loss: 0.454748\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527183; batch adversarial loss: 0.453481\n",
      "epoch 18; iter: 0; batch classifier loss: 0.599144; batch adversarial loss: 0.432639\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530566; batch adversarial loss: 0.431364\n",
      "epoch 20; iter: 0; batch classifier loss: 0.539457; batch adversarial loss: 0.398827\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512582; batch adversarial loss: 0.411705\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516718; batch adversarial loss: 0.420784\n",
      "epoch 23; iter: 0; batch classifier loss: 0.462000; batch adversarial loss: 0.442260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.517584; batch adversarial loss: 0.331324\n",
      "epoch 25; iter: 0; batch classifier loss: 0.494629; batch adversarial loss: 0.389777\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508053; batch adversarial loss: 0.431566\n",
      "epoch 27; iter: 0; batch classifier loss: 0.546096; batch adversarial loss: 0.459832\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486821; batch adversarial loss: 0.369049\n",
      "epoch 29; iter: 0; batch classifier loss: 0.425184; batch adversarial loss: 0.430984\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479188; batch adversarial loss: 0.357548\n",
      "epoch 31; iter: 0; batch classifier loss: 0.493672; batch adversarial loss: 0.375404\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484351; batch adversarial loss: 0.400136\n",
      "epoch 33; iter: 0; batch classifier loss: 0.488548; batch adversarial loss: 0.361958\n",
      "epoch 34; iter: 0; batch classifier loss: 0.502934; batch adversarial loss: 0.316341\n",
      "epoch 35; iter: 0; batch classifier loss: 0.521917; batch adversarial loss: 0.425770\n",
      "epoch 36; iter: 0; batch classifier loss: 0.473499; batch adversarial loss: 0.372289\n",
      "epoch 37; iter: 0; batch classifier loss: 0.511141; batch adversarial loss: 0.402104\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403578; batch adversarial loss: 0.340501\n",
      "epoch 39; iter: 0; batch classifier loss: 0.534609; batch adversarial loss: 0.317851\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474871; batch adversarial loss: 0.391334\n",
      "epoch 41; iter: 0; batch classifier loss: 0.502691; batch adversarial loss: 0.411480\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444352; batch adversarial loss: 0.336469\n",
      "epoch 43; iter: 0; batch classifier loss: 0.509876; batch adversarial loss: 0.366902\n",
      "epoch 44; iter: 0; batch classifier loss: 0.447353; batch adversarial loss: 0.316859\n",
      "epoch 45; iter: 0; batch classifier loss: 0.514005; batch adversarial loss: 0.354664\n",
      "epoch 46; iter: 0; batch classifier loss: 0.529979; batch adversarial loss: 0.311114\n",
      "epoch 47; iter: 0; batch classifier loss: 0.495280; batch adversarial loss: 0.270987\n",
      "epoch 48; iter: 0; batch classifier loss: 0.594638; batch adversarial loss: 0.413141\n",
      "epoch 49; iter: 0; batch classifier loss: 0.526127; batch adversarial loss: 0.391813\n",
      "epoch 50; iter: 0; batch classifier loss: 0.581972; batch adversarial loss: 0.329924\n",
      "epoch 51; iter: 0; batch classifier loss: 0.577958; batch adversarial loss: 0.388635\n",
      "epoch 52; iter: 0; batch classifier loss: 0.471433; batch adversarial loss: 0.287416\n",
      "epoch 53; iter: 0; batch classifier loss: 0.526209; batch adversarial loss: 0.432252\n",
      "epoch 54; iter: 0; batch classifier loss: 0.499903; batch adversarial loss: 0.286452\n",
      "epoch 55; iter: 0; batch classifier loss: 0.468210; batch adversarial loss: 0.255207\n",
      "epoch 56; iter: 0; batch classifier loss: 0.509867; batch adversarial loss: 0.372813\n",
      "epoch 57; iter: 0; batch classifier loss: 0.549177; batch adversarial loss: 0.372607\n",
      "epoch 58; iter: 0; batch classifier loss: 0.494475; batch adversarial loss: 0.387797\n",
      "epoch 59; iter: 0; batch classifier loss: 0.547613; batch adversarial loss: 0.395820\n",
      "epoch 60; iter: 0; batch classifier loss: 0.603503; batch adversarial loss: 0.334112\n",
      "epoch 61; iter: 0; batch classifier loss: 0.594802; batch adversarial loss: 0.260608\n",
      "epoch 62; iter: 0; batch classifier loss: 0.667443; batch adversarial loss: 0.312764\n",
      "epoch 63; iter: 0; batch classifier loss: 0.592992; batch adversarial loss: 0.407377\n",
      "epoch 64; iter: 0; batch classifier loss: 0.396089; batch adversarial loss: 0.325160\n",
      "epoch 65; iter: 0; batch classifier loss: 0.429129; batch adversarial loss: 0.262499\n",
      "epoch 66; iter: 0; batch classifier loss: 0.325491; batch adversarial loss: 0.332277\n",
      "epoch 67; iter: 0; batch classifier loss: 0.385958; batch adversarial loss: 0.344416\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400342; batch adversarial loss: 0.344110\n",
      "epoch 69; iter: 0; batch classifier loss: 0.405013; batch adversarial loss: 0.282423\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414392; batch adversarial loss: 0.343949\n",
      "epoch 71; iter: 0; batch classifier loss: 0.450905; batch adversarial loss: 0.281310\n",
      "epoch 72; iter: 0; batch classifier loss: 0.404979; batch adversarial loss: 0.287347\n",
      "epoch 73; iter: 0; batch classifier loss: 0.370511; batch adversarial loss: 0.289118\n",
      "epoch 74; iter: 0; batch classifier loss: 0.430477; batch adversarial loss: 0.364674\n",
      "epoch 75; iter: 0; batch classifier loss: 0.323257; batch adversarial loss: 0.308134\n",
      "epoch 76; iter: 0; batch classifier loss: 0.380951; batch adversarial loss: 0.316130\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413288; batch adversarial loss: 0.335760\n",
      "epoch 78; iter: 0; batch classifier loss: 0.342909; batch adversarial loss: 0.228482\n",
      "epoch 79; iter: 0; batch classifier loss: 0.369407; batch adversarial loss: 0.367363\n",
      "epoch 80; iter: 0; batch classifier loss: 0.458816; batch adversarial loss: 0.417904\n",
      "epoch 81; iter: 0; batch classifier loss: 0.396372; batch adversarial loss: 0.276344\n",
      "epoch 82; iter: 0; batch classifier loss: 0.443252; batch adversarial loss: 0.269648\n",
      "epoch 83; iter: 0; batch classifier loss: 0.376581; batch adversarial loss: 0.276918\n",
      "epoch 84; iter: 0; batch classifier loss: 0.444224; batch adversarial loss: 0.269316\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395375; batch adversarial loss: 0.396365\n",
      "epoch 86; iter: 0; batch classifier loss: 0.402415; batch adversarial loss: 0.298096\n",
      "epoch 87; iter: 0; batch classifier loss: 0.374828; batch adversarial loss: 0.312221\n",
      "epoch 88; iter: 0; batch classifier loss: 0.404154; batch adversarial loss: 0.258988\n",
      "epoch 89; iter: 0; batch classifier loss: 0.370691; batch adversarial loss: 0.268615\n",
      "epoch 90; iter: 0; batch classifier loss: 0.400308; batch adversarial loss: 0.260341\n",
      "epoch 91; iter: 0; batch classifier loss: 0.393654; batch adversarial loss: 0.359126\n",
      "epoch 92; iter: 0; batch classifier loss: 0.353060; batch adversarial loss: 0.241785\n",
      "epoch 93; iter: 0; batch classifier loss: 0.338041; batch adversarial loss: 0.287344\n",
      "epoch 94; iter: 0; batch classifier loss: 0.362839; batch adversarial loss: 0.286856\n",
      "epoch 95; iter: 0; batch classifier loss: 0.403581; batch adversarial loss: 0.293404\n",
      "epoch 96; iter: 0; batch classifier loss: 0.376854; batch adversarial loss: 0.309298\n",
      "epoch 97; iter: 0; batch classifier loss: 0.376331; batch adversarial loss: 0.290059\n",
      "epoch 98; iter: 0; batch classifier loss: 0.358749; batch adversarial loss: 0.253387\n",
      "epoch 99; iter: 0; batch classifier loss: 0.342823; batch adversarial loss: 0.227746\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697777; batch adversarial loss: 0.845058\n",
      "epoch 1; iter: 0; batch classifier loss: 1.124595; batch adversarial loss: 0.920406\n",
      "epoch 2; iter: 0; batch classifier loss: 1.124324; batch adversarial loss: 0.803334\n",
      "epoch 3; iter: 0; batch classifier loss: 0.855071; batch adversarial loss: 0.818272\n",
      "epoch 4; iter: 0; batch classifier loss: 0.774837; batch adversarial loss: 0.728277\n",
      "epoch 5; iter: 0; batch classifier loss: 0.681920; batch adversarial loss: 0.676963\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570430; batch adversarial loss: 0.642923\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553601; batch adversarial loss: 0.615262\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553013; batch adversarial loss: 0.601791\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533119; batch adversarial loss: 0.574507\n",
      "epoch 10; iter: 0; batch classifier loss: 0.508045; batch adversarial loss: 0.584701\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547105; batch adversarial loss: 0.545509\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514546; batch adversarial loss: 0.537304\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521213; batch adversarial loss: 0.533661\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480780; batch adversarial loss: 0.499626\n",
      "epoch 15; iter: 0; batch classifier loss: 0.486543; batch adversarial loss: 0.478419\n",
      "epoch 16; iter: 0; batch classifier loss: 0.607517; batch adversarial loss: 0.452290\n",
      "epoch 17; iter: 0; batch classifier loss: 0.479901; batch adversarial loss: 0.465127\n",
      "epoch 18; iter: 0; batch classifier loss: 0.507940; batch adversarial loss: 0.460467\n",
      "epoch 19; iter: 0; batch classifier loss: 0.521945; batch adversarial loss: 0.460797\n",
      "epoch 20; iter: 0; batch classifier loss: 0.479432; batch adversarial loss: 0.436880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.534719; batch adversarial loss: 0.445336\n",
      "epoch 22; iter: 0; batch classifier loss: 0.538262; batch adversarial loss: 0.458923\n",
      "epoch 23; iter: 0; batch classifier loss: 0.496161; batch adversarial loss: 0.504754\n",
      "epoch 24; iter: 0; batch classifier loss: 0.497155; batch adversarial loss: 0.366243\n",
      "epoch 25; iter: 0; batch classifier loss: 0.530413; batch adversarial loss: 0.424166\n",
      "epoch 26; iter: 0; batch classifier loss: 0.619486; batch adversarial loss: 0.484638\n",
      "epoch 27; iter: 0; batch classifier loss: 0.641802; batch adversarial loss: 0.500900\n",
      "epoch 28; iter: 0; batch classifier loss: 0.577865; batch adversarial loss: 0.410073\n",
      "epoch 29; iter: 0; batch classifier loss: 0.521063; batch adversarial loss: 0.465232\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504002; batch adversarial loss: 0.381473\n",
      "epoch 31; iter: 0; batch classifier loss: 0.546765; batch adversarial loss: 0.403297\n",
      "epoch 32; iter: 0; batch classifier loss: 0.573792; batch adversarial loss: 0.431146\n",
      "epoch 33; iter: 0; batch classifier loss: 0.549919; batch adversarial loss: 0.393056\n",
      "epoch 34; iter: 0; batch classifier loss: 0.547149; batch adversarial loss: 0.337421\n",
      "epoch 35; iter: 0; batch classifier loss: 0.591713; batch adversarial loss: 0.438585\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492151; batch adversarial loss: 0.381620\n",
      "epoch 37; iter: 0; batch classifier loss: 0.532688; batch adversarial loss: 0.414495\n",
      "epoch 38; iter: 0; batch classifier loss: 0.436372; batch adversarial loss: 0.341699\n",
      "epoch 39; iter: 0; batch classifier loss: 0.475050; batch adversarial loss: 0.323104\n",
      "epoch 40; iter: 0; batch classifier loss: 0.474120; batch adversarial loss: 0.390129\n",
      "epoch 41; iter: 0; batch classifier loss: 0.529966; batch adversarial loss: 0.408125\n",
      "epoch 42; iter: 0; batch classifier loss: 0.450610; batch adversarial loss: 0.337135\n",
      "epoch 43; iter: 0; batch classifier loss: 0.487800; batch adversarial loss: 0.352630\n",
      "epoch 44; iter: 0; batch classifier loss: 0.404214; batch adversarial loss: 0.314750\n",
      "epoch 45; iter: 0; batch classifier loss: 0.484764; batch adversarial loss: 0.340857\n",
      "epoch 46; iter: 0; batch classifier loss: 0.511563; batch adversarial loss: 0.300809\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466342; batch adversarial loss: 0.270024\n",
      "epoch 48; iter: 0; batch classifier loss: 0.601943; batch adversarial loss: 0.383867\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487248; batch adversarial loss: 0.367747\n",
      "epoch 50; iter: 0; batch classifier loss: 0.541373; batch adversarial loss: 0.313869\n",
      "epoch 51; iter: 0; batch classifier loss: 0.582713; batch adversarial loss: 0.362790\n",
      "epoch 52; iter: 0; batch classifier loss: 0.507903; batch adversarial loss: 0.281996\n",
      "epoch 53; iter: 0; batch classifier loss: 0.403458; batch adversarial loss: 0.393491\n",
      "epoch 54; iter: 0; batch classifier loss: 0.424104; batch adversarial loss: 0.276178\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405727; batch adversarial loss: 0.247903\n",
      "epoch 56; iter: 0; batch classifier loss: 0.390065; batch adversarial loss: 0.350960\n",
      "epoch 57; iter: 0; batch classifier loss: 0.416777; batch adversarial loss: 0.352666\n",
      "epoch 58; iter: 0; batch classifier loss: 0.329746; batch adversarial loss: 0.365703\n",
      "epoch 59; iter: 0; batch classifier loss: 0.416756; batch adversarial loss: 0.377733\n",
      "epoch 60; iter: 0; batch classifier loss: 0.360310; batch adversarial loss: 0.317995\n",
      "epoch 61; iter: 0; batch classifier loss: 0.391842; batch adversarial loss: 0.247555\n",
      "epoch 62; iter: 0; batch classifier loss: 0.407894; batch adversarial loss: 0.302420\n",
      "epoch 63; iter: 0; batch classifier loss: 0.351493; batch adversarial loss: 0.404042\n",
      "epoch 64; iter: 0; batch classifier loss: 0.346457; batch adversarial loss: 0.323038\n",
      "epoch 65; iter: 0; batch classifier loss: 0.321739; batch adversarial loss: 0.256067\n",
      "epoch 66; iter: 0; batch classifier loss: 0.283211; batch adversarial loss: 0.330393\n",
      "epoch 67; iter: 0; batch classifier loss: 0.331515; batch adversarial loss: 0.343787\n",
      "epoch 68; iter: 0; batch classifier loss: 0.356651; batch adversarial loss: 0.341892\n",
      "epoch 69; iter: 0; batch classifier loss: 0.392062; batch adversarial loss: 0.280043\n",
      "epoch 70; iter: 0; batch classifier loss: 0.358402; batch adversarial loss: 0.343771\n",
      "epoch 71; iter: 0; batch classifier loss: 0.373763; batch adversarial loss: 0.279522\n",
      "epoch 72; iter: 0; batch classifier loss: 0.372500; batch adversarial loss: 0.287200\n",
      "epoch 73; iter: 0; batch classifier loss: 0.293237; batch adversarial loss: 0.288352\n",
      "epoch 74; iter: 0; batch classifier loss: 0.354196; batch adversarial loss: 0.366809\n",
      "epoch 75; iter: 0; batch classifier loss: 0.275865; batch adversarial loss: 0.307178\n",
      "epoch 76; iter: 0; batch classifier loss: 0.290007; batch adversarial loss: 0.314474\n",
      "epoch 77; iter: 0; batch classifier loss: 0.346840; batch adversarial loss: 0.334208\n",
      "epoch 78; iter: 0; batch classifier loss: 0.285080; batch adversarial loss: 0.227746\n",
      "epoch 79; iter: 0; batch classifier loss: 0.302284; batch adversarial loss: 0.368327\n",
      "epoch 80; iter: 0; batch classifier loss: 0.353343; batch adversarial loss: 0.417039\n",
      "epoch 81; iter: 0; batch classifier loss: 0.334413; batch adversarial loss: 0.279512\n",
      "epoch 82; iter: 0; batch classifier loss: 0.398989; batch adversarial loss: 0.271475\n",
      "epoch 83; iter: 0; batch classifier loss: 0.266856; batch adversarial loss: 0.277383\n",
      "epoch 84; iter: 0; batch classifier loss: 0.362095; batch adversarial loss: 0.270456\n",
      "epoch 85; iter: 0; batch classifier loss: 0.356164; batch adversarial loss: 0.397741\n",
      "epoch 86; iter: 0; batch classifier loss: 0.303848; batch adversarial loss: 0.295754\n",
      "epoch 87; iter: 0; batch classifier loss: 0.321169; batch adversarial loss: 0.313468\n",
      "epoch 88; iter: 0; batch classifier loss: 0.395778; batch adversarial loss: 0.261862\n",
      "epoch 89; iter: 0; batch classifier loss: 0.352181; batch adversarial loss: 0.269746\n",
      "epoch 90; iter: 0; batch classifier loss: 0.393777; batch adversarial loss: 0.258127\n",
      "epoch 91; iter: 0; batch classifier loss: 0.356106; batch adversarial loss: 0.358305\n",
      "epoch 92; iter: 0; batch classifier loss: 0.307290; batch adversarial loss: 0.241988\n",
      "epoch 93; iter: 0; batch classifier loss: 0.278475; batch adversarial loss: 0.289981\n",
      "epoch 94; iter: 0; batch classifier loss: 0.323529; batch adversarial loss: 0.285333\n",
      "epoch 95; iter: 0; batch classifier loss: 0.313632; batch adversarial loss: 0.295317\n",
      "epoch 96; iter: 0; batch classifier loss: 0.318746; batch adversarial loss: 0.308987\n",
      "epoch 97; iter: 0; batch classifier loss: 0.281786; batch adversarial loss: 0.290543\n",
      "epoch 98; iter: 0; batch classifier loss: 0.310103; batch adversarial loss: 0.254948\n",
      "epoch 99; iter: 0; batch classifier loss: 0.332912; batch adversarial loss: 0.227450\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.097514; batch adversarial loss: 0.918857\n",
      "epoch 2; iter: 0; batch classifier loss: 1.013004; batch adversarial loss: 0.793514\n",
      "epoch 3; iter: 0; batch classifier loss: 0.790461; batch adversarial loss: 0.808756\n",
      "epoch 4; iter: 0; batch classifier loss: 0.712697; batch adversarial loss: 0.711057\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613254; batch adversarial loss: 0.651773\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572239; batch adversarial loss: 0.636279\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587595; batch adversarial loss: 0.611220\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555076; batch adversarial loss: 0.601594\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538537; batch adversarial loss: 0.575123\n",
      "epoch 10; iter: 0; batch classifier loss: 0.554340; batch adversarial loss: 0.582690\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576682; batch adversarial loss: 0.542766\n",
      "epoch 12; iter: 0; batch classifier loss: 0.542234; batch adversarial loss: 0.535665\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543199; batch adversarial loss: 0.530520\n",
      "epoch 14; iter: 0; batch classifier loss: 0.529847; batch adversarial loss: 0.491272\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540819; batch adversarial loss: 0.469548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.599488; batch adversarial loss: 0.451715\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506221; batch adversarial loss: 0.456925\n",
      "epoch 18; iter: 0; batch classifier loss: 0.554246; batch adversarial loss: 0.447661\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527359; batch adversarial loss: 0.447847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.506674; batch adversarial loss: 0.418744\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504426; batch adversarial loss: 0.428593\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522461; batch adversarial loss: 0.443831\n",
      "epoch 23; iter: 0; batch classifier loss: 0.476452; batch adversarial loss: 0.486362\n",
      "epoch 24; iter: 0; batch classifier loss: 0.545929; batch adversarial loss: 0.355255\n",
      "epoch 25; iter: 0; batch classifier loss: 0.512092; batch adversarial loss: 0.416265\n",
      "epoch 26; iter: 0; batch classifier loss: 0.567966; batch adversarial loss: 0.465758\n",
      "epoch 27; iter: 0; batch classifier loss: 0.631308; batch adversarial loss: 0.490938\n",
      "epoch 28; iter: 0; batch classifier loss: 0.556707; batch adversarial loss: 0.401178\n",
      "epoch 29; iter: 0; batch classifier loss: 0.490010; batch adversarial loss: 0.461272\n",
      "epoch 30; iter: 0; batch classifier loss: 0.514091; batch adversarial loss: 0.378317\n",
      "epoch 31; iter: 0; batch classifier loss: 0.549068; batch adversarial loss: 0.398651\n",
      "epoch 32; iter: 0; batch classifier loss: 0.589821; batch adversarial loss: 0.432782\n",
      "epoch 33; iter: 0; batch classifier loss: 0.558662; batch adversarial loss: 0.393286\n",
      "epoch 34; iter: 0; batch classifier loss: 0.532620; batch adversarial loss: 0.335795\n",
      "epoch 35; iter: 0; batch classifier loss: 0.634947; batch adversarial loss: 0.445608\n",
      "epoch 36; iter: 0; batch classifier loss: 0.544826; batch adversarial loss: 0.387254\n",
      "epoch 37; iter: 0; batch classifier loss: 0.587909; batch adversarial loss: 0.421763\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444802; batch adversarial loss: 0.347786\n",
      "epoch 39; iter: 0; batch classifier loss: 0.554551; batch adversarial loss: 0.321996\n",
      "epoch 40; iter: 0; batch classifier loss: 0.513087; batch adversarial loss: 0.393288\n",
      "epoch 41; iter: 0; batch classifier loss: 0.598252; batch adversarial loss: 0.416667\n",
      "epoch 42; iter: 0; batch classifier loss: 0.493916; batch adversarial loss: 0.341991\n",
      "epoch 43; iter: 0; batch classifier loss: 0.531395; batch adversarial loss: 0.357464\n",
      "epoch 44; iter: 0; batch classifier loss: 0.470985; batch adversarial loss: 0.318401\n",
      "epoch 45; iter: 0; batch classifier loss: 0.537406; batch adversarial loss: 0.345997\n",
      "epoch 46; iter: 0; batch classifier loss: 0.552151; batch adversarial loss: 0.305186\n",
      "epoch 47; iter: 0; batch classifier loss: 0.498377; batch adversarial loss: 0.271192\n",
      "epoch 48; iter: 0; batch classifier loss: 0.604900; batch adversarial loss: 0.390701\n",
      "epoch 49; iter: 0; batch classifier loss: 0.522183; batch adversarial loss: 0.374692\n",
      "epoch 50; iter: 0; batch classifier loss: 0.598753; batch adversarial loss: 0.318521\n",
      "epoch 51; iter: 0; batch classifier loss: 0.605143; batch adversarial loss: 0.370424\n",
      "epoch 52; iter: 0; batch classifier loss: 0.511690; batch adversarial loss: 0.284379\n",
      "epoch 53; iter: 0; batch classifier loss: 0.553511; batch adversarial loss: 0.406484\n",
      "epoch 54; iter: 0; batch classifier loss: 0.555241; batch adversarial loss: 0.280770\n",
      "epoch 55; iter: 0; batch classifier loss: 0.545716; batch adversarial loss: 0.252407\n",
      "epoch 56; iter: 0; batch classifier loss: 0.619201; batch adversarial loss: 0.355865\n",
      "epoch 57; iter: 0; batch classifier loss: 0.516012; batch adversarial loss: 0.353731\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423492; batch adversarial loss: 0.366355\n",
      "epoch 59; iter: 0; batch classifier loss: 0.447723; batch adversarial loss: 0.377653\n",
      "epoch 60; iter: 0; batch classifier loss: 0.473403; batch adversarial loss: 0.320896\n",
      "epoch 61; iter: 0; batch classifier loss: 0.453161; batch adversarial loss: 0.250115\n",
      "epoch 62; iter: 0; batch classifier loss: 0.484577; batch adversarial loss: 0.304252\n",
      "epoch 63; iter: 0; batch classifier loss: 0.450371; batch adversarial loss: 0.404159\n",
      "epoch 64; iter: 0; batch classifier loss: 0.362801; batch adversarial loss: 0.321654\n",
      "epoch 65; iter: 0; batch classifier loss: 0.436423; batch adversarial loss: 0.258303\n",
      "epoch 66; iter: 0; batch classifier loss: 0.315784; batch adversarial loss: 0.330749\n",
      "epoch 67; iter: 0; batch classifier loss: 0.400965; batch adversarial loss: 0.344385\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400254; batch adversarial loss: 0.343619\n",
      "epoch 69; iter: 0; batch classifier loss: 0.411560; batch adversarial loss: 0.280585\n",
      "epoch 70; iter: 0; batch classifier loss: 0.414876; batch adversarial loss: 0.343761\n",
      "epoch 71; iter: 0; batch classifier loss: 0.468331; batch adversarial loss: 0.280131\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419852; batch adversarial loss: 0.286728\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372189; batch adversarial loss: 0.288139\n",
      "epoch 74; iter: 0; batch classifier loss: 0.432968; batch adversarial loss: 0.364657\n",
      "epoch 75; iter: 0; batch classifier loss: 0.345177; batch adversarial loss: 0.308140\n",
      "epoch 76; iter: 0; batch classifier loss: 0.370750; batch adversarial loss: 0.315022\n",
      "epoch 77; iter: 0; batch classifier loss: 0.417586; batch adversarial loss: 0.336505\n",
      "epoch 78; iter: 0; batch classifier loss: 0.347425; batch adversarial loss: 0.228051\n",
      "epoch 79; iter: 0; batch classifier loss: 0.377476; batch adversarial loss: 0.367411\n",
      "epoch 80; iter: 0; batch classifier loss: 0.468840; batch adversarial loss: 0.418186\n",
      "epoch 81; iter: 0; batch classifier loss: 0.399000; batch adversarial loss: 0.277755\n",
      "epoch 82; iter: 0; batch classifier loss: 0.450411; batch adversarial loss: 0.270916\n",
      "epoch 83; iter: 0; batch classifier loss: 0.378376; batch adversarial loss: 0.276195\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446956; batch adversarial loss: 0.269012\n",
      "epoch 85; iter: 0; batch classifier loss: 0.383873; batch adversarial loss: 0.397018\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416544; batch adversarial loss: 0.297378\n",
      "epoch 87; iter: 0; batch classifier loss: 0.378747; batch adversarial loss: 0.312581\n",
      "epoch 88; iter: 0; batch classifier loss: 0.438769; batch adversarial loss: 0.258738\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385327; batch adversarial loss: 0.269483\n",
      "epoch 90; iter: 0; batch classifier loss: 0.443003; batch adversarial loss: 0.260723\n",
      "epoch 91; iter: 0; batch classifier loss: 0.407471; batch adversarial loss: 0.360650\n",
      "epoch 92; iter: 0; batch classifier loss: 0.367327; batch adversarial loss: 0.241836\n",
      "epoch 93; iter: 0; batch classifier loss: 0.328476; batch adversarial loss: 0.288051\n",
      "epoch 94; iter: 0; batch classifier loss: 0.369354; batch adversarial loss: 0.285798\n",
      "epoch 95; iter: 0; batch classifier loss: 0.423789; batch adversarial loss: 0.293669\n",
      "epoch 96; iter: 0; batch classifier loss: 0.376118; batch adversarial loss: 0.309773\n",
      "epoch 97; iter: 0; batch classifier loss: 0.356631; batch adversarial loss: 0.289219\n",
      "epoch 98; iter: 0; batch classifier loss: 0.371730; batch adversarial loss: 0.253626\n",
      "epoch 99; iter: 0; batch classifier loss: 0.339811; batch adversarial loss: 0.227629\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.247620; batch adversarial loss: 0.926180\n",
      "epoch 2; iter: 0; batch classifier loss: 1.130428; batch adversarial loss: 0.800020\n",
      "epoch 3; iter: 0; batch classifier loss: 0.884703; batch adversarial loss: 0.819334\n",
      "epoch 4; iter: 0; batch classifier loss: 0.818648; batch adversarial loss: 0.724522\n",
      "epoch 5; iter: 0; batch classifier loss: 0.681145; batch adversarial loss: 0.663934\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584771; batch adversarial loss: 0.635998\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580208; batch adversarial loss: 0.612535\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551679; batch adversarial loss: 0.601431\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540300; batch adversarial loss: 0.572961\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540528; batch adversarial loss: 0.582389\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568948; batch adversarial loss: 0.541267\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528837; batch adversarial loss: 0.535015\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533097; batch adversarial loss: 0.528828\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512919; batch adversarial loss: 0.493510\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525354; batch adversarial loss: 0.474317\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592502; batch adversarial loss: 0.456486\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508172; batch adversarial loss: 0.463735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.542807; batch adversarial loss: 0.454248\n",
      "epoch 19; iter: 0; batch classifier loss: 0.555217; batch adversarial loss: 0.463021\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522188; batch adversarial loss: 0.435832\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545929; batch adversarial loss: 0.451724\n",
      "epoch 22; iter: 0; batch classifier loss: 0.580614; batch adversarial loss: 0.467088\n",
      "epoch 23; iter: 0; batch classifier loss: 0.534403; batch adversarial loss: 0.507357\n",
      "epoch 24; iter: 0; batch classifier loss: 0.586088; batch adversarial loss: 0.366681\n",
      "epoch 25; iter: 0; batch classifier loss: 0.558696; batch adversarial loss: 0.432539\n",
      "epoch 26; iter: 0; batch classifier loss: 0.649108; batch adversarial loss: 0.485179\n",
      "epoch 27; iter: 0; batch classifier loss: 0.702586; batch adversarial loss: 0.500629\n",
      "epoch 28; iter: 0; batch classifier loss: 0.614426; batch adversarial loss: 0.410551\n",
      "epoch 29; iter: 0; batch classifier loss: 0.530730; batch adversarial loss: 0.466254\n",
      "epoch 30; iter: 0; batch classifier loss: 0.555821; batch adversarial loss: 0.382063\n",
      "epoch 31; iter: 0; batch classifier loss: 0.602724; batch adversarial loss: 0.403418\n",
      "epoch 32; iter: 0; batch classifier loss: 0.633000; batch adversarial loss: 0.431039\n",
      "epoch 33; iter: 0; batch classifier loss: 0.590057; batch adversarial loss: 0.395265\n",
      "epoch 34; iter: 0; batch classifier loss: 0.542191; batch adversarial loss: 0.335470\n",
      "epoch 35; iter: 0; batch classifier loss: 0.669920; batch adversarial loss: 0.438505\n",
      "epoch 36; iter: 0; batch classifier loss: 0.549095; batch adversarial loss: 0.382138\n",
      "epoch 37; iter: 0; batch classifier loss: 0.596264; batch adversarial loss: 0.414400\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442367; batch adversarial loss: 0.343945\n",
      "epoch 39; iter: 0; batch classifier loss: 0.560161; batch adversarial loss: 0.320529\n",
      "epoch 40; iter: 0; batch classifier loss: 0.518879; batch adversarial loss: 0.387820\n",
      "epoch 41; iter: 0; batch classifier loss: 0.596325; batch adversarial loss: 0.407514\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498624; batch adversarial loss: 0.337658\n",
      "epoch 43; iter: 0; batch classifier loss: 0.542841; batch adversarial loss: 0.351525\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463714; batch adversarial loss: 0.315084\n",
      "epoch 45; iter: 0; batch classifier loss: 0.513229; batch adversarial loss: 0.340544\n",
      "epoch 46; iter: 0; batch classifier loss: 0.531368; batch adversarial loss: 0.300894\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484959; batch adversarial loss: 0.268937\n",
      "epoch 48; iter: 0; batch classifier loss: 0.596427; batch adversarial loss: 0.383316\n",
      "epoch 49; iter: 0; batch classifier loss: 0.522492; batch adversarial loss: 0.368683\n",
      "epoch 50; iter: 0; batch classifier loss: 0.584286; batch adversarial loss: 0.313916\n",
      "epoch 51; iter: 0; batch classifier loss: 0.593618; batch adversarial loss: 0.364654\n",
      "epoch 52; iter: 0; batch classifier loss: 0.519808; batch adversarial loss: 0.282305\n",
      "epoch 53; iter: 0; batch classifier loss: 0.578828; batch adversarial loss: 0.399448\n",
      "epoch 54; iter: 0; batch classifier loss: 0.627220; batch adversarial loss: 0.278390\n",
      "epoch 55; iter: 0; batch classifier loss: 0.462293; batch adversarial loss: 0.249666\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449992; batch adversarial loss: 0.352389\n",
      "epoch 57; iter: 0; batch classifier loss: 0.494781; batch adversarial loss: 0.352804\n",
      "epoch 58; iter: 0; batch classifier loss: 0.427523; batch adversarial loss: 0.365724\n",
      "epoch 59; iter: 0; batch classifier loss: 0.463347; batch adversarial loss: 0.377484\n",
      "epoch 60; iter: 0; batch classifier loss: 0.485076; batch adversarial loss: 0.320152\n",
      "epoch 61; iter: 0; batch classifier loss: 0.464538; batch adversarial loss: 0.248951\n",
      "epoch 62; iter: 0; batch classifier loss: 0.476894; batch adversarial loss: 0.303492\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465277; batch adversarial loss: 0.404581\n",
      "epoch 64; iter: 0; batch classifier loss: 0.361207; batch adversarial loss: 0.321140\n",
      "epoch 65; iter: 0; batch classifier loss: 0.449556; batch adversarial loss: 0.257598\n",
      "epoch 66; iter: 0; batch classifier loss: 0.316793; batch adversarial loss: 0.330413\n",
      "epoch 67; iter: 0; batch classifier loss: 0.409540; batch adversarial loss: 0.344121\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400929; batch adversarial loss: 0.343456\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432864; batch adversarial loss: 0.280833\n",
      "epoch 70; iter: 0; batch classifier loss: 0.426788; batch adversarial loss: 0.343224\n",
      "epoch 71; iter: 0; batch classifier loss: 0.480434; batch adversarial loss: 0.279980\n",
      "epoch 72; iter: 0; batch classifier loss: 0.407638; batch adversarial loss: 0.286518\n",
      "epoch 73; iter: 0; batch classifier loss: 0.372297; batch adversarial loss: 0.287111\n",
      "epoch 74; iter: 0; batch classifier loss: 0.465538; batch adversarial loss: 0.364217\n",
      "epoch 75; iter: 0; batch classifier loss: 0.360154; batch adversarial loss: 0.308571\n",
      "epoch 76; iter: 0; batch classifier loss: 0.368129; batch adversarial loss: 0.314864\n",
      "epoch 77; iter: 0; batch classifier loss: 0.414292; batch adversarial loss: 0.336585\n",
      "epoch 78; iter: 0; batch classifier loss: 0.348201; batch adversarial loss: 0.228188\n",
      "epoch 79; iter: 0; batch classifier loss: 0.374496; batch adversarial loss: 0.367098\n",
      "epoch 80; iter: 0; batch classifier loss: 0.485524; batch adversarial loss: 0.417953\n",
      "epoch 81; iter: 0; batch classifier loss: 0.427719; batch adversarial loss: 0.278597\n",
      "epoch 82; iter: 0; batch classifier loss: 0.455938; batch adversarial loss: 0.271648\n",
      "epoch 83; iter: 0; batch classifier loss: 0.380618; batch adversarial loss: 0.276418\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446516; batch adversarial loss: 0.268455\n",
      "epoch 85; iter: 0; batch classifier loss: 0.390859; batch adversarial loss: 0.396704\n",
      "epoch 86; iter: 0; batch classifier loss: 0.417563; batch adversarial loss: 0.297261\n",
      "epoch 87; iter: 0; batch classifier loss: 0.373728; batch adversarial loss: 0.312845\n",
      "epoch 88; iter: 0; batch classifier loss: 0.422531; batch adversarial loss: 0.259462\n",
      "epoch 89; iter: 0; batch classifier loss: 0.393246; batch adversarial loss: 0.270119\n",
      "epoch 90; iter: 0; batch classifier loss: 0.450430; batch adversarial loss: 0.260139\n",
      "epoch 91; iter: 0; batch classifier loss: 0.412737; batch adversarial loss: 0.359930\n",
      "epoch 92; iter: 0; batch classifier loss: 0.377750; batch adversarial loss: 0.242040\n",
      "epoch 93; iter: 0; batch classifier loss: 0.341830; batch adversarial loss: 0.288422\n",
      "epoch 94; iter: 0; batch classifier loss: 0.382227; batch adversarial loss: 0.285409\n",
      "epoch 95; iter: 0; batch classifier loss: 0.411377; batch adversarial loss: 0.293972\n",
      "epoch 96; iter: 0; batch classifier loss: 0.366058; batch adversarial loss: 0.309168\n",
      "epoch 97; iter: 0; batch classifier loss: 0.378037; batch adversarial loss: 0.290020\n",
      "epoch 98; iter: 0; batch classifier loss: 0.380384; batch adversarial loss: 0.254574\n",
      "epoch 99; iter: 0; batch classifier loss: 0.364459; batch adversarial loss: 0.227973\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.248175; batch adversarial loss: 0.926195\n",
      "epoch 2; iter: 0; batch classifier loss: 1.130693; batch adversarial loss: 0.800022\n",
      "epoch 3; iter: 0; batch classifier loss: 0.885441; batch adversarial loss: 0.819349\n",
      "epoch 4; iter: 0; batch classifier loss: 0.819337; batch adversarial loss: 0.724537\n",
      "epoch 5; iter: 0; batch classifier loss: 0.681879; batch adversarial loss: 0.663984\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585128; batch adversarial loss: 0.636025\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580447; batch adversarial loss: 0.612496\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552006; batch adversarial loss: 0.601484\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539430; batch adversarial loss: 0.573096\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540400; batch adversarial loss: 0.582380\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568617; batch adversarial loss: 0.541321\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529141; batch adversarial loss: 0.535037\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533327; batch adversarial loss: 0.528810\n",
      "epoch 14; iter: 0; batch classifier loss: 0.512615; batch adversarial loss: 0.493544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.524745; batch adversarial loss: 0.474362\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591485; batch adversarial loss: 0.456521\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508693; batch adversarial loss: 0.463702\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543209; batch adversarial loss: 0.454237\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554744; batch adversarial loss: 0.462571\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522010; batch adversarial loss: 0.435906\n",
      "epoch 21; iter: 0; batch classifier loss: 0.544278; batch adversarial loss: 0.451453\n",
      "epoch 22; iter: 0; batch classifier loss: 0.581243; batch adversarial loss: 0.466969\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531723; batch adversarial loss: 0.506829\n",
      "epoch 24; iter: 0; batch classifier loss: 0.585057; batch adversarial loss: 0.366626\n",
      "epoch 25; iter: 0; batch classifier loss: 0.561929; batch adversarial loss: 0.432332\n",
      "epoch 26; iter: 0; batch classifier loss: 0.647195; batch adversarial loss: 0.484812\n",
      "epoch 27; iter: 0; batch classifier loss: 0.705871; batch adversarial loss: 0.500806\n",
      "epoch 28; iter: 0; batch classifier loss: 0.613261; batch adversarial loss: 0.410561\n",
      "epoch 29; iter: 0; batch classifier loss: 0.527619; batch adversarial loss: 0.466268\n",
      "epoch 30; iter: 0; batch classifier loss: 0.552450; batch adversarial loss: 0.382152\n",
      "epoch 31; iter: 0; batch classifier loss: 0.602439; batch adversarial loss: 0.403833\n",
      "epoch 32; iter: 0; batch classifier loss: 0.629354; batch adversarial loss: 0.431228\n",
      "epoch 33; iter: 0; batch classifier loss: 0.592120; batch adversarial loss: 0.395239\n",
      "epoch 34; iter: 0; batch classifier loss: 0.543404; batch adversarial loss: 0.335655\n",
      "epoch 35; iter: 0; batch classifier loss: 0.669724; batch adversarial loss: 0.438528\n",
      "epoch 36; iter: 0; batch classifier loss: 0.548732; batch adversarial loss: 0.381914\n",
      "epoch 37; iter: 0; batch classifier loss: 0.593894; batch adversarial loss: 0.414307\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443151; batch adversarial loss: 0.343982\n",
      "epoch 39; iter: 0; batch classifier loss: 0.558804; batch adversarial loss: 0.320614\n",
      "epoch 40; iter: 0; batch classifier loss: 0.519498; batch adversarial loss: 0.387571\n",
      "epoch 41; iter: 0; batch classifier loss: 0.595777; batch adversarial loss: 0.407266\n",
      "epoch 42; iter: 0; batch classifier loss: 0.498029; batch adversarial loss: 0.337604\n",
      "epoch 43; iter: 0; batch classifier loss: 0.538203; batch adversarial loss: 0.351287\n",
      "epoch 44; iter: 0; batch classifier loss: 0.465065; batch adversarial loss: 0.315188\n",
      "epoch 45; iter: 0; batch classifier loss: 0.511785; batch adversarial loss: 0.340758\n",
      "epoch 46; iter: 0; batch classifier loss: 0.534250; batch adversarial loss: 0.301202\n",
      "epoch 47; iter: 0; batch classifier loss: 0.491270; batch adversarial loss: 0.268924\n",
      "epoch 48; iter: 0; batch classifier loss: 0.596003; batch adversarial loss: 0.383306\n",
      "epoch 49; iter: 0; batch classifier loss: 0.519332; batch adversarial loss: 0.368668\n",
      "epoch 50; iter: 0; batch classifier loss: 0.581616; batch adversarial loss: 0.313931\n",
      "epoch 51; iter: 0; batch classifier loss: 0.591104; batch adversarial loss: 0.364634\n",
      "epoch 52; iter: 0; batch classifier loss: 0.520268; batch adversarial loss: 0.282306\n",
      "epoch 53; iter: 0; batch classifier loss: 0.577221; batch adversarial loss: 0.399386\n",
      "epoch 54; iter: 0; batch classifier loss: 0.624904; batch adversarial loss: 0.278393\n",
      "epoch 55; iter: 0; batch classifier loss: 0.465651; batch adversarial loss: 0.249675\n",
      "epoch 56; iter: 0; batch classifier loss: 0.452222; batch adversarial loss: 0.352392\n",
      "epoch 57; iter: 0; batch classifier loss: 0.490968; batch adversarial loss: 0.352798\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423989; batch adversarial loss: 0.365730\n",
      "epoch 59; iter: 0; batch classifier loss: 0.465691; batch adversarial loss: 0.377494\n",
      "epoch 60; iter: 0; batch classifier loss: 0.488216; batch adversarial loss: 0.320140\n",
      "epoch 61; iter: 0; batch classifier loss: 0.460956; batch adversarial loss: 0.248970\n",
      "epoch 62; iter: 0; batch classifier loss: 0.479243; batch adversarial loss: 0.303518\n",
      "epoch 63; iter: 0; batch classifier loss: 0.458020; batch adversarial loss: 0.404519\n",
      "epoch 64; iter: 0; batch classifier loss: 0.361262; batch adversarial loss: 0.321266\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447418; batch adversarial loss: 0.257588\n",
      "epoch 66; iter: 0; batch classifier loss: 0.318298; batch adversarial loss: 0.330551\n",
      "epoch 67; iter: 0; batch classifier loss: 0.408964; batch adversarial loss: 0.344321\n",
      "epoch 68; iter: 0; batch classifier loss: 0.405262; batch adversarial loss: 0.343436\n",
      "epoch 69; iter: 0; batch classifier loss: 0.429217; batch adversarial loss: 0.280832\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422679; batch adversarial loss: 0.343354\n",
      "epoch 71; iter: 0; batch classifier loss: 0.485213; batch adversarial loss: 0.280130\n",
      "epoch 72; iter: 0; batch classifier loss: 0.408685; batch adversarial loss: 0.286671\n",
      "epoch 73; iter: 0; batch classifier loss: 0.368460; batch adversarial loss: 0.287030\n",
      "epoch 74; iter: 0; batch classifier loss: 0.464257; batch adversarial loss: 0.363920\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352261; batch adversarial loss: 0.308505\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366132; batch adversarial loss: 0.314786\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423660; batch adversarial loss: 0.336676\n",
      "epoch 78; iter: 0; batch classifier loss: 0.353056; batch adversarial loss: 0.228417\n",
      "epoch 79; iter: 0; batch classifier loss: 0.385516; batch adversarial loss: 0.366884\n",
      "epoch 80; iter: 0; batch classifier loss: 0.481889; batch adversarial loss: 0.418642\n",
      "epoch 81; iter: 0; batch classifier loss: 0.406367; batch adversarial loss: 0.278405\n",
      "epoch 82; iter: 0; batch classifier loss: 0.467031; batch adversarial loss: 0.271511\n",
      "epoch 83; iter: 0; batch classifier loss: 0.386242; batch adversarial loss: 0.276569\n",
      "epoch 84; iter: 0; batch classifier loss: 0.444398; batch adversarial loss: 0.268540\n",
      "epoch 85; iter: 0; batch classifier loss: 0.395517; batch adversarial loss: 0.396658\n",
      "epoch 86; iter: 0; batch classifier loss: 0.416566; batch adversarial loss: 0.296940\n",
      "epoch 87; iter: 0; batch classifier loss: 0.370328; batch adversarial loss: 0.312511\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423669; batch adversarial loss: 0.259693\n",
      "epoch 89; iter: 0; batch classifier loss: 0.385391; batch adversarial loss: 0.269964\n",
      "epoch 90; iter: 0; batch classifier loss: 0.451172; batch adversarial loss: 0.260174\n",
      "epoch 91; iter: 0; batch classifier loss: 0.411603; batch adversarial loss: 0.359847\n",
      "epoch 92; iter: 0; batch classifier loss: 0.371856; batch adversarial loss: 0.241870\n",
      "epoch 93; iter: 0; batch classifier loss: 0.342129; batch adversarial loss: 0.288213\n",
      "epoch 94; iter: 0; batch classifier loss: 0.384292; batch adversarial loss: 0.285332\n",
      "epoch 95; iter: 0; batch classifier loss: 0.414162; batch adversarial loss: 0.294034\n",
      "epoch 96; iter: 0; batch classifier loss: 0.370050; batch adversarial loss: 0.308975\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369277; batch adversarial loss: 0.289820\n",
      "epoch 98; iter: 0; batch classifier loss: 0.384232; batch adversarial loss: 0.254051\n",
      "epoch 99; iter: 0; batch classifier loss: 0.361465; batch adversarial loss: 0.228072\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.245735; batch adversarial loss: 0.926125\n",
      "epoch 2; iter: 0; batch classifier loss: 1.129608; batch adversarial loss: 0.799981\n",
      "epoch 3; iter: 0; batch classifier loss: 0.883383; batch adversarial loss: 0.819174\n",
      "epoch 4; iter: 0; batch classifier loss: 0.817421; batch adversarial loss: 0.724522\n",
      "epoch 5; iter: 0; batch classifier loss: 0.678558; batch adversarial loss: 0.663715\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584606; batch adversarial loss: 0.636047\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580637; batch adversarial loss: 0.612455\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551271; batch adversarial loss: 0.601581\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540312; batch adversarial loss: 0.573007\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540441; batch adversarial loss: 0.582437\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568611; batch adversarial loss: 0.541352\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529659; batch adversarial loss: 0.534948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13; iter: 0; batch classifier loss: 0.532924; batch adversarial loss: 0.528844\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513112; batch adversarial loss: 0.493442\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525666; batch adversarial loss: 0.474149\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592298; batch adversarial loss: 0.456495\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507290; batch adversarial loss: 0.463673\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542985; batch adversarial loss: 0.454126\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554726; batch adversarial loss: 0.462531\n",
      "epoch 20; iter: 0; batch classifier loss: 0.522402; batch adversarial loss: 0.435149\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545129; batch adversarial loss: 0.451437\n",
      "epoch 22; iter: 0; batch classifier loss: 0.580472; batch adversarial loss: 0.466657\n",
      "epoch 23; iter: 0; batch classifier loss: 0.530279; batch adversarial loss: 0.506684\n",
      "epoch 24; iter: 0; batch classifier loss: 0.585644; batch adversarial loss: 0.366633\n",
      "epoch 25; iter: 0; batch classifier loss: 0.557971; batch adversarial loss: 0.432243\n",
      "epoch 26; iter: 0; batch classifier loss: 0.649054; batch adversarial loss: 0.485129\n",
      "epoch 27; iter: 0; batch classifier loss: 0.701110; batch adversarial loss: 0.500447\n",
      "epoch 28; iter: 0; batch classifier loss: 0.613458; batch adversarial loss: 0.410545\n",
      "epoch 29; iter: 0; batch classifier loss: 0.531791; batch adversarial loss: 0.466463\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550487; batch adversarial loss: 0.382047\n",
      "epoch 31; iter: 0; batch classifier loss: 0.599888; batch adversarial loss: 0.403576\n",
      "epoch 32; iter: 0; batch classifier loss: 0.629044; batch adversarial loss: 0.430823\n",
      "epoch 33; iter: 0; batch classifier loss: 0.591538; batch adversarial loss: 0.395391\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544127; batch adversarial loss: 0.335549\n",
      "epoch 35; iter: 0; batch classifier loss: 0.667983; batch adversarial loss: 0.438532\n",
      "epoch 36; iter: 0; batch classifier loss: 0.549173; batch adversarial loss: 0.382283\n",
      "epoch 37; iter: 0; batch classifier loss: 0.591075; batch adversarial loss: 0.414461\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442523; batch adversarial loss: 0.344072\n",
      "epoch 39; iter: 0; batch classifier loss: 0.562553; batch adversarial loss: 0.320640\n",
      "epoch 40; iter: 0; batch classifier loss: 0.521688; batch adversarial loss: 0.387760\n",
      "epoch 41; iter: 0; batch classifier loss: 0.592517; batch adversarial loss: 0.407280\n",
      "epoch 42; iter: 0; batch classifier loss: 0.497654; batch adversarial loss: 0.337728\n",
      "epoch 43; iter: 0; batch classifier loss: 0.542961; batch adversarial loss: 0.351614\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463747; batch adversarial loss: 0.315150\n",
      "epoch 45; iter: 0; batch classifier loss: 0.514261; batch adversarial loss: 0.340747\n",
      "epoch 46; iter: 0; batch classifier loss: 0.535340; batch adversarial loss: 0.301193\n",
      "epoch 47; iter: 0; batch classifier loss: 0.491107; batch adversarial loss: 0.268797\n",
      "epoch 48; iter: 0; batch classifier loss: 0.593915; batch adversarial loss: 0.383466\n",
      "epoch 49; iter: 0; batch classifier loss: 0.524953; batch adversarial loss: 0.368760\n",
      "epoch 50; iter: 0; batch classifier loss: 0.592262; batch adversarial loss: 0.314098\n",
      "epoch 51; iter: 0; batch classifier loss: 0.597232; batch adversarial loss: 0.364662\n",
      "epoch 52; iter: 0; batch classifier loss: 0.518887; batch adversarial loss: 0.282341\n",
      "epoch 53; iter: 0; batch classifier loss: 0.578283; batch adversarial loss: 0.399452\n",
      "epoch 54; iter: 0; batch classifier loss: 0.623361; batch adversarial loss: 0.278398\n",
      "epoch 55; iter: 0; batch classifier loss: 0.462271; batch adversarial loss: 0.249701\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449396; batch adversarial loss: 0.352404\n",
      "epoch 57; iter: 0; batch classifier loss: 0.498651; batch adversarial loss: 0.352778\n",
      "epoch 58; iter: 0; batch classifier loss: 0.423543; batch adversarial loss: 0.365670\n",
      "epoch 59; iter: 0; batch classifier loss: 0.468485; batch adversarial loss: 0.377472\n",
      "epoch 60; iter: 0; batch classifier loss: 0.477305; batch adversarial loss: 0.320061\n",
      "epoch 61; iter: 0; batch classifier loss: 0.464610; batch adversarial loss: 0.248946\n",
      "epoch 62; iter: 0; batch classifier loss: 0.478848; batch adversarial loss: 0.303463\n",
      "epoch 63; iter: 0; batch classifier loss: 0.462353; batch adversarial loss: 0.404461\n",
      "epoch 64; iter: 0; batch classifier loss: 0.358508; batch adversarial loss: 0.321283\n",
      "epoch 65; iter: 0; batch classifier loss: 0.444320; batch adversarial loss: 0.257567\n",
      "epoch 66; iter: 0; batch classifier loss: 0.321373; batch adversarial loss: 0.330455\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407297; batch adversarial loss: 0.344183\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406012; batch adversarial loss: 0.343471\n",
      "epoch 69; iter: 0; batch classifier loss: 0.429750; batch adversarial loss: 0.280733\n",
      "epoch 70; iter: 0; batch classifier loss: 0.422486; batch adversarial loss: 0.343486\n",
      "epoch 71; iter: 0; batch classifier loss: 0.483055; batch adversarial loss: 0.280008\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411467; batch adversarial loss: 0.286463\n",
      "epoch 73; iter: 0; batch classifier loss: 0.365117; batch adversarial loss: 0.287120\n",
      "epoch 74; iter: 0; batch classifier loss: 0.465285; batch adversarial loss: 0.364400\n",
      "epoch 75; iter: 0; batch classifier loss: 0.352616; batch adversarial loss: 0.308483\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369677; batch adversarial loss: 0.314887\n",
      "epoch 77; iter: 0; batch classifier loss: 0.413338; batch adversarial loss: 0.336485\n",
      "epoch 78; iter: 0; batch classifier loss: 0.351473; batch adversarial loss: 0.228329\n",
      "epoch 79; iter: 0; batch classifier loss: 0.380224; batch adversarial loss: 0.366725\n",
      "epoch 80; iter: 0; batch classifier loss: 0.486384; batch adversarial loss: 0.418068\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419352; batch adversarial loss: 0.278483\n",
      "epoch 82; iter: 0; batch classifier loss: 0.468893; batch adversarial loss: 0.271876\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382645; batch adversarial loss: 0.276402\n",
      "epoch 84; iter: 0; batch classifier loss: 0.445992; batch adversarial loss: 0.269168\n",
      "epoch 85; iter: 0; batch classifier loss: 0.396837; batch adversarial loss: 0.396563\n",
      "epoch 86; iter: 0; batch classifier loss: 0.408696; batch adversarial loss: 0.296916\n",
      "epoch 87; iter: 0; batch classifier loss: 0.375762; batch adversarial loss: 0.312718\n",
      "epoch 88; iter: 0; batch classifier loss: 0.425535; batch adversarial loss: 0.259426\n",
      "epoch 89; iter: 0; batch classifier loss: 0.388307; batch adversarial loss: 0.269962\n",
      "epoch 90; iter: 0; batch classifier loss: 0.458585; batch adversarial loss: 0.259948\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410999; batch adversarial loss: 0.359590\n",
      "epoch 92; iter: 0; batch classifier loss: 0.386028; batch adversarial loss: 0.241875\n",
      "epoch 93; iter: 0; batch classifier loss: 0.342232; batch adversarial loss: 0.288173\n",
      "epoch 94; iter: 0; batch classifier loss: 0.379437; batch adversarial loss: 0.284938\n",
      "epoch 95; iter: 0; batch classifier loss: 0.413384; batch adversarial loss: 0.293972\n",
      "epoch 96; iter: 0; batch classifier loss: 0.379033; batch adversarial loss: 0.309121\n",
      "epoch 97; iter: 0; batch classifier loss: 0.363575; batch adversarial loss: 0.289901\n",
      "epoch 98; iter: 0; batch classifier loss: 0.374954; batch adversarial loss: 0.254219\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366936; batch adversarial loss: 0.227972\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.266344; batch adversarial loss: 0.926814\n",
      "epoch 2; iter: 0; batch classifier loss: 1.144944; batch adversarial loss: 0.800607\n",
      "epoch 3; iter: 0; batch classifier loss: 0.897158; batch adversarial loss: 0.820258\n",
      "epoch 4; iter: 0; batch classifier loss: 0.832151; batch adversarial loss: 0.725748\n",
      "epoch 5; iter: 0; batch classifier loss: 0.691661; batch adversarial loss: 0.665123\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587284; batch adversarial loss: 0.636096\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580181; batch adversarial loss: 0.612610\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550492; batch adversarial loss: 0.601655\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541044; batch adversarial loss: 0.572657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.538983; batch adversarial loss: 0.582328\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567630; batch adversarial loss: 0.541200\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528467; batch adversarial loss: 0.534771\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533187; batch adversarial loss: 0.528700\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510229; batch adversarial loss: 0.494128\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525118; batch adversarial loss: 0.474988\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591729; batch adversarial loss: 0.457154\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508276; batch adversarial loss: 0.464745\n",
      "epoch 18; iter: 0; batch classifier loss: 0.540974; batch adversarial loss: 0.454963\n",
      "epoch 19; iter: 0; batch classifier loss: 0.564932; batch adversarial loss: 0.466353\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532334; batch adversarial loss: 0.439901\n",
      "epoch 21; iter: 0; batch classifier loss: 0.555413; batch adversarial loss: 0.454671\n",
      "epoch 22; iter: 0; batch classifier loss: 0.590889; batch adversarial loss: 0.469356\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538483; batch adversarial loss: 0.507770\n",
      "epoch 24; iter: 0; batch classifier loss: 0.591054; batch adversarial loss: 0.367949\n",
      "epoch 25; iter: 0; batch classifier loss: 0.566283; batch adversarial loss: 0.433856\n",
      "epoch 26; iter: 0; batch classifier loss: 0.658986; batch adversarial loss: 0.486054\n",
      "epoch 27; iter: 0; batch classifier loss: 0.710459; batch adversarial loss: 0.500587\n",
      "epoch 28; iter: 0; batch classifier loss: 0.617207; batch adversarial loss: 0.410776\n",
      "epoch 29; iter: 0; batch classifier loss: 0.536478; batch adversarial loss: 0.466194\n",
      "epoch 30; iter: 0; batch classifier loss: 0.552570; batch adversarial loss: 0.382074\n",
      "epoch 31; iter: 0; batch classifier loss: 0.608367; batch adversarial loss: 0.403477\n",
      "epoch 32; iter: 0; batch classifier loss: 0.634655; batch adversarial loss: 0.430391\n",
      "epoch 33; iter: 0; batch classifier loss: 0.593519; batch adversarial loss: 0.395067\n",
      "epoch 34; iter: 0; batch classifier loss: 0.546077; batch adversarial loss: 0.335382\n",
      "epoch 35; iter: 0; batch classifier loss: 0.666599; batch adversarial loss: 0.437758\n",
      "epoch 36; iter: 0; batch classifier loss: 0.550588; batch adversarial loss: 0.381675\n",
      "epoch 37; iter: 0; batch classifier loss: 0.594345; batch adversarial loss: 0.414101\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444159; batch adversarial loss: 0.343378\n",
      "epoch 39; iter: 0; batch classifier loss: 0.564196; batch adversarial loss: 0.320143\n",
      "epoch 40; iter: 0; batch classifier loss: 0.522991; batch adversarial loss: 0.387092\n",
      "epoch 41; iter: 0; batch classifier loss: 0.591765; batch adversarial loss: 0.406539\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496167; batch adversarial loss: 0.337275\n",
      "epoch 43; iter: 0; batch classifier loss: 0.536024; batch adversarial loss: 0.350545\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462927; batch adversarial loss: 0.315007\n",
      "epoch 45; iter: 0; batch classifier loss: 0.512770; batch adversarial loss: 0.340396\n",
      "epoch 46; iter: 0; batch classifier loss: 0.526409; batch adversarial loss: 0.300723\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483587; batch adversarial loss: 0.268810\n",
      "epoch 48; iter: 0; batch classifier loss: 0.596549; batch adversarial loss: 0.382934\n",
      "epoch 49; iter: 0; batch classifier loss: 0.521650; batch adversarial loss: 0.368210\n",
      "epoch 50; iter: 0; batch classifier loss: 0.594992; batch adversarial loss: 0.313856\n",
      "epoch 51; iter: 0; batch classifier loss: 0.603629; batch adversarial loss: 0.364258\n",
      "epoch 52; iter: 0; batch classifier loss: 0.517594; batch adversarial loss: 0.282159\n",
      "epoch 53; iter: 0; batch classifier loss: 0.576196; batch adversarial loss: 0.398656\n",
      "epoch 54; iter: 0; batch classifier loss: 0.629618; batch adversarial loss: 0.278078\n",
      "epoch 55; iter: 0; batch classifier loss: 0.460251; batch adversarial loss: 0.249464\n",
      "epoch 56; iter: 0; batch classifier loss: 0.447224; batch adversarial loss: 0.352195\n",
      "epoch 57; iter: 0; batch classifier loss: 0.494073; batch adversarial loss: 0.352749\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426398; batch adversarial loss: 0.365653\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462204; batch adversarial loss: 0.377505\n",
      "epoch 60; iter: 0; batch classifier loss: 0.490302; batch adversarial loss: 0.320180\n",
      "epoch 61; iter: 0; batch classifier loss: 0.464034; batch adversarial loss: 0.248894\n",
      "epoch 62; iter: 0; batch classifier loss: 0.484627; batch adversarial loss: 0.303535\n",
      "epoch 63; iter: 0; batch classifier loss: 0.465871; batch adversarial loss: 0.404412\n",
      "epoch 64; iter: 0; batch classifier loss: 0.368510; batch adversarial loss: 0.321208\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447953; batch adversarial loss: 0.257584\n",
      "epoch 66; iter: 0; batch classifier loss: 0.322090; batch adversarial loss: 0.330452\n",
      "epoch 67; iter: 0; batch classifier loss: 0.404978; batch adversarial loss: 0.344263\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410231; batch adversarial loss: 0.343225\n",
      "epoch 69; iter: 0; batch classifier loss: 0.431931; batch adversarial loss: 0.280862\n",
      "epoch 70; iter: 0; batch classifier loss: 0.429264; batch adversarial loss: 0.343453\n",
      "epoch 71; iter: 0; batch classifier loss: 0.484493; batch adversarial loss: 0.279915\n",
      "epoch 72; iter: 0; batch classifier loss: 0.416598; batch adversarial loss: 0.286362\n",
      "epoch 73; iter: 0; batch classifier loss: 0.365367; batch adversarial loss: 0.286917\n",
      "epoch 74; iter: 0; batch classifier loss: 0.457343; batch adversarial loss: 0.364022\n",
      "epoch 75; iter: 0; batch classifier loss: 0.356525; batch adversarial loss: 0.308481\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366395; batch adversarial loss: 0.314708\n",
      "epoch 77; iter: 0; batch classifier loss: 0.421842; batch adversarial loss: 0.336648\n",
      "epoch 78; iter: 0; batch classifier loss: 0.353687; batch adversarial loss: 0.228411\n",
      "epoch 79; iter: 0; batch classifier loss: 0.384976; batch adversarial loss: 0.366682\n",
      "epoch 80; iter: 0; batch classifier loss: 0.472962; batch adversarial loss: 0.418468\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419393; batch adversarial loss: 0.278284\n",
      "epoch 82; iter: 0; batch classifier loss: 0.454898; batch adversarial loss: 0.271713\n",
      "epoch 83; iter: 0; batch classifier loss: 0.387010; batch adversarial loss: 0.276531\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446294; batch adversarial loss: 0.268599\n",
      "epoch 85; iter: 0; batch classifier loss: 0.393186; batch adversarial loss: 0.396651\n",
      "epoch 86; iter: 0; batch classifier loss: 0.402076; batch adversarial loss: 0.297178\n",
      "epoch 87; iter: 0; batch classifier loss: 0.367729; batch adversarial loss: 0.313048\n",
      "epoch 88; iter: 0; batch classifier loss: 0.420622; batch adversarial loss: 0.259503\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383082; batch adversarial loss: 0.269985\n",
      "epoch 90; iter: 0; batch classifier loss: 0.444495; batch adversarial loss: 0.260167\n",
      "epoch 91; iter: 0; batch classifier loss: 0.409363; batch adversarial loss: 0.359583\n",
      "epoch 92; iter: 0; batch classifier loss: 0.376459; batch adversarial loss: 0.241655\n",
      "epoch 93; iter: 0; batch classifier loss: 0.339124; batch adversarial loss: 0.288390\n",
      "epoch 94; iter: 0; batch classifier loss: 0.381466; batch adversarial loss: 0.285342\n",
      "epoch 95; iter: 0; batch classifier loss: 0.428971; batch adversarial loss: 0.294135\n",
      "epoch 96; iter: 0; batch classifier loss: 0.375804; batch adversarial loss: 0.308889\n",
      "epoch 97; iter: 0; batch classifier loss: 0.368509; batch adversarial loss: 0.289487\n",
      "epoch 98; iter: 0; batch classifier loss: 0.386943; batch adversarial loss: 0.254597\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363612; batch adversarial loss: 0.227678\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697777; batch adversarial loss: 0.845058\n",
      "epoch 1; iter: 0; batch classifier loss: 1.132847; batch adversarial loss: 0.920906\n",
      "epoch 2; iter: 0; batch classifier loss: 1.132719; batch adversarial loss: 0.803628\n",
      "epoch 3; iter: 0; batch classifier loss: 0.861458; batch adversarial loss: 0.818901\n",
      "epoch 4; iter: 0; batch classifier loss: 0.781220; batch adversarial loss: 0.728630\n",
      "epoch 5; iter: 0; batch classifier loss: 0.689725; batch adversarial loss: 0.677508\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572757; batch adversarial loss: 0.642657\n",
      "epoch 7; iter: 0; batch classifier loss: 0.552573; batch adversarial loss: 0.615346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.553785; batch adversarial loss: 0.601845\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534020; batch adversarial loss: 0.574257\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507327; batch adversarial loss: 0.584686\n",
      "epoch 11; iter: 0; batch classifier loss: 0.547973; batch adversarial loss: 0.545265\n",
      "epoch 12; iter: 0; batch classifier loss: 0.512983; batch adversarial loss: 0.537215\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520526; batch adversarial loss: 0.533594\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480947; batch adversarial loss: 0.499769\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485495; batch adversarial loss: 0.478489\n",
      "epoch 16; iter: 0; batch classifier loss: 0.605288; batch adversarial loss: 0.452764\n",
      "epoch 17; iter: 0; batch classifier loss: 0.478506; batch adversarial loss: 0.465857\n",
      "epoch 18; iter: 0; batch classifier loss: 0.506165; batch adversarial loss: 0.460500\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527021; batch adversarial loss: 0.461954\n",
      "epoch 20; iter: 0; batch classifier loss: 0.479573; batch adversarial loss: 0.437825\n",
      "epoch 21; iter: 0; batch classifier loss: 0.540166; batch adversarial loss: 0.446799\n",
      "epoch 22; iter: 0; batch classifier loss: 0.540879; batch adversarial loss: 0.460220\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501774; batch adversarial loss: 0.505598\n",
      "epoch 24; iter: 0; batch classifier loss: 0.499854; batch adversarial loss: 0.367075\n",
      "epoch 25; iter: 0; batch classifier loss: 0.535910; batch adversarial loss: 0.425294\n",
      "epoch 26; iter: 0; batch classifier loss: 0.633118; batch adversarial loss: 0.486378\n",
      "epoch 27; iter: 0; batch classifier loss: 0.649178; batch adversarial loss: 0.501116\n",
      "epoch 28; iter: 0; batch classifier loss: 0.586456; batch adversarial loss: 0.411082\n",
      "epoch 29; iter: 0; batch classifier loss: 0.517890; batch adversarial loss: 0.465008\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504602; batch adversarial loss: 0.381160\n",
      "epoch 31; iter: 0; batch classifier loss: 0.545834; batch adversarial loss: 0.402877\n",
      "epoch 32; iter: 0; batch classifier loss: 0.571383; batch adversarial loss: 0.430612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.544227; batch adversarial loss: 0.392962\n",
      "epoch 34; iter: 0; batch classifier loss: 0.545467; batch adversarial loss: 0.337555\n",
      "epoch 35; iter: 0; batch classifier loss: 0.589294; batch adversarial loss: 0.438630\n",
      "epoch 36; iter: 0; batch classifier loss: 0.489476; batch adversarial loss: 0.381052\n",
      "epoch 37; iter: 0; batch classifier loss: 0.531303; batch adversarial loss: 0.413466\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440620; batch adversarial loss: 0.341146\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478438; batch adversarial loss: 0.322888\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477130; batch adversarial loss: 0.390108\n",
      "epoch 41; iter: 0; batch classifier loss: 0.531198; batch adversarial loss: 0.407268\n",
      "epoch 42; iter: 0; batch classifier loss: 0.455453; batch adversarial loss: 0.337036\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478667; batch adversarial loss: 0.352168\n",
      "epoch 44; iter: 0; batch classifier loss: 0.409358; batch adversarial loss: 0.314860\n",
      "epoch 45; iter: 0; batch classifier loss: 0.488029; batch adversarial loss: 0.340716\n",
      "epoch 46; iter: 0; batch classifier loss: 0.516274; batch adversarial loss: 0.300818\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466052; batch adversarial loss: 0.269790\n",
      "epoch 48; iter: 0; batch classifier loss: 0.602409; batch adversarial loss: 0.383548\n",
      "epoch 49; iter: 0; batch classifier loss: 0.489798; batch adversarial loss: 0.367445\n",
      "epoch 50; iter: 0; batch classifier loss: 0.542625; batch adversarial loss: 0.313675\n",
      "epoch 51; iter: 0; batch classifier loss: 0.592192; batch adversarial loss: 0.362351\n",
      "epoch 52; iter: 0; batch classifier loss: 0.492945; batch adversarial loss: 0.281661\n",
      "epoch 53; iter: 0; batch classifier loss: 0.393505; batch adversarial loss: 0.393421\n",
      "epoch 54; iter: 0; batch classifier loss: 0.422624; batch adversarial loss: 0.276028\n",
      "epoch 55; iter: 0; batch classifier loss: 0.410599; batch adversarial loss: 0.247819\n",
      "epoch 56; iter: 0; batch classifier loss: 0.399550; batch adversarial loss: 0.350846\n",
      "epoch 57; iter: 0; batch classifier loss: 0.398162; batch adversarial loss: 0.352542\n",
      "epoch 58; iter: 0; batch classifier loss: 0.331183; batch adversarial loss: 0.365842\n",
      "epoch 59; iter: 0; batch classifier loss: 0.412497; batch adversarial loss: 0.377841\n",
      "epoch 60; iter: 0; batch classifier loss: 0.366250; batch adversarial loss: 0.318053\n",
      "epoch 61; iter: 0; batch classifier loss: 0.392080; batch adversarial loss: 0.247529\n",
      "epoch 62; iter: 0; batch classifier loss: 0.408089; batch adversarial loss: 0.302369\n",
      "epoch 63; iter: 0; batch classifier loss: 0.359276; batch adversarial loss: 0.404198\n",
      "epoch 64; iter: 0; batch classifier loss: 0.349458; batch adversarial loss: 0.323101\n",
      "epoch 65; iter: 0; batch classifier loss: 0.329725; batch adversarial loss: 0.256110\n",
      "epoch 66; iter: 0; batch classifier loss: 0.278672; batch adversarial loss: 0.330306\n",
      "epoch 67; iter: 0; batch classifier loss: 0.328037; batch adversarial loss: 0.343925\n",
      "epoch 68; iter: 0; batch classifier loss: 0.357267; batch adversarial loss: 0.341789\n",
      "epoch 69; iter: 0; batch classifier loss: 0.384337; batch adversarial loss: 0.280033\n",
      "epoch 70; iter: 0; batch classifier loss: 0.353641; batch adversarial loss: 0.343712\n",
      "epoch 71; iter: 0; batch classifier loss: 0.366546; batch adversarial loss: 0.279410\n",
      "epoch 72; iter: 0; batch classifier loss: 0.371418; batch adversarial loss: 0.287010\n",
      "epoch 73; iter: 0; batch classifier loss: 0.296238; batch adversarial loss: 0.288728\n",
      "epoch 74; iter: 0; batch classifier loss: 0.361766; batch adversarial loss: 0.366256\n",
      "epoch 75; iter: 0; batch classifier loss: 0.278991; batch adversarial loss: 0.307118\n",
      "epoch 76; iter: 0; batch classifier loss: 0.287540; batch adversarial loss: 0.314607\n",
      "epoch 77; iter: 0; batch classifier loss: 0.352075; batch adversarial loss: 0.334193\n",
      "epoch 78; iter: 0; batch classifier loss: 0.298358; batch adversarial loss: 0.227951\n",
      "epoch 79; iter: 0; batch classifier loss: 0.295034; batch adversarial loss: 0.367711\n",
      "epoch 80; iter: 0; batch classifier loss: 0.352994; batch adversarial loss: 0.417252\n",
      "epoch 81; iter: 0; batch classifier loss: 0.332228; batch adversarial loss: 0.279513\n",
      "epoch 82; iter: 0; batch classifier loss: 0.386783; batch adversarial loss: 0.271493\n",
      "epoch 83; iter: 0; batch classifier loss: 0.263440; batch adversarial loss: 0.277251\n",
      "epoch 84; iter: 0; batch classifier loss: 0.349378; batch adversarial loss: 0.270387\n",
      "epoch 85; iter: 0; batch classifier loss: 0.367229; batch adversarial loss: 0.397888\n",
      "epoch 86; iter: 0; batch classifier loss: 0.304793; batch adversarial loss: 0.294539\n",
      "epoch 87; iter: 0; batch classifier loss: 0.323891; batch adversarial loss: 0.313224\n",
      "epoch 88; iter: 0; batch classifier loss: 0.396944; batch adversarial loss: 0.261679\n",
      "epoch 89; iter: 0; batch classifier loss: 0.345971; batch adversarial loss: 0.269479\n",
      "epoch 90; iter: 0; batch classifier loss: 0.390308; batch adversarial loss: 0.258003\n",
      "epoch 91; iter: 0; batch classifier loss: 0.328095; batch adversarial loss: 0.358598\n",
      "epoch 92; iter: 0; batch classifier loss: 0.325421; batch adversarial loss: 0.241985\n",
      "epoch 93; iter: 0; batch classifier loss: 0.285068; batch adversarial loss: 0.289980\n",
      "epoch 94; iter: 0; batch classifier loss: 0.319756; batch adversarial loss: 0.284969\n",
      "epoch 95; iter: 0; batch classifier loss: 0.313897; batch adversarial loss: 0.295162\n",
      "epoch 96; iter: 0; batch classifier loss: 0.302984; batch adversarial loss: 0.309123\n",
      "epoch 97; iter: 0; batch classifier loss: 0.285876; batch adversarial loss: 0.290170\n",
      "epoch 98; iter: 0; batch classifier loss: 0.299915; batch adversarial loss: 0.254731\n",
      "epoch 99; iter: 0; batch classifier loss: 0.338447; batch adversarial loss: 0.227254\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.266341; batch adversarial loss: 0.926814\n",
      "epoch 2; iter: 0; batch classifier loss: 1.144942; batch adversarial loss: 0.800607\n",
      "epoch 3; iter: 0; batch classifier loss: 0.897157; batch adversarial loss: 0.820258\n",
      "epoch 4; iter: 0; batch classifier loss: 0.832149; batch adversarial loss: 0.725748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.691659; batch adversarial loss: 0.665123\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587283; batch adversarial loss: 0.636096\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580181; batch adversarial loss: 0.612610\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550492; batch adversarial loss: 0.601655\n",
      "epoch 9; iter: 0; batch classifier loss: 0.541044; batch adversarial loss: 0.572657\n",
      "epoch 10; iter: 0; batch classifier loss: 0.538983; batch adversarial loss: 0.582328\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567649; batch adversarial loss: 0.541197\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528452; batch adversarial loss: 0.534772\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533164; batch adversarial loss: 0.528707\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510160; batch adversarial loss: 0.494117\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525096; batch adversarial loss: 0.474998\n",
      "epoch 16; iter: 0; batch classifier loss: 0.591825; batch adversarial loss: 0.457179\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508313; batch adversarial loss: 0.464715\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541081; batch adversarial loss: 0.454924\n",
      "epoch 19; iter: 0; batch classifier loss: 0.565360; batch adversarial loss: 0.466341\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532303; batch adversarial loss: 0.439893\n",
      "epoch 21; iter: 0; batch classifier loss: 0.556679; batch adversarial loss: 0.454720\n",
      "epoch 22; iter: 0; batch classifier loss: 0.589937; batch adversarial loss: 0.469331\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538201; batch adversarial loss: 0.507745\n",
      "epoch 24; iter: 0; batch classifier loss: 0.590467; batch adversarial loss: 0.367782\n",
      "epoch 25; iter: 0; batch classifier loss: 0.566422; batch adversarial loss: 0.433621\n",
      "epoch 26; iter: 0; batch classifier loss: 0.660269; batch adversarial loss: 0.486067\n",
      "epoch 27; iter: 0; batch classifier loss: 0.711811; batch adversarial loss: 0.500694\n",
      "epoch 28; iter: 0; batch classifier loss: 0.618122; batch adversarial loss: 0.410774\n",
      "epoch 29; iter: 0; batch classifier loss: 0.534509; batch adversarial loss: 0.465930\n",
      "epoch 30; iter: 0; batch classifier loss: 0.551717; batch adversarial loss: 0.382020\n",
      "epoch 31; iter: 0; batch classifier loss: 0.609587; batch adversarial loss: 0.403660\n",
      "epoch 32; iter: 0; batch classifier loss: 0.636248; batch adversarial loss: 0.430502\n",
      "epoch 33; iter: 0; batch classifier loss: 0.596133; batch adversarial loss: 0.395266\n",
      "epoch 34; iter: 0; batch classifier loss: 0.545652; batch adversarial loss: 0.335499\n",
      "epoch 35; iter: 0; batch classifier loss: 0.664510; batch adversarial loss: 0.437736\n",
      "epoch 36; iter: 0; batch classifier loss: 0.550197; batch adversarial loss: 0.381683\n",
      "epoch 37; iter: 0; batch classifier loss: 0.592302; batch adversarial loss: 0.414063\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443226; batch adversarial loss: 0.343324\n",
      "epoch 39; iter: 0; batch classifier loss: 0.563575; batch adversarial loss: 0.320169\n",
      "epoch 40; iter: 0; batch classifier loss: 0.524190; batch adversarial loss: 0.387366\n",
      "epoch 41; iter: 0; batch classifier loss: 0.588845; batch adversarial loss: 0.406351\n",
      "epoch 42; iter: 0; batch classifier loss: 0.499101; batch adversarial loss: 0.337289\n",
      "epoch 43; iter: 0; batch classifier loss: 0.536278; batch adversarial loss: 0.350574\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463291; batch adversarial loss: 0.314978\n",
      "epoch 45; iter: 0; batch classifier loss: 0.514693; batch adversarial loss: 0.340410\n",
      "epoch 46; iter: 0; batch classifier loss: 0.528981; batch adversarial loss: 0.300755\n",
      "epoch 47; iter: 0; batch classifier loss: 0.485583; batch adversarial loss: 0.268782\n",
      "epoch 48; iter: 0; batch classifier loss: 0.596182; batch adversarial loss: 0.382874\n",
      "epoch 49; iter: 0; batch classifier loss: 0.518606; batch adversarial loss: 0.368143\n",
      "epoch 50; iter: 0; batch classifier loss: 0.596201; batch adversarial loss: 0.313724\n",
      "epoch 51; iter: 0; batch classifier loss: 0.599305; batch adversarial loss: 0.364178\n",
      "epoch 52; iter: 0; batch classifier loss: 0.514389; batch adversarial loss: 0.282136\n",
      "epoch 53; iter: 0; batch classifier loss: 0.573282; batch adversarial loss: 0.398726\n",
      "epoch 54; iter: 0; batch classifier loss: 0.630646; batch adversarial loss: 0.278093\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459229; batch adversarial loss: 0.249489\n",
      "epoch 56; iter: 0; batch classifier loss: 0.450011; batch adversarial loss: 0.352222\n",
      "epoch 57; iter: 0; batch classifier loss: 0.496904; batch adversarial loss: 0.352798\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426613; batch adversarial loss: 0.365642\n",
      "epoch 59; iter: 0; batch classifier loss: 0.462454; batch adversarial loss: 0.377523\n",
      "epoch 60; iter: 0; batch classifier loss: 0.488786; batch adversarial loss: 0.320142\n",
      "epoch 61; iter: 0; batch classifier loss: 0.460318; batch adversarial loss: 0.248862\n",
      "epoch 62; iter: 0; batch classifier loss: 0.484651; batch adversarial loss: 0.303523\n",
      "epoch 63; iter: 0; batch classifier loss: 0.464383; batch adversarial loss: 0.404480\n",
      "epoch 64; iter: 0; batch classifier loss: 0.367067; batch adversarial loss: 0.321101\n",
      "epoch 65; iter: 0; batch classifier loss: 0.447487; batch adversarial loss: 0.257537\n",
      "epoch 66; iter: 0; batch classifier loss: 0.318171; batch adversarial loss: 0.330341\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406545; batch adversarial loss: 0.344182\n",
      "epoch 68; iter: 0; batch classifier loss: 0.412071; batch adversarial loss: 0.343329\n",
      "epoch 69; iter: 0; batch classifier loss: 0.430446; batch adversarial loss: 0.280852\n",
      "epoch 70; iter: 0; batch classifier loss: 0.428452; batch adversarial loss: 0.343468\n",
      "epoch 71; iter: 0; batch classifier loss: 0.484079; batch adversarial loss: 0.279964\n",
      "epoch 72; iter: 0; batch classifier loss: 0.419688; batch adversarial loss: 0.286326\n",
      "epoch 73; iter: 0; batch classifier loss: 0.368685; batch adversarial loss: 0.286704\n",
      "epoch 74; iter: 0; batch classifier loss: 0.458929; batch adversarial loss: 0.363856\n",
      "epoch 75; iter: 0; batch classifier loss: 0.355316; batch adversarial loss: 0.308519\n",
      "epoch 76; iter: 0; batch classifier loss: 0.367559; batch adversarial loss: 0.314782\n",
      "epoch 77; iter: 0; batch classifier loss: 0.423154; batch adversarial loss: 0.336655\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352841; batch adversarial loss: 0.228469\n",
      "epoch 79; iter: 0; batch classifier loss: 0.382931; batch adversarial loss: 0.366603\n",
      "epoch 80; iter: 0; batch classifier loss: 0.476574; batch adversarial loss: 0.418315\n",
      "epoch 81; iter: 0; batch classifier loss: 0.418010; batch adversarial loss: 0.278409\n",
      "epoch 82; iter: 0; batch classifier loss: 0.451795; batch adversarial loss: 0.271697\n",
      "epoch 83; iter: 0; batch classifier loss: 0.381057; batch adversarial loss: 0.276612\n",
      "epoch 84; iter: 0; batch classifier loss: 0.446095; batch adversarial loss: 0.268713\n",
      "epoch 85; iter: 0; batch classifier loss: 0.387662; batch adversarial loss: 0.396784\n",
      "epoch 86; iter: 0; batch classifier loss: 0.408932; batch adversarial loss: 0.297283\n",
      "epoch 87; iter: 0; batch classifier loss: 0.371549; batch adversarial loss: 0.312886\n",
      "epoch 88; iter: 0; batch classifier loss: 0.424197; batch adversarial loss: 0.259295\n",
      "epoch 89; iter: 0; batch classifier loss: 0.382831; batch adversarial loss: 0.270028\n",
      "epoch 90; iter: 0; batch classifier loss: 0.447616; batch adversarial loss: 0.260130\n",
      "epoch 91; iter: 0; batch classifier loss: 0.402604; batch adversarial loss: 0.359170\n",
      "epoch 92; iter: 0; batch classifier loss: 0.372329; batch adversarial loss: 0.241624\n",
      "epoch 93; iter: 0; batch classifier loss: 0.340814; batch adversarial loss: 0.288398\n",
      "epoch 94; iter: 0; batch classifier loss: 0.382826; batch adversarial loss: 0.285404\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417998; batch adversarial loss: 0.293641\n",
      "epoch 96; iter: 0; batch classifier loss: 0.374569; batch adversarial loss: 0.309067\n",
      "epoch 97; iter: 0; batch classifier loss: 0.365823; batch adversarial loss: 0.289578\n",
      "epoch 98; iter: 0; batch classifier loss: 0.387202; batch adversarial loss: 0.254659\n",
      "epoch 99; iter: 0; batch classifier loss: 0.366066; batch adversarial loss: 0.227710\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.264566; batch adversarial loss: 0.926757\n",
      "epoch 2; iter: 0; batch classifier loss: 1.143818; batch adversarial loss: 0.800554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.896040; batch adversarial loss: 0.820231\n",
      "epoch 4; iter: 0; batch classifier loss: 0.831314; batch adversarial loss: 0.725613\n",
      "epoch 5; iter: 0; batch classifier loss: 0.690246; batch adversarial loss: 0.664956\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587230; batch adversarial loss: 0.635984\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580231; batch adversarial loss: 0.612576\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550619; batch adversarial loss: 0.601647\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540662; batch adversarial loss: 0.572724\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539038; batch adversarial loss: 0.582336\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567954; batch adversarial loss: 0.541178\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528278; batch adversarial loss: 0.534862\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532537; batch adversarial loss: 0.528788\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509658; batch adversarial loss: 0.494152\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524743; batch adversarial loss: 0.475003\n",
      "epoch 16; iter: 0; batch classifier loss: 0.590867; batch adversarial loss: 0.457141\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507850; batch adversarial loss: 0.464658\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539483; batch adversarial loss: 0.454772\n",
      "epoch 19; iter: 0; batch classifier loss: 0.563415; batch adversarial loss: 0.465974\n",
      "epoch 20; iter: 0; batch classifier loss: 0.530744; batch adversarial loss: 0.439968\n",
      "epoch 21; iter: 0; batch classifier loss: 0.555089; batch adversarial loss: 0.454779\n",
      "epoch 22; iter: 0; batch classifier loss: 0.590050; batch adversarial loss: 0.469332\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538013; batch adversarial loss: 0.507505\n",
      "epoch 24; iter: 0; batch classifier loss: 0.589201; batch adversarial loss: 0.367648\n",
      "epoch 25; iter: 0; batch classifier loss: 0.567464; batch adversarial loss: 0.433112\n",
      "epoch 26; iter: 0; batch classifier loss: 0.656384; batch adversarial loss: 0.485514\n",
      "epoch 27; iter: 0; batch classifier loss: 0.706800; batch adversarial loss: 0.500290\n",
      "epoch 28; iter: 0; batch classifier loss: 0.619222; batch adversarial loss: 0.410785\n",
      "epoch 29; iter: 0; batch classifier loss: 0.530386; batch adversarial loss: 0.465505\n",
      "epoch 30; iter: 0; batch classifier loss: 0.550797; batch adversarial loss: 0.382070\n",
      "epoch 31; iter: 0; batch classifier loss: 0.605733; batch adversarial loss: 0.403367\n",
      "epoch 32; iter: 0; batch classifier loss: 0.636028; batch adversarial loss: 0.430527\n",
      "epoch 33; iter: 0; batch classifier loss: 0.589520; batch adversarial loss: 0.395297\n",
      "epoch 34; iter: 0; batch classifier loss: 0.549381; batch adversarial loss: 0.335554\n",
      "epoch 35; iter: 0; batch classifier loss: 0.670664; batch adversarial loss: 0.437764\n",
      "epoch 36; iter: 0; batch classifier loss: 0.551273; batch adversarial loss: 0.381657\n",
      "epoch 37; iter: 0; batch classifier loss: 0.593136; batch adversarial loss: 0.414148\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441905; batch adversarial loss: 0.343625\n",
      "epoch 39; iter: 0; batch classifier loss: 0.558953; batch adversarial loss: 0.320164\n",
      "epoch 40; iter: 0; batch classifier loss: 0.520216; batch adversarial loss: 0.386999\n",
      "epoch 41; iter: 0; batch classifier loss: 0.598175; batch adversarial loss: 0.406809\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501431; batch adversarial loss: 0.337292\n",
      "epoch 43; iter: 0; batch classifier loss: 0.539729; batch adversarial loss: 0.350985\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466790; batch adversarial loss: 0.314815\n",
      "epoch 45; iter: 0; batch classifier loss: 0.511276; batch adversarial loss: 0.340330\n",
      "epoch 46; iter: 0; batch classifier loss: 0.529640; batch adversarial loss: 0.300761\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487538; batch adversarial loss: 0.268682\n",
      "epoch 48; iter: 0; batch classifier loss: 0.594132; batch adversarial loss: 0.382842\n",
      "epoch 49; iter: 0; batch classifier loss: 0.517484; batch adversarial loss: 0.368274\n",
      "epoch 50; iter: 0; batch classifier loss: 0.586683; batch adversarial loss: 0.313800\n",
      "epoch 51; iter: 0; batch classifier loss: 0.599090; batch adversarial loss: 0.364240\n",
      "epoch 52; iter: 0; batch classifier loss: 0.520740; batch adversarial loss: 0.282176\n",
      "epoch 53; iter: 0; batch classifier loss: 0.573651; batch adversarial loss: 0.398779\n",
      "epoch 54; iter: 0; batch classifier loss: 0.630073; batch adversarial loss: 0.278115\n",
      "epoch 55; iter: 0; batch classifier loss: 0.467881; batch adversarial loss: 0.249498\n",
      "epoch 56; iter: 0; batch classifier loss: 0.449990; batch adversarial loss: 0.352278\n",
      "epoch 57; iter: 0; batch classifier loss: 0.491791; batch adversarial loss: 0.352737\n",
      "epoch 58; iter: 0; batch classifier loss: 0.425842; batch adversarial loss: 0.365680\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467980; batch adversarial loss: 0.377482\n",
      "epoch 60; iter: 0; batch classifier loss: 0.482431; batch adversarial loss: 0.320044\n",
      "epoch 61; iter: 0; batch classifier loss: 0.462041; batch adversarial loss: 0.248852\n",
      "epoch 62; iter: 0; batch classifier loss: 0.483451; batch adversarial loss: 0.303535\n",
      "epoch 63; iter: 0; batch classifier loss: 0.461101; batch adversarial loss: 0.404514\n",
      "epoch 64; iter: 0; batch classifier loss: 0.368309; batch adversarial loss: 0.321273\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448814; batch adversarial loss: 0.257549\n",
      "epoch 66; iter: 0; batch classifier loss: 0.321973; batch adversarial loss: 0.330461\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412462; batch adversarial loss: 0.344378\n",
      "epoch 68; iter: 0; batch classifier loss: 0.411772; batch adversarial loss: 0.343592\n",
      "epoch 69; iter: 0; batch classifier loss: 0.431172; batch adversarial loss: 0.280910\n",
      "epoch 70; iter: 0; batch classifier loss: 0.431767; batch adversarial loss: 0.343444\n",
      "epoch 71; iter: 0; batch classifier loss: 0.481493; batch adversarial loss: 0.280065\n",
      "epoch 72; iter: 0; batch classifier loss: 0.412206; batch adversarial loss: 0.286437\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366161; batch adversarial loss: 0.287056\n",
      "epoch 74; iter: 0; batch classifier loss: 0.455436; batch adversarial loss: 0.363963\n",
      "epoch 75; iter: 0; batch classifier loss: 0.359725; batch adversarial loss: 0.308592\n",
      "epoch 76; iter: 0; batch classifier loss: 0.365044; batch adversarial loss: 0.314769\n",
      "epoch 77; iter: 0; batch classifier loss: 0.409522; batch adversarial loss: 0.336684\n",
      "epoch 78; iter: 0; batch classifier loss: 0.361384; batch adversarial loss: 0.228450\n",
      "epoch 79; iter: 0; batch classifier loss: 0.388794; batch adversarial loss: 0.366990\n",
      "epoch 80; iter: 0; batch classifier loss: 0.476306; batch adversarial loss: 0.418373\n",
      "epoch 81; iter: 0; batch classifier loss: 0.424850; batch adversarial loss: 0.278511\n",
      "epoch 82; iter: 0; batch classifier loss: 0.466085; batch adversarial loss: 0.272053\n",
      "epoch 83; iter: 0; batch classifier loss: 0.382513; batch adversarial loss: 0.276469\n",
      "epoch 84; iter: 0; batch classifier loss: 0.447261; batch adversarial loss: 0.268765\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392073; batch adversarial loss: 0.396691\n",
      "epoch 86; iter: 0; batch classifier loss: 0.407151; batch adversarial loss: 0.296939\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380312; batch adversarial loss: 0.312866\n",
      "epoch 88; iter: 0; batch classifier loss: 0.419954; batch adversarial loss: 0.259721\n",
      "epoch 89; iter: 0; batch classifier loss: 0.386258; batch adversarial loss: 0.270227\n",
      "epoch 90; iter: 0; batch classifier loss: 0.462442; batch adversarial loss: 0.260195\n",
      "epoch 91; iter: 0; batch classifier loss: 0.416706; batch adversarial loss: 0.359585\n",
      "epoch 92; iter: 0; batch classifier loss: 0.369194; batch adversarial loss: 0.241811\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349599; batch adversarial loss: 0.288360\n",
      "epoch 94; iter: 0; batch classifier loss: 0.368457; batch adversarial loss: 0.285421\n",
      "epoch 95; iter: 0; batch classifier loss: 0.414619; batch adversarial loss: 0.293693\n",
      "epoch 96; iter: 0; batch classifier loss: 0.387669; batch adversarial loss: 0.309033\n",
      "epoch 97; iter: 0; batch classifier loss: 0.365506; batch adversarial loss: 0.289633\n",
      "epoch 98; iter: 0; batch classifier loss: 0.388452; batch adversarial loss: 0.254708\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363158; batch adversarial loss: 0.227906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.261218; batch adversarial loss: 0.926655\n",
      "epoch 2; iter: 0; batch classifier loss: 1.141628; batch adversarial loss: 0.800452\n",
      "epoch 3; iter: 0; batch classifier loss: 0.894953; batch adversarial loss: 0.820115\n",
      "epoch 4; iter: 0; batch classifier loss: 0.829137; batch adversarial loss: 0.725380\n",
      "epoch 5; iter: 0; batch classifier loss: 0.688970; batch adversarial loss: 0.664911\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587371; batch adversarial loss: 0.635933\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580413; batch adversarial loss: 0.612546\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550792; batch adversarial loss: 0.601522\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540582; batch adversarial loss: 0.572825\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539641; batch adversarial loss: 0.582275\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568577; batch adversarial loss: 0.541155\n",
      "epoch 12; iter: 0; batch classifier loss: 0.528482; batch adversarial loss: 0.534915\n",
      "epoch 13; iter: 0; batch classifier loss: 0.532083; batch adversarial loss: 0.528882\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510910; batch adversarial loss: 0.494015\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525170; batch adversarial loss: 0.474900\n",
      "epoch 16; iter: 0; batch classifier loss: 0.593270; batch adversarial loss: 0.456912\n",
      "epoch 17; iter: 0; batch classifier loss: 0.509085; batch adversarial loss: 0.464287\n",
      "epoch 18; iter: 0; batch classifier loss: 0.541108; batch adversarial loss: 0.454718\n",
      "epoch 19; iter: 0; batch classifier loss: 0.563119; batch adversarial loss: 0.465505\n",
      "epoch 20; iter: 0; batch classifier loss: 0.529013; batch adversarial loss: 0.438913\n",
      "epoch 21; iter: 0; batch classifier loss: 0.552603; batch adversarial loss: 0.454228\n",
      "epoch 22; iter: 0; batch classifier loss: 0.586759; batch adversarial loss: 0.469026\n",
      "epoch 23; iter: 0; batch classifier loss: 0.537733; batch adversarial loss: 0.507700\n",
      "epoch 24; iter: 0; batch classifier loss: 0.586703; batch adversarial loss: 0.367631\n",
      "epoch 25; iter: 0; batch classifier loss: 0.565388; batch adversarial loss: 0.433513\n",
      "epoch 26; iter: 0; batch classifier loss: 0.655326; batch adversarial loss: 0.485669\n",
      "epoch 27; iter: 0; batch classifier loss: 0.710903; batch adversarial loss: 0.500697\n",
      "epoch 28; iter: 0; batch classifier loss: 0.615878; batch adversarial loss: 0.410531\n",
      "epoch 29; iter: 0; batch classifier loss: 0.534214; batch adversarial loss: 0.465860\n",
      "epoch 30; iter: 0; batch classifier loss: 0.552177; batch adversarial loss: 0.382095\n",
      "epoch 31; iter: 0; batch classifier loss: 0.607834; batch adversarial loss: 0.403708\n",
      "epoch 32; iter: 0; batch classifier loss: 0.632485; batch adversarial loss: 0.430406\n",
      "epoch 33; iter: 0; batch classifier loss: 0.593100; batch adversarial loss: 0.395087\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544600; batch adversarial loss: 0.335532\n",
      "epoch 35; iter: 0; batch classifier loss: 0.666053; batch adversarial loss: 0.437737\n",
      "epoch 36; iter: 0; batch classifier loss: 0.548870; batch adversarial loss: 0.381533\n",
      "epoch 37; iter: 0; batch classifier loss: 0.593644; batch adversarial loss: 0.414014\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442512; batch adversarial loss: 0.343528\n",
      "epoch 39; iter: 0; batch classifier loss: 0.563847; batch adversarial loss: 0.320384\n",
      "epoch 40; iter: 0; batch classifier loss: 0.519833; batch adversarial loss: 0.387235\n",
      "epoch 41; iter: 0; batch classifier loss: 0.590956; batch adversarial loss: 0.406541\n",
      "epoch 42; iter: 0; batch classifier loss: 0.499092; batch adversarial loss: 0.337286\n",
      "epoch 43; iter: 0; batch classifier loss: 0.541161; batch adversarial loss: 0.350893\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464772; batch adversarial loss: 0.314845\n",
      "epoch 45; iter: 0; batch classifier loss: 0.513113; batch adversarial loss: 0.340575\n",
      "epoch 46; iter: 0; batch classifier loss: 0.533085; batch adversarial loss: 0.300928\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484126; batch adversarial loss: 0.268860\n",
      "epoch 48; iter: 0; batch classifier loss: 0.599368; batch adversarial loss: 0.382877\n",
      "epoch 49; iter: 0; batch classifier loss: 0.518553; batch adversarial loss: 0.368246\n",
      "epoch 50; iter: 0; batch classifier loss: 0.587505; batch adversarial loss: 0.313774\n",
      "epoch 51; iter: 0; batch classifier loss: 0.599203; batch adversarial loss: 0.364310\n",
      "epoch 52; iter: 0; batch classifier loss: 0.519423; batch adversarial loss: 0.282162\n",
      "epoch 53; iter: 0; batch classifier loss: 0.572329; batch adversarial loss: 0.398869\n",
      "epoch 54; iter: 0; batch classifier loss: 0.631040; batch adversarial loss: 0.278148\n",
      "epoch 55; iter: 0; batch classifier loss: 0.459069; batch adversarial loss: 0.249503\n",
      "epoch 56; iter: 0; batch classifier loss: 0.445090; batch adversarial loss: 0.352243\n",
      "epoch 57; iter: 0; batch classifier loss: 0.495226; batch adversarial loss: 0.352739\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424249; batch adversarial loss: 0.365663\n",
      "epoch 59; iter: 0; batch classifier loss: 0.469567; batch adversarial loss: 0.377457\n",
      "epoch 60; iter: 0; batch classifier loss: 0.487282; batch adversarial loss: 0.320102\n",
      "epoch 61; iter: 0; batch classifier loss: 0.468583; batch adversarial loss: 0.248890\n",
      "epoch 62; iter: 0; batch classifier loss: 0.482097; batch adversarial loss: 0.303452\n",
      "epoch 63; iter: 0; batch classifier loss: 0.462997; batch adversarial loss: 0.404451\n",
      "epoch 64; iter: 0; batch classifier loss: 0.364372; batch adversarial loss: 0.321176\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448344; batch adversarial loss: 0.257560\n",
      "epoch 66; iter: 0; batch classifier loss: 0.318750; batch adversarial loss: 0.330451\n",
      "epoch 67; iter: 0; batch classifier loss: 0.406442; batch adversarial loss: 0.344156\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410409; batch adversarial loss: 0.343368\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432187; batch adversarial loss: 0.280857\n",
      "epoch 70; iter: 0; batch classifier loss: 0.431654; batch adversarial loss: 0.343392\n",
      "epoch 71; iter: 0; batch classifier loss: 0.484672; batch adversarial loss: 0.279910\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415083; batch adversarial loss: 0.286370\n",
      "epoch 73; iter: 0; batch classifier loss: 0.366431; batch adversarial loss: 0.286852\n",
      "epoch 74; iter: 0; batch classifier loss: 0.461435; batch adversarial loss: 0.364126\n",
      "epoch 75; iter: 0; batch classifier loss: 0.360264; batch adversarial loss: 0.308573\n",
      "epoch 76; iter: 0; batch classifier loss: 0.368828; batch adversarial loss: 0.314765\n",
      "epoch 77; iter: 0; batch classifier loss: 0.418074; batch adversarial loss: 0.336593\n",
      "epoch 78; iter: 0; batch classifier loss: 0.354400; batch adversarial loss: 0.228381\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381414; batch adversarial loss: 0.366783\n",
      "epoch 80; iter: 0; batch classifier loss: 0.484583; batch adversarial loss: 0.418006\n",
      "epoch 81; iter: 0; batch classifier loss: 0.419228; batch adversarial loss: 0.278625\n",
      "epoch 82; iter: 0; batch classifier loss: 0.458494; batch adversarial loss: 0.271671\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385364; batch adversarial loss: 0.276143\n",
      "epoch 84; iter: 0; batch classifier loss: 0.443585; batch adversarial loss: 0.268396\n",
      "epoch 85; iter: 0; batch classifier loss: 0.392372; batch adversarial loss: 0.396471\n",
      "epoch 86; iter: 0; batch classifier loss: 0.413584; batch adversarial loss: 0.297128\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377199; batch adversarial loss: 0.312988\n",
      "epoch 88; iter: 0; batch classifier loss: 0.426860; batch adversarial loss: 0.259342\n",
      "epoch 89; iter: 0; batch classifier loss: 0.383649; batch adversarial loss: 0.270058\n",
      "epoch 90; iter: 0; batch classifier loss: 0.451869; batch adversarial loss: 0.260077\n",
      "epoch 91; iter: 0; batch classifier loss: 0.415707; batch adversarial loss: 0.359620\n",
      "epoch 92; iter: 0; batch classifier loss: 0.372418; batch adversarial loss: 0.241921\n",
      "epoch 93; iter: 0; batch classifier loss: 0.349280; batch adversarial loss: 0.288410\n",
      "epoch 94; iter: 0; batch classifier loss: 0.375123; batch adversarial loss: 0.285211\n",
      "epoch 95; iter: 0; batch classifier loss: 0.422752; batch adversarial loss: 0.293977\n",
      "epoch 96; iter: 0; batch classifier loss: 0.378762; batch adversarial loss: 0.309071\n",
      "epoch 97; iter: 0; batch classifier loss: 0.366854; batch adversarial loss: 0.289585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.391152; batch adversarial loss: 0.254354\n",
      "epoch 99; iter: 0; batch classifier loss: 0.363863; batch adversarial loss: 0.227983\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.222299; batch adversarial loss: 0.925279\n",
      "epoch 2; iter: 0; batch classifier loss: 1.112474; batch adversarial loss: 0.799212\n",
      "epoch 3; iter: 0; batch classifier loss: 0.868629; batch adversarial loss: 0.818014\n",
      "epoch 4; iter: 0; batch classifier loss: 0.800216; batch adversarial loss: 0.723060\n",
      "epoch 5; iter: 0; batch classifier loss: 0.667531; batch adversarial loss: 0.662128\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581316; batch adversarial loss: 0.636181\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580923; batch adversarial loss: 0.612411\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551607; batch adversarial loss: 0.601678\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539449; batch adversarial loss: 0.573331\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542763; batch adversarial loss: 0.582535\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568880; batch adversarial loss: 0.541698\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531512; batch adversarial loss: 0.535081\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534507; batch adversarial loss: 0.528759\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515712; batch adversarial loss: 0.492771\n",
      "epoch 15; iter: 0; batch classifier loss: 0.526608; batch adversarial loss: 0.473365\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592321; batch adversarial loss: 0.455926\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506266; batch adversarial loss: 0.462580\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543686; batch adversarial loss: 0.453397\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545387; batch adversarial loss: 0.459467\n",
      "epoch 20; iter: 0; batch classifier loss: 0.517958; batch adversarial loss: 0.431224\n",
      "epoch 21; iter: 0; batch classifier loss: 0.533060; batch adversarial loss: 0.447074\n",
      "epoch 22; iter: 0; batch classifier loss: 0.567972; batch adversarial loss: 0.461683\n",
      "epoch 23; iter: 0; batch classifier loss: 0.523159; batch adversarial loss: 0.505518\n",
      "epoch 24; iter: 0; batch classifier loss: 0.578878; batch adversarial loss: 0.365684\n",
      "epoch 25; iter: 0; batch classifier loss: 0.550339; batch adversarial loss: 0.430215\n",
      "epoch 26; iter: 0; batch classifier loss: 0.634262; batch adversarial loss: 0.483720\n",
      "epoch 27; iter: 0; batch classifier loss: 0.690704; batch adversarial loss: 0.500066\n",
      "epoch 28; iter: 0; batch classifier loss: 0.609152; batch adversarial loss: 0.410050\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524571; batch adversarial loss: 0.467078\n",
      "epoch 30; iter: 0; batch classifier loss: 0.547960; batch adversarial loss: 0.382225\n",
      "epoch 31; iter: 0; batch classifier loss: 0.596483; batch adversarial loss: 0.403578\n",
      "epoch 32; iter: 0; batch classifier loss: 0.627611; batch adversarial loss: 0.431995\n",
      "epoch 33; iter: 0; batch classifier loss: 0.587419; batch adversarial loss: 0.395727\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544143; batch adversarial loss: 0.335862\n",
      "epoch 35; iter: 0; batch classifier loss: 0.663570; batch adversarial loss: 0.439445\n",
      "epoch 36; iter: 0; batch classifier loss: 0.551131; batch adversarial loss: 0.383181\n",
      "epoch 37; iter: 0; batch classifier loss: 0.590507; batch adversarial loss: 0.415477\n",
      "epoch 38; iter: 0; batch classifier loss: 0.442225; batch adversarial loss: 0.344463\n",
      "epoch 39; iter: 0; batch classifier loss: 0.558033; batch adversarial loss: 0.320935\n",
      "epoch 40; iter: 0; batch classifier loss: 0.518378; batch adversarial loss: 0.388419\n",
      "epoch 41; iter: 0; batch classifier loss: 0.593534; batch adversarial loss: 0.408615\n",
      "epoch 42; iter: 0; batch classifier loss: 0.495861; batch adversarial loss: 0.338193\n",
      "epoch 43; iter: 0; batch classifier loss: 0.541371; batch adversarial loss: 0.352244\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461194; batch adversarial loss: 0.315242\n",
      "epoch 45; iter: 0; batch classifier loss: 0.516825; batch adversarial loss: 0.341373\n",
      "epoch 46; iter: 0; batch classifier loss: 0.537922; batch adversarial loss: 0.301545\n",
      "epoch 47; iter: 0; batch classifier loss: 0.491205; batch adversarial loss: 0.269122\n",
      "epoch 48; iter: 0; batch classifier loss: 0.597789; batch adversarial loss: 0.384378\n",
      "epoch 49; iter: 0; batch classifier loss: 0.520407; batch adversarial loss: 0.369552\n",
      "epoch 50; iter: 0; batch classifier loss: 0.588549; batch adversarial loss: 0.314529\n",
      "epoch 51; iter: 0; batch classifier loss: 0.592074; batch adversarial loss: 0.365315\n",
      "epoch 52; iter: 0; batch classifier loss: 0.519168; batch adversarial loss: 0.282592\n",
      "epoch 53; iter: 0; batch classifier loss: 0.570377; batch adversarial loss: 0.400287\n",
      "epoch 54; iter: 0; batch classifier loss: 0.612013; batch adversarial loss: 0.278776\n",
      "epoch 55; iter: 0; batch classifier loss: 0.520338; batch adversarial loss: 0.250215\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448152; batch adversarial loss: 0.352601\n",
      "epoch 57; iter: 0; batch classifier loss: 0.495080; batch adversarial loss: 0.352795\n",
      "epoch 58; iter: 0; batch classifier loss: 0.426192; batch adversarial loss: 0.365724\n",
      "epoch 59; iter: 0; batch classifier loss: 0.467787; batch adversarial loss: 0.377576\n",
      "epoch 60; iter: 0; batch classifier loss: 0.475107; batch adversarial loss: 0.320135\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459616; batch adversarial loss: 0.249123\n",
      "epoch 62; iter: 0; batch classifier loss: 0.482344; batch adversarial loss: 0.303648\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463630; batch adversarial loss: 0.404497\n",
      "epoch 64; iter: 0; batch classifier loss: 0.366166; batch adversarial loss: 0.321286\n",
      "epoch 65; iter: 0; batch classifier loss: 0.451263; batch adversarial loss: 0.257762\n",
      "epoch 66; iter: 0; batch classifier loss: 0.323737; batch adversarial loss: 0.330519\n",
      "epoch 67; iter: 0; batch classifier loss: 0.412721; batch adversarial loss: 0.344366\n",
      "epoch 68; iter: 0; batch classifier loss: 0.410201; batch adversarial loss: 0.343375\n",
      "epoch 69; iter: 0; batch classifier loss: 0.432696; batch adversarial loss: 0.280818\n",
      "epoch 70; iter: 0; batch classifier loss: 0.419228; batch adversarial loss: 0.343421\n",
      "epoch 71; iter: 0; batch classifier loss: 0.482784; batch adversarial loss: 0.280051\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411416; batch adversarial loss: 0.286435\n",
      "epoch 73; iter: 0; batch classifier loss: 0.375194; batch adversarial loss: 0.287349\n",
      "epoch 74; iter: 0; batch classifier loss: 0.453257; batch adversarial loss: 0.364163\n",
      "epoch 75; iter: 0; batch classifier loss: 0.360341; batch adversarial loss: 0.308426\n",
      "epoch 76; iter: 0; batch classifier loss: 0.366410; batch adversarial loss: 0.315050\n",
      "epoch 77; iter: 0; batch classifier loss: 0.411351; batch adversarial loss: 0.336581\n",
      "epoch 78; iter: 0; batch classifier loss: 0.364757; batch adversarial loss: 0.228452\n",
      "epoch 79; iter: 0; batch classifier loss: 0.381051; batch adversarial loss: 0.367527\n",
      "epoch 80; iter: 0; batch classifier loss: 0.483258; batch adversarial loss: 0.418155\n",
      "epoch 81; iter: 0; batch classifier loss: 0.430167; batch adversarial loss: 0.278177\n",
      "epoch 82; iter: 0; batch classifier loss: 0.454604; batch adversarial loss: 0.271436\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385136; batch adversarial loss: 0.276607\n",
      "epoch 84; iter: 0; batch classifier loss: 0.442204; batch adversarial loss: 0.268905\n",
      "epoch 85; iter: 0; batch classifier loss: 0.405273; batch adversarial loss: 0.396324\n",
      "epoch 86; iter: 0; batch classifier loss: 0.418049; batch adversarial loss: 0.296992\n",
      "epoch 87; iter: 0; batch classifier loss: 0.380904; batch adversarial loss: 0.312308\n",
      "epoch 88; iter: 0; batch classifier loss: 0.423733; batch adversarial loss: 0.259153\n",
      "epoch 89; iter: 0; batch classifier loss: 0.389343; batch adversarial loss: 0.269948\n",
      "epoch 90; iter: 0; batch classifier loss: 0.452668; batch adversarial loss: 0.260273\n",
      "epoch 91; iter: 0; batch classifier loss: 0.406066; batch adversarial loss: 0.360147\n",
      "epoch 92; iter: 0; batch classifier loss: 0.380993; batch adversarial loss: 0.241729\n",
      "epoch 93; iter: 0; batch classifier loss: 0.353272; batch adversarial loss: 0.288318\n",
      "epoch 94; iter: 0; batch classifier loss: 0.386068; batch adversarial loss: 0.285371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.412004; batch adversarial loss: 0.294133\n",
      "epoch 96; iter: 0; batch classifier loss: 0.372131; batch adversarial loss: 0.309328\n",
      "epoch 97; iter: 0; batch classifier loss: 0.365822; batch adversarial loss: 0.290119\n",
      "epoch 98; iter: 0; batch classifier loss: 0.390331; batch adversarial loss: 0.254453\n",
      "epoch 99; iter: 0; batch classifier loss: 0.358804; batch adversarial loss: 0.228117\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698631; batch adversarial loss: 0.855974\n",
      "epoch 1; iter: 0; batch classifier loss: 1.246396; batch adversarial loss: 0.926144\n",
      "epoch 2; iter: 0; batch classifier loss: 1.130200; batch adversarial loss: 0.799991\n",
      "epoch 3; iter: 0; batch classifier loss: 0.883969; batch adversarial loss: 0.819221\n",
      "epoch 4; iter: 0; batch classifier loss: 0.817921; batch adversarial loss: 0.724591\n",
      "epoch 5; iter: 0; batch classifier loss: 0.680059; batch adversarial loss: 0.663856\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584567; batch adversarial loss: 0.636168\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580751; batch adversarial loss: 0.612465\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551056; batch adversarial loss: 0.601563\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539945; batch adversarial loss: 0.573058\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540105; batch adversarial loss: 0.582469\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568665; batch adversarial loss: 0.541325\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529251; batch adversarial loss: 0.535007\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533036; batch adversarial loss: 0.528834\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513165; batch adversarial loss: 0.493438\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525301; batch adversarial loss: 0.474274\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592183; batch adversarial loss: 0.456566\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507383; batch adversarial loss: 0.463785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543812; batch adversarial loss: 0.454156\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554489; batch adversarial loss: 0.462696\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523793; batch adversarial loss: 0.435509\n",
      "epoch 21; iter: 0; batch classifier loss: 0.544241; batch adversarial loss: 0.451381\n",
      "epoch 22; iter: 0; batch classifier loss: 0.578534; batch adversarial loss: 0.466600\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531312; batch adversarial loss: 0.506495\n",
      "epoch 24; iter: 0; batch classifier loss: 0.584076; batch adversarial loss: 0.366470\n",
      "epoch 25; iter: 0; batch classifier loss: 0.557420; batch adversarial loss: 0.432205\n",
      "epoch 26; iter: 0; batch classifier loss: 0.645232; batch adversarial loss: 0.484696\n",
      "epoch 27; iter: 0; batch classifier loss: 0.701726; batch adversarial loss: 0.500444\n",
      "epoch 28; iter: 0; batch classifier loss: 0.614102; batch adversarial loss: 0.410726\n",
      "epoch 29; iter: 0; batch classifier loss: 0.529555; batch adversarial loss: 0.466368\n",
      "epoch 30; iter: 0; batch classifier loss: 0.551030; batch adversarial loss: 0.382095\n",
      "epoch 31; iter: 0; batch classifier loss: 0.602901; batch adversarial loss: 0.403506\n",
      "epoch 32; iter: 0; batch classifier loss: 0.633221; batch adversarial loss: 0.431133\n",
      "epoch 33; iter: 0; batch classifier loss: 0.590771; batch adversarial loss: 0.395682\n",
      "epoch 34; iter: 0; batch classifier loss: 0.543398; batch adversarial loss: 0.335687\n",
      "epoch 35; iter: 0; batch classifier loss: 0.668171; batch adversarial loss: 0.438544\n",
      "epoch 36; iter: 0; batch classifier loss: 0.549943; batch adversarial loss: 0.382168\n",
      "epoch 37; iter: 0; batch classifier loss: 0.592278; batch adversarial loss: 0.414565\n",
      "epoch 38; iter: 0; batch classifier loss: 0.444465; batch adversarial loss: 0.344060\n",
      "epoch 39; iter: 0; batch classifier loss: 0.562020; batch adversarial loss: 0.320532\n",
      "epoch 40; iter: 0; batch classifier loss: 0.519115; batch adversarial loss: 0.387787\n",
      "epoch 41; iter: 0; batch classifier loss: 0.597539; batch adversarial loss: 0.407445\n",
      "epoch 42; iter: 0; batch classifier loss: 0.496712; batch adversarial loss: 0.337696\n",
      "epoch 43; iter: 0; batch classifier loss: 0.542853; batch adversarial loss: 0.351545\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463737; batch adversarial loss: 0.315238\n",
      "epoch 45; iter: 0; batch classifier loss: 0.512963; batch adversarial loss: 0.340819\n",
      "epoch 46; iter: 0; batch classifier loss: 0.538596; batch adversarial loss: 0.301230\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487315; batch adversarial loss: 0.268908\n",
      "epoch 48; iter: 0; batch classifier loss: 0.594735; batch adversarial loss: 0.383324\n",
      "epoch 49; iter: 0; batch classifier loss: 0.523590; batch adversarial loss: 0.368638\n",
      "epoch 50; iter: 0; batch classifier loss: 0.590509; batch adversarial loss: 0.313953\n",
      "epoch 51; iter: 0; batch classifier loss: 0.593961; batch adversarial loss: 0.364658\n",
      "epoch 52; iter: 0; batch classifier loss: 0.517658; batch adversarial loss: 0.282343\n",
      "epoch 53; iter: 0; batch classifier loss: 0.579863; batch adversarial loss: 0.399489\n",
      "epoch 54; iter: 0; batch classifier loss: 0.620212; batch adversarial loss: 0.278410\n",
      "epoch 55; iter: 0; batch classifier loss: 0.471171; batch adversarial loss: 0.249717\n",
      "epoch 56; iter: 0; batch classifier loss: 0.448911; batch adversarial loss: 0.352391\n",
      "epoch 57; iter: 0; batch classifier loss: 0.494522; batch adversarial loss: 0.352778\n",
      "epoch 58; iter: 0; batch classifier loss: 0.424606; batch adversarial loss: 0.365668\n",
      "epoch 59; iter: 0; batch classifier loss: 0.465940; batch adversarial loss: 0.377466\n",
      "epoch 60; iter: 0; batch classifier loss: 0.478266; batch adversarial loss: 0.320130\n",
      "epoch 61; iter: 0; batch classifier loss: 0.459924; batch adversarial loss: 0.248962\n",
      "epoch 62; iter: 0; batch classifier loss: 0.478491; batch adversarial loss: 0.303543\n",
      "epoch 63; iter: 0; batch classifier loss: 0.463993; batch adversarial loss: 0.404525\n",
      "epoch 64; iter: 0; batch classifier loss: 0.360951; batch adversarial loss: 0.321308\n",
      "epoch 65; iter: 0; batch classifier loss: 0.448464; batch adversarial loss: 0.257580\n",
      "epoch 66; iter: 0; batch classifier loss: 0.319352; batch adversarial loss: 0.330513\n",
      "epoch 67; iter: 0; batch classifier loss: 0.407577; batch adversarial loss: 0.344142\n",
      "epoch 68; iter: 0; batch classifier loss: 0.404013; batch adversarial loss: 0.343526\n",
      "epoch 69; iter: 0; batch classifier loss: 0.425149; batch adversarial loss: 0.280696\n",
      "epoch 70; iter: 0; batch classifier loss: 0.421419; batch adversarial loss: 0.343273\n",
      "epoch 71; iter: 0; batch classifier loss: 0.484021; batch adversarial loss: 0.280023\n",
      "epoch 72; iter: 0; batch classifier loss: 0.411703; batch adversarial loss: 0.286364\n",
      "epoch 73; iter: 0; batch classifier loss: 0.367775; batch adversarial loss: 0.287026\n",
      "epoch 74; iter: 0; batch classifier loss: 0.464954; batch adversarial loss: 0.364032\n",
      "epoch 75; iter: 0; batch classifier loss: 0.357059; batch adversarial loss: 0.308516\n",
      "epoch 76; iter: 0; batch classifier loss: 0.368192; batch adversarial loss: 0.314902\n",
      "epoch 77; iter: 0; batch classifier loss: 0.425127; batch adversarial loss: 0.336638\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352134; batch adversarial loss: 0.228301\n",
      "epoch 79; iter: 0; batch classifier loss: 0.383410; batch adversarial loss: 0.366864\n",
      "epoch 80; iter: 0; batch classifier loss: 0.482259; batch adversarial loss: 0.418365\n",
      "epoch 81; iter: 0; batch classifier loss: 0.414650; batch adversarial loss: 0.278411\n",
      "epoch 82; iter: 0; batch classifier loss: 0.466889; batch adversarial loss: 0.271566\n",
      "epoch 83; iter: 0; batch classifier loss: 0.385594; batch adversarial loss: 0.276495\n",
      "epoch 84; iter: 0; batch classifier loss: 0.445684; batch adversarial loss: 0.268601\n",
      "epoch 85; iter: 0; batch classifier loss: 0.389103; batch adversarial loss: 0.396956\n",
      "epoch 86; iter: 0; batch classifier loss: 0.412285; batch adversarial loss: 0.297019\n",
      "epoch 87; iter: 0; batch classifier loss: 0.377096; batch adversarial loss: 0.312654\n",
      "epoch 88; iter: 0; batch classifier loss: 0.416462; batch adversarial loss: 0.259606\n",
      "epoch 89; iter: 0; batch classifier loss: 0.379414; batch adversarial loss: 0.269951\n",
      "epoch 90; iter: 0; batch classifier loss: 0.458037; batch adversarial loss: 0.260039\n",
      "epoch 91; iter: 0; batch classifier loss: 0.410752; batch adversarial loss: 0.359773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.372284; batch adversarial loss: 0.241835\n",
      "epoch 93; iter: 0; batch classifier loss: 0.336933; batch adversarial loss: 0.287995\n",
      "epoch 94; iter: 0; batch classifier loss: 0.376365; batch adversarial loss: 0.285284\n",
      "epoch 95; iter: 0; batch classifier loss: 0.417349; batch adversarial loss: 0.294180\n",
      "epoch 96; iter: 0; batch classifier loss: 0.380747; batch adversarial loss: 0.308953\n",
      "epoch 97; iter: 0; batch classifier loss: 0.369505; batch adversarial loss: 0.289935\n",
      "epoch 98; iter: 0; batch classifier loss: 0.381620; batch adversarial loss: 0.254585\n",
      "epoch 99; iter: 0; batch classifier loss: 0.367181; batch adversarial loss: 0.227574\n",
      "Probas: [[0.94845995 0.05154005]\n",
      " [0.92977738 0.07022262]\n",
      " [0.07904565 0.92095435]\n",
      " [0.61798522 0.38201478]\n",
      " [0.78461628 0.21538372]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.89453278 0.10546722]\n",
      " [0.92977738 0.07022262]\n",
      " [0.07904565 0.92095435]\n",
      " [0.61798522 0.38201478]\n",
      " [0.78461628 0.21538372]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.84458637 0.15541363]\n",
      " [0.92977738 0.07022262]\n",
      " [0.07904565 0.92095435]\n",
      " [0.61798522 0.38201478]\n",
      " [0.78461628 0.21538372]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.80583829 0.19416171]\n",
      " [0.92977738 0.07022262]\n",
      " [0.07904565 0.92095435]\n",
      " [0.61798522 0.38201478]\n",
      " [0.78461628 0.21538372]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[8.38041306e-05 9.99916196e-01]\n",
      " [9.29777376e-01 7.02226236e-02]\n",
      " [7.90456533e-02 9.20954347e-01]\n",
      " [6.17985219e-01 3.82014781e-01]\n",
      " [7.84616277e-01 2.15383723e-01]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.66601366 0.33398634]\n",
      " [0.92977738 0.07022262]\n",
      " [0.07904565 0.92095435]\n",
      " [0.61798522 0.38201478]\n",
      " [0.78461628 0.21538372]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.68851623 0.31148377]\n",
      " [0.92977738 0.07022262]\n",
      " [0.07904565 0.92095435]\n",
      " [0.61798522 0.38201478]\n",
      " [0.78461628 0.21538372]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.69880879 0.30119121]\n",
      " [0.92977738 0.07022262]\n",
      " [0.07904565 0.92095435]\n",
      " [0.61798522 0.38201478]\n",
      " [0.78461628 0.21538372]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.63756719 0.36243281]\n",
      " [0.92977738 0.07022262]\n",
      " [0.07904565 0.92095435]\n",
      " [0.61798522 0.38201478]\n",
      " [0.78461628 0.21538372]] Sums: [1. 1. 1. 1. 1.]\n",
      "Probas: [[0.87328303 0.12671697]\n",
      " [0.92977738 0.07022262]\n",
      " [0.07904565 0.92095435]\n",
      " [0.61798522 0.38201478]\n",
      " [0.78461628 0.21538372]] Sums: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Uso da função:\n",
    "df_final_high, best_model_high, best_params_high, best_score_high, explanations_high = AIF360.InAdversarialDebiasingOptuna(X_train_high, y_train_high, X_test_high, y_test_high, df_train_high, df_test_high, protected_attribute, alpha = 0.1, num_trials=50)\n",
    "df_final_medium, best_model_medium, best_params_medium, best_score_medium, explanations_medium = AIF360.InAdversarialDebiasingOptuna(X_train_medium, y_train_medium, X_test_medium, y_test_medium, df_train_medium, df_test_medium, protected_attribute, alpha = 0.1, num_trials=50)\n",
    "df_final_low, best_model_low, best_params_low, best_score_low, explanations_low = AIF360.InAdversarialDebiasingOptuna(X_train_low, y_train_low, X_test_low, y_test_low, df_train_low, df_test_low, protected_attribute, alpha = 0.1, num_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8543a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High - Parâmetros: {'num_epochs': 100, 'classifier_num_hidden_units': 100, 'adversary_loss_weight': 0.28323409221070855}\n",
      "Medium - Parâmetros: {'num_epochs': 100, 'classifier_num_hidden_units': 100, 'adversary_loss_weight': 1.2714604833643484}\n",
      "Low - Parâmetros: {'num_epochs': 100, 'classifier_num_hidden_units': 100, 'adversary_loss_weight': 1.837140526256818}\n"
     ]
    }
   ],
   "source": [
    "print('High - Parâmetros:', best_params_high)\n",
    "print('Medium - Parâmetros:', best_params_medium)\n",
    "print('Low - Parâmetros:', best_params_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93db46c0",
   "metadata": {},
   "source": [
    "Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c60f929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas do modelo\n",
    "df_metrics_high = Metrics.ModelMetrics(df_final_high, 'case:protected', 'High', 'Inprocessing: Adversarial Debiasing', privileged_group, unprivileged_group)\n",
    "df_metrics_medium = Metrics.ModelMetrics(df_final_medium, 'case:protected', 'Medium', 'Inprocessing: Adversarial Debiasing', privileged_group, unprivileged_group)\n",
    "df_metrics_low = Metrics.ModelMetrics(df_final_low, 'case:protected', 'Low', 'Inprocessing: Adversarial Debiasing', privileged_group, unprivileged_group)\n",
    "\n",
    "df_metrics_Adv = pd.concat([df_metrics_high, df_metrics_medium, df_metrics_low], ignore_index=True)\n",
    "df_metrics = pd.concat([df_metrics, df_metrics_Adv], ignore_index=True)\n",
    "df_metrics.to_excel(f'{name_prefix}_metrics.xlsx', index = False)\n",
    "#df_metrics[df_metrics['Metric'].isin(['Accuracy', 'F1-Score', 'Disparate Impact'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba25896",
   "metadata": {},
   "source": [
    "Explicação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "337ab8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance_High</th>\n",
       "      <th>Importance_Medium</th>\n",
       "      <th>Importance_Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; skipped_examination</th>\n",
       "      <td>-0.445036</td>\n",
       "      <td>-0.231998</td>\n",
       "      <td>-0.251927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; Submit File to Underwriter</th>\n",
       "      <td>0.177934</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.287398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 3 -&gt; Loan Officer 4</th>\n",
       "      <td>-0.135006</td>\n",
       "      <td>-0.035624</td>\n",
       "      <td>-0.075527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Make Visit to Assess Colatteral -&gt; Make Visit to Assess Colatteral</th>\n",
       "      <td>0.133532</td>\n",
       "      <td>0.120779</td>\n",
       "      <td>0.032278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; Make Visit to Assess Colatteral</th>\n",
       "      <td>-0.132456</td>\n",
       "      <td>-0.061633</td>\n",
       "      <td>-0.166009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource 3 -&gt; Online System</th>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.026328</td>\n",
       "      <td>0.004894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource 3 -&gt; Resource 5</th>\n",
       "      <td>-0.001514</td>\n",
       "      <td>-0.025411</td>\n",
       "      <td>-0.088125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Request Appointment -&gt; Set Appointment</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hand In Credit Appliaction -&gt; Verify Borrowers Information</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set Appointment -&gt; Hand In Credit Appliaction</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Importance_High  \\\n",
       "Feature                                                               \n",
       "Verify Borrowers Information -> skipped_examina...        -0.445036   \n",
       "Verify Borrowers Information -> Submit File to ...         0.177934   \n",
       "Loan Officer 3 -> Loan Officer 4                          -0.135006   \n",
       "Make Visit to Assess Colatteral -> Make Visit t...         0.133532   \n",
       "Verify Borrowers Information -> Make Visit to A...        -0.132456   \n",
       "...                                                             ...   \n",
       "Resource 3 -> Online System                                0.001880   \n",
       "Resource 3 -> Resource 5                                  -0.001514   \n",
       "Request Appointment -> Set Appointment                     0.000000   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...         0.000000   \n",
       "Set Appointment -> Hand In Credit Appliaction              0.000000   \n",
       "\n",
       "                                                    Importance_Medium  \\\n",
       "Feature                                                                 \n",
       "Verify Borrowers Information -> skipped_examina...          -0.231998   \n",
       "Verify Borrowers Information -> Submit File to ...           0.000042   \n",
       "Loan Officer 3 -> Loan Officer 4                            -0.035624   \n",
       "Make Visit to Assess Colatteral -> Make Visit t...           0.120779   \n",
       "Verify Borrowers Information -> Make Visit to A...          -0.061633   \n",
       "...                                                               ...   \n",
       "Resource 3 -> Online System                                  0.026328   \n",
       "Resource 3 -> Resource 5                                    -0.025411   \n",
       "Request Appointment -> Set Appointment                       0.000000   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...           0.000000   \n",
       "Set Appointment -> Hand In Credit Appliaction                0.000000   \n",
       "\n",
       "                                                    Importance_Low  \n",
       "Feature                                                             \n",
       "Verify Borrowers Information -> skipped_examina...       -0.251927  \n",
       "Verify Borrowers Information -> Submit File to ...        0.287398  \n",
       "Loan Officer 3 -> Loan Officer 4                         -0.075527  \n",
       "Make Visit to Assess Colatteral -> Make Visit t...        0.032278  \n",
       "Verify Borrowers Information -> Make Visit to A...       -0.166009  \n",
       "...                                                            ...  \n",
       "Resource 3 -> Online System                               0.004894  \n",
       "Resource 3 -> Resource 5                                 -0.088125  \n",
       "Request Appointment -> Set Appointment                    0.000000  \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...        0.000000  \n",
       "Set Appointment -> Hand In Credit Appliaction             0.000000  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerar tabelas de importância das variáveis\n",
    "importance_high = get_feature_importance(explanations_high, X_train_high.columns)\n",
    "importance_medium = get_feature_importance(explanations_medium, X_train_medium.columns)\n",
    "importance_low = get_feature_importance(explanations_low, X_train_low.columns)\n",
    "\n",
    "# Criar DataFrames com a importância das variáveis\n",
    "importance_high_df = pd.DataFrame({'Feature': X_train_high.columns, 'Importance_High': importance_high})\n",
    "importance_medium_df = pd.DataFrame({'Feature': X_train_medium.columns, 'Importance_Medium': importance_medium})\n",
    "importance_low_df = pd.DataFrame({'Feature': X_train_low.columns, 'Importance_Low': importance_low})\n",
    "\n",
    "# Realizar o merge dos DataFrames utilizando 'Feature' como chave e preenchendo valores faltantes com NaN\n",
    "importance_df = importance_high_df.merge(importance_medium_df, on='Feature', how='outer').merge(importance_low_df, on='Feature', how='outer')\n",
    "\n",
    "# Ordenar o DataFrame com base no módulo dos valores da coluna 'Importance_High'\n",
    "importance_df['Importance_High_Abs'] = importance_df['Importance_High'].abs()\n",
    "importance_df = importance_df.sort_values(by='Importance_High_Abs', ascending=False)\n",
    "importance_df.drop(columns=['Importance_High_Abs'], inplace=True)\n",
    "\n",
    "# Definir o índice como a coluna 'Feature'\n",
    "importance_df.set_index('Feature', inplace=True)\n",
    "\n",
    "# Salvar o DataFrame como CSV\n",
    "importance_df.to_csv(f'{name_prefix}_in_adv_model_lime.csv')\n",
    "\n",
    "# Exibir o DataFrame\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9679fa",
   "metadata": {},
   "source": [
    "<b> 2.4 Equalized Odds Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37401057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso da função:\n",
    "df_final_high, best_model_high, best_params_high, best_score_high, explanations_high = AIF360.PostEOddsPostprocessingRandomFlorestOptuna(X_train_high, y_train_high, X_test_high, y_test_high, df_train_high, df_test_high, protected_attribute, alpha = 0.1, num_trials=50)\n",
    "df_final_medium, best_model_medium, best_params_medium, best_score_medium, explanations_medium = AIF360.PostEOddsPostprocessingRandomFlorestOptuna(X_train_medium, y_train_medium, X_test_medium, y_test_medium, df_train_medium, df_test_medium, protected_attribute, alpha = 0.1, num_trials=50)\n",
    "df_final_low, best_model_low, best_params_low, best_score_low, explanations_low = AIF360.PostEOddsPostprocessingRandomFlorestOptuna(X_train_low, y_train_low, X_test_low, y_test_low, df_train_low, df_test_low, protected_attribute, alpha = 0.1, num_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73a03cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High - Parâmetros: {'n_estimators': 67, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.9765345728639062}\n",
      "Medium - Parâmetros: {'n_estimators': 70, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.9415478986146185}\n",
      "Low - Parâmetros: {'n_estimators': 70, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.99977219466241}\n"
     ]
    }
   ],
   "source": [
    "#Serão os parâmetros da Random Florest\n",
    "print('High - Parâmetros:', best_params_high)\n",
    "print('Medium - Parâmetros:', best_params_medium)\n",
    "print('Low - Parâmetros:', best_params_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62932111",
   "metadata": {},
   "source": [
    "Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a07c4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas do modelo\n",
    "df_metrics_high = Metrics.ModelMetrics(df_final_high, 'case:protected', 'High', 'Postprocessing: Equalized Odds', privileged_group, unprivileged_group)\n",
    "df_metrics_medium = Metrics.ModelMetrics(df_final_medium, 'case:protected', 'Medium', 'Postprocessing: Equalized Odds', privileged_group, unprivileged_group)\n",
    "df_metrics_low = Metrics.ModelMetrics(df_final_low, 'case:protected', 'Low', 'Postprocessing: Equalized Odds', privileged_group, unprivileged_group)\n",
    "\n",
    "df_metrics_PostEOdds = pd.concat([df_metrics_high, df_metrics_medium, df_metrics_low], ignore_index=True)\n",
    "df_metrics = pd.concat([df_metrics, df_metrics_PostEOdds], ignore_index=True)\n",
    "df_metrics.to_excel(f'{name_prefix}_metrics.xlsx', index = False)\n",
    "#df_metrics[df_metrics['Metric'].isin(['Accuracy', 'F1-Score', 'Disparate Impact'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044498cc",
   "metadata": {},
   "source": [
    "Explicação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e324cf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance_High</th>\n",
       "      <th>Importance_Medium</th>\n",
       "      <th>Importance_Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; skipped_examination</th>\n",
       "      <td>-0.290242</td>\n",
       "      <td>-0.313468</td>\n",
       "      <td>-0.346762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; Submit File to Underwriter</th>\n",
       "      <td>0.049495</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.075752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case:protected</th>\n",
       "      <td>0.040857</td>\n",
       "      <td>0.153343</td>\n",
       "      <td>0.045431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 3 -&gt; Loan Officer 4</th>\n",
       "      <td>-0.037494</td>\n",
       "      <td>-0.014124</td>\n",
       "      <td>-0.071097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 4 -&gt; Loan Officer 4</th>\n",
       "      <td>-0.035197</td>\n",
       "      <td>-0.024937</td>\n",
       "      <td>-0.009905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 5 -&gt; Loan Officer 1</th>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>-0.039586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource 3 -&gt; Resource 1</th>\n",
       "      <td>-0.000072</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.018073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set Appointment -&gt; Hand In Credit Appliaction</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Request Appointment -&gt; Set Appointment</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hand In Credit Appliaction -&gt; Verify Borrowers Information</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Importance_High  \\\n",
       "Feature                                                               \n",
       "Verify Borrowers Information -> skipped_examina...        -0.290242   \n",
       "Verify Borrowers Information -> Submit File to ...         0.049495   \n",
       "case:protected                                             0.040857   \n",
       "Loan Officer 3 -> Loan Officer 4                          -0.037494   \n",
       "Loan Officer 4 -> Loan Officer 4                          -0.035197   \n",
       "...                                                             ...   \n",
       "Loan Officer 5 -> Loan Officer 1                          -0.000202   \n",
       "Resource 3 -> Resource 1                                  -0.000072   \n",
       "Set Appointment -> Hand In Credit Appliaction              0.000000   \n",
       "Request Appointment -> Set Appointment                     0.000000   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...         0.000000   \n",
       "\n",
       "                                                    Importance_Medium  \\\n",
       "Feature                                                                 \n",
       "Verify Borrowers Information -> skipped_examina...          -0.313468   \n",
       "Verify Borrowers Information -> Submit File to ...           0.000247   \n",
       "case:protected                                               0.153343   \n",
       "Loan Officer 3 -> Loan Officer 4                            -0.014124   \n",
       "Loan Officer 4 -> Loan Officer 4                            -0.024937   \n",
       "...                                                               ...   \n",
       "Loan Officer 5 -> Loan Officer 1                             0.005235   \n",
       "Resource 3 -> Resource 1                                     0.009216   \n",
       "Set Appointment -> Hand In Credit Appliaction                0.000000   \n",
       "Request Appointment -> Set Appointment                       0.000000   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...           0.000000   \n",
       "\n",
       "                                                    Importance_Low  \n",
       "Feature                                                             \n",
       "Verify Borrowers Information -> skipped_examina...       -0.346762  \n",
       "Verify Borrowers Information -> Submit File to ...        0.075752  \n",
       "case:protected                                            0.045431  \n",
       "Loan Officer 3 -> Loan Officer 4                         -0.071097  \n",
       "Loan Officer 4 -> Loan Officer 4                         -0.009905  \n",
       "...                                                            ...  \n",
       "Loan Officer 5 -> Loan Officer 1                         -0.039586  \n",
       "Resource 3 -> Resource 1                                  0.018073  \n",
       "Set Appointment -> Hand In Credit Appliaction             0.000000  \n",
       "Request Appointment -> Set Appointment                    0.000000  \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...        0.000000  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerar tabelas de importância das variáveis\n",
    "importance_high = get_feature_importance(explanations_high, X_train_high.columns)\n",
    "importance_medium = get_feature_importance(explanations_medium, X_train_medium.columns)\n",
    "importance_low = get_feature_importance(explanations_low, X_train_low.columns)\n",
    "\n",
    "# Criar DataFrames com a importância das variáveis\n",
    "importance_high_df = pd.DataFrame({'Feature': X_train_high.columns, 'Importance_High': importance_high})\n",
    "importance_medium_df = pd.DataFrame({'Feature': X_train_medium.columns, 'Importance_Medium': importance_medium})\n",
    "importance_low_df = pd.DataFrame({'Feature': X_train_low.columns, 'Importance_Low': importance_low})\n",
    "\n",
    "# Realizar o merge dos DataFrames utilizando 'Feature' como chave e preenchendo valores faltantes com NaN\n",
    "importance_df = importance_high_df.merge(importance_medium_df, on='Feature', how='outer').merge(importance_low_df, on='Feature', how='outer')\n",
    "\n",
    "# Ordenar o DataFrame com base no módulo dos valores da coluna 'Importance_High'\n",
    "importance_df['Importance_High_Abs'] = importance_df['Importance_High'].abs()\n",
    "importance_df = importance_df.sort_values(by='Importance_High_Abs', ascending=False)\n",
    "importance_df.drop(columns=['Importance_High_Abs'], inplace=True)\n",
    "\n",
    "# Definir o índice como a coluna 'Feature'\n",
    "importance_df.set_index('Feature', inplace=True)\n",
    "\n",
    "# Salvar o DataFrame como CSV\n",
    "importance_df.to_csv(f'{name_prefix}_post_eodds_model_lime.csv')\n",
    "\n",
    "# Exibir o DataFrame\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3792ef10",
   "metadata": {},
   "source": [
    "<b> 2.5 Calibrated EqOdds Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1fbe8e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:19:58,330] Trial 0 failed with parameters: {'n_estimators': 168, 'max_depth': 13, 'min_samples_split': 12, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.9597983627213863, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:19:58,333] Trial 0 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:04,361] Trial 5 failed with parameters: {'n_estimators': 51, 'max_depth': 17, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6833087670070379, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:04,362] Trial 5 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:07,782] Trial 8 failed with parameters: {'n_estimators': 96, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.998285791016671, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:07,783] Trial 8 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:10,586] Trial 10 failed with parameters: {'n_estimators': 190, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6757425453250594, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:10,587] Trial 10 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:11,726] Trial 11 failed with parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.9778237300735209, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:11,727] Trial 11 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:12,789] Trial 12 failed with parameters: {'n_estimators': 77, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.7396566068085442, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:12,789] Trial 12 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:15,112] Trial 13 failed with parameters: {'n_estimators': 191, 'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.9230636162826665, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:15,113] Trial 13 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:25,664] Trial 22 failed with parameters: {'n_estimators': 131, 'max_depth': 17, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6311531438481071, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:25,666] Trial 22 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:26,757] Trial 23 failed with parameters: {'n_estimators': 128, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6012176517341832, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:26,758] Trial 23 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:28,280] Trial 24 failed with parameters: {'n_estimators': 133, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6080071182918663, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:28,281] Trial 24 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:29,758] Trial 25 failed with parameters: {'n_estimators': 118, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6105482392211659, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:29,760] Trial 25 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:31,912] Trial 26 failed with parameters: {'n_estimators': 129, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6000165646736321, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-03-03 17:20:31,913] Trial 26 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:33,234] Trial 27 failed with parameters: {'n_estimators': 120, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6079769999083358, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:33,235] Trial 27 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:34,782] Trial 28 failed with parameters: {'n_estimators': 135, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6008358104723539, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:34,782] Trial 28 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:36,191] Trial 29 failed with parameters: {'n_estimators': 129, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6025413192013257, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:36,192] Trial 29 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:37,798] Trial 30 failed with parameters: {'n_estimators': 130, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.602933419952205, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:37,798] Trial 30 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:38,852] Trial 31 failed with parameters: {'n_estimators': 122, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6212366452188778, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:38,853] Trial 31 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:40,143] Trial 32 failed with parameters: {'n_estimators': 125, 'max_depth': 16, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6031783530986908, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:40,145] Trial 32 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:41,521] Trial 33 failed with parameters: {'n_estimators': 128, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6131148872888305, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:41,523] Trial 33 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:43,150] Trial 34 failed with parameters: {'n_estimators': 129, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6081671826580484, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:43,151] Trial 34 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:44,916] Trial 35 failed with parameters: {'n_estimators': 136, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6222085662347879, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:44,919] Trial 35 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:46,698] Trial 36 failed with parameters: {'n_estimators': 130, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6005119378761747, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:46,699] Trial 36 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:48,464] Trial 37 failed with parameters: {'n_estimators': 129, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6032053653979582, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:48,465] Trial 37 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:50,085] Trial 38 failed with parameters: {'n_estimators': 131, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6092305285369708, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:50,087] Trial 38 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:51,397] Trial 39 failed with parameters: {'n_estimators': 130, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6171419147357923, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-03-03 17:20:51,398] Trial 39 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:52,961] Trial 40 failed with parameters: {'n_estimators': 139, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.7546479441682719, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:52,962] Trial 40 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:54,429] Trial 41 failed with parameters: {'n_estimators': 130, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6142229442763966, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:54,431] Trial 41 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:55,938] Trial 42 failed with parameters: {'n_estimators': 120, 'max_depth': 16, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6103433580184923, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:55,940] Trial 42 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:57,590] Trial 43 failed with parameters: {'n_estimators': 134, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6067135218424703, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:57,591] Trial 43 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:20:58,855] Trial 44 failed with parameters: {'n_estimators': 124, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6145324713630668, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:20:58,856] Trial 44 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:21:00,499] Trial 45 failed with parameters: {'n_estimators': 124, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6011937100648201, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:21:00,501] Trial 45 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:21:02,180] Trial 46 failed with parameters: {'n_estimators': 130, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6038873196896679, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:21:02,182] Trial 46 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:21:03,285] Trial 47 failed with parameters: {'n_estimators': 121, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6065313458494138, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:21:03,286] Trial 47 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:21:04,948] Trial 48 failed with parameters: {'n_estimators': 143, 'max_depth': 16, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6022533614071668, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:21:04,950] Trial 48 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:21:06,898] Trial 49 failed with parameters: {'n_estimators': 132, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6114635026242372, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:21:06,900] Trial 49 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "[W 2025-03-03 17:21:14,574] Trial 1 failed with parameters: {'n_estimators': 125, 'max_depth': 5, 'min_samples_split': 14, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.9589640872299917, 'cost_constraint': 'fnr'} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-03-03 17:21:14,576] Trial 1 failed with value nan.\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n",
      "C:\\Users\\micka\\OneDrive\\Documentos\\[EACH USP] Doutorado\\2. Pesquisa\\6. Experimento\\3. Predictive Process Monitoring\\_PythonProcessMining\\Metrics.py:37: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  di = unprivileged_positive_rate / privileged_positive_rate\n"
     ]
    }
   ],
   "source": [
    "# Uso da função:\n",
    "df_final_high, best_model_high, best_params_high, best_score_high, explanations_high = AIF360.PostCalibratedEOddsRandomFlorestOptuna(X_train_high, y_train_high, X_test_high, y_test_high, df_train_high, df_test_high, protected_attribute, alpha = 0.1, num_trials=50)\n",
    "df_final_medium, best_model_medium, best_params_medium, best_score_medium, explanations_medium = AIF360.PostCalibratedEOddsRandomFlorestOptuna(X_train_medium, y_train_medium, X_test_medium, y_test_medium, df_train_medium, df_test_medium, protected_attribute, alpha = 0.1, num_trials=50)\n",
    "df_final_low, best_model_low, best_params_low, best_score_low, explanations_low = AIF360.PostCalibratedEOddsRandomFlorestOptuna(X_train_low, y_train_low, X_test_low, y_test_low, df_train_low, df_test_low, protected_attribute, alpha = 0.1, num_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0facb2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High - Parâmetros: {'n_estimators': 79, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.6264385822795913, 'cost_constraint': 'weighted'}\n",
      "Medium - Parâmetros: {'n_estimators': 86, 'max_depth': 19, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.9813547868546778, 'cost_constraint': 'weighted'}\n",
      "Low - Parâmetros: {'n_estimators': 194, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced', 'max_samples': 0.8457204689223464, 'cost_constraint': 'weighted'}\n"
     ]
    }
   ],
   "source": [
    "print('High - Parâmetros:', best_params_high)\n",
    "print('Medium - Parâmetros:', best_params_medium)\n",
    "print('Low - Parâmetros:', best_params_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037510d0",
   "metadata": {},
   "source": [
    "Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bdf4b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas do modelo\n",
    "df_metrics_high = Metrics.ModelMetrics(df_final_high, 'case:protected', 'High', 'Postprocessing: Calibrated EqOdds', privileged_group, unprivileged_group)\n",
    "df_metrics_medium = Metrics.ModelMetrics(df_final_medium, 'case:protected', 'Medium', 'Postprocessing: Calibrated EqOdds', privileged_group, unprivileged_group)\n",
    "df_metrics_low = Metrics.ModelMetrics(df_final_low, 'case:protected', 'Low', 'Postprocessing: Calibrated EqOdds', privileged_group, unprivileged_group)\n",
    "\n",
    "df_metrics_PostCalibrated = pd.concat([df_metrics_high, df_metrics_medium, df_metrics_low], ignore_index=True)\n",
    "df_metrics = pd.concat([df_metrics, df_metrics_PostCalibrated], ignore_index=True)\n",
    "df_metrics.to_excel(f'{name_prefix}_metrics.xlsx', index = False)\n",
    "#df_metrics[df_metrics['Metric'].isin(['Accuracy', 'F1-Score', 'Disparate Impact'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200898e4",
   "metadata": {},
   "source": [
    "Explicação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f69d240e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance_High</th>\n",
       "      <th>Importance_Medium</th>\n",
       "      <th>Importance_Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; skipped_examination</th>\n",
       "      <td>-0.293015</td>\n",
       "      <td>-0.235222</td>\n",
       "      <td>-0.354471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verify Borrowers Information -&gt; Submit File to Underwriter</th>\n",
       "      <td>0.052355</td>\n",
       "      <td>-0.000586</td>\n",
       "      <td>0.072900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case:protected</th>\n",
       "      <td>0.035864</td>\n",
       "      <td>0.134198</td>\n",
       "      <td>0.054939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 4 -&gt; Loan Officer 4</th>\n",
       "      <td>-0.032895</td>\n",
       "      <td>-0.026255</td>\n",
       "      <td>-0.008398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Officer 3 -&gt; Loan Officer 4</th>\n",
       "      <td>-0.031480</td>\n",
       "      <td>-0.009668</td>\n",
       "      <td>-0.055862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hotline -&gt; Hotline</th>\n",
       "      <td>-0.000505</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>-0.004081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearsOfEducation_Secondary Education</th>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set Appointment -&gt; Hand In Credit Appliaction</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hand In Credit Appliaction -&gt; Verify Borrowers Information</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Request Appointment -&gt; Set Appointment</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Importance_High  \\\n",
       "Feature                                                               \n",
       "Verify Borrowers Information -> skipped_examina...        -0.293015   \n",
       "Verify Borrowers Information -> Submit File to ...         0.052355   \n",
       "case:protected                                             0.035864   \n",
       "Loan Officer 4 -> Loan Officer 4                          -0.032895   \n",
       "Loan Officer 3 -> Loan Officer 4                          -0.031480   \n",
       "...                                                             ...   \n",
       "Hotline -> Hotline                                        -0.000505   \n",
       "yearsOfEducation_Secondary Education                      -0.000026   \n",
       "Set Appointment -> Hand In Credit Appliaction              0.000000   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...         0.000000   \n",
       "Request Appointment -> Set Appointment                     0.000000   \n",
       "\n",
       "                                                    Importance_Medium  \\\n",
       "Feature                                                                 \n",
       "Verify Borrowers Information -> skipped_examina...          -0.235222   \n",
       "Verify Borrowers Information -> Submit File to ...          -0.000586   \n",
       "case:protected                                               0.134198   \n",
       "Loan Officer 4 -> Loan Officer 4                            -0.026255   \n",
       "Loan Officer 3 -> Loan Officer 4                            -0.009668   \n",
       "...                                                               ...   \n",
       "Hotline -> Hotline                                           0.024048   \n",
       "yearsOfEducation_Secondary Education                        -0.000295   \n",
       "Set Appointment -> Hand In Credit Appliaction                0.000000   \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...           0.000000   \n",
       "Request Appointment -> Set Appointment                       0.000000   \n",
       "\n",
       "                                                    Importance_Low  \n",
       "Feature                                                             \n",
       "Verify Borrowers Information -> skipped_examina...       -0.354471  \n",
       "Verify Borrowers Information -> Submit File to ...        0.072900  \n",
       "case:protected                                            0.054939  \n",
       "Loan Officer 4 -> Loan Officer 4                         -0.008398  \n",
       "Loan Officer 3 -> Loan Officer 4                         -0.055862  \n",
       "...                                                            ...  \n",
       "Hotline -> Hotline                                       -0.004081  \n",
       "yearsOfEducation_Secondary Education                     -0.000537  \n",
       "Set Appointment -> Hand In Credit Appliaction             0.000000  \n",
       "Hand In Credit Appliaction -> Verify Borrowers ...        0.000000  \n",
       "Request Appointment -> Set Appointment                    0.000000  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerar tabelas de importância das variáveis\n",
    "importance_high = get_feature_importance(explanations_high, X_train_high.columns)\n",
    "importance_medium = get_feature_importance(explanations_medium, X_train_medium.columns)\n",
    "importance_low = get_feature_importance(explanations_low, X_train_low.columns)\n",
    "\n",
    "# Criar DataFrames com a importância das variáveis\n",
    "importance_high_df = pd.DataFrame({'Feature': X_train_high.columns, 'Importance_High': importance_high})\n",
    "importance_medium_df = pd.DataFrame({'Feature': X_train_medium.columns, 'Importance_Medium': importance_medium})\n",
    "importance_low_df = pd.DataFrame({'Feature': X_train_low.columns, 'Importance_Low': importance_low})\n",
    "\n",
    "# Realizar o merge dos DataFrames utilizando 'Feature' como chave e preenchendo valores faltantes com NaN\n",
    "importance_df = importance_high_df.merge(importance_medium_df, on='Feature', how='outer').merge(importance_low_df, on='Feature', how='outer')\n",
    "\n",
    "# Ordenar o DataFrame com base no módulo dos valores da coluna 'Importance_High'\n",
    "importance_df['Importance_High_Abs'] = importance_df['Importance_High'].abs()\n",
    "importance_df = importance_df.sort_values(by='Importance_High_Abs', ascending=False)\n",
    "importance_df.drop(columns=['Importance_High_Abs'], inplace=True)\n",
    "\n",
    "# Definir o índice como a coluna 'Feature'\n",
    "importance_df.set_index('Feature', inplace=True)\n",
    "\n",
    "# Salvar o DataFrame como CSV\n",
    "importance_df.to_csv(f'{name_prefix}_post_calibrated_model_lime.csv')\n",
    "\n",
    "# Exibir o DataFrame\n",
    "importance_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
